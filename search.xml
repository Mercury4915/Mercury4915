<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>RocketMQ高级功能+源码分析</title>
      <link href="/2023/06/20/blog20/"/>
      <url>/2023/06/20/blog20/</url>
      
        <content type="html"><![CDATA[<h1 id="1-高级功能"><a href="#1-高级功能" class="headerlink" title="1. 高级功能"></a>1. 高级功能</h1><h2 id="1-1-消息存储"><a href="#1-1-消息存储" class="headerlink" title="1.1 消息存储"></a>1.1 消息存储</h2><p>分布式队列因为有高可靠性的要求，所以数据要进行持久化存储。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F.png"></p><ol><li>消息生成者发送消息</li><li>MQ收到消息，将消息进行持久化，在存储中新增一条记录</li><li>返回ACK给生产者</li><li>MQ push 消息给对应的消费者，然后等待消费者返回ACK</li><li>如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤</li><li>MQ删除消息</li></ol><h3 id="1-1-1-存储介质"><a href="#1-1-1-存储介质" class="headerlink" title="1.1.1 存储介质"></a>1.1.1 存储介质</h3><ul><li>关系型数据库DB</li></ul><p>Apache下开源的另外一款MQ—ActiveMQ（默认采用的KahaDB做消息存储）可选用JDBC的方式来做消息持久化，通过简单的xml配置信息即可实现JDBC消息存储。由于，普通关系型数据库（如Mysql）在单表数据量达到千万级别的情况下，其IO读写性能往往会出现瓶颈。在可靠性方面，该种方案非常依赖DB，如果一旦DB出现故障，则MQ的消息就无法落盘存储会导致线上故障</p><p><img src="/../imgs/blog20/MySQL.png"></p><ul><li><p>文件系统</p><p>目前业界较为常用的几款产品（RocketMQ&#x2F;Kafka&#x2F;RabbitMQ）均采用的是消息刷盘至所部署虚拟机&#x2F;物理机的文件系统来做持久化（刷盘一般可以分为异步刷盘和同步刷盘两种模式）。消息刷盘为消息存储提供了一种高效率、高可靠性和高性能的数据持久化方式。除非部署MQ机器本身或是本地磁盘挂了，否则一般是不会出现无法持久化的故障问题。</p><p><img src="/../imgs/blog20/%E7%A3%81%E7%9B%98.png"></p></li></ul><p>###1.1.2 性能对比</p><p>文件系统&gt;关系型数据库DB</p><h3 id="1-1-3-消息的存储和发送"><a href="#1-1-3-消息的存储和发送" class="headerlink" title="1.1.3 消息的存储和发送"></a>1.1.3 消息的存储和发送</h3><h4 id="1）消息存储"><a href="#1）消息存储" class="headerlink" title="1）消息存储"></a>1）消息存储</h4><p>磁盘如果使用得当，磁盘的速度完全可以匹配上网络 的数据传输速度。目前的高性能磁盘，顺序写速度可以达到600MB&#x2F;s， 超过了一般网卡的传输速度。但是磁盘随机写的速度只有大概100KB&#x2F;s，和顺序写的性能相差6000倍！因为有如此巨大的速度差别，好的消息队列系统会比普通的消息队列系统速度快多个数量级。RocketMQ的消息用顺序写,保证了消息存储的速度。</p><p>####2）消息发送</p><p>Linux操作系统分为【用户态】和【内核态】，文件操作、网络操作需要涉及这两种形态的切换，免不了进行数据复制。</p><p>一台服务器 把本机磁盘文件的内容发送到客户端，一般分为两个步骤：</p><p>1）read；读取本地文件内容； </p><p>2）write；将读取的内容通过网络发送出去。</p><p>这两个看似简单的操作，实际进行了4 次数据复制，分别是：</p><ol><li>从磁盘复制数据到内核态内存；</li><li>从内核态内存复 制到用户态内存；</li><li>然后从用户态 内存复制到网络驱动的内核态内存；</li><li>最后是从网络驱动的内核态内存复 制到网卡中进行传输。</li></ol><p><img src="/../imgs/blog20/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%E5%92%8C%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C.png">通过使用mmap的方式，可以省去向用户态的内存复制，提高速度。这种机制在Java中是通过MappedByteBuffer实现的</p><p>RocketMQ充分利用了上述特性，也就是所谓的“零拷贝”技术，提高消息存盘和网络发送的速度。</p><blockquote><p>这里需要注意的是，采用MappedByteBuffer这种内存映射的方式有几个限制，其中之一是一次只能映射1.5~2G 的文件至用户态的虚拟内存，这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因了</p></blockquote><h3 id="1-1-4-消息存储结构"><a href="#1-1-4-消息存储结构" class="headerlink" title="1.1.4 消息存储结构"></a>1.1.4 消息存储结构</h3><p>RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成 的，消息真正的物理存储文件是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。每 个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png"></p><ul><li>CommitLog：存储消息的元数据</li><li>ConsumerQueue：存储消息在CommitLog的索引</li><li>IndexFile：为了消息查询提供了一种通过key或时间区间来查询消息的方法，这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程</li></ul><h3 id="1-1-5-刷盘机制"><a href="#1-1-5-刷盘机制" class="headerlink" title="1.1.5 刷盘机制"></a>1.1.5 刷盘机制</h3><p>RocketMQ的消息是存储到磁盘上的，这样既能保证断电后恢复， 又可以让存储的消息量超出内存的限制。RocketMQ为了提高性能，会尽可能地保证磁盘的顺序写。消息在通过Producer写入RocketMQ的时 候，有两种写磁盘方式，分布式同步刷盘和异步刷盘。</p><p><img src="/../imgs/blog20/%E5%90%8C%E6%AD%A5%E5%88%B7%E7%9B%98%E5%92%8C%E5%BC%82%E6%AD%A5%E5%88%B7%E7%9B%98.png"></p><h4 id="1）同步刷盘"><a href="#1）同步刷盘" class="headerlink" title="1）同步刷盘"></a>1）同步刷盘</h4><p>在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写 成功的状态。</p><h4 id="2）异步刷盘"><a href="#2）异步刷盘" class="headerlink" title="2）异步刷盘"></a>2）异步刷盘</h4><p>在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。</p><p>####3）配置</p><p><strong>同步刷盘还是异步刷盘，都是通过Broker配置文件里的flushDiskType 参数设置的，这个参数被配置成SYNC_FLUSH、ASYNC_FLUSH中的 一个。</strong></p><h2 id="1-2-高可用性机制"><a href="#1-2-高可用性机制" class="headerlink" title="1.2 高可用性机制"></a>1.2 高可用性机制</h2><p><img src="/../imgs/blog20/RocketMQ%E8%A7%92%E8%89%B2.jpg"></p><p>RocketMQ分布式集群是通过Master和Slave的配合达到高可用性的。</p><p>Master和Slave的区别：在Broker的配置文件中，参数 brokerId的值为0表明这个Broker是Master，大于0表明这个Broker是 Slave，同时brokerRole参数也会说明这个Broker是Master还是Slave。</p><p>Master角色的Broker支持读和写，Slave角色的Broker仅支持读，也就是 Producer只能和Master角色的Broker连接写入消息；Consumer可以连接 Master角色的Broker，也可以连接Slave角色的Broker来读取消息。</p><h3 id="1-2-1-消息消费高可用"><a href="#1-2-1-消息消费高可用" class="headerlink" title="1.2.1 消息消费高可用"></a>1.2.1 消息消费高可用</h3><p>在Consumer的配置文件中，并不需要设置是从Master读还是从Slave 读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave 读。有了自动切换Consumer这种机制，当一个Master角色的机器出现故障后，Consumer仍然可以从Slave读取消息，不影响Consumer程序。这就达到了消费端的高可用性。</p><h3 id="1-2-2-消息发送高可用"><a href="#1-2-2-消息发送高可用" class="headerlink" title="1.2.2 消息发送高可用"></a>1.2.2 消息发送高可用</h3><p>在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上（相同Broker名称，不同 brokerId的机器组成一个Broker组），这样当一个Broker组的Master不可 用后，其他组的Master仍然可用，Producer仍然可以发送消息。 RocketMQ目前还不支持把Slave自动转成Master，如果机器资源不足， 需要把Slave转成Master，则要手动停止Slave角色的Broker，更改配置文 件，用新的配置文件启动Broker。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%BE%E8%AE%A1.jpg"></p><h3 id="1-2-3-消息主从复制"><a href="#1-2-3-消息主从复制" class="headerlink" title="1.2.3 消息主从复制"></a>1.2.3 消息主从复制</h3><p>如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式。</p><p>####1）同步复制</p><p>同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态；</p><p>在同步复制方式下，如果Master出故障， Slave上有全部的备份数据，容易恢复，但是同步复制会增大数据写入 延迟，降低系统吞吐量。</p><p>####2）异步复制 </p><p>异步复制方式是只要Master写成功 即可反馈给客户端写成功状态。</p><p>在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因为没有被写 入Slave，有可能会丢失；</p><p>####3）配置</p><p>同步复制和异步复制是通过Broker配置文件里的brokerRole参数进行设置的，这个参数可以被设置成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。</p><p>####4）总结</p><p><img src="/../imgs/blog20/%E5%A4%8D%E5%88%B6%E5%88%B7%E7%9B%98.png"></p><p>实际应用中要结合业务场景，合理设置刷盘方式和主从复制方式， 尤其是SYNC_FLUSH方式，由于频繁地触发磁盘写动作，会明显降低 性能。通常情况下，应该把Master和Save配置成ASYNC_FLUSH的刷盘 方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台 机器出故障，仍然能保证数据不丢，是个不错的选择。</p><h2 id="1-3-负载均衡"><a href="#1-3-负载均衡" class="headerlink" title="1.3 负载均衡"></a>1.3 负载均衡</h2><h3 id="1-3-1-Producer负载均衡"><a href="#1-3-1-Producer负载均衡" class="headerlink" title="1.3.1 Producer负载均衡"></a>1.3.1 Producer负载均衡</h3><p>Producer端，每个实例在发消息的时候，默认会轮询所有的message queue发送，以达到让消息平均落在不同的queue上。而由于queue可以散落在不同的broker，所以消息就发送到不同的broker下，如下图：</p><p><img src="/../imgs/blog20/producer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png"></p><p>图中箭头线条上的标号代表顺序，发布方会把第一条消息发送至 Queue 0，然后第二条消息发送至 Queue 1，以此类推。</p><h3 id="1-3-2-Consumer负载均衡"><a href="#1-3-2-Consumer负载均衡" class="headerlink" title="1.3.2 Consumer负载均衡"></a>1.3.2 Consumer负载均衡</h3><h4 id="1）集群模式"><a href="#1）集群模式" class="headerlink" title="1）集群模式"></a>1）集群模式</h4><p>在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。RocketMQ采用主动拉取的方式拉取并消费消息，在拉取的时候需要明确指定拉取哪一条message queue。</p><p>而每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时候会按照queue的数量和实例的数量平均分配queue给每个实例。</p><p>默认的分配算法是AllocateMessageQueueAveragely，如下图：</p><p><img src="/../imgs/blog20/consumer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png"></p><p>还有另外一种平均的算法是AllocateMessageQueueAveragelyByCircle，也是平均分摊每一条queue，只是以环状轮流分queue的形式，如下图：</p><p><img src="/../imgs/blog20/consumer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A12.png"></p><p>需要注意的是，集群模式下，queue都是只允许分配只一个实例，这是由于如果多个实例同时消费一个queue的消息，由于拉取哪些消息是consumer主动控制的，那样会导致同一个消息在不同的实例下被消费多次，所以算法上都是一个queue只分给一个consumer实例，一个consumer实例可以允许同时分到不同的queue。</p><p>通过增加consumer实例去分摊queue的消费，可以起到水平扩展的消费能力的作用。而有实例下线的时候，会重新触发负载均衡，这时候原来分配到的queue将分配到其他实例上继续消费。</p><p>但是如果consumer实例的数量比message queue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。</p><p>####2）广播模式</p><p>由于广播模式下要求一条消息需要投递到一个消费组下面所有的消费者实例，所以也就没有消息被分摊消费的说法。</p><p>在实现上，其中一个不同就是在consumer分配queue的时候，所有consumer都分到所有的queue。</p><p><img src="/../imgs/blog20/consumer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A13.png"></p><h2 id="1-4-消息重试"><a href="#1-4-消息重试" class="headerlink" title="1.4 消息重试"></a>1.4 消息重试</h2><h3 id="1-4-1-顺序消息的重试"><a href="#1-4-1-顺序消息的重试" class="headerlink" title="1.4.1 顺序消息的重试"></a>1.4.1 顺序消息的重试</h3><p>对于顺序消息，当消费者消费消息失败后，消息队列 RocketMQ 会自动不断进行消息重试（每次间隔时间为 1 秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。</p><h3 id="1-4-2-无序消息的重试"><a href="#1-4-2-无序消息的重试" class="headerlink" title="1.4.2 无序消息的重试"></a>1.4.2 无序消息的重试</h3><p>对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回状态达到消息重试的结果。</p><p>无序消息的重试只针对集群消费方式生效；广播方式不提供失败重试特性，即消费失败后，失败消息不再重试，继续消费新的消息。</p><h4 id="1）重试次数"><a href="#1）重试次数" class="headerlink" title="1）重试次数"></a>1）重试次数</h4><p>消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：</p><table><thead><tr><th align="center">第几次重试</th><th align="center">与上次重试的间隔时间</th><th align="center">第几次重试</th><th align="center">与上次重试的间隔时间</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">10 秒</td><td align="center">9</td><td align="center">7 分钟</td></tr><tr><td align="center">2</td><td align="center">30 秒</td><td align="center">10</td><td align="center">8 分钟</td></tr><tr><td align="center">3</td><td align="center">1 分钟</td><td align="center">11</td><td align="center">9 分钟</td></tr><tr><td align="center">4</td><td align="center">2 分钟</td><td align="center">12</td><td align="center">10 分钟</td></tr><tr><td align="center">5</td><td align="center">3 分钟</td><td align="center">13</td><td align="center">20 分钟</td></tr><tr><td align="center">6</td><td align="center">4 分钟</td><td align="center">14</td><td align="center">30 分钟</td></tr><tr><td align="center">7</td><td align="center">5 分钟</td><td align="center">15</td><td align="center">1 小时</td></tr><tr><td align="center">8</td><td align="center">6 分钟</td><td align="center">16</td><td align="center">2 小时</td></tr></tbody></table><p>如果消息重试 16 次后仍然失败，消息将不再投递。如果严格按照上述重试时间间隔计算，某条消息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围消息将不再重试投递。</p><p><strong>注意：</strong> 一条消息无论重试多少次，这些重试消息的 Message ID 不会改变。</p><h4 id="2）配置方式"><a href="#2）配置方式" class="headerlink" title="2）配置方式"></a>2）配置方式</h4><p><strong>消费失败后，重试配置方式</strong></p><p>集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置（三种方式任选一种）：</p><ul><li>返回 Action.ReconsumeLater （推荐）</li><li>返回 Null</li><li>抛出异常</li></ul><pre><code class="java">public class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        //处理消息        doConsumeMessage(message);        //方式1：返回 Action.ReconsumeLater，消息将重试        return Action.ReconsumeLater;        //方式2：返回 null，消息将重试        return null;        //方式3：直接抛出异常， 消息将重试        throw new RuntimeException(&quot;Consumer Message exceotion&quot;);    &#125;&#125;</code></pre><p><strong>消费失败后，不重试配置方式</strong></p><p>集群消费方式下，消息失败后期望消息不重试，需要捕获消费逻辑中可能抛出的异常，最终返回 Action.CommitMessage，此后这条消息将不会再重试。</p><pre><code class="java">public class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        try &#123;            doConsumeMessage(message);        &#125; catch (Throwable e) &#123;            //捕获消费逻辑中的所有异常，并返回 Action.CommitMessage;            return Action.CommitMessage;        &#125;        //消息处理正常，直接返回 Action.CommitMessage;        return Action.CommitMessage;    &#125;&#125;</code></pre><p><strong>自定义消息最大重试次数</strong></p><p>消息队列 RocketMQ 允许 Consumer 启动的时候设置最大重试次数，重试时间间隔将按照如下策略：</p><ul><li>最大重试次数小于等于 16 次，则重试时间间隔同上表描述。</li><li>最大重试次数大于 16 次，超过 16 次的重试时间间隔均为每次 2 小时。</li></ul><pre><code class="java">Properties properties = new Properties();//配置对应 Group ID 的最大消息重试次数为 20 次properties.put(PropertyKeyConst.MaxReconsumeTimes,&quot;20&quot;);Consumer consumer =ONSFactory.createConsumer(properties);</code></pre><blockquote><p>注意：</p></blockquote><ul><li>消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。</li><li>如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了 MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。</li><li>配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置</li></ul><p><strong>获取消息重试次数</strong></p><p>消费者收到消息后，可按照如下方式获取消息的重试次数：</p><pre><code class="java">public class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        //获取消息的重试次数        System.out.println(message.getReconsumeTimes());        return Action.CommitMessage;    &#125;&#125;</code></pre><h2 id="1-5-死信队列"><a href="#1-5-死信队列" class="headerlink" title="1.5 死信队列"></a>1.5 死信队列</h2><p>当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。</p><p>在消息队列 RocketMQ 中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。</p><h3 id="1-5-1-死信特性"><a href="#1-5-1-死信特性" class="headerlink" title="1.5.1 死信特性"></a>1.5.1 死信特性</h3><p>死信消息具有以下特性</p><ul><li>不会再被消费者正常消费。</li><li>有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。</li></ul><p>死信队列具有以下特性：</p><ul><li>一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。</li><li>如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。</li><li>一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。</li></ul><h3 id="1-5-2-查看死信信息"><a href="#1-5-2-查看死信信息" class="headerlink" title="1.5.2 查看死信信息"></a>1.5.2 查看死信信息</h3><ol><li>在控制台查询出现死信队列的主题信息</li></ol><p><img src="/../imgs/blog20/%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%E4%B8%BB%E9%A2%98.png"></p><ol start="2"><li>在消息界面根据主题查询死信消息</li></ol><p><img src="/../imgs/blog20/%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%E4%B8%BB%E9%A2%982.png"></p><ol start="3"><li>选择重新发送消息</li></ol><p>一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，通常需要您对其进行特殊处理。排查可疑因素并解决问题后，可以在消息队列 RocketMQ 控制台重新发送该消息，让消费者重新消费一次。</p><h2 id="1-6-消费幂等"><a href="#1-6-消费幂等" class="headerlink" title="1.6 消费幂等"></a>1.6 消费幂等</h2><p>消息队列 RocketMQ 消费者在接收到消息以后，有必要根据业务上的唯一 Key 对消息做幂等处理的必要性。</p><h3 id="1-6-1-消费幂等的必要性"><a href="#1-6-1-消费幂等的必要性" class="headerlink" title="1.6.1 消费幂等的必要性"></a>1.6.1 消费幂等的必要性</h3><p>在互联网应用中，尤其在网络不稳定的情况下，消息队列 RocketMQ 的消息有可能会出现重复，这个重复简单可以概括为以下情况：</p><ul><li><p>发送时消息重复</p><p>当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。</p></li><li><p>投递时消息重复</p><p>消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。 为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。</p></li><li><p>负载均衡时消息重复（包括但不限于网络抖动、Broker 重启以及订阅方应用重启）</p><p>当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。</p></li></ul><h3 id="1-6-2-处理方式"><a href="#1-6-2-处理方式" class="headerlink" title="1.6.2 处理方式"></a>1.6.2 处理方式</h3><p>因为 Message ID 有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以 Message ID 作为处理依据。 最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息 Key 进行设置：</p><pre><code class="java">Message message = new Message();message.setKey(&quot;ORDERID_100&quot;);SendResult sendResult = producer.send(message);</code></pre><p>订阅方收到消息时可以根据消息的 Key 进行幂等处理：</p><pre><code class="java">consumer.subscribe(&quot;ons_test&quot;, &quot;*&quot;, new MessageListener() &#123;    public Action consume(Message message, ConsumeContext context) &#123;        String key = message.getKey()        // 根据业务唯一标识的 key 做幂等处理    &#125;&#125;);</code></pre><h1 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2. 源码分析"></a>2. 源码分析</h1><h2 id="2-1-环境搭建"><a href="#2-1-环境搭建" class="headerlink" title="2.1 环境搭建"></a>2.1 环境搭建</h2><p>依赖工具</p><ul><li>JDK ：1.8+</li><li>Maven</li><li>IntelliJ IDEA</li></ul><h3 id="2-1-1-源码拉取"><a href="#2-1-1-源码拉取" class="headerlink" title="2.1.1 源码拉取"></a>2.1.1 源码拉取</h3><p>从官方仓库 <a href="https://github.com/apache/rocketmq">https://github.com/apache/rocketmq</a> <code>clone</code>或者<code>download</code>源码。</p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%811.png"></p><p><strong>源码目录结构：</strong></p><ul><li><p>broker: broker 模块（broke 启动进程） </p></li><li><p>client ：消息客户端，包含消息生产者、消息消费者相关类 </p></li><li><p>common ：公共包 </p></li><li><p>dev ：开发者信息（非源代码） </p></li><li><p>distribution ：部署实例文件夹（非源代码） </p></li><li><p>example: RocketMQ 例代码 </p></li><li><p>filter ：消息过滤相关基础类</p></li><li><p>filtersrv：消息过滤服务器实现相关类（Filter启动进程）</p></li><li><p>logappender：日志实现相关类</p></li><li><p>namesrv：NameServer实现相关类（NameServer启动进程）</p></li><li><p>openmessageing：消息开放标准</p></li><li><p>remoting：远程通信模块，给予Netty</p></li><li><p>srcutil：服务工具类</p></li><li><p>store：消息存储实现相关类</p></li><li><p>style：checkstyle相关实现</p></li><li><p>test：测试相关类</p></li><li><p>tools：工具类，监控命令相关实现类</p></li></ul><p>###2.1.2 导入IDEA</p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%812.png"></p><p><strong>执行安装</strong></p><pre><code class="sh">clean install -Dmaven.test.skip=true</code></pre><h3 id="2-1-3-调试"><a href="#2-1-3-调试" class="headerlink" title="2.1.3 调试"></a>2.1.3 调试</h3><p>创建<code>conf</code>配置文件夹,从<code>distribution</code>拷贝<code>broker.conf</code>和<code>logback_broker.xml</code>和<code>logback_namesrv.xml</code></p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%816.png"></p><h4 id="1）启动NameServer"><a href="#1）启动NameServer" class="headerlink" title="1）启动NameServer"></a>1）启动NameServer</h4><ul><li>展开namesrv模块，右键NamesrvStartup.java</li></ul><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%813.png"></p><ul><li>配置<strong>ROCKETMQ_HOME</strong></li></ul><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%814.png"></p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%815.png"></p><ul><li><p>重新启动</p><p>控制台打印结果</p></li></ul><pre><code class="sh">The Name Server boot success. serializeType=JSON</code></pre><h4 id="2）启动Broker"><a href="#2）启动Broker" class="headerlink" title="2）启动Broker"></a>2）启动Broker</h4><ul><li><code>broker.conf</code>配置文件内容</li></ul><pre><code class="properties">brokerClusterName = DefaultClusterbrokerName = broker-abrokerId = 0# namesrvAddr地址namesrvAddr=127.0.0.1:9876deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSHautoCreateTopicEnable=true# 存储路径storePathRootDir=E:\\RocketMQ\\data\\rocketmq\\dataDir# commitLog路径storePathCommitLog=E:\\RocketMQ\\data\\rocketmq\\dataDir\\commitlog# 消息队列存储路径storePathConsumeQueue=E:\\RocketMQ\\data\\rocketmq\\dataDir\\consumequeue# 消息索引存储路径storePathIndex=E:\\RocketMQ\\data\\rocketmq\\dataDir\\index# checkpoint文件路径storeCheckpoint=E:\\RocketMQ\\data\\rocketmq\\dataDir\\checkpoint# abort文件存储路径abortFile=E:\\RocketMQ\\data\\rocketmq\\dataDir\\abort</code></pre><ul><li>创建数据文件夹<code>dataDir</code></li><li>启动<code>BrokerStartup</code>,配置<code>broker.conf</code>和<code>ROCKETMQ_HOME</code></li></ul><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%817.png"></p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%818.png"></p><p>####3）发送消息</p><ul><li>进入example模块的<code>org.apache.rocketmq.example.quickstart</code></li><li>指定Namesrv地址</li></ul><pre><code class="java">DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</code></pre><ul><li>运行<code>main</code>方法，发送消息</li></ul><h4 id="4）消费消息"><a href="#4）消费消息" class="headerlink" title="4）消费消息"></a>4）消费消息</h4><ul><li>进入example模块的<code>org.apache.rocketmq.example.quickstart</code></li><li>指定Namesrv地址</li></ul><pre><code class="java">DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_4&quot;);consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</code></pre><ul><li>运行<code>main</code>方法，消费消息</li></ul><h2 id="2-2-NameServer"><a href="#2-2-NameServer" class="headerlink" title="2.2 NameServer"></a>2.2 NameServer</h2><h3 id="2-2-1-架构设计"><a href="#2-2-1-架构设计" class="headerlink" title="2.2.1 架构设计"></a>2.2.1 架构设计</h3><p>消息中间件的设计思路一般是基于主题订阅发布的机制，消息生产者（Producer）发送某一个主题到消息服务器，消息服务器负责将消息持久化存储，消息消费者（Consumer）订阅该兴趣的主题，消息服务器根据订阅信息（路由信息）将消息推送到消费者（Push模式）或者消费者主动向消息服务器拉去（Pull模式），从而实现消息生产者与消息消费者解耦。为了避免消息服务器的单点故障导致的整个系统瘫痪，通常会部署多台消息服务器共同承担消息的存储。那消息生产者如何知道消息要发送到哪台消息服务器呢？如果某一台消息服务器宕机了，那么消息生产者如何在不重启服务情况下感知呢？</p><p>NameServer就是为了解决以上问题设计的。</p><p><img src="/../imgs/blog20/RocketMQ%E8%A7%92%E8%89%B2.jpg"></p><p>Broker消息服务器在启动的时向所有NameServer注册，消息生产者（Producer）在发送消息时之前先从NameServer获取Broker服务器地址列表，然后根据负载均衡算法从列表中选择一台服务器进行发送。NameServer与每台Broker保持长连接，并间隔30S检测Broker是否存活，如果检测到Broker宕机，则从路由注册表中删除。但是路由变化不会马上通知消息生产者。这样设计的目的是为了降低NameServer实现的复杂度，在消息发送端提供容错机制保证消息发送的可用性。</p><p>NameServer本身的高可用是通过部署多台NameServer来实现，但彼此之间不通讯，也就是NameServer服务器之间在某一个时刻的数据并不完全相同，但这对消息发送并不会造成任何影响，这也是NameServer设计的一个亮点，总之，RocketMQ设计追求简单高效。</p><h3 id="2-2-2-启动流程"><a href="#2-2-2-启动流程" class="headerlink" title="2.2.2 启动流程"></a>2.2.2 启动流程</h3><p><img src="/../imgs/blog20/NameServer%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.png"></p><p>启动类：<code>org.apache.rocketmq.namesrv.NamesrvStartup</code></p><p>####步骤一</p><p>解析配置文件，填充NameServerConfig、NettyServerConfig属性值，并创建NamesrvController</p><p><em><strong>代码：NamesrvController#createNamesrvController</strong></em></p><pre><code class="java">//创建NamesrvConfigfinal NamesrvConfig namesrvConfig = new NamesrvConfig();//创建NettyServerConfigfinal NettyServerConfig nettyServerConfig = new NettyServerConfig();//设置启动端口号nettyServerConfig.setListenPort(9876);//解析启动-c参数if (commandLine.hasOption(&#39;c&#39;)) &#123;    String file = commandLine.getOptionValue(&#39;c&#39;);    if (file != null) &#123;        InputStream in = new BufferedInputStream(new FileInputStream(file));        properties = new Properties();        properties.load(in);        MixAll.properties2Object(properties, namesrvConfig);        MixAll.properties2Object(properties, nettyServerConfig);        namesrvConfig.setConfigStorePath(file);        System.out.printf(&quot;load config properties file OK, %s%n&quot;, file);        in.close();    &#125;&#125;//解析启动-p参数if (commandLine.hasOption(&#39;p&#39;)) &#123;    InternalLogger console = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_CONSOLE_NAME);    MixAll.printObjectProperties(console, namesrvConfig);    MixAll.printObjectProperties(console, nettyServerConfig);    System.exit(0);&#125;//将启动参数填充到namesrvConfig,nettyServerConfigMixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig);//创建NameServerControllerfinal NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig);</code></pre><p><u><strong>NamesrvConfig属性</strong></u></p><pre><code class="java">private String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV));private String kvConfigPath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;kvConfig.json&quot;;private String configStorePath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;namesrv.properties&quot;;private String productEnvName = &quot;center&quot;;private boolean clusterTest = false;private boolean orderMessageEnable = false;</code></pre><p><strong>rocketmqHome：</strong>rocketmq主目录</p><p><strong>kvConfig：</strong>NameServer存储KV配置属性的持久化路径</p><p><strong>configStorePath：</strong>nameServer默认配置文件路径</p><p><strong>orderMessageEnable：</strong>是否支持顺序消息</p><p><u><strong>NettyServerConfig属性</strong></u></p><pre><code class="java">private int listenPort = 8888;private int serverWorkerThreads = 8;private int serverCallbackExecutorThreads = 0;private int serverSelectorThreads = 3;private int serverOnewaySemaphoreValue = 256;private int serverAsyncSemaphoreValue = 64;private int serverChannelMaxIdleTimeSeconds = 120;private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize;private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize;private boolean serverPooledByteBufAllocatorEnable = true;private boolean useEpollNativeSelector = false;</code></pre><p><strong>listenPort：</strong>NameServer监听端口，该值默认会被初始化为9876<br><strong>serverWorkerThreads：</strong>Netty业务线程池线程个数<br><strong>serverCallbackExecutorThreads：</strong>Netty public任务线程池线程个数，Netty网络设计，根据业务类型会创建不同的线程池，比如处理消息发送、消息消费、心跳检测等。如果该业务类型未注册线程池，则由public线程池执行。<br><strong>serverSelectorThreads：</strong>IO线程池个数，主要是NameServer、Broker端解析请求、返回相应的线程个数，这类线程主要是处理网路请求的，解析请求包，然后转发到各个业务线程池完成具体的操作，然后将结果返回给调用方;<br><strong>serverOnewaySemaphoreValue：</strong>send oneway消息请求并发读（Broker端参数）;<br><strong>serverAsyncSemaphoreValue：</strong>异步消息发送最大并发度;<br><strong>serverChannelMaxIdleTimeSeconds ：</strong>网络连接最大的空闲时间，默认120s。<br><strong>serverSocketSndBufSize：</strong>网络socket发送缓冲区大小。<br><strong>serverSocketRcvBufSize：</strong> 网络接收端缓存区大小。<br><strong>serverPooledByteBufAllocatorEnable：</strong>ByteBuffer是否开启缓存;<br><strong>useEpollNativeSelector：</strong>是否启用Epoll IO模型。</p><h4 id="步骤二"><a href="#步骤二" class="headerlink" title="步骤二"></a>步骤二</h4><p>根据启动属性创建NamesrvController实例，并初始化该实例。NameServerController实例为NameServer核心控制器</p><p><em><strong>代码：NamesrvController#initialize</strong></em></p><pre><code class="java">public boolean initialize() &#123;    //加载KV配置    this.kvConfigManager.load();    //创建NettyServer网络处理对象    this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService);    //开启定时任务:每隔10s扫描一次Broker,移除不活跃的Broker    this.remotingExecutor =        Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(&quot;RemotingExecutorThread_&quot;));    this.registerProcessor();    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            NamesrvController.this.routeInfoManager.scanNotActiveBroker();        &#125;    &#125;, 5, 10, TimeUnit.SECONDS);    //开启定时任务:每隔10min打印一次KV配置    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            NamesrvController.this.kvConfigManager.printAllPeriodically();        &#125;    &#125;, 1, 10, TimeUnit.MINUTES);    return true;&#125;</code></pre><h4 id="步骤三"><a href="#步骤三" class="headerlink" title="步骤三"></a>步骤三</h4><p>在JVM进程关闭之前，先将线程池关闭，及时释放资源</p><p><em><strong>代码：NamesrvStartup#start</strong></em></p><pre><code class="java">//注册JVM钩子函数代码Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() &#123;    @Override    public Void call() throws Exception &#123;        //释放资源        controller.shutdown();        return null;    &#125;&#125;));</code></pre><h3 id="2-2-3-路由管理"><a href="#2-2-3-路由管理" class="headerlink" title="2.2.3 路由管理"></a>2.2.3 路由管理</h3><p>NameServer的主要作用是为消息的生产者和消息消费者提供关于主题Topic的路由信息，那么NameServer需要存储路由的基础信息，还要管理Broker节点，包括路由注册、路由删除等。</p><h4 id="2-2-3-1-路由元信息"><a href="#2-2-3-1-路由元信息" class="headerlink" title="2.2.3.1 路由元信息"></a>2.2.3.1 路由元信息</h4><p><em><strong>代码：RouteInfoManager</strong></em></p><pre><code class="java">private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;</code></pre><p><img src="/../imgs/blog20/%E8%B7%AF%E7%94%B1%E5%AE%9E%E4%BD%93%E5%9B%BE.png"></p><p><strong>topicQueueTable：</strong>Topic消息队列路由信息，消息发送时根据路由表进行负载均衡</p><p><strong>brokerAddrTable：</strong>Broker基础信息，包括brokerName、所属集群名称、主备Broker地址</p><p><strong>clusterAddrTable：</strong>Broker集群信息，存储集群中所有Broker名称</p><p><strong>brokerLiveTable：</strong>Broker状态信息，NameServer每次收到心跳包是会替换该信息</p><p><strong>filterServerTable：</strong>Broker上的FilterServer列表，用于类模式消息过滤。</p><blockquote><p>RocketMQ基于定于发布机制，一个Topic拥有多个消息队列，一个Broker为每一个主题创建4个读队列和4个写队列。多个Broker组成一个集群，集群由相同的多台Broker组成Master-Slave架构，brokerId为0代表Master，大于0为Slave。BrokerLiveInfo中的lastUpdateTimestamp存储上次收到Broker心跳包的时间。</p></blockquote><p><img src="/../imgs/blog20/%E5%AE%9E%E4%BD%93%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%BE%8B.png"></p><p><img src="/../imgs/blog20/%E5%AE%9E%E4%BD%93%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%BE%8B2.png"></p><h4 id="2-2-3-2-路由注册"><a href="#2-2-3-2-路由注册" class="headerlink" title="2.2.3.2 路由注册"></a>2.2.3.2 路由注册</h4><p>#####1）发送心跳包</p><p><img src="/../imgs/blog20/%E8%B7%AF%E7%94%B1%E6%B3%A8%E5%86%8C.png"></p><p>RocketMQ路由注册是通过Broker与NameServer的心跳功能实现的。Broker启动时向集群中所有的NameServer发送心跳信息，每隔30s向集群中所有NameServer发送心跳包，NameServer收到心跳包时会更新brokerLiveTable缓存中BrokerLiveInfo的lastUpdataTimeStamp信息，然后NameServer每隔10s扫描brokerLiveTable，如果连续120S没有收到心跳包，NameServer将移除Broker的路由信息同时关闭Socket连接。</p><p><em><strong>代码：BrokerController#start</strong></em></p><pre><code class="java">//注册Broker信息this.registerBrokerAll(true, false, true);//每隔30s上报Broker信息到NameServerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;    @Override    public void run() &#123;        try &#123;            BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister());        &#125; catch (Throwable e) &#123;            log.error(&quot;registerBrokerAll Exception&quot;, e);        &#125;    &#125;&#125;, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)),                                                   TimeUnit.MILLISECONDS);</code></pre><p><em><strong>代码：BrokerOuterAPI#registerBrokerAll</strong></em></p><pre><code class="java">//获得nameServer地址信息List&lt;String&gt; nameServerAddressList = this.remotingClient.getNameServerAddressList();//遍历所有nameserver列表if (nameServerAddressList != null &amp;&amp; nameServerAddressList.size() &gt; 0) &#123;    //封装请求头    final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader();    requestHeader.setBrokerAddr(brokerAddr);    requestHeader.setBrokerId(brokerId);    requestHeader.setBrokerName(brokerName);    requestHeader.setClusterName(clusterName);    requestHeader.setHaServerAddr(haServerAddr);    requestHeader.setCompressed(compressed);    //封装请求体    RegisterBrokerBody requestBody = new RegisterBrokerBody();    requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper);    requestBody.setFilterServerList(filterServerList);    final byte[] body = requestBody.encode(compressed);    final int bodyCrc32 = UtilAll.crc32(body);    requestHeader.setBodyCrc32(bodyCrc32);    final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size());    for (final String namesrvAddr : nameServerAddressList) &#123;        brokerOuterExecutor.execute(new Runnable() &#123;            @Override            public void run() &#123;                try &#123;                    //分别向NameServer注册                    RegisterBrokerResult result = registerBroker(namesrvAddr,oneway, timeoutMills,requestHeader,body);                    if (result != null) &#123;                        registerBrokerResultList.add(result);                    &#125;                    log.info(&quot;register broker[&#123;&#125;]to name server &#123;&#125; OK&quot;, brokerId, namesrvAddr);                &#125; catch (Exception e) &#123;                    log.warn(&quot;registerBroker Exception, &#123;&#125;&quot;, namesrvAddr, e);                &#125; finally &#123;                    countDownLatch.countDown();                &#125;            &#125;        &#125;);    &#125;    try &#123;        countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS);    &#125; catch (InterruptedException e) &#123;    &#125;&#125;</code></pre><p><em><strong>代码：BrokerOutAPI#registerBroker</strong></em></p><pre><code class="java">if (oneway) &#123;    try &#123;        this.remotingClient.invokeOneway(namesrvAddr, request, timeoutMills);    &#125; catch (RemotingTooMuchRequestException e) &#123;        // Ignore    &#125;    return null;&#125;RemotingCommand response = this.remotingClient.invokeSync(namesrvAddr, request, timeoutMills);</code></pre><h5 id="2）处理心跳包"><a href="#2）处理心跳包" class="headerlink" title="2）处理心跳包"></a>2）处理心跳包</h5><p><img src="/../imgs/blog20/NameServer%E5%A4%84%E7%90%86%E8%B7%AF%E7%94%B1%E6%B3%A8%E5%86%8C.png"></p><p><code>org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor</code>网路处理类解析请求类型，如果请求类型是为<em><strong>REGISTER_BROKER</strong></em>，则将请求转发到<code>RouteInfoManager#regiesterBroker</code></p><p><em><strong>代码：DefaultRequestProcessor#processRequest</strong></em></p><pre><code class="java">//判断是注册Broker信息case RequestCode.REGISTER_BROKER:    Version brokerVersion = MQVersion.value2Version(request.getVersion());    if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) &#123;        return this.registerBrokerWithFilterServer(ctx, request);    &#125; else &#123;        //注册Broker信息        return this.registerBroker(ctx, request);    &#125;</code></pre><p><em><strong>代码：DefaultRequestProcessor#registerBroker</strong></em></p><pre><code class="java">RegisterBrokerResult result = this.namesrvController.getRouteInfoManager().registerBroker(    requestHeader.getClusterName(),    requestHeader.getBrokerAddr(),    requestHeader.getBrokerName(),    requestHeader.getBrokerId(),    requestHeader.getHaServerAddr(),    topicConfigWrapper,    null,    ctx.channel());</code></pre><p><em><strong>代码：RouteInfoManager#registerBroker</strong></em></p><p>维护路由信息</p><pre><code class="java">//加锁this.lock.writeLock().lockInterruptibly();//维护clusterAddrTableSet&lt;String&gt; brokerNames = this.clusterAddrTable.get(clusterName);if (null == brokerNames) &#123;    brokerNames = new HashSet&lt;String&gt;();    this.clusterAddrTable.put(clusterName, brokerNames);&#125;brokerNames.add(brokerName);</code></pre><pre><code class="java">//维护brokerAddrTableBrokerData brokerData = this.brokerAddrTable.get(brokerName);//第一次注册,则创建brokerDataif (null == brokerData) &#123;    registerFirst = true;    brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;());    this.brokerAddrTable.put(brokerName, brokerData);&#125;//非第一次注册,更新BrokerMap&lt;Long, String&gt; brokerAddrsMap = brokerData.getBrokerAddrs();Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerAddrsMap.entrySet().iterator();while (it.hasNext()) &#123;    Entry&lt;Long, String&gt; item = it.next();    if (null != brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId != item.getKey()) &#123;        it.remove();    &#125;&#125;String oldAddr = brokerData.getBrokerAddrs().put(brokerId, brokerAddr);registerFirst = registerFirst || (null == oldAddr);</code></pre><pre><code class="java">//维护topicQueueTableif (null != topicConfigWrapper &amp;&amp; MixAll.MASTER_ID == brokerId) &#123;    if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion()) ||         registerFirst) &#123;        ConcurrentMap&lt;String, TopicConfig&gt; tcTable = topicConfigWrapper.getTopicConfigTable();        if (tcTable != null) &#123;            for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) &#123;                this.createAndUpdateQueueData(brokerName, entry.getValue());            &#125;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：RouteInfoManager#createAndUpdateQueueData</strong></em></p><pre><code class="java">private void createAndUpdateQueueData(final String brokerName, final TopicConfig topicConfig) &#123;    //创建QueueData    QueueData queueData = new QueueData();    queueData.setBrokerName(brokerName);    queueData.setWriteQueueNums(topicConfig.getWriteQueueNums());    queueData.setReadQueueNums(topicConfig.getReadQueueNums());    queueData.setPerm(topicConfig.getPerm());    queueData.setTopicSynFlag(topicConfig.getTopicSysFlag());    //获得topicQueueTable中队列集合    List&lt;QueueData&gt; queueDataList = this.topicQueueTable.get(topicConfig.getTopicName());    //topicQueueTable为空,则直接添加queueData到队列集合    if (null == queueDataList) &#123;        queueDataList = new LinkedList&lt;QueueData&gt;();        queueDataList.add(queueData);        this.topicQueueTable.put(topicConfig.getTopicName(), queueDataList);        log.info(&quot;new topic registered, &#123;&#125; &#123;&#125;&quot;, topicConfig.getTopicName(), queueData);    &#125; else &#123;        //判断是否是新的队列        boolean addNewOne = true;        Iterator&lt;QueueData&gt; it = queueDataList.iterator();        while (it.hasNext()) &#123;            QueueData qd = it.next();            //如果brokerName相同,代表不是新的队列            if (qd.getBrokerName().equals(brokerName)) &#123;                if (qd.equals(queueData)) &#123;                    addNewOne = false;            &#125; else &#123;                        log.info(&quot;topic changed, &#123;&#125; OLD: &#123;&#125; NEW: &#123;&#125;&quot;, topicConfig.getTopicName(), qd,                            queueData);                        it.remove();                    &#125;                &#125;            &#125;        //如果是新的队列,则添加队列到queueDataList        if (addNewOne) &#123;            queueDataList.add(queueData);        &#125;    &#125;&#125;</code></pre><pre><code class="java">//维护brokerLiveTableBrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddr,new BrokerLiveInfo(    System.currentTimeMillis(),    topicConfigWrapper.getDataVersion(),    channel,    haServerAddr));</code></pre><pre><code class="java">//维护filterServerListif (filterServerList != null) &#123;    if (filterServerList.isEmpty()) &#123;        this.filterServerTable.remove(brokerAddr);    &#125; else &#123;        this.filterServerTable.put(brokerAddr, filterServerList);    &#125;&#125;if (MixAll.MASTER_ID != brokerId) &#123;    String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID);    if (masterAddr != null) &#123;        BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.get(masterAddr);        if (brokerLiveInfo != null) &#123;            result.setHaServerAddr(brokerLiveInfo.getHaServerAddr());            result.setMasterAddr(masterAddr);        &#125;    &#125;&#125;</code></pre><h4 id="2-2-3-3-路由删除"><a href="#2-2-3-3-路由删除" class="headerlink" title="2.2.3.3 路由删除"></a>2.2.3.3 路由删除</h4><p><code>Broker</code>每隔30s向<code>NameServer</code>发送一个心跳包，心跳包包含<code>BrokerId</code>，<code>Broker</code>地址，<code>Broker</code>名称，<code>Broker</code>所属集群名称、<code>Broker</code>关联的<code>FilterServer</code>列表。但是如果<code>Broker</code>宕机，<code>NameServer</code>无法收到心跳包，此时<code>NameServer</code>如何来剔除这些失效的<code>Broker</code>呢？<code>NameServer</code>会每隔10s扫描<code>brokerLiveTable</code>状态表，如果<code>BrokerLive</code>的<strong>lastUpdateTimestamp</strong>的时间戳距当前时间超过120s，则认为<code>Broker</code>失效，移除该<code>Broker</code>，关闭与<code>Broker</code>连接，同时更新<code>topicQueueTable</code>、<code>brokerAddrTable</code>、<code>brokerLiveTable</code>、<code>filterServerTable</code>。</p><p><strong>RocketMQ有两个触发点来删除路由信息</strong>：</p><ul><li>NameServer定期扫描brokerLiveTable检测上次心跳包与当前系统的时间差，如果时间超过120s，则需要移除broker。</li><li>Broker在正常关闭的情况下，会执行unregisterBroker指令</li></ul><p>这两种方式路由删除的方法都是一样的，就是从相关路由表中删除与该broker相关的信息。</p><p><img src="/../imgs/blog20/%E8%B7%AF%E7%94%B1%E5%88%A0%E9%99%A4.png"></p><p><em><strong>代码：NamesrvController#initialize</strong></em></p><pre><code class="java">//每隔10s扫描一次为活跃Brokerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;    @Override    public void run() &#123;        NamesrvController.this.routeInfoManager.scanNotActiveBroker();    &#125;&#125;, 5, 10, TimeUnit.SECONDS);</code></pre><p><em><strong>代码：RouteInfoManager#scanNotActiveBroker</strong></em></p><pre><code class="java">public void scanNotActiveBroker() &#123;    //获得brokerLiveTable    Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; it = this.brokerLiveTable.entrySet().iterator();    //遍历brokerLiveTable    while (it.hasNext()) &#123;        Entry&lt;String, BrokerLiveInfo&gt; next = it.next();        long last = next.getValue().getLastUpdateTimestamp();        //如果收到心跳包的时间距当时时间是否超过120s        if ((last + BROKER_CHANNEL_EXPIRED_TIME) &lt; System.currentTimeMillis()) &#123;            //关闭连接            RemotingUtil.closeChannel(next.getValue().getChannel());            //移除broker            it.remove();            //维护路由表            this.onChannelDestroy(next.getKey(), next.getValue().getChannel());        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：RouteInfoManager#onChannelDestroy</strong></em></p><pre><code class="java">//申请写锁,根据brokerAddress从brokerLiveTable和filterServerTable移除this.lock.writeLock().lockInterruptibly();this.brokerLiveTable.remove(brokerAddrFound);this.filterServerTable.remove(brokerAddrFound);</code></pre><pre><code class="java">//维护brokerAddrTableString brokerNameFound = null;boolean removeBrokerName = false;Iterator&lt;Entry&lt;String, BrokerData&gt;&gt; itBrokerAddrTable =this.brokerAddrTable.entrySet().iterator();//遍历brokerAddrTablewhile (itBrokerAddrTable.hasNext() &amp;&amp; (null == brokerNameFound)) &#123;    BrokerData brokerData = itBrokerAddrTable.next().getValue();    //遍历broker地址    Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerData.getBrokerAddrs().entrySet().iterator();    while (it.hasNext()) &#123;        Entry&lt;Long, String&gt; entry = it.next();        Long brokerId = entry.getKey();        String brokerAddr = entry.getValue();        //根据broker地址移除brokerAddr        if (brokerAddr.equals(brokerAddrFound)) &#123;            brokerNameFound = brokerData.getBrokerName();            it.remove();            log.info(&quot;remove brokerAddr[&#123;&#125;, &#123;&#125;] from brokerAddrTable, because channel destroyed&quot;,                brokerId, brokerAddr);            break;        &#125;    &#125;    //如果当前主题只包含待移除的broker,则移除该topic    if (brokerData.getBrokerAddrs().isEmpty()) &#123;        removeBrokerName = true;        itBrokerAddrTable.remove();        log.info(&quot;remove brokerName[&#123;&#125;] from brokerAddrTable, because channel destroyed&quot;,            brokerData.getBrokerName());    &#125;&#125;</code></pre><pre><code class="java">//维护clusterAddrTableif (brokerNameFound != null &amp;&amp; removeBrokerName) &#123;    Iterator&lt;Entry&lt;String, Set&lt;String&gt;&gt;&gt; it = this.clusterAddrTable.entrySet().iterator();    //遍历clusterAddrTable    while (it.hasNext()) &#123;        Entry&lt;String, Set&lt;String&gt;&gt; entry = it.next();        //获得集群名称        String clusterName = entry.getKey();        //获得集群中brokerName集合        Set&lt;String&gt; brokerNames = entry.getValue();        //从brokerNames中移除brokerNameFound        boolean removed = brokerNames.remove(brokerNameFound);        if (removed) &#123;            log.info(&quot;remove brokerName[&#123;&#125;], clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed&quot;,                brokerNameFound, clusterName);            if (brokerNames.isEmpty()) &#123;                log.info(&quot;remove the clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed and no broker in this cluster&quot;,                    clusterName);                //如果集群中不包含任何broker,则移除该集群                it.remove();            &#125;            break;        &#125;    &#125;&#125;</code></pre><pre><code class="java">//维护topicQueueTable队列if (removeBrokerName) &#123;    //遍历topicQueueTable    Iterator&lt;Entry&lt;String, List&lt;QueueData&gt;&gt;&gt; itTopicQueueTable =        this.topicQueueTable.entrySet().iterator();    while (itTopicQueueTable.hasNext()) &#123;        Entry&lt;String, List&lt;QueueData&gt;&gt; entry = itTopicQueueTable.next();        //主题名称        String topic = entry.getKey();        //队列集合        List&lt;QueueData&gt; queueDataList = entry.getValue();        //遍历该主题队列        Iterator&lt;QueueData&gt; itQueueData = queueDataList.iterator();        while (itQueueData.hasNext()) &#123;            //从队列中移除为活跃broker信息            QueueData queueData = itQueueData.next();            if (queueData.getBrokerName().equals(brokerNameFound)) &#123;                itQueueData.remove();                log.info(&quot;remove topic[&#123;&#125; &#123;&#125;], from topicQueueTable, because channel destroyed&quot;,                    topic, queueData);            &#125;        &#125;        //如果该topic的队列为空,则移除该topic        if (queueDataList.isEmpty()) &#123;            itTopicQueueTable.remove();            log.info(&quot;remove topic[&#123;&#125;] all queue, from topicQueueTable, because channel destroyed&quot;,                topic);        &#125;    &#125;&#125;</code></pre><pre><code class="java">//释放写锁finally &#123;    this.lock.writeLock().unlock();&#125;</code></pre><h4 id="2-2-3-4-路由发现"><a href="#2-2-3-4-路由发现" class="headerlink" title="2.2.3.4 路由发现"></a>2.2.3.4 路由发现</h4><p>RocketMQ路由发现是非实时的，当Topic路由出现变化后，NameServer不会主动推送给客户端，而是由客户端定时拉取主题最新的路由。</p><p><em><strong>代码：DefaultRequestProcessor#getRouteInfoByTopic</strong></em></p><pre><code class="java">public RemotingCommand getRouteInfoByTopic(ChannelHandlerContext ctx,    RemotingCommand request) throws RemotingCommandException &#123;    final RemotingCommand response = RemotingCommand.createResponseCommand(null);    final GetRouteInfoRequestHeader requestHeader =        (GetRouteInfoRequestHeader) request.decodeCommandCustomHeader(GetRouteInfoRequestHeader.class);    //调用RouteInfoManager的方法,从路由表topicQueueTable、brokerAddrTable、filterServerTable中分别填充TopicRouteData的List&lt;QueueData&gt;、List&lt;BrokerData&gt;、filterServer    TopicRouteData topicRouteData = this.namesrvController.getRouteInfoManager().pickupTopicRouteData(requestHeader.getTopic());    //如果找到主题对应你的路由信息并且该主题为顺序消息，则从NameServer KVConfig中获取关于顺序消息相关的配置填充路由信息    if (topicRouteData != null) &#123;        if (this.namesrvController.getNamesrvConfig().isOrderMessageEnable()) &#123;            String orderTopicConf =                this.namesrvController.getKvConfigManager().getKVConfig(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG,                    requestHeader.getTopic());            topicRouteData.setOrderTopicConf(orderTopicConf);        &#125;        byte[] content = topicRouteData.encode();        response.setBody(content);        response.setCode(ResponseCode.SUCCESS);        response.setRemark(null);        return response;    &#125;    response.setCode(ResponseCode.TOPIC_NOT_EXIST);    response.setRemark(&quot;No topic route info in name server for the topic: &quot; + requestHeader.getTopic()        + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));    return response;&#125;</code></pre><h3 id="2-2-4-小结"><a href="#2-2-4-小结" class="headerlink" title="2.2.4 小结"></a>2.2.4 小结</h3><p><img src="/../imgs/blog20/NameServer%E5%B0%8F%E7%BB%93.png"></p><h2 id="2-3-Producer"><a href="#2-3-Producer" class="headerlink" title="2.3 Producer"></a>2.3 Producer</h2><p>消息生产者的代码都在client模块中，相对于RocketMQ来讲，消息生产者就是客户端，也是消息的提供者。</p><p><img src="/../imgs/blog20/DefaultMQProducer%E7%B1%BB%E5%9B%BE.png"></p><p>###2.3.1 方法和属性</p><p>####1）主要方法介绍</p><p><img src="/../imgs/blog20/MQAdmin.png"></p><ul><li><pre><code class="java">//创建主题void createTopic(final String key, final String newTopic, final int queueNum) throws MQClientException;</code></pre></li><li><pre><code class="java">//根据时间戳从队列中查找消息偏移量long searchOffset(final MessageQueue mq, final long timestamp)</code></pre></li><li><pre><code class="java">//查找消息队列中最大的偏移量long maxOffset(final MessageQueue mq) throws MQClientException;</code></pre></li><li><pre><code class="java">//查找消息队列中最小的偏移量long minOffset(final MessageQueue mq) </code></pre></li><li><pre><code class="java">//根据偏移量查找消息MessageExt viewMessage(final String offsetMsgId) throws RemotingException, MQBrokerException,        InterruptedException, MQClientException;</code></pre></li><li><pre><code class="java">//根据条件查找消息QueryResult queryMessage(final String topic, final String key, final int maxNum, final long begin,        final long end) throws MQClientException, InterruptedException;</code></pre></li><li><pre><code class="java">//根据消息ID和主题查找消息MessageExt viewMessage(String topic,String msgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException;</code></pre></li></ul><p><img src="/../imgs/blog20/MQProducer.png"></p><ul><li><pre><code class="java">//启动void start() throws MQClientException;</code></pre></li><li><pre><code class="java">//关闭void shutdown();</code></pre></li><li><pre><code class="java">//查找该主题下所有消息List&lt;MessageQueue&gt; fetchPublishMessageQueues(final String topic) throws MQClientException;</code></pre></li><li><pre><code class="java">//同步发送消息SendResult send(final Message msg) throws MQClientException, RemotingException, MQBrokerException,        InterruptedException;</code></pre></li><li><pre><code class="java">//同步超时发送消息SendResult send(final Message msg, final long timeout) throws MQClientException,        RemotingException, MQBrokerException, InterruptedException;</code></pre></li><li><pre><code class="java">//异步发送消息void send(final Message msg, final SendCallback sendCallback) throws MQClientException,        RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//异步超时发送消息void send(final Message msg, final SendCallback sendCallback, final long timeout)    throws MQClientException, RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//发送单向消息void sendOneway(final Message msg) throws MQClientException, RemotingException,    InterruptedException;</code></pre></li><li><pre><code class="java">//选择指定队列同步发送消息SendResult send(final Message msg, final MessageQueue mq) throws MQClientException,    RemotingException, MQBrokerException, InterruptedException;</code></pre></li><li><pre><code class="java">//选择指定队列异步发送消息void send(final Message msg, final MessageQueue mq, final SendCallback sendCallback)    throws MQClientException, RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//选择指定队列单项发送消息void sendOneway(final Message msg, final MessageQueue mq) throws MQClientException,    RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//批量发送消息SendResult send(final Collection&lt;Message&gt; msgs) throws MQClientException, RemotingException, MQBrokerException,InterruptedException;</code></pre></li></ul><p>####2）属性介绍</p><p><img src="/../imgs/blog20/DefaultMQProducer%E5%B1%9E%E6%80%A7.png"></p><pre><code class="java">producerGroup：生产者所属组createTopicKey：默认TopicdefaultTopicQueueNums：默认主题在每一个Broker队列数量sendMsgTimeout：发送消息默认超时时间，默认3scompressMsgBodyOverHowmuch：消息体超过该值则启用压缩，默认4kretryTimesWhenSendFailed：同步方式发送消息重试次数，默认为2，总共执行3次retryTimesWhenSendAsyncFailed：异步方法发送消息重试次数，默认为2retryAnotherBrokerWhenNotStoreOK：消息重试时选择另外一个Broker时，是否不等待存储结果就返回，默认为falsemaxMessageSize：允许发送的最大消息长度，默认为4M</code></pre><h3 id="2-3-2-启动流程"><a href="#2-3-2-启动流程" class="headerlink" title="2.3.2 启动流程"></a>2.3.2 启动流程</h3><p><img src="/../imgs/blog20/%E7%94%9F%E4%BA%A7%E8%80%85%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：DefaultMQProducerImpl#start</strong></em></p><pre><code class="java">//检查生产者组是否满足要求this.checkConfig();//更改当前instanceName为进程IDif (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) &#123;    this.defaultMQProducer.changeInstanceNameToPID();&#125;//获得MQ客户端实例this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQProducer, rpcHook);</code></pre><blockquote><p>整个JVM中只存在一个MQClientManager实例，维护一个MQClientInstance缓存表</p><p>ConcurrentMap&lt;String&#x2F;* clientId *&#x2F;, MQClientInstance&gt; factoryTable &#x3D; new ConcurrentHashMap&lt;String,MQClientInstance&gt;();</p><p>同一个clientId只会创建一个MQClientInstance。</p><p>MQClientInstance封装了RocketMQ网络处理API，是消息生产者和消息消费者与NameServer、Broker打交道的网络通道</p></blockquote><p><em><strong>代码：MQClientManager#getAndCreateMQClientInstance</strong></em></p><pre><code class="java">public MQClientInstance getAndCreateMQClientInstance(final ClientConfig clientConfig,                                                      RPCHook rpcHook) &#123;    //构建客户端ID    String clientId = clientConfig.buildMQClientId();    //根据客户端ID或者客户端实例    MQClientInstance instance = this.factoryTable.get(clientId);    //实例如果为空就创建新的实例,并添加到实例表中    if (null == instance) &#123;        instance =            new MQClientInstance(clientConfig.cloneClientConfig(),                this.factoryIndexGenerator.getAndIncrement(), clientId, rpcHook);        MQClientInstance prev = this.factoryTable.putIfAbsent(clientId, instance);        if (prev != null) &#123;            instance = prev;            log.warn(&quot;Returned Previous MQClientInstance for clientId:[&#123;&#125;]&quot;, clientId);        &#125; else &#123;            log.info(&quot;Created new MQClientInstance for clientId:[&#123;&#125;]&quot;, clientId);        &#125;    &#125;    return instance;&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#start</strong></em></p><pre><code class="java">//注册当前生产者到到MQClientInstance管理中,方便后续调用网路请求boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this);if (!registerOK) &#123;    this.serviceState = ServiceState.CREATE_JUST;    throw new MQClientException(&quot;The producer group[&quot; + this.defaultMQProducer.getProducerGroup()        + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),        null);&#125;//启动生产者if (startFactory) &#123;    mQClientFactory.start();&#125;</code></pre><h3 id="2-3-3-消息发送"><a href="#2-3-3-消息发送" class="headerlink" title="2.3.3 消息发送"></a>2.3.3 消息发送</h3><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81.png"></p><p><em><strong>代码：DefaultMQProducerImpl#send(Message msg)</strong></em></p><pre><code class="java">//发送消息public SendResult send(Message msg) &#123;    return send(msg, this.defaultMQProducer.getSendMsgTimeout());&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#send(Message msg,long timeout)</strong></em></p><pre><code class="java">//发送消息,默认超时时间为3spublic SendResult send(Message msg,long timeout)&#123;    return this.sendDefaultImpl(msg, CommunicationMode.SYNC, null, timeout);&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#sendDefaultImpl</strong></em></p><pre><code class="java">//校验消息Validators.checkMessage(msg, this.defaultMQProducer);</code></pre><p>####1）验证消息</p><p><em><strong>代码：Validators#checkMessage</strong></em></p><pre><code class="java">public static void checkMessage(Message msg, DefaultMQProducer defaultMQProducer)    throws MQClientException &#123;    //判断是否为空    if (null == msg) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message is null&quot;);    &#125;    // 校验主题    Validators.checkTopic(msg.getTopic());            // 校验消息体    if (null == msg.getBody()) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body is null&quot;);    &#125;    if (0 == msg.getBody().length) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body length is zero&quot;);    &#125;    if (msg.getBody().length &gt; defaultMQProducer.getMaxMessageSize()) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL,            &quot;the message body size over max value, MAX: &quot; + defaultMQProducer.getMaxMessageSize());    &#125;&#125;</code></pre><p>####2）查找路由</p><p><em><strong>代码：DefaultMQProducerImpl#tryToFindTopicPublishInfo</strong></em></p><pre><code class="java">private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123;    //从缓存中获得主题的路由信息    TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic);    //路由信息为空,则从NameServer获取路由    if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123;        this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo());        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic);        topicPublishInfo = this.topicPublishInfoTable.get(topic);    &#125;    if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123;        return topicPublishInfo;    &#125; else &#123;        //如果未找到当前主题的路由信息,则用默认主题继续查找        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer);        topicPublishInfo = this.topicPublishInfoTable.get(topic);        return topicPublishInfo;    &#125;&#125;</code></pre><p><img src="/../imgs/blog20/Topic%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF.png"></p><p><em><strong>代码：TopicPublishInfo</strong></em></p><pre><code class="java">public class TopicPublishInfo &#123;    private boolean orderTopic = false;//是否是顺序消息    private boolean haveTopicRouterInfo = false;     private List&lt;MessageQueue&gt; messageQueueList = new ArrayList&lt;MessageQueue&gt;();//该主题消息队列    private volatile ThreadLocalIndex sendWhichQueue = new ThreadLocalIndex();//每选择一次消息队列,该值+1    private TopicRouteData topicRouteData;//关联Topic路由元信息&#125;</code></pre><p><em><strong>代码：MQClientInstance#updateTopicRouteInfoFromNameServer</strong></em></p><pre><code class="java">TopicRouteData topicRouteData;//使用默认主题从NameServer获取路由信息if (isDefault &amp;&amp; defaultMQProducer != null) &#123;    topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(),        1000 * 3);    if (topicRouteData != null) &#123;        for (QueueData data : topicRouteData.getQueueDatas()) &#123;            int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums());            data.setReadQueueNums(queueNums);            data.setWriteQueueNums(queueNums);        &#125;    &#125;&#125; else &#123;    //使用指定主题从NameServer获取路由信息    topicRouteData = this.mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, 1000 * 3);&#125;</code></pre><p><em><strong>代码：MQClientInstance#updateTopicRouteInfoFromNameServer</strong></em></p><pre><code class="java">//判断路由是否需要更改TopicRouteData old = this.topicRouteTable.get(topic);boolean changed = topicRouteDataIsChange(old, topicRouteData);if (!changed) &#123;    changed = this.isNeedUpdateTopicRouteInfo(topic);&#125; else &#123;    log.info(&quot;the topic[&#123;&#125;] route info changed, old[&#123;&#125;] ,new[&#123;&#125;]&quot;, topic, old, topicRouteData);&#125;</code></pre><p><em><strong>代码：MQClientInstance#updateTopicRouteInfoFromNameServer</strong></em></p><pre><code class="java">if (changed) &#123;    //将topicRouteData转换为发布队列    TopicPublishInfo publishInfo = topicRouteData2TopicPublishInfo(topic, topicRouteData);    publishInfo.setHaveTopicRouterInfo(true);    //遍历生产    Iterator&lt;Entry&lt;String, MQProducerInner&gt;&gt; it = this.producerTable.entrySet().iterator();    while (it.hasNext()) &#123;        Entry&lt;String, MQProducerInner&gt; entry = it.next();        MQProducerInner impl = entry.getValue();        if (impl != null) &#123;            //生产者不为空时,更新publishInfo信息            impl.updateTopicPublishInfo(topic, publishInfo);        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：MQClientInstance#topicRouteData2TopicPublishInfo</strong></em></p><pre><code class="java">public static TopicPublishInfo topicRouteData2TopicPublishInfo(final String topic, final TopicRouteData route) &#123;        //创建TopicPublishInfo对象        TopicPublishInfo info = new TopicPublishInfo();        //关联topicRoute        info.setTopicRouteData(route);        //顺序消息,更新TopicPublishInfo        if (route.getOrderTopicConf() != null &amp;&amp; route.getOrderTopicConf().length() &gt; 0) &#123;            String[] brokers = route.getOrderTopicConf().split(&quot;;&quot;);            for (String broker : brokers) &#123;                String[] item = broker.split(&quot;:&quot;);                int nums = Integer.parseInt(item[1]);                for (int i = 0; i &lt; nums; i++) &#123;                    MessageQueue mq = new MessageQueue(topic, item[0], i);                    info.getMessageQueueList().add(mq);                &#125;            &#125;            info.setOrderTopic(true);        &#125; else &#123;            //非顺序消息更新TopicPublishInfo            List&lt;QueueData&gt; qds = route.getQueueDatas();            Collections.sort(qds);            //遍历topic队列信息            for (QueueData qd : qds) &#123;                //是否是写队列                if (PermName.isWriteable(qd.getPerm())) &#123;                    BrokerData brokerData = null;                    //遍历写队列Broker                    for (BrokerData bd : route.getBrokerDatas()) &#123;                        //根据名称获得读队列对应的Broker                        if (bd.getBrokerName().equals(qd.getBrokerName())) &#123;                        brokerData = bd;                        break;                    &#125;                &#125;                if (null == brokerData) &#123;                    continue;                &#125;                if (!brokerData.getBrokerAddrs().containsKey(MixAll.MASTER_ID)) &#123;                    continue;                &#125;                //封装TopicPublishInfo写队列                for (int i = 0; i &lt; qd.getWriteQueueNums(); i++) &#123;                    MessageQueue mq = new MessageQueue(topic, qd.getBrokerName(), i);                    info.getMessageQueueList().add(mq);                &#125;            &#125;        &#125;        info.setOrderTopic(false);    &#125;    //返回TopicPublishInfo对象    return info;&#125;</code></pre><h4 id="3）选择队列"><a href="#3）选择队列" class="headerlink" title="3）选择队列"></a>3）选择队列</h4><ul><li>默认不启用Broker故障延迟机制</li></ul><p><em><strong>代码：TopicPublishInfo#selectOneMessageQueue(lastBrokerName)</strong></em></p><pre><code class="java">public MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123;    //第一次选择队列    if (lastBrokerName == null) &#123;        return selectOneMessageQueue();    &#125; else &#123;        //sendWhichQueue        int index = this.sendWhichQueue.getAndIncrement();        //遍历消息队列集合        for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123;            //sendWhichQueue自增后取模            int pos = Math.abs(index++) % this.messageQueueList.size();            if (pos &lt; 0)                pos = 0;            //规避上次Broker队列            MessageQueue mq = this.messageQueueList.get(pos);            if (!mq.getBrokerName().equals(lastBrokerName)) &#123;                return mq;            &#125;        &#125;        //如果以上情况都不满足,返回sendWhichQueue取模后的队列        return selectOneMessageQueue();    &#125;&#125;</code></pre><p><em><strong>代码：TopicPublishInfo#selectOneMessageQueue()</strong></em></p><pre><code class="java">//第一次选择队列public MessageQueue selectOneMessageQueue() &#123;    //sendWhichQueue自增    int index = this.sendWhichQueue.getAndIncrement();    //对队列大小取模    int pos = Math.abs(index) % this.messageQueueList.size();    if (pos &lt; 0)        pos = 0;    //返回对应的队列    return this.messageQueueList.get(pos);&#125;</code></pre><ul><li>启用Broker故障延迟机制</li></ul><pre><code class="java">public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123;    //Broker故障延迟机制    if (this.sendLatencyFaultEnable) &#123;        try &#123;            //对sendWhichQueue自增            int index = tpInfo.getSendWhichQueue().getAndIncrement();            //对消息队列轮询获取一个队列            for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123;                int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size();                if (pos &lt; 0)                    pos = 0;                MessageQueue mq = tpInfo.getMessageQueueList().get(pos);                //验证该队列是否可用                if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123;                    //可用                    if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName))                        return mq;                &#125;            &#125;            //从规避的Broker中选择一个可用的Broker            final String notBestBroker = latencyFaultTolerance.pickOneAtLeast();            //获得Broker的写队列集合            int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker);            if (writeQueueNums &gt; 0) &#123;                //获得一个队列,指定broker和队列ID并返回                final MessageQueue mq = tpInfo.selectOneMessageQueue();                if (notBestBroker != null) &#123;                    mq.setBrokerName(notBestBroker);                    mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums);                &#125;                return mq;            &#125; else &#123;                latencyFaultTolerance.remove(notBestBroker);            &#125;        &#125; catch (Exception e) &#123;            log.error(&quot;Error occurred when selecting message queue&quot;, e);        &#125;        return tpInfo.selectOneMessageQueue();    &#125;    return tpInfo.selectOneMessageQueue(lastBrokerName);&#125;</code></pre><p><img src="/../imgs/blog20/Broker%E6%95%85%E9%9A%9C%E5%BB%B6%E8%BF%9F%E6%9C%BA%E5%88%B6%E6%A0%B8%E5%BF%83%E7%B1%BB.png"></p><ul><li>延迟机制接口规范</li></ul><pre><code class="java">public interface LatencyFaultTolerance&lt;T&gt; &#123;    //更新失败条目    void updateFaultItem(final T name, final long currentLatency, final long notAvailableDuration);    //判断Broker是否可用    boolean isAvailable(final T name);    //移除Fault条目    void remove(final T name);    //尝试从规避的Broker中选择一个可用的Broker    T pickOneAtLeast();&#125;</code></pre><ul><li>FaultItem：失败条目</li></ul><pre><code class="java">class FaultItem implements Comparable&lt;FaultItem&gt; &#123;    //条目唯一键,这里为brokerName    private final String name;    //本次消息发送延迟    private volatile long currentLatency;    //故障规避开始时间    private volatile long startTimestamp;&#125;</code></pre><ul><li>消息失败策略</li></ul><pre><code class="java">public class MQFaultStrategy &#123;   //根据currentLatency本地消息发送延迟,从latencyMax尾部向前找到第一个比currentLatency小的索引,如果没有找到,返回0    private long[] latencyMax = &#123;50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L&#125;;    //根据这个索引从notAvailableDuration取出对应的时间,在该时长内,Broker设置为不可用    private long[] notAvailableDuration = &#123;0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L&#125;;&#125;</code></pre><p><u><em><strong>原理分析</strong></em></u></p><p><em><strong>代码：DefaultMQProducerImpl#sendDefaultImpl</strong></em></p><pre><code class="java">sendResult = this.sendKernelImpl(msg,                                  mq,                                  communicationMode,                                  sendCallback,                                  topicPublishInfo,                                  timeout - costTime);endTimestamp = System.currentTimeMillis();this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false);</code></pre><p>如果上述发送过程出现异常，则调用<code>DefaultMQProducerImpl#updateFaultItem</code></p><pre><code class="java">public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123;    //参数一：broker名称    //参数二:本次消息发送延迟时间    //参数三:是否隔离    this.mqFaultStrategy.updateFaultItem(brokerName, currentLatency, isolation);&#125;</code></pre><p><em><strong>代码：MQFaultStrategy#updateFaultItem</strong></em></p><pre><code class="java">public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123;    if (this.sendLatencyFaultEnable) &#123;        //计算broker规避的时长        long duration = computeNotAvailableDuration(isolation ? 30000 : currentLatency);        //更新该FaultItem规避时长        this.latencyFaultTolerance.updateFaultItem(brokerName, currentLatency, duration);    &#125;&#125;</code></pre><p><em><strong>代码：MQFaultStrategy#computeNotAvailableDuration</strong></em></p><pre><code class="java">private long computeNotAvailableDuration(final long currentLatency) &#123;    //遍历latencyMax    for (int i = latencyMax.length - 1; i &gt;= 0; i--) &#123;        //找到第一个比currentLatency的latencyMax值        if (currentLatency &gt;= latencyMax[i])            return this.notAvailableDuration[i];    &#125;    //没有找到则返回0    return 0;&#125;</code></pre><p><em><strong>代码：LatencyFaultToleranceImpl#updateFaultItem</strong></em></p><pre><code class="java">public void updateFaultItem(final String name, final long currentLatency, final long notAvailableDuration) &#123;    //获得原FaultItem    FaultItem old = this.faultItemTable.get(name);    //为空新建faultItem对象,设置规避时长和开始时间    if (null == old) &#123;        final FaultItem faultItem = new FaultItem(name);        faultItem.setCurrentLatency(currentLatency);        faultItem.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);        old = this.faultItemTable.putIfAbsent(name, faultItem);        if (old != null) &#123;            old.setCurrentLatency(currentLatency);            old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);        &#125;    &#125; else &#123;        //更新规避时长和开始时间        old.setCurrentLatency(currentLatency);        old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);    &#125;&#125;</code></pre><p>####4）发送消息</p><p>消息发送API核心入口<em><strong>DefaultMQProducerImpl#sendKernelImpl</strong></em></p><pre><code class="java">private SendResult sendKernelImpl(    final Message msg,//待发送消息    final MessageQueue mq,//消息发送队列    final CommunicationMode communicationMode,//消息发送内模式    final SendCallback sendCallback,pp//异步消息回调函数    final TopicPublishInfo topicPublishInfo,//主题路由信息    final long timeout//超时时间    )</code></pre><p><em><strong>代码：DefaultMQProducerImpl#sendKernelImpl</strong></em></p><pre><code class="java">//获得broker网络地址信息String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());if (null == brokerAddr) &#123;    //没有找到从NameServer更新broker网络地址信息    tryToFindTopicPublishInfo(mq.getTopic());    brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());&#125;</code></pre><pre><code class="java">//为消息分类唯一IDif (!(msg instanceof MessageBatch)) &#123;    MessageClientIDSetter.setUniqID(msg);&#125;boolean topicWithNamespace = false;if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123;    msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace());    topicWithNamespace = true;&#125;//消息大小超过4K,启用消息压缩int sysFlag = 0;boolean msgBodyCompressed = false;if (this.tryToCompressMessage(msg)) &#123;    sysFlag |= MessageSysFlag.COMPRESSED_FLAG;    msgBodyCompressed = true;&#125;//如果是事务消息,设置消息标记MessageSysFlag.TRANSACTION_PREPARED_TYPEfinal String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123;    sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;&#125;</code></pre><pre><code class="java">//如果注册了消息发送钩子函数,在执行消息发送前的增强逻辑if (this.hasSendMessageHook()) &#123;    context = new SendMessageContext();    context.setProducer(this);    context.setProducerGroup(this.defaultMQProducer.getProducerGroup());    context.setCommunicationMode(communicationMode);    context.setBornHost(this.defaultMQProducer.getClientIP());    context.setBrokerAddr(brokerAddr);    context.setMessage(msg);    context.setMq(mq);    context.setNamespace(this.defaultMQProducer.getNamespace());    String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);    if (isTrans != null &amp;&amp; isTrans.equals(&quot;true&quot;)) &#123;        context.setMsgType(MessageType.Trans_Msg_Half);    &#125;    if (msg.getProperty(&quot;__STARTDELIVERTIME&quot;) != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) &#123;        context.setMsgType(MessageType.Delay_Msg);    &#125;    this.executeSendMessageHookBefore(context);&#125;</code></pre><p><em><strong>代码：SendMessageHook</strong></em></p><pre><code class="java">public interface SendMessageHook &#123;    String hookName();    void sendMessageBefore(final SendMessageContext context);    void sendMessageAfter(final SendMessageContext context);&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#sendKernelImpl</strong></em></p><pre><code class="java">//构建消息发送请求包SendMessageRequestHeader requestHeader = new SendMessageRequestHeader();//生产者组requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());//主题requestHeader.setTopic(msg.getTopic());//默认创建主题KeyrequestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey());//该主题在单个Broker默认队列树requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums());//队列IDrequestHeader.setQueueId(mq.getQueueId());//消息系统标记requestHeader.setSysFlag(sysFlag);//消息发送时间requestHeader.setBornTimestamp(System.currentTimeMillis());//消息标记requestHeader.setFlag(msg.getFlag());//消息扩展信息requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties()));//消息重试次数requestHeader.setReconsumeTimes(0);requestHeader.setUnitMode(this.isUnitMode());//是否是批量消息等requestHeader.setBatch(msg instanceof MessageBatch);if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;    String reconsumeTimes = MessageAccessor.getReconsumeTime(msg);    if (reconsumeTimes != null) &#123;        requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes));        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME);    &#125;    String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg);    if (maxReconsumeTimes != null) &#123;        requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes));        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES);    &#125;&#125;</code></pre><pre><code class="java">case ASYNC://异步发送    Message tmpMessage = msg;    boolean messageCloned = false;    if (msgBodyCompressed) &#123;        //If msg body was compressed, msgbody should be reset using prevBody.        //Clone new message using commpressed message body and recover origin massage.        //Fix bug:https://github.com/apache/rocketmq-externals/issues/66        tmpMessage = MessageAccessor.cloneMessage(msg);        messageCloned = true;        msg.setBody(prevBody);    &#125;    if (topicWithNamespace) &#123;        if (!messageCloned) &#123;            tmpMessage = MessageAccessor.cloneMessage(msg);            messageCloned = true;        &#125;        msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(),                                                     this.defaultMQProducer.getNamespace()));    &#125;        long costTimeAsync = System.currentTimeMillis() - beginStartTime;        if (timeout &lt; costTimeAsync) &#123;            throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);        &#125;        sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(                    brokerAddr,                    mq.getBrokerName(),                    tmpMessage,                    requestHeader,                    timeout - costTimeAsync,                    communicationMode,                    sendCallback,                    topicPublishInfo,                    this.mQClientFactory,                    this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(),                    context,                    this);        break;case ONEWAY:case SYNC://同步发送    long costTimeSync = System.currentTimeMillis() - beginStartTime;        if (timeout &lt; costTimeSync) &#123;            throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);        &#125;        sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(            brokerAddr,            mq.getBrokerName(),            msg,            requestHeader,            timeout - costTimeSync,            communicationMode,            context,            this);        break;    default:        assert false;        break;&#125;</code></pre><pre><code class="java">//如果注册了钩子函数,则发送完毕后执行钩子函数if (this.hasSendMessageHook()) &#123;    context.setSendResult(sendResult);    this.executeSendMessageHookAfter(context);&#125;</code></pre><h3 id="2-3-4-批量消息发送"><a href="#2-3-4-批量消息发送" class="headerlink" title="2.3.4 批量消息发送"></a>2.3.4 批量消息发送</h3><p><img src="/../imgs/blog20/%E5%8F%91%E9%80%81%E6%89%B9%E9%87%8F%E6%B6%88%E6%81%AF.png"></p><p>批量消息发送是将同一个主题的多条消息一起打包发送到消息服务端，减少网络调用次数，提高网络传输效率。当然，并不是在同一批次中发送的消息数量越多越好，其判断依据是单条消息的长度，如果单条消息内容比较长，则打包多条消息发送会影响其他线程发送消息的响应时间，并且单批次消息总长度不能超过DefaultMQProducer#maxMessageSize。</p><p>批量消息发送要解决的问题是如何将这些消息编码以便服务端能够正确解码出每条消息的消息内容。</p><p><em><strong>代码：DefaultMQProducer#send</strong></em></p><pre><code class="java">public SendResult send(Collection&lt;Message&gt; msgs)     throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123;    //压缩消息集合成一条消息,然后发送出去    return this.defaultMQProducerImpl.send(batch(msgs));&#125;</code></pre><p><em><strong>代码：DefaultMQProducer#batch</strong></em></p><pre><code class="java">private MessageBatch batch(Collection&lt;Message&gt; msgs) throws MQClientException &#123;    MessageBatch msgBatch;    try &#123;        //将集合消息封装到MessageBatch        msgBatch = MessageBatch.generateFromList(msgs);        //遍历消息集合,检查消息合法性,设置消息ID,设置Topic        for (Message message : msgBatch) &#123;            Validators.checkMessage(message, this);            MessageClientIDSetter.setUniqID(message);            message.setTopic(withNamespace(message.getTopic()));        &#125;        //压缩消息,设置消息body        msgBatch.setBody(msgBatch.encode());    &#125; catch (Exception e) &#123;        throw new MQClientException(&quot;Failed to initiate the MessageBatch&quot;, e);    &#125;    //设置msgBatch的topic    msgBatch.setTopic(withNamespace(msgBatch.getTopic()));    return msgBatch;&#125;</code></pre><h2 id="2-4-消息存储"><a href="#2-4-消息存储" class="headerlink" title="2.4 消息存储"></a>2.4 消息存储</h2><p>###2.4.1 消息存储核心类</p><p><img src="/../imgs/blog20/DefaultMessageStore.png"></p><pre><code class="java">private final MessageStoreConfig messageStoreConfig;//消息配置属性private final CommitLog commitLog;//CommitLog文件存储的实现类private final ConcurrentMap&lt;String/* topic */, ConcurrentMap&lt;Integer/* queueId */, ConsumeQueue&gt;&gt; consumeQueueTable;//消息队列存储缓存表,按照消息主题分组private final FlushConsumeQueueService flushConsumeQueueService;//消息队列文件刷盘线程private final CleanCommitLogService cleanCommitLogService;//清除CommitLog文件服务private final CleanConsumeQueueService cleanConsumeQueueService;//清除ConsumerQueue队列文件服务private final IndexService indexService;//索引实现类private final AllocateMappedFileService allocateMappedFileService;//MappedFile分配服务private final ReputMessageService reputMessageService;//CommitLog消息分发,根据CommitLog文件构建ConsumerQueue、IndexFile文件private final HAService haService;//存储HA机制private final ScheduleMessageService scheduleMessageService;//消息服务调度线程private final StoreStatsService storeStatsService;//消息存储服务private final TransientStorePool transientStorePool;//消息堆外内存缓存private final BrokerStatsManager brokerStatsManager;//Broker状态管理器private final MessageArrivingListener messageArrivingListener;//消息拉取长轮询模式消息达到监听器private final BrokerConfig brokerConfig;//Broker配置类private StoreCheckpoint storeCheckpoint;//文件刷盘监测点private final LinkedList&lt;CommitLogDispatcher&gt; dispatcherList;//CommitLog文件转发请求</code></pre><h3 id="2-4-2-消息存储流程"><a href="#2-4-2-消息存储流程" class="headerlink" title="2.4.2 消息存储流程"></a>2.4.2 消息存储流程</h3><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>消息存储入口：DefaultMessageStore#putMessage</strong></em></p><pre><code class="java">//判断Broker角色如果是从节点,则无需写入if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) &#123;        long value = this.printTimes.getAndIncrement();        if ((value % 50000) == 0) &#123;            log.warn(&quot;message store is slave mode, so putMessage is forbidden &quot;);        &#125;    return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125;//判断当前写入状态如果是正在写入,则不能继续if (!this.runningFlags.isWriteable()) &#123;        long value = this.printTimes.getAndIncrement();        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125; else &#123;    this.printTimes.set(0);&#125;//判断消息主题长度是否超过最大限制if (msg.getTopic().length() &gt; Byte.MAX_VALUE) &#123;    log.warn(&quot;putMessage message topic length too long &quot; + msg.getTopic().length());    return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);&#125;//判断消息属性长度是否超过限制if (msg.getPropertiesString() != null &amp;&amp; msg.getPropertiesString().length() &gt; Short.MAX_VALUE) &#123;    log.warn(&quot;putMessage message properties length too long &quot; + msg.getPropertiesString().length());    return new PutMessageResult(PutMessageStatus.PROPERTIES_SIZE_EXCEEDED, null);&#125;//判断系统PageCache缓存去是否占用if (this.isOSPageCacheBusy()) &#123;    return new PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, null);&#125;//将消息写入CommitLog文件PutMessageResult result = this.commitLog.putMessage(msg);</code></pre><p><em><strong>代码：CommitLog#putMessage</strong></em></p><pre><code class="java">//记录消息存储时间msg.setStoreTimestamp(beginLockTimestamp);//判断如果mappedFile如果为空或者已满,创建新的mappedFile文件if (null == mappedFile || mappedFile.isFull()) &#123;    mappedFile = this.mappedFileQueue.getLastMappedFile(0); &#125;//如果创建失败,直接返回if (null == mappedFile) &#123;    log.error(&quot;create mapped file1 error, topic: &quot; + msg.getTopic() + &quot; clientAddr: &quot; + msg.getBornHostString());    beginTimeInLock = 0;    return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);&#125;//写入消息到mappedFile中result = mappedFile.appendMessage(msg, this.appendMessageCallback);</code></pre><p><em><strong>代码：MappedFile#appendMessagesInner</strong></em></p><pre><code class="java">//获得文件的写入指针int currentPos = this.wrotePosition.get();//如果指针大于文件大小则直接返回if (currentPos &lt; this.fileSize) &#123;    //通过writeBuffer.slice()创建一个与MappedFile共享的内存区,并设置position为当前指针    ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice();    byteBuffer.position(currentPos);    AppendMessageResult result = null;    if (messageExt instanceof MessageExtBrokerInner) &#123;           //通过回调方法写入        result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt);    &#125; else if (messageExt instanceof MessageExtBatch) &#123;        result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt);    &#125; else &#123;        return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);    &#125;    this.wrotePosition.addAndGet(result.getWroteBytes());    this.storeTimestamp = result.getStoreTimestamp();    return result;&#125;</code></pre><p><em><strong>代码：CommitLog#doAppend</strong></em></p><pre><code class="java">//文件写入位置long wroteOffset = fileFromOffset + byteBuffer.position();//设置消息IDthis.resetByteBuffer(hostHolder, 8);String msgId = MessageDecoder.createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset);//获得该消息在消息队列中的偏移量keyBuilder.setLength(0);keyBuilder.append(msgInner.getTopic());keyBuilder.append(&#39;-&#39;);keyBuilder.append(msgInner.getQueueId());String key = keyBuilder.toString();Long queueOffset = CommitLog.this.topicQueueTable.get(key);if (null == queueOffset) &#123;    queueOffset = 0L;    CommitLog.this.topicQueueTable.put(key, queueOffset);&#125;//获得消息属性长度final byte[] propertiesData =msgInner.getPropertiesString() == null ? null : msgInner.getPropertiesString().getBytes(MessageDecoder.CHARSET_UTF8);final int propertiesLength = propertiesData == null ? 0 : propertiesData.length;if (propertiesLength &gt; Short.MAX_VALUE) &#123;    log.warn(&quot;putMessage message properties length too long. length=&#123;&#125;&quot;, propertiesData.length);    return new AppendMessageResult(AppendMessageStatus.PROPERTIES_SIZE_EXCEEDED);&#125;//获得消息主题大小final byte[] topicData = msgInner.getTopic().getBytes(MessageDecoder.CHARSET_UTF8);final int topicLength = topicData.length;//获得消息体大小final int bodyLength = msgInner.getBody() == null ? 0 : msgInner.getBody().length;//计算消息总长度final int msgLen = calMsgLength(bodyLength, topicLength, propertiesLength);</code></pre><p><em><strong>代码：CommitLog#calMsgLength</strong></em></p><pre><code class="java">protected static int calMsgLength(int bodyLength, int topicLength, int propertiesLength) &#123;    final int msgLen = 4 //TOTALSIZE        + 4 //MAGICCODE          + 4 //BODYCRC        + 4 //QUEUEID        + 4 //FLAG        + 8 //QUEUEOFFSET        + 8 //PHYSICALOFFSET        + 4 //SYSFLAG        + 8 //BORNTIMESTAMP        + 8 //BORNHOST        + 8 //STORETIMESTAMP        + 8 //STOREHOSTADDRESS        + 4 //RECONSUMETIMES        + 8 //Prepared Transaction Offset        + 4 + (bodyLength &gt; 0 ? bodyLength : 0) //BODY        + 1 + topicLength //TOPIC        + 2 + (propertiesLength &gt; 0 ? propertiesLength : 0) //propertiesLength        + 0;    return msgLen;&#125;</code></pre><p><em><strong>代码：CommitLog#doAppend</strong></em></p><pre><code class="java">//消息长度不能超过4Mif (msgLen &gt; this.maxMessageSize) &#123;    CommitLog.log.warn(&quot;message size exceeded, msg total size: &quot; + msgLen + &quot;, msg body size: &quot; + bodyLength        + &quot;, maxMessageSize: &quot; + this.maxMessageSize);    return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED);&#125;//消息是如果没有足够的存储空间则新创建CommitLog文件if ((msgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) &#123;    this.resetByteBuffer(this.msgStoreItemMemory, maxBlank);    // 1 TOTALSIZE    this.msgStoreItemMemory.putInt(maxBlank);    // 2 MAGICCODE    this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);    // 3 The remaining space may be any value    // Here the length of the specially set maxBlank    final long beginTimeMills = CommitLog.this.defaultMessageStore.now();    byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank);    return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgId, msgInner.getStoreTimestamp(),        queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);&#125;//将消息存储到ByteBuffer中,返回AppendMessageResultfinal long beginTimeMills = CommitLog.this.defaultMessageStore.now();// Write messages to the queue bufferbyteBuffer.put(this.msgStoreItemMemory.array(), 0, msgLen);AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset,                                                      msgLen, msgId,msgInner.getStoreTimestamp(),                                                      queueOffset,                                                      CommitLog.this.defaultMessageStore.now()                                                      -beginTimeMills);switch (tranType) &#123;    case MessageSysFlag.TRANSACTION_PREPARED_TYPE:    case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:        break;    case MessageSysFlag.TRANSACTION_NOT_TYPE:    case MessageSysFlag.TRANSACTION_COMMIT_TYPE:        //更新消息队列偏移量        CommitLog.this.topicQueueTable.put(key, ++queueOffset);        break;    default:        break;&#125;</code></pre><p><em><strong>代码：CommitLog#putMessage</strong></em></p><pre><code class="java">//释放锁putMessageLock.unlock();//刷盘handleDiskFlush(result, putMessageResult, msg);//执行HA主从同步handleHA(result, putMessageResult, msg);</code></pre><h3 id="2-4-3-存储文件"><a href="#2-4-3-存储文件" class="headerlink" title="2.4.3 存储文件"></a>2.4.3 存储文件</h3><p><img src="/../imgs/blog20/%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6.png"></p><ul><li>commitLog：消息存储目录</li><li>config：运行期间一些配置信息</li><li>consumerqueue：消息消费队列存储目录</li><li>index：消息索引文件存储目录</li><li>abort：如果存在改文件寿命Broker非正常关闭</li><li>checkpoint：文件检查点，存储CommitLog文件最后一次刷盘时间戳、consumerquueue最后一次刷盘时间，index索引文件最后一次刷盘时间戳。</li></ul><h3 id="2-4-4-存储文件内存映射"><a href="#2-4-4-存储文件内存映射" class="headerlink" title="2.4.4 存储文件内存映射"></a>2.4.4 存储文件内存映射</h3><p>RocketMQ通过使用内存映射文件提高IO访问性能，无论是CommitLog、ConsumerQueue还是IndexFile，单个文件都被设计为固定长度，如果一个文件写满以后再创建一个新文件，文件名就为该文件第一条消息对应的全局物理偏移量。</p><p>####1）MappedFileQueue</p><p><img src="/../imgs/blog20/MappedFileQueue.png"></p><pre><code class="java">String storePath;//存储目录int mappedFileSize;// 单个文件大小CopyOnWriteArrayList&lt;MappedFile&gt; mappedFiles;//MappedFile文件集合AllocateMappedFileService allocateMappedFileService;//创建MapFile服务类long flushedWhere = 0;//当前刷盘指针long committedWhere = 0;//当前数据提交指针,内存中ByteBuffer当前的写指针,该值大于等于flushWhere</code></pre><ul><li>根据存储时间查询MappedFile</li></ul><pre><code class="java">public MappedFile getMappedFileByTime(final long timestamp) &#123;    Object[] mfs = this.copyMappedFiles(0);        if (null == mfs)        return null;    //遍历MappedFile文件数组    for (int i = 0; i &lt; mfs.length; i++) &#123;        MappedFile mappedFile = (MappedFile) mfs[i];        //MappedFile文件的最后修改时间大于指定时间戳则返回该文件        if (mappedFile.getLastModifiedTimestamp() &gt;= timestamp) &#123;            return mappedFile;        &#125;    &#125;    return (MappedFile) mfs[mfs.length - 1];&#125;</code></pre><ul><li>根据消息偏移量offset查找MappedFile</li></ul><pre><code class="java">public MappedFile findMappedFileByOffset(final long offset, final boolean returnFirstOnNotFound) &#123;    try &#123;        //获得第一个MappedFile文件        MappedFile firstMappedFile = this.getFirstMappedFile();        //获得最后一个MappedFile文件        MappedFile lastMappedFile = this.getLastMappedFile();        //第一个文件和最后一个文件均不为空,则进行处理        if (firstMappedFile != null &amp;&amp; lastMappedFile != null) &#123;            if (offset &lt; firstMappedFile.getFileFromOffset() ||                 offset &gt;= lastMappedFile.getFileFromOffset() + this.mappedFileSize) &#123;            &#125; else &#123;                //获得文件索引                int index = (int) ((offset / this.mappedFileSize)                                    - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));                MappedFile targetFile = null;                try &#123;                    //根据索引返回目标文件                    targetFile = this.mappedFiles.get(index);                &#125; catch (Exception ignored) &#123;                &#125;                if (targetFile != null &amp;&amp; offset &gt;= targetFile.getFileFromOffset()                    &amp;&amp; offset &lt; targetFile.getFileFromOffset() + this.mappedFileSize) &#123;                    return targetFile;                &#125;                for (MappedFile tmpMappedFile : this.mappedFiles) &#123;                    if (offset &gt;= tmpMappedFile.getFileFromOffset()                        &amp;&amp; offset &lt; tmpMappedFile.getFileFromOffset() + this.mappedFileSize) &#123;                        return tmpMappedFile;                    &#125;                &#125;            &#125;            if (returnFirstOnNotFound) &#123;                return firstMappedFile;            &#125;        &#125;    &#125; catch (Exception e) &#123;        log.error(&quot;findMappedFileByOffset Exception&quot;, e);    &#125;    return null;&#125;</code></pre><ul><li>获取存储文件最小偏移量</li></ul><pre><code class="java">public long getMinOffset() &#123;    if (!this.mappedFiles.isEmpty()) &#123;        try &#123;            return this.mappedFiles.get(0).getFileFromOffset();        &#125; catch (IndexOutOfBoundsException e) &#123;            //continue;        &#125; catch (Exception e) &#123;            log.error(&quot;getMinOffset has exception.&quot;, e);        &#125;    &#125;    return -1;&#125;</code></pre><ul><li>获取存储文件最大偏移量</li></ul><pre><code class="java">public long getMaxOffset() &#123;    MappedFile mappedFile = getLastMappedFile();    if (mappedFile != null) &#123;        return mappedFile.getFileFromOffset() + mappedFile.getReadPosition();    &#125;    return 0;&#125;</code></pre><ul><li>返回存储文件当前写指针</li></ul><pre><code class="java">public long getMaxWrotePosition() &#123;    MappedFile mappedFile = getLastMappedFile();    if (mappedFile != null) &#123;        return mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();    &#125;    return 0;&#125;</code></pre><p>####2）MappedFile</p><p><img src="/../imgs/blog20/MappedFile.png"></p><pre><code class="java">int OS_PAGE_SIZE = 1024 * 4;//操作系统每页大小,默认4KAtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0);//当前JVM实例中MappedFile虚拟内存AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0);//当前JVM实例中MappedFile对象个数AtomicInteger wrotePosition = new AtomicInteger(0);//当前文件的写指针AtomicInteger committedPosition = new AtomicInteger(0);//当前文件的提交指针AtomicInteger flushedPosition = new AtomicInteger(0);//刷写到磁盘指针int fileSize;//文件大小FileChannel fileChannel;//文件通道ByteBuffer writeBuffer = null;//堆外内存ByteBufferTransientStorePool transientStorePool = null;//堆外内存池String fileName;//文件名称long fileFromOffset;//该文件的处理偏移量File file;//物理文件MappedByteBuffer mappedByteBuffer;//物理文件对应的内存映射Buffervolatile long storeTimestamp = 0;//文件最后一次内容写入时间boolean firstCreateInQueue = false;//是否是MappedFileQueue队列中第一个文件</code></pre><p><em><strong>MappedFile初始化</strong></em></p><ul><li>未开启<code>transientStorePoolEnable</code>。<code>transientStorePoolEnable=true</code>为<code>true</code>表示数据先存储到堆外内存，然后通过<code>Commit</code>线程将数据提交到内存映射Buffer中，再通过<code>Flush</code>线程将内存映射<code>Buffer</code>中数据持久化磁盘。</li></ul><pre><code class="java">private void init(final String fileName, final int fileSize) throws IOException &#123;    this.fileName = fileName;    this.fileSize = fileSize;    this.file = new File(fileName);    this.fileFromOffset = Long.parseLong(this.file.getName());    boolean ok = false;        ensureDirOK(this.file.getParent());    try &#123;        this.fileChannel = new RandomAccessFile(this.file, &quot;rw&quot;).getChannel();        this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize);        TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(fileSize);        TOTAL_MAPPED_FILES.incrementAndGet();        ok = true;    &#125; catch (FileNotFoundException e) &#123;        log.error(&quot;create file channel &quot; + this.fileName + &quot; Failed. &quot;, e);        throw e;    &#125; catch (IOException e) &#123;        log.error(&quot;map file &quot; + this.fileName + &quot; Failed. &quot;, e);        throw e;    &#125; finally &#123;        if (!ok &amp;&amp; this.fileChannel != null) &#123;            this.fileChannel.close();        &#125;    &#125;&#125;</code></pre><p>开启<code>transientStorePoolEnable</code></p><pre><code class="java">public void init(final String fileName, final int fileSize,    final TransientStorePool transientStorePool) throws IOException &#123;    init(fileName, fileSize);    this.writeBuffer = transientStorePool.borrowBuffer();//初始化writeBuffer    this.transientStorePool = transientStorePool;&#125;</code></pre><p><em><strong>MappedFile提交</strong></em></p><p>提交数据到FileChannel，commitLeastPages为本次提交最小的页数，如果待提交数据不满commitLeastPages，则不执行本次提交操作。如果writeBuffer如果为空，直接返回writePosition指针，无需执行commit操作，表名commit操作主体是writeBuffer。</p><pre><code class="java">public int commit(final int commitLeastPages) &#123;    if (writeBuffer == null) &#123;        //no need to commit data to file channel, so just regard wrotePosition as committedPosition.        return this.wrotePosition.get();    &#125;    //判断是否满足提交条件    if (this.isAbleToCommit(commitLeastPages)) &#123;        if (this.hold()) &#123;            commit0(commitLeastPages);            this.release();        &#125; else &#123;            log.warn(&quot;in commit, hold failed, commit offset = &quot; + this.committedPosition.get());        &#125;    &#125;    // 所有数据提交后,清空缓冲区    if (writeBuffer != null &amp;&amp; this.transientStorePool != null &amp;&amp; this.fileSize == this.committedPosition.get()) &#123;        this.transientStorePool.returnBuffer(writeBuffer);        this.writeBuffer = null;    &#125;    return this.committedPosition.get();&#125;</code></pre><p><em><strong>MappedFile#isAbleToCommit</strong></em></p><p>判断是否执行commit操作，如果文件已满返回true；如果commitLeastpages大于0，则比较writePosition与上一次提交的指针commitPosition的差值，除以OS_PAGE_SIZE得到当前脏页的数量，如果大于commitLeastPages则返回true，如果commitLeastpages小于0表示只要存在脏页就提交。</p><pre><code class="java">protected boolean isAbleToCommit(final int commitLeastPages) &#123;    //已经刷盘指针    int flush = this.committedPosition.get();    //文件写指针    int write = this.wrotePosition.get();    //写满刷盘    if (this.isFull()) &#123;        return true;    &#125;    if (commitLeastPages &gt; 0) &#123;        //文件内容达到commitLeastPages页数,则刷盘        return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) &gt;= commitLeastPages;    &#125;    return write &gt; flush;&#125;</code></pre><p><em><strong>MappedFile#commit0</strong></em></p><p>具体提交的实现，首先创建WriteBuffer区共享缓存区，然后将新创建的position回退到上一次提交的位置（commitPosition），设置limit为wrotePosition（当前最大有效数据指针），然后把commitPosition到wrotePosition的数据写入到FileChannel中，然后更新committedPosition指针为wrotePosition。commit的作用就是将MappedFile的writeBuffer中数据提交到文件通道FileChannel中。</p><pre><code class="java">protected void commit0(final int commitLeastPages) &#123;    //写指针    int writePos = this.wrotePosition.get();    //上次提交指针    int lastCommittedPosition = this.committedPosition.get();    if (writePos - this.committedPosition.get() &gt; 0) &#123;        try &#123;            //复制共享内存区域            ByteBuffer byteBuffer = writeBuffer.slice();            //设置提交位置是上次提交位置            byteBuffer.position(lastCommittedPosition);            //最大提交数量            byteBuffer.limit(writePos);            //设置fileChannel位置为上次提交位置            this.fileChannel.position(lastCommittedPosition);            //将lastCommittedPosition到writePos的数据复制到FileChannel中            this.fileChannel.write(byteBuffer);            //重置提交位置            this.committedPosition.set(writePos);        &#125; catch (Throwable e) &#123;            log.error(&quot;Error occurred when commit data to FileChannel.&quot;, e);        &#125;    &#125;&#125;</code></pre><p><em><strong>MappedFile#flush</strong></em></p><p>刷写磁盘，直接调用MappedByteBuffer或fileChannel的force方法将内存中的数据持久化到磁盘，那么flushedPosition应该等于MappedByteBuffer中的写指针；如果writeBuffer不为空，则flushPosition应该等于上一次的commit指针；因为上一次提交的数据就是进入到MappedByteBuffer中的数据；如果writeBuffer为空，数据时直接进入到MappedByteBuffer，wrotePosition代表的是MappedByteBuffer中的指针，故设置flushPosition为wrotePosition。</p><p><img src="/../imgs/blog20/flush.jpg"></p><pre><code class="java">public int flush(final int flushLeastPages) &#123;    //数据达到刷盘条件    if (this.isAbleToFlush(flushLeastPages)) &#123;        //加锁，同步刷盘        if (this.hold()) &#123;            //获得读指针            int value = getReadPosition();            try &#123;                //数据从writeBuffer提交数据到fileChannel再刷新到磁盘                if (writeBuffer != null || this.fileChannel.position() != 0) &#123;                    this.fileChannel.force(false);                &#125; else &#123;                    //从mmap刷新数据到磁盘                    this.mappedByteBuffer.force();                &#125;            &#125; catch (Throwable e) &#123;                log.error(&quot;Error occurred when force data to disk.&quot;, e);            &#125;            //更新刷盘位置            this.flushedPosition.set(value);            this.release();        &#125; else &#123;            log.warn(&quot;in flush, hold failed, flush offset = &quot; + this.flushedPosition.get());            this.flushedPosition.set(getReadPosition());        &#125;    &#125;    return this.getFlushedPosition();&#125;</code></pre><p><em><strong>MappedFile#getReadPosition</strong></em></p><p>获取当前文件最大可读指针。如果writeBuffer为空，则直接返回当前的写指针；如果writeBuffer不为空，则返回上一次提交的指针。在MappedFile设置中,只有提交了的数据（写入到MappedByteBuffer或FileChannel中的数据）才是安全的数据</p><pre><code class="java">public int getReadPosition() &#123;    //如果writeBuffer为空,刷盘的位置就是应该等于上次commit的位置,如果为空则为mmap的写指针    return this.writeBuffer == null ? this.wrotePosition.get() : this.committedPosition.get();&#125;</code></pre><p><em><strong>MappedFile#selectMappedBuffer</strong></em></p><p>查找pos到当前最大可读之间的数据，由于在整个写入期间都未曾改MappedByteBuffer的指针，如果mappedByteBuffer.slice()方法返回的共享缓存区空间为整个MappedFile，然后通过设置ByteBuffer的position为待查找的值，读取字节长度当前可读最大长度，最终返回的ByteBuffer的limit为size。整个共享缓存区的容量为（MappedFile#fileSize-pos）。故在操作SelectMappedBufferResult不能对包含在里面的ByteBuffer调用filp方法。</p><pre><code class="java">public SelectMappedBufferResult selectMappedBuffer(int pos) &#123;    //获得最大可读指针    int readPosition = getReadPosition();    //pos小于最大可读指针,并且大于0    if (pos &lt; readPosition &amp;&amp; pos &gt;= 0) &#123;        if (this.hold()) &#123;            //复制mappedByteBuffer读共享区            ByteBuffer byteBuffer = this.mappedByteBuffer.slice();            //设置读指针位置            byteBuffer.position(pos);            //获得可读范围            int size = readPosition - pos;            //设置最大刻度范围            ByteBuffer byteBufferNew = byteBuffer.slice();            byteBufferNew.limit(size);            return new SelectMappedBufferResult(this.fileFromOffset + pos, byteBufferNew, size, this);        &#125;    &#125;    return null;&#125;</code></pre><p><em><strong>MappedFile#shutdown</strong></em></p><p>MappedFile文件销毁的实现方法为public boolean destory(long intervalForcibly)，intervalForcibly表示拒绝被销毁的最大存活时间。</p><pre><code class="java">public void shutdown(final long intervalForcibly) &#123;    if (this.available) &#123;        //关闭MapedFile        this.available = false;        //设置当前关闭时间戳        this.firstShutdownTimestamp = System.currentTimeMillis();        //释放资源        this.release();    &#125; else if (this.getRefCount() &gt; 0) &#123;        if ((System.currentTimeMillis() - this.firstShutdownTimestamp) &gt;= intervalForcibly) &#123;            this.refCount.set(-1000 - this.getRefCount());            this.release();        &#125;    &#125;&#125;</code></pre><h4 id="3）TransientStorePool"><a href="#3）TransientStorePool" class="headerlink" title="3）TransientStorePool"></a>3）TransientStorePool</h4><p>短暂的存储池。RocketMQ单独创建一个MappedByteBuffer内存缓存池，用来临时存储数据，数据先写入该内存映射中，然后由commit线程定时将数据从该内存复制到与目标物理文件对应的内存映射中。RocketMQ引入该机制主要的原因是提供一种内存锁定，将当前堆外内存一直锁定在内存中，避免被进程将内存交换到磁盘。</p><p><img src="/../imgs/blog20/TransientStorePool.png"></p><pre><code class="java">private final int poolSize;//availableBuffers个数private final int fileSize;//每隔ByteBuffer大小private final Deque&lt;ByteBuffer&gt; availableBuffers;//ByteBuffer容器。双端队列</code></pre><p><em><strong>初始化</strong></em></p><pre><code class="java">public void init() &#123;    //创建poolSize个堆外内存    for (int i = 0; i &lt; poolSize; i++) &#123;        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);        final long address = ((DirectBuffer) byteBuffer).address();        Pointer pointer = new Pointer(address);        //使用com.sun.jna.Library类库将该批内存锁定,避免被置换到交换区,提高存储性能        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));        availableBuffers.offer(byteBuffer);    &#125;&#125;</code></pre><h3 id="2-4-5-实时更新消息消费队列与索引文件"><a href="#2-4-5-实时更新消息消费队列与索引文件" class="headerlink" title="2.4.5 实时更新消息消费队列与索引文件"></a>2.4.5 实时更新消息消费队列与索引文件</h3><p>消息消费队文件、消息属性索引文件都是基于CommitLog文件构建的，当消息生产者提交的消息存储在CommitLog文件中，ConsumerQueue、IndexFile需要及时更新，否则消息无法及时被消费，根据消息属性查找消息也会出现较大延迟。RocketMQ通过开启一个线程ReputMessageService来准实时转发CommitLog文件更新事件，相应的任务处理器根据转发的消息及时更新ConsumerQueue、IndexFile文件。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png"></p><p><img src="/../imgs/blog20/%E6%9E%84%E5%BB%BA%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E9%98%9F%E5%88%97%E5%92%8C%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6.png"></p><p><em><strong>代码：DefaultMessageStore：start</strong></em></p><pre><code class="java">//设置CommitLog内存中最大偏移量this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);//启动this.reputMessageService.start();</code></pre><p><em><strong>代码：DefaultMessageStore：run</strong></em></p><pre><code class="java">public void run() &#123;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service started&quot;);    //每隔1毫秒就继续尝试推送消息到消息消费队列和索引文件    while (!this.isStopped()) &#123;        try &#123;            Thread.sleep(1);            this.doReput();        &#125; catch (Exception e) &#123;            DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><em><strong>代码：DefaultMessageStore：deReput</strong></em></p><pre><code class="java">//从result中循环遍历消息,一次读一条,创建DispatherRequest对象。for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123;    DispatchRequest dispatchRequest =                               DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false);    int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize();    if (dispatchRequest.isSuccess()) &#123;        if (size &gt; 0) &#123;            DefaultMessageStore.this.doDispatch(dispatchRequest);        &#125;    &#125;&#125;</code></pre><p><em><strong>DispatchRequest</strong></em></p><p><img src="/../imgs/blog20/DispatchRequest.png"></p><pre><code class="java">String topic; //消息主题名称int queueId;  //消息队列IDlong commitLogOffset;//消息物理偏移量int msgSize;//消息长度long tagsCode;//消息过滤tag hashCodelong storeTimestamp;//消息存储时间戳long consumeQueueOffset;//消息队列偏移量String keys;//消息索引keyboolean success;//是否成功解析到完整的消息String uniqKey;//消息唯一键int sysFlag;//消息系统标记long preparedTransactionOffset;//消息预处理事务偏移量Map&lt;String, String&gt; propertiesMap;//消息属性byte[] bitMap;//位图</code></pre><h4 id="1）转发到ConsumerQueue"><a href="#1）转发到ConsumerQueue" class="headerlink" title="1）转发到ConsumerQueue"></a>1）转发到ConsumerQueue</h4><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91%E5%88%B0%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E9%98%9F%E5%88%97.png"></p><pre><code class="java">class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher &#123;    @Override    public void dispatch(DispatchRequest request) &#123;        final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());        switch (tranType) &#123;            case MessageSysFlag.TRANSACTION_NOT_TYPE:            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:                //消息分发                DefaultMessageStore.this.putMessagePositionInfo(request);                break;            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:                break;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#putMessagePositionInfo</strong></em></p><pre><code class="java">public void putMessagePositionInfo(DispatchRequest dispatchRequest) &#123;    //获得消费队列    ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId());    //消费队列分发消息    cq.putMessagePositionInfoWrapper(dispatchRequest);&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#putMessagePositionInfo</strong></em></p><pre><code class="java">//依次将消息偏移量、消息长度、tag写入到ByteBuffer中this.byteBufferIndex.flip();this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE);this.byteBufferIndex.putLong(offset);this.byteBufferIndex.putInt(size);this.byteBufferIndex.putLong(tagsCode);//获得内存映射文件MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset);if (mappedFile != null) &#123;    //将消息追加到内存映射文件,异步输盘    return mappedFile.appendMessage(this.byteBufferIndex.array());&#125;</code></pre><h4 id="2）转发到Index"><a href="#2）转发到Index" class="headerlink" title="2）转发到Index"></a>2）转发到Index</h4><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91%E5%88%B0%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6.png"></p><pre><code class="java">class CommitLogDispatcherBuildIndex implements CommitLogDispatcher &#123;    @Override    public void dispatch(DispatchRequest request) &#123;        if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) &#123;            DefaultMessageStore.this.indexService.buildIndex(request);        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#buildIndex</strong></em></p><pre><code class="java">public void buildIndex(DispatchRequest req) &#123;    //获得索引文件    IndexFile indexFile = retryGetAndCreateIndexFile();    if (indexFile != null) &#123;        //获得文件最大物理偏移量        long endPhyOffset = indexFile.getEndPhyOffset();        DispatchRequest msg = req;        String topic = msg.getTopic();        String keys = msg.getKeys();        //如果该消息的物理偏移量小于索引文件中的最大物理偏移量,则说明是重复数据,忽略本次索引构建        if (msg.getCommitLogOffset() &lt; endPhyOffset) &#123;            return;        &#125;        final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());        switch (tranType) &#123;            case MessageSysFlag.TRANSACTION_NOT_TYPE:            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:                break;            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:                return;        &#125;                //如果消息ID不为空,则添加到Hash索引中        if (req.getUniqKey() != null) &#123;            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));            if (indexFile == null) &#123;                return;            &#125;        &#125;        //构建索引key,RocketMQ支持为同一个消息建立多个索引,多个索引键空格隔开.        if (keys != null &amp;&amp; keys.length() &gt; 0) &#123;            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);            for (int i = 0; i &lt; keyset.length; i++) &#123;                String key = keyset[i];                if (key.length() &gt; 0) &#123;                    indexFile = putKey(indexFile, msg, buildKey(topic, key));                    if (indexFile == null) &#123;                        return;                    &#125;                &#125;            &#125;        &#125;    &#125; else &#123;        log.error(&quot;build index error, stop building index&quot;);    &#125;&#125;</code></pre><h3 id="2-4-6-消息队列和索引文件恢复"><a href="#2-4-6-消息队列和索引文件恢复" class="headerlink" title="2.4.6 消息队列和索引文件恢复"></a>2.4.6 消息队列和索引文件恢复</h3><p>由于RocketMQ存储首先将消息全量存储在CommitLog文件中，然后异步生成转发任务更新ConsumerQueue和Index文件。如果消息成功存储到CommitLog文件中，转发任务未成功执行，此时消息服务器Broker由于某个愿意宕机，导致CommitLog、ConsumerQueue、IndexFile文件数据不一致。如果不加以人工修复的话，会有一部分消息即便在CommitLog中文件中存在，但由于没有转发到ConsumerQueue，这部分消息将永远复发被消费者消费。</p><p><img src="/../imgs/blog20/%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B.png"></p><p>####1）存储文件加载</p><p><em><strong>代码：DefaultMessageStore#load</strong></em></p><p>判断上一次是否异常退出。实现机制是Broker在启动时创建abort文件，在退出时通过JVM钩子函数删除abort文件。如果下次启动时存在abort文件。说明Broker时异常退出的，CommitLog与ConsumerQueue数据有可能不一致，需要进行修复。</p><pre><code class="java">//判断临时文件是否存在boolean lastExitOK = !this.isTempFileExist();//根据临时文件判断当前Broker是否异常退出private boolean isTempFileExist() &#123;    String fileName = StorePathConfigHelper        .getAbortFile(this.messageStoreConfig.getStorePathRootDir());    File file = new File(fileName);    return file.exists();&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#load</strong></em></p><pre><code class="java">//加载延时队列if (null != scheduleMessageService) &#123;    result = result &amp;&amp; this.scheduleMessageService.load();&#125;// 加载CommitLog文件result = result &amp;&amp; this.commitLog.load();// 加载消费队列文件result = result &amp;&amp; this.loadConsumeQueue();if (result) &#123;    //加载存储监测点,监测点主要记录CommitLog文件、ConsumerQueue文件、Index索引文件的刷盘点    this.storeCheckpoint =new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir()));    //加载index文件    this.indexService.load(lastExitOK);    //根据Broker是否异常退出,执行不同的恢复策略    this.recover(lastExitOK);&#125;</code></pre><p><em><strong>代码：MappedFileQueue#load</strong></em></p><p>加载CommitLog到映射文件</p><pre><code class="java">//指向CommitLog文件目录File dir = new File(this.storePath);//获得文件数组File[] files = dir.listFiles();if (files != null) &#123;    // 文件排序    Arrays.sort(files);    //遍历文件    for (File file : files) &#123;        //如果文件大小和配置文件不一致,退出        if (file.length() != this.mappedFileSize) &#123;                        return false;        &#125;        try &#123;            //创建映射文件            MappedFile mappedFile = new MappedFile(file.getPath(), mappedFileSize);            mappedFile.setWrotePosition(this.mappedFileSize);            mappedFile.setFlushedPosition(this.mappedFileSize);            mappedFile.setCommittedPosition(this.mappedFileSize);            //将映射文件添加到队列            this.mappedFiles.add(mappedFile);            log.info(&quot;load &quot; + file.getPath() + &quot; OK&quot;);        &#125; catch (IOException e) &#123;            log.error(&quot;load file &quot; + file + &quot; error&quot;, e);            return false;        &#125;    &#125;&#125;return true;</code></pre><p><em><strong>代码：DefaultMessageStore#loadConsumeQueue</strong></em></p><p>加载消息消费队列</p><pre><code class="java">//执行消费队列目录File dirLogic = new File(StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()));//遍历消费队列目录File[] fileTopicList = dirLogic.listFiles();if (fileTopicList != null) &#123;    for (File fileTopic : fileTopicList) &#123;        //获得子目录名称,即topic名称        String topic = fileTopic.getName();        //遍历子目录下的消费队列文件        File[] fileQueueIdList = fileTopic.listFiles();        if (fileQueueIdList != null) &#123;            //遍历文件            for (File fileQueueId : fileQueueIdList) &#123;                //文件名称即队列ID                int queueId;                try &#123;                    queueId = Integer.parseInt(fileQueueId.getName());                &#125; catch (NumberFormatException e) &#123;                    continue;                &#125;                //创建消费队列并加载到内存                ConsumeQueue logic = new ConsumeQueue(                    topic,                    queueId,                    StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()),            this.getMessageStoreConfig().getMapedFileSizeConsumeQueue(),                    this);                this.putConsumeQueue(topic, queueId, logic);                if (!logic.load()) &#123;                    return false;                &#125;            &#125;        &#125;    &#125;&#125;log.info(&quot;load logics queue all over, OK&quot;);return true;</code></pre><p><em><strong>代码：IndexService#load</strong></em></p><p>加载索引文件</p><pre><code class="java">public boolean load(final boolean lastExitOK) &#123;    //索引文件目录    File dir = new File(this.storePath);    //遍历索引文件    File[] files = dir.listFiles();    if (files != null) &#123;        //文件排序        Arrays.sort(files);        //遍历文件        for (File file : files) &#123;            try &#123;                //加载索引文件                IndexFile f = new IndexFile(file.getPath(), this.hashSlotNum, this.indexNum, 0, 0);                f.load();                if (!lastExitOK) &#123;                    //索引文件上次的刷盘时间小于该索引文件的消息时间戳,该文件将立即删除                    if (f.getEndTimestamp() &gt; this.defaultMessageStore.getStoreCheckpoint()                        .getIndexMsgTimestamp()) &#123;                        f.destroy(0);                        continue;                    &#125;                &#125;                //将索引文件添加到队列                log.info(&quot;load index file OK, &quot; + f.getFileName());                this.indexFileList.add(f);            &#125; catch (IOException e) &#123;                log.error(&quot;load file &#123;&#125; error&quot;, file, e);                return false;            &#125; catch (NumberFormatException e) &#123;                log.error(&quot;load file &#123;&#125; error&quot;, file, e);            &#125;        &#125;    &#125;    return true;&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#recover</strong></em></p><p>文件恢复，根据Broker是否正常退出执行不同的恢复策略</p><pre><code class="java">private void recover(final boolean lastExitOK) &#123;    //获得最大的物理便宜消费队列    long maxPhyOffsetOfConsumeQueue = this.recoverConsumeQueue();    if (lastExitOK) &#123;        //正常恢复        this.commitLog.recoverNormally(maxPhyOffsetOfConsumeQueue);    &#125; else &#123;        //异常恢复        this.commitLog.recoverAbnormally(maxPhyOffsetOfConsumeQueue);    &#125;    //在CommitLog中保存每个消息消费队列当前的存储逻辑偏移量    this.recoverTopicQueueTable();&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#recoverTopicQueueTable</strong></em></p><p>恢复ConsumerQueue后，将在CommitLog实例中保存每隔消息队列当前的存储逻辑偏移量，这也是消息中不仅存储主题、消息队列ID、还存储了消息队列的关键所在。</p><pre><code class="java">public void recoverTopicQueueTable() &#123;    HashMap&lt;String/* topic-queueid */, Long/* offset */&gt; table = new HashMap&lt;String, Long&gt;(1024);    //CommitLog最小偏移量    long minPhyOffset = this.commitLog.getMinOffset();    //遍历消费队列,将消费队列保存在CommitLog中    for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) &#123;        for (ConsumeQueue logic : maps.values()) &#123;            String key = logic.getTopic() + &quot;-&quot; + logic.getQueueId();            table.put(key, logic.getMaxOffsetInQueue());            logic.correctMinOffset(minPhyOffset);        &#125;    &#125;    this.commitLog.setTopicQueueTable(table);&#125;</code></pre><p>####2）正常恢复</p><p><em><strong>代码：CommitLog#recoverNormally</strong></em></p><pre><code class="java">public void recoverNormally(long maxPhyOffsetOfConsumeQueue) &#123;        final List&lt;MappedFile&gt; mappedFiles = this.mappedFileQueue.getMappedFiles();    if (!mappedFiles.isEmpty()) &#123;         //Broker正常停止再重启时,从倒数第三个开始恢复,如果不足3个文件,则从第一个文件开始恢复。        int index = mappedFiles.size() - 3;        if (index &lt; 0)            index = 0;        MappedFile mappedFile = mappedFiles.get(index);        ByteBuffer byteBuffer = mappedFile.sliceByteBuffer();        long processOffset = mappedFile.getFileFromOffset();        //代表当前已校验通过的offset        long mappedFileOffset = 0;        while (true) &#123;            //查找消息            DispatchRequest dispatchRequest = this.checkMessageAndReturnSize(byteBuffer, checkCRCOnRecover);            //消息长度            int size = dispatchRequest.getMsgSize();               //查找结果为true,并且消息长度大于0,表示消息正确.mappedFileOffset向前移动本消息长度            if (dispatchRequest.isSuccess() &amp;&amp; size &gt; 0) &#123;                mappedFileOffset += size;            &#125;            //如果查找结果为true且消息长度等于0,表示已到该文件末尾,如果还有下一个文件,则重置processOffset和MappedFileOffset重复查找下一个文件,否则跳出循环。            else if (dispatchRequest.isSuccess() &amp;&amp; size == 0) &#123;              index++;              if (index &gt;= mappedFiles.size()) &#123;                  // Current branch can not happen                  break;              &#125; else &#123;                  //取出每个文件                  mappedFile = mappedFiles.get(index);                  byteBuffer = mappedFile.sliceByteBuffer();                  processOffset = mappedFile.getFileFromOffset();                  mappedFileOffset = 0;                                    &#125;            &#125;            // 查找结果为false，表明该文件未填满所有消息，跳出循环，结束循环            else if (!dispatchRequest.isSuccess()) &#123;                log.info(&quot;recover physics file end, &quot; + mappedFile.getFileName());                break;            &#125;        &#125;        //更新MappedFileQueue的flushedWhere和committedWhere指针        processOffset += mappedFileOffset;        this.mappedFileQueue.setFlushedWhere(processOffset);        this.mappedFileQueue.setCommittedWhere(processOffset);        //删除offset之后的所有文件        this.mappedFileQueue.truncateDirtyFiles(processOffset);                if (maxPhyOffsetOfConsumeQueue &gt;= processOffset) &#123;            this.defaultMessageStore.truncateDirtyLogicFiles(processOffset);        &#125;    &#125; else &#123;        this.mappedFileQueue.setFlushedWhere(0);        this.mappedFileQueue.setCommittedWhere(0);        this.defaultMessageStore.destroyLogics();    &#125;&#125;</code></pre><p><em><strong>代码：MappedFileQueue#truncateDirtyFiles</strong></em></p><pre><code class="java">public void truncateDirtyFiles(long offset) &#123;    List&lt;MappedFile&gt; willRemoveFiles = new ArrayList&lt;MappedFile&gt;();    //遍历目录下文件    for (MappedFile file : this.mappedFiles) &#123;        //文件尾部的偏移量        long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize;        //文件尾部的偏移量大于offset        if (fileTailOffset &gt; offset) &#123;            //offset大于文件的起始偏移量            if (offset &gt;= file.getFileFromOffset()) &#123;                //更新wrotePosition、committedPosition、flushedPosistion                file.setWrotePosition((int) (offset % this.mappedFileSize));                file.setCommittedPosition((int) (offset % this.mappedFileSize));                file.setFlushedPosition((int) (offset % this.mappedFileSize));            &#125; else &#123;                //offset小于文件的起始偏移量,说明该文件是有效文件后面创建的,释放mappedFile占用内存,删除文件                file.destroy(1000);                willRemoveFiles.add(file);            &#125;        &#125;    &#125;    this.deleteExpiredFile(willRemoveFiles);&#125;</code></pre><p>####3）异常恢复</p><p>Broker异常停止文件恢复的实现为CommitLog#recoverAbnormally。异常文件恢复步骤与正常停止文件恢复流程基本相同，其主要差别有两个。首先，正常停止默认从倒数第三个文件开始进行恢复，而异常停止则需要从最后一个文件往前走，找到第一个消息存储正常的文件。其次，如果CommitLog目录没有消息文件，如果消息消费队列目录下存在文件，则需要销毁。</p><p><em><strong>代码：CommitLog#recoverAbnormally</strong></em></p><pre><code class="java">if (!mappedFiles.isEmpty()) &#123;    // Looking beginning to recover from which file    int index = mappedFiles.size() - 1;    MappedFile mappedFile = null;    for (; index &gt;= 0; index--) &#123;        mappedFile = mappedFiles.get(index);        //判断消息文件是否是一个正确的文件        if (this.isMappedFileMatchedRecover(mappedFile)) &#123;            log.info(&quot;recover from this mapped file &quot; + mappedFile.getFileName());            break;        &#125;    &#125;    //根据索引取出mappedFile文件    if (index &lt; 0) &#123;        index = 0;        mappedFile = mappedFiles.get(index);    &#125;    //...验证消息的合法性,并将消息转发到消息消费队列和索引文件       &#125;else&#123;    //未找到mappedFile,重置flushWhere、committedWhere都为0，销毁消息队列文件    this.mappedFileQueue.setFlushedWhere(0);    this.mappedFileQueue.setCommittedWhere(0);    this.defaultMessageStore.destroyLogics();&#125;</code></pre><h3 id="2-4-7-刷盘机制"><a href="#2-4-7-刷盘机制" class="headerlink" title="2.4.7 刷盘机制"></a>2.4.7 刷盘机制</h3><p>RocketMQ的存储是基于JDK NIO的内存映射机制（MappedByteBuffer）的，消息存储首先将消息追加到内存，再根据配置的刷盘策略在不同时间进行刷写磁盘。</p><h4 id="同步刷盘"><a href="#同步刷盘" class="headerlink" title="同步刷盘"></a>同步刷盘</h4><p>消息追加到内存后，立即将数据刷写到磁盘文件</p><p><img src="/../imgs/blog20/%E5%90%8C%E6%AD%A5%E5%88%B7%E7%9B%98%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：CommitLog#handleDiskFlush</strong></em></p><pre><code class="java">//刷盘服务final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;if (messageExt.isWaitStoreMsgOK()) &#123;    //封装刷盘请求    GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes());    //提交刷盘请求    service.putRequest(request);    //线程阻塞5秒，等待刷盘结束    boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout());    if (!flushOK) &#123;        putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT);    &#125;</code></pre><p><em><strong>GroupCommitRequest</strong></em></p><p><img src="/../imgs/blog20/GroupCommitRequest.png"></p><pre><code class="java">long nextOffset;//刷盘点偏移量CountDownLatch countDownLatch = new CountDownLatch(1);//倒计树锁存器volatile boolean flushOK = false;//刷盘结果;默认为false</code></pre><p><em><strong>代码：GroupCommitService#run</strong></em></p><pre><code class="java">public void run() &#123;    CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);    while (!this.isStopped()) &#123;        try &#123;            //线程等待10ms            this.waitForRunning(10);            //执行提交            this.doCommit();        &#125; catch (Exception e) &#123;            CommitLog.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    ...&#125;</code></pre><p><em><strong>代码：GroupCommitService#doCommit</strong></em></p><pre><code class="java">private void doCommit() &#123;    //加锁    synchronized (this.requestsRead) &#123;        if (!this.requestsRead.isEmpty()) &#123;            //遍历requestsRead            for (GroupCommitRequest req : this.requestsRead) &#123;                // There may be a message in the next file, so a maximum of                // two times the flush                boolean flushOK = false;                for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) &#123;                    flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset();                    //刷盘                    if (!flushOK) &#123;                        CommitLog.this.mappedFileQueue.flush(0);                    &#125;                &#125;                //唤醒发送消息客户端                req.wakeupCustomer(flushOK);            &#125;                        //更新刷盘监测点            long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();            if (storeTimestamp &gt; 0) &#123;               CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);            &#125;                        this.requestsRead.clear();        &#125; else &#123;            // Because of individual messages is set to not sync flush, it            // will come to this process            CommitLog.this.mappedFileQueue.flush(0);        &#125;    &#125;&#125;</code></pre><h4 id="异步刷盘"><a href="#异步刷盘" class="headerlink" title="异步刷盘"></a>异步刷盘</h4><p>在消息追加到内存后，立即返回给消息发送端。如果开启transientStorePoolEnable，RocketMQ会单独申请一个与目标物理文件（commitLog）同样大小的堆外内存，该堆外内存将使用内存锁定，确保不会被置换到虚拟内存中去，消息首先追加到堆外内存，然后提交到物理文件的内存映射中，然后刷写到磁盘。如果未开启transientStorePoolEnable，消息直接追加到物理文件直接映射文件中，然后刷写到磁盘中。</p><p><img src="/../imgs/blog20/%E5%BC%82%E6%AD%A5%E5%88%B7%E7%9B%98%E6%B5%81%E7%A8%8B.png"></p><p>开启transientStorePoolEnable后异步刷盘步骤:</p><ol><li>将消息直接追加到ByteBuffer（堆外内存）</li><li>CommitRealTimeService线程每隔200ms将ByteBuffer新追加内容提交到MappedByteBuffer中</li><li>MappedByteBuffer在内存中追加提交的内容，wrotePosition指针向后移动</li><li>commit操作成功返回，将committedPosition位置恢复</li><li>FlushRealTimeService线程默认每500ms将MappedByteBuffer中新追加的内存刷写到磁盘</li></ol><p><em><strong>代码：CommitLog$CommitRealTimeService#run</strong></em></p><p>提交线程工作机制</p><pre><code class="java">//间隔时间,默认200msint interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();//一次提交的至少页数int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();//两次真实提交的最大间隔,默认200msint commitDataThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();//上次提交间隔超过commitDataThoroughInterval,则忽略提交commitDataThoroughInterval参数,直接提交long begin = System.currentTimeMillis();if (begin &gt;= (this.lastCommitTimestamp + commitDataThoroughInterval)) &#123;    this.lastCommitTimestamp = begin;    commitDataLeastPages = 0;&#125;//执行提交操作,将待提交数据提交到物理文件的内存映射区boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);long end = System.currentTimeMillis();if (!result) &#123;    this.lastCommitTimestamp = end; // result = false means some data committed.    //now wake up flush thread.    //唤醒刷盘线程    flushCommitLogService.wakeup();&#125;if (end - begin &gt; 500) &#123;    log.info(&quot;Commit data to file costs &#123;&#125; ms&quot;, end - begin);&#125;this.waitForRunning(interval);</code></pre><p><em><strong>代码：CommitLog$FlushRealTimeService#run</strong></em></p><p>刷盘线程工作机制</p><pre><code class="java">//表示await方法等待,默认falseboolean flushCommitLogTimed = CommitLog.this.defaultMessageStore.getMessageStoreConfig().isFlushCommitLogTimed();//线程执行时间间隔int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushIntervalCommitLog();//一次刷写任务至少包含页数int flushPhysicQueueLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogLeastPages();//两次真实刷写任务最大间隔int flushPhysicQueueThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogThoroughInterval();...//距离上次提交间隔超过flushPhysicQueueThoroughInterval,则本次刷盘任务将忽略flushPhysicQueueLeastPages,直接提交long currentTimeMillis = System.currentTimeMillis();if (currentTimeMillis &gt;= (this.lastFlushTimestamp + flushPhysicQueueThoroughInterval)) &#123;    this.lastFlushTimestamp = currentTimeMillis;    flushPhysicQueueLeastPages = 0;    printFlushProgress = (printTimes++ % 10) == 0;&#125;...//执行一次刷盘前,先等待指定时间间隔if (flushCommitLogTimed) &#123;    Thread.sleep(interval);&#125; else &#123;    this.waitForRunning(interval);&#125;...long begin = System.currentTimeMillis();//刷写磁盘CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages);long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();if (storeTimestamp &gt; 0) &#123;//更新存储监测点文件的时间戳CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);</code></pre><h3 id="2-4-8-过期文件删除机制"><a href="#2-4-8-过期文件删除机制" class="headerlink" title="2.4.8 过期文件删除机制"></a>2.4.8 过期文件删除机制</h3><p>由于RocketMQ操作CommitLog、ConsumerQueue文件是基于内存映射机制并在启动的时候回加载CommitLog、ConsumerQueue目录下的所有文件，为了避免内存与磁盘的浪费，不可能将消息永久存储在消息服务器上，所以要引入一种机制来删除已过期的文件。RocketMQ顺序写CommitLog、ConsumerQueue文件，所有写操作全部落在最后一个CommitLog或者ConsumerQueue文件上，之前的文件在下一个文件创建后将不会再被更新。RocketMQ清除过期文件的方法时：如果当前文件在在一定时间间隔内没有再次被消费，则认为是过期文件，可以被删除，RocketMQ不会关注这个文件上的消息是否全部被消费。默认每个文件的过期时间为72小时，通过在Broker配置文件中设置fileReservedTime来改变过期时间，单位为小时。</p><p><em><strong>代码：DefaultMessageStore#addScheduleTask</strong></em></p><pre><code class="java">private void addScheduleTask() &#123;    //每隔10s调度一次清除文件    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            DefaultMessageStore.this.cleanFilesPeriodically();        &#125;    &#125;, 1000 * 60, this.messageStoreConfig.getCleanResourceInterval(), TimeUnit.MILLISECONDS);    ...&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#cleanFilesPeriodically</strong></em></p><pre><code class="java">private void cleanFilesPeriodically() &#123;    //清除存储文件    this.cleanCommitLogService.run();    //清除消息消费队列文件    this.cleanConsumeQueueService.run();&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#deleteExpiredFiles</strong></em></p><pre><code class="java">private void deleteExpiredFiles() &#123;    //删除的数量    int deleteCount = 0;    //文件保留的时间    long fileReservedTime = DefaultMessageStore.this.getMessageStoreConfig().getFileReservedTime();    //删除物理文件的间隔    int deletePhysicFilesInterval = DefaultMessageStore.this.getMessageStoreConfig().getDeleteCommitLogFilesInterval();    //线程被占用,第一次拒绝删除后能保留的最大时间,超过该时间,文件将被强制删除    int destroyMapedFileIntervalForcibly = DefaultMessageStore.this.getMessageStoreConfig().getDestroyMapedFileIntervalForcibly();boolean timeup = this.isTimeToDelete();boolean spacefull = this.isSpaceToDelete();boolean manualDelete = this.manualDeleteFileSeveralTimes &gt; 0;if (timeup || spacefull || manualDelete) &#123;    ...执行删除逻辑&#125;else&#123;    ...无作为&#125;</code></pre><p>删除文件操作的条件</p><ol><li>指定删除文件的时间点，RocketMQ通过deleteWhen设置一天的固定时间执行一次删除过期文件操作，默认4点</li><li>磁盘空间如果不充足，删除过期文件</li><li>预留，手工触发。</li></ol><p><em><strong>代码：CleanCommitLogService#isSpaceToDelete</strong></em></p><p>当磁盘空间不足时执行删除过期文件</p><pre><code class="java">private boolean isSpaceToDelete() &#123;    //磁盘分区的最大使用量    double ratio = DefaultMessageStore.this.getMessageStoreConfig().getDiskMaxUsedSpaceRatio() / 100.0;    //是否需要立即执行删除过期文件操作    cleanImmediately = false;    &#123;        String storePathPhysic = DefaultMessageStore.this.getMessageStoreConfig().getStorePathCommitLog();        //当前CommitLog目录所在的磁盘分区的磁盘使用率        double physicRatio = UtilAll.getDiskPartitionSpaceUsedPercent(storePathPhysic);        //diskSpaceWarningLevelRatio:磁盘使用率警告阈值,默认0.90        if (physicRatio &gt; diskSpaceWarningLevelRatio) &#123;            boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskFull();            if (diskok) &#123;                DefaultMessageStore.log.error(&quot;physic disk maybe full soon &quot; + physicRatio + &quot;, so mark disk full&quot;);            &#125;            //diskSpaceCleanForciblyRatio:强制清除阈值,默认0.85            cleanImmediately = true;        &#125; else if (physicRatio &gt; diskSpaceCleanForciblyRatio) &#123;            cleanImmediately = true;        &#125; else &#123;            boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskOK();            if (!diskok) &#123;            DefaultMessageStore.log.info(&quot;physic disk space OK &quot; + physicRatio + &quot;, so mark disk ok&quot;);        &#125;    &#125;    if (physicRatio &lt; 0 || physicRatio &gt; ratio) &#123;        DefaultMessageStore.log.info(&quot;physic disk maybe full soon, so reclaim space, &quot; + physicRatio);        return true;    &#125;&#125;</code></pre><p><em><strong>代码：MappedFileQueue#deleteExpiredFileByTime</strong></em></p><p>执行文件销毁和删除</p><pre><code class="java">for (int i = 0; i &lt; mfsLength; i++) &#123;    //遍历每隔文件    MappedFile mappedFile = (MappedFile) mfs[i];    //计算文件存活时间    long liveMaxTimestamp = mappedFile.getLastModifiedTimestamp() + expiredTime;    //如果超过72小时,执行文件删除    if (System.currentTimeMillis() &gt;= liveMaxTimestamp || cleanImmediately) &#123;        if (mappedFile.destroy(intervalForcibly)) &#123;            files.add(mappedFile);            deleteCount++;            if (files.size() &gt;= DELETE_FILES_BATCH_MAX) &#123;                break;            &#125;            if (deleteFilesInterval &gt; 0 &amp;&amp; (i + 1) &lt; mfsLength) &#123;                try &#123;                    Thread.sleep(deleteFilesInterval);                &#125; catch (InterruptedException e) &#123;                &#125;            &#125;        &#125; else &#123;            break;        &#125;    &#125; else &#123;        //avoid deleting files in the middle        break;    &#125;&#125;</code></pre><h3 id="2-4-9-小结"><a href="#2-4-9-小结" class="headerlink" title="2.4.9 小结"></a>2.4.9 小结</h3><p>RocketMQ的存储文件包括消息文件（Commitlog）、消息消费队列文件（ConsumerQueue）、Hash索引文件（IndexFile）、监测点文件（checkPoint）、abort（关闭异常文件）。单个消息存储文件、消息消费队列文件、Hash索引文件长度固定以便使用内存映射机制进行文件的读写操作。RocketMQ组织文件以文件的起始偏移量来命令文件，这样根据偏移量能快速定位到真实的物理文件。RocketMQ基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制，异步刷盘是指在消息存储时先追加到内存映射文件，然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘。</p><p>CommitLog，消息存储文件，RocketMQ为了保证消息发送的高吞吐量，采用单一文件存储所有主题消息，保证消息存储是完全的顺序写，但这样给文件读取带来了不便，为此RocketMQ为了方便消息消费构建了消息消费队列文件，基于主题与队列进行组织，同时RocketMQ为消息实现了Hash索引，可以为消息设置索引键，根据所以能够快速从CommitLog文件中检索消息。</p><p>当消息达到CommitLog后，会通过ReputMessageService线程接近实时地将消息转发给消息消费队列文件与索引文件。为了安全起见，RocketMQ引入abort文件，记录Broker的停机是否是正常关闭还是异常关闭，在重启Broker时为了保证CommitLog文件，消息消费队列文件与Hash索引文件的正确性，分别采用不同策略来恢复文件。</p><p>RocketMQ不会永久存储消息文件、消息消费队列文件，而是启动文件过期机制并在磁盘空间不足或者默认凌晨4点删除过期文件，文件保存72小时并且在删除文件时并不会判断该消息文件上的消息是否被消费。</p><h2 id="2-5-Consumer"><a href="#2-5-Consumer" class="headerlink" title="2.5 Consumer"></a>2.5 Consumer</h2><h3 id="2-5-1-消息消费概述"><a href="#2-5-1-消息消费概述" class="headerlink" title="2.5.1 消息消费概述"></a>2.5.1 消息消费概述</h3><p>消息消费以组的模式开展，一个消费组内可以包含多个消费者，每一个消费者组可订阅多个主题，消费组之间有ff式和广播模式两种消费模式。集群模式，主题下的同一条消息只允许被其中一个消费者消费。广播模式，主题下的同一条消息，将被集群内的所有消费者消费一次。消息服务器与消费者之间的消息传递也有两种模式：推模式、拉模式。所谓的拉模式，是消费端主动拉起拉消息请求，而推模式是消息达到消息服务器后，推送给消息消费者。RocketMQ消息推模式的实现基于拉模式，在拉模式上包装一层，一个拉取任务完成后开始下一个拉取任务。</p><p>集群模式下，多个消费者如何对消息队列进行负载呢？消息队列负载机制遵循一个通用思想：一个消息队列同一个时间只允许被一个消费者消费，一个消费者可以消费多个消息队列。</p><p>RocketMQ支持局部顺序消息消费，也就是保证同一个消息队列上的消息顺序消费。不支持消息全局顺序消费，如果要实现某一个主题的全局顺序消费，可以将该主题的队列数设置为1，牺牲高可用性。</p><p>###2.5.2 消息消费初探</p><p><strong><u>消息推送模式</u></strong></p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81.png"></p><p><strong><u>消息消费重要方法</u></strong></p><pre><code class="java">void sendMessageBack(final MessageExt msg, final int delayLevel, final String brokerName)：发送消息确认Set&lt;MessageQueue&gt; fetchSubscribeMessageQueues(final String topic) :获取消费者对主题分配了那些消息队列void registerMessageListener(final MessageListenerConcurrently messageListener)：注册并发事件监听器void registerMessageListener(final MessageListenerOrderly messageListener)：注册顺序消息事件监听器void subscribe(final String topic, final String subExpression)：基于主题订阅消息，消息过滤使用表达式void subscribe(final String topic, final String fullClassName,final String filterClassSource)：基于主题订阅消息，消息过滤使用类模式void subscribe(final String topic, final MessageSelector selector) ：订阅消息，并指定队列选择器void unsubscribe(final String topic)：取消消息订阅</code></pre><p><strong><u>DefaultMQPushConsumer</u></strong></p><p><img src="/../imgs/blog20/DefaultMQPushConsumer.png"></p><pre><code class="java">//消费者组private String consumerGroup;//消息消费模式private MessageModel messageModel = MessageModel.CLUSTERING;//指定消费开始偏移量（最大偏移量、最小偏移量、启动时间戳）开始消费private ConsumeFromWhere consumeFromWhere = ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET;//集群模式下的消息队列负载策略private AllocateMessageQueueStrategy allocateMessageQueueStrategy;//订阅信息private Map&lt;String /* topic */, String /* sub expression */&gt; subscription = new HashMap&lt;String, String&gt;();//消息业务监听器private MessageListener messageListener;//消息消费进度存储器private OffsetStore offsetStore;//消费者最小线程数量private int consumeThreadMin = 20;//消费者最大线程数量private int consumeThreadMax = 20;//并发消息消费时处理队列最大跨度private int consumeConcurrentlyMaxSpan = 2000;//每1000次流控后打印流控日志private int pullThresholdForQueue = 1000;//推模式下任务间隔时间private long pullInterval = 0;//推模式下任务拉取的条数,默认32条private int pullBatchSize = 32;//每次传入MessageListener#consumerMessage中消息的数量private int consumeMessageBatchMaxSize = 1;//是否每次拉取消息都订阅消息private boolean postSubscriptionWhenPull = false;//消息重试次数,-1代表16次private int maxReconsumeTimes = -1;//消息消费超时时间private long consumeTimeout = 15;</code></pre><h3 id="2-5-3-消费者启动流程"><a href="#2-5-3-消费者启动流程" class="headerlink" title="2.5.3 消费者启动流程"></a>2.5.3 消费者启动流程</h3><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：DefaultMQPushConsumerImpl#start</strong></em></p><pre><code class="java">public synchronized void start() throws MQClientException &#123;    switch (this.serviceState) &#123;        case CREATE_JUST:                            this.defaultMQPushConsumer.getMessageModel(), this.defaultMQPushConsumer.isUnitMode());            this.serviceState = ServiceState.START_FAILED;            //检查消息者是否合法            this.checkConfig();            //构建主题订阅信息            this.copySubscription();            //设置消费者客户端实例名称为进程ID            if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123;                this.defaultMQPushConsumer.changeInstanceNameToPID();            &#125;            //创建MQClient实例            this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook);            //构建rebalanceImpl            this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup());            this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel());            this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy());            this.rebalanceImpl.setmQClientFactory(this.mQClientFactor            this.pullAPIWrapper = new PullAPIWrapper(                mQClientFactory,                this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode());            this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookLis            if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123;                this.offsetStore = this.defaultMQPushConsumer.getOffsetStore();            &#125; else &#123;                   switch (this.defaultMQPushConsumer.getMessageModel()) &#123;                                  case BROADCASTING: //消息消费广播模式,将消费进度保存在本地                       this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());                           break;                       case CLUSTERING://消息消费集群模式,将消费进度保存在远端Broker                           this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());                           break;                       default:                           break;                   &#125;                   this.defaultMQPushConsumer.setOffsetStore(this.offsetStore);               &#125;            this.offsetStore.load            //创建顺序消息消费服务            if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123;                this.consumeOrderly = true;                this.consumeMessageService =                    new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner());                //创建并发消息消费服务            &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123;                this.consumeOrderly = false;                this.consumeMessageService =                    new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner());            &#125;            //消息消费服务启动            this.consumeMessageService.start();            //注册消费者实例            boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this);                        if (!registerOK) &#123;                this.serviceState = ServiceState.CREATE_JUST;                this.consumeMessageService.shutdown();                throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup()                    + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),                    null);            //启动消费者客户端            mQClientFactory.start();            log.info(&quot;the consumer [&#123;&#125;] start OK.&quot;, this.defaultMQPushConsumer.getConsumerGroup());            this.serviceState = ServiceState.RUNNING;            break;            case RUNNING:            case START_FAILED:        case SHUTDOWN_ALREADY:            throw new MQClientException(&quot;The PushConsumer service state not OK, maybe started once, &quot;                + this.serviceState                + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),                null);        default:            break;    &#125;    this.updateTopicSubscribeInfoWhenSubscriptionChanged();    this.mQClientFactory.checkClientInBroker();    this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();    this.mQClientFactory.rebalanceImmediately();&#125;</code></pre><h3 id="2-5-4-消息拉取"><a href="#2-5-4-消息拉取" class="headerlink" title="2.5.4 消息拉取"></a>2.5.4 消息拉取</h3><p>消息消费模式有两种模式：广播模式与集群模式。广播模式比较简单，每一个消费者需要拉取订阅主题下所有队列的消息。本文重点讲解集群模式。在集群模式下，同一个消费者组内有多个消息消费者，同一个主题存在多个消费队列，消费者通过负载均衡的方式消费消息。</p><p>消息队列负载均衡，通常的作法是一个消息队列在同一个时间只允许被一个消费消费者消费，一个消息消费者可以同时消费多个消息队列。</p><h4 id="1）PullMessageService实现机制"><a href="#1）PullMessageService实现机制" class="headerlink" title="1）PullMessageService实现机制"></a>1）PullMessageService实现机制</h4><p>从MQClientInstance的启动流程中可以看出，RocketMQ使用一个单独的线程PullMessageService来负责消息的拉取。</p><p><img src="/../imgs/blog20/pullMessageService%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6.png"></p><p><em><strong>代码：PullMessageService#run</strong></em></p><pre><code class="java">public void run() &#123;    log.info(this.getServiceName() + &quot; service started&quot;);    //循环拉取消息    while (!this.isStopped()) &#123;        try &#123;            //从请求队列中获取拉取消息请求            PullRequest pullRequest = this.pullRequestQueue.take();            //拉取消息            this.pullMessage(pullRequest);        &#125; catch (InterruptedException ignored) &#123;        &#125; catch (Exception e) &#123;            log.error(&quot;Pull Message Service Run Method exception&quot;, e);        &#125;    &#125;    log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><u><strong>PullRequest</strong></u></p><p><img src="/../imgs/blog20/PullRequest.png"></p><pre><code class="java">private String consumerGroup;//消费者组private MessageQueue messageQueue;//待拉取消息队列private ProcessQueue processQueue;//消息处理队列private long nextOffset;//待拉取的MessageQueue偏移量private boolean lockedFirst = false;//是否被锁定</code></pre><p><em><strong>代码：PullMessageService#pullMessage</strong></em></p><pre><code class="java">private void pullMessage(final PullRequest pullRequest) &#123;    //获得消费者实例    final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup());    if (consumer != null) &#123;        //强转为推送模式消费者        DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer;        //推送消息        impl.pullMessage(pullRequest);    &#125; else &#123;        log.warn(&quot;No matched consumer for the PullRequest &#123;&#125;, drop it&quot;, pullRequest);    &#125;&#125;</code></pre><p>####2）ProcessQueue实现机制</p><p>ProcessQueue是MessageQueue在消费端的重现、快照。PullMessageService从消息服务器默认每次拉取32条消息，按照消息的队列偏移量顺序存放在ProcessQueue中，PullMessageService然后将消息提交到消费者消费线程池，消息成功消费后从ProcessQueue中移除。</p><p><img src="/../imgs/blog20/ProcessQueue.png"></p><p><strong><u>属性</u></strong></p><pre><code class="java">//消息容器private final TreeMap&lt;Long, MessageExt&gt; msgTreeMap = new TreeMap&lt;Long, MessageExt&gt;();//读写锁private final ReadWriteLock lockTreeMap = new ReentrantReadWriteLock();//ProcessQueue总消息树private final AtomicLong msgCount = new AtomicLong();//ProcessQueue队列最大偏移量private volatile long queueOffsetMax = 0L;//当前ProcessQueue是否被丢弃private volatile boolean dropped = false;//上一次拉取时间戳private volatile long lastPullTimestamp = System.currentTimeMillis();//上一次消费时间戳private volatile long lastConsumeTimestamp = System.currentTimeMillis();</code></pre><p><strong><u>方法</u></strong></p><pre><code class="java">//移除消费超时消息public void cleanExpiredMsg(DefaultMQPushConsumer pushConsumer)//添加消息public boolean putMessage(final List&lt;MessageExt&gt; msgs)//获取消息最大间隔public long getMaxSpan()//移除消息public long removeMessage(final List&lt;MessageExt&gt; msgs)//将consumingMsgOrderlyTreeMap中消息重新放在msgTreeMap,并清空consumingMsgOrderlyTreeMap   public void rollback() //将consumingMsgOrderlyTreeMap消息清除,表示成功处理该批消息public long commit()//重新处理该批消息public void makeMessageToCosumeAgain(List&lt;MessageExt&gt; msgs) //从processQueue中取出batchSize条消息public List&lt;MessageExt&gt; takeMessags(final int batchSize)</code></pre><h4 id="3）消息拉取基本流程"><a href="#3）消息拉取基本流程" class="headerlink" title="3）消息拉取基本流程"></a>3）消息拉取基本流程</h4><p>#####1.客户端发起拉取请求</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：DefaultMQPushConsumerImpl#pullMessage</strong></em></p><pre><code class="java">public void pullMessage(final PullRequest pullRequest) &#123;    //从pullRequest获得ProcessQueue    final ProcessQueue processQueue = pullRequest.getProcessQueue();    //如果处理队列被丢弃,直接返回    if (processQueue.isDropped()) &#123;        log.info(&quot;the pull request[&#123;&#125;] is dropped.&quot;, pullRequest.toString());        return;    &#125;    //如果处理队列未被丢弃,更新时间戳    pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis());    try &#123;        this.makeSureStateOK();    &#125; catch (MQClientException e) &#123;        log.warn(&quot;pullMessage exception, consumer state not ok&quot;, e);        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);        return;    &#125;    //如果处理队列被挂起,延迟1s后再执行    if (this.isPause()) &#123;        log.warn(&quot;consumer was paused, execute pull request later. instanceName=&#123;&#125;, group=&#123;&#125;&quot;, this.defaultMQPushConsumer.getInstanceName(), this.defaultMQPushConsumer.getConsumerGroup());        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND);        return;    &#125;    //获得最大待处理消息数量    long cachedMessageCount = processQueue.getMsgCount().get();    //获得最大待处理消息大小    long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);    //从数量进行流控    if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123;        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);        if ((queueFlowControlTimes++ % 1000) == 0) &#123;            log.warn(                &quot;the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,                this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);        &#125;        return;    &#125;    //从消息大小进行流控    if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123;        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);        if ((queueFlowControlTimes++ % 1000) == 0) &#123;            log.warn(                &quot;the cached message size exceeds the threshold &#123;&#125; MiB, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,                this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);        &#125;        return;    &#125;        //获得订阅信息         final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());        if (null == subscriptionData) &#123;            this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);            log.warn(&quot;find the consumer&#39;s subscription failed, &#123;&#125;&quot;, pullRequest);            return;        //与服务端交互,获取消息        this.pullAPIWrapper.pullKernelImpl(        pullRequest.getMessageQueue(),        subExpression,        subscriptionData.getExpressionType(),        subscriptionData.getSubVersion(),        pullRequest.getNextOffset(),        this.defaultMQPushConsumer.getPullBatchSize(),        sysFlag,        commitOffsetValue,        BROKER_SUSPEND_MAX_TIME_MILLIS,        CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND,        CommunicationMode.ASYNC,        pullCallback    );            &#125;</code></pre><p>#####2.消息服务端Broker组装消息</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%9C%8D%E5%8A%A1%E7%AB%AFBroker%E7%BB%84%E8%A3%85%E6%B6%88%E6%81%AF.png"></p><p><em><strong>代码：PullMessageProcessor#processRequest</strong></em></p><pre><code class="java">//构建消息过滤器MessageFilter messageFilter;if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123;    messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData,        this.brokerController.getConsumerFilterManager());&#125; else &#123;    messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData,        this.brokerController.getConsumerFilterManager());&#125;//调用MessageStore.getMessage查找消息final GetMessageResult getMessageResult =    this.brokerController.getMessageStore().getMessage(                    requestHeader.getConsumerGroup(), //消费组名称                    requestHeader.getTopic(),//主题名称                    requestHeader.getQueueId(), //队列ID                    requestHeader.getQueueOffset(), //待拉取偏移量                    requestHeader.getMaxMsgNums(), //最大拉取消息条数                    messageFilter//消息过滤器            );</code></pre><p><em><strong>代码：DefaultMessageStore#getMessage</strong></em></p><pre><code class="java">GetMessageStatus status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;long nextBeginOffset = offset;//查找下一次队列偏移量long minOffset = 0;//当前消息队列最小偏移量long maxOffset = 0;//当前消息队列最大偏移量GetMessageResult getResult = new GetMessageResult();final long maxOffsetPy = this.commitLog.getMaxOffset();//当前commitLog最大偏移量//根据主题名称和队列编号获取消息消费队列ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId);...minOffset = consumeQueue.getMinOffsetInQueue();maxOffset = consumeQueue.getMaxOffsetInQueue();//消息偏移量异常情况校对下一次拉取偏移量if (maxOffset == 0) &#123;//表示当前消息队列中没有消息    status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;    nextBeginOffset = nextOffsetCorrection(offset, 0);&#125; else if (offset &lt; minOffset) &#123;//待拉取消息的偏移量小于队列的其实偏移量    status = GetMessageStatus.OFFSET_TOO_SMALL;    nextBeginOffset = nextOffsetCorrection(offset, minOffset);&#125; else if (offset == maxOffset) &#123;//待拉取偏移量为队列最大偏移量    status = GetMessageStatus.OFFSET_OVERFLOW_ONE;    nextBeginOffset = nextOffsetCorrection(offset, offset);&#125; else if (offset &gt; maxOffset) &#123;//偏移量越界    status = GetMessageStatus.OFFSET_OVERFLOW_BADLY;    if (0 == minOffset) &#123;        nextBeginOffset = nextOffsetCorrection(offset, minOffset);    &#125; else &#123;        nextBeginOffset = nextOffsetCorrection(offset, maxOffset);    &#125;&#125;...//根据偏移量从CommitLog中拉取32条消息SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy);</code></pre><p><em><strong>代码：PullMessageProcessor#processRequest</strong></em></p><pre><code class="java">//根据拉取结果填充responseHeaderresponse.setRemark(getMessageResult.getStatus().name());responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset());responseHeader.setMinOffset(getMessageResult.getMinOffset());responseHeader.setMaxOffset(getMessageResult.getMaxOffset());//判断如果存在主从同步慢,设置下一次拉取任务的ID为主节点switch (this.brokerController.getMessageStoreConfig().getBrokerRole()) &#123;    case ASYNC_MASTER:    case SYNC_MASTER:        break;    case SLAVE:        if (!this.brokerController.getBrokerConfig().isSlaveReadEnable()) &#123;            response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);            responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID);        &#125;        break;&#125;...//GetMessageResult与Response的Code转换switch (getMessageResult.getStatus()) &#123;    case FOUND://成功        response.setCode(ResponseCode.SUCCESS);        break;    case MESSAGE_WAS_REMOVING://消息存放在下一个commitLog中        response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);//消息重试        break;    case NO_MATCHED_LOGIC_QUEUE://未找到队列    case NO_MESSAGE_IN_QUEUE://队列中未包含消息        if (0 != requestHeader.getQueueOffset()) &#123;            response.setCode(ResponseCode.PULL_OFFSET_MOVED);            requestHeader.getQueueOffset(),            getMessageResult.getNextBeginOffset(),            requestHeader.getTopic(),            requestHeader.getQueueId(),            requestHeader.getConsumerGroup()            );        &#125; else &#123;            response.setCode(ResponseCode.PULL_NOT_FOUND);        &#125;        break;    case NO_MATCHED_MESSAGE://未找到消息        response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);        break;    case OFFSET_FOUND_NULL://消息物理偏移量为空        response.setCode(ResponseCode.PULL_NOT_FOUND);        break;    case OFFSET_OVERFLOW_BADLY://offset越界        response.setCode(ResponseCode.PULL_OFFSET_MOVED);        // XXX: warn and notify me        log.info(&quot;the request offset: &#123;&#125; over flow badly, broker max offset: &#123;&#125;, consumer: &#123;&#125;&quot;,                requestHeader.getQueueOffset(), getMessageResult.getMaxOffset(), channel.remoteAddress());        break;    case OFFSET_OVERFLOW_ONE://offset在队列中未找到        response.setCode(ResponseCode.PULL_NOT_FOUND);        break;    case OFFSET_TOO_SMALL://offset未在队列中        response.setCode(ResponseCode.PULL_OFFSET_MOVED);        requestHeader.getConsumerGroup(),         requestHeader.getTopic(),         requestHeader.getQueueOffset(),        getMessageResult.getMinOffset(), channel.remoteAddress());        break;    default:        assert false;        break;&#125;...//如果CommitLog标记可用,并且当前Broker为主节点,则更新消息消费进度boolean storeOffsetEnable = brokerAllowSuspend;storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag;storeOffsetEnable = storeOffsetEnable    &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE;if (storeOffsetEnable) &#123;    this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel),        requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset());&#125;</code></pre><p>#####3.消息拉取客户端处理消息</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%A4%84%E7%90%86%E6%B6%88%E6%81%AF.png"></p><p><em><strong>代码：MQClientAPIImpl#processPullResponse</strong></em></p><pre><code class="java">private PullResult processPullResponse(    final RemotingCommand response) throws MQBrokerException, RemotingCommandException &#123;    PullStatus pullStatus = PullStatus.NO_NEW_MSG;       //判断响应结果    switch (response.getCode()) &#123;        case ResponseCode.SUCCESS:            pullStatus = PullStatus.FOUND;            break;        case ResponseCode.PULL_NOT_FOUND:            pullStatus = PullStatus.NO_NEW_MSG;            break;        case ResponseCode.PULL_RETRY_IMMEDIATELY:            pullStatus = PullStatus.NO_MATCHED_MSG;            break;        case ResponseCode.PULL_OFFSET_MOVED:            pullStatus = PullStatus.OFFSET_ILLEGAL;            break;        default:            throw new MQBrokerException(response.getCode(), response.getRemark());    &#125;    //解码响应头    PullMessageResponseHeader responseHeader =        (PullMessageResponseHeader) response.decodeCommandCustomHeader(PullMessageResponseHeader.class);    //封装PullResultExt返回    return new PullResultExt(pullStatus, responseHeader.getNextBeginOffset(), responseHeader.getMinOffset(),        responseHeader.getMaxOffset(), null, responseHeader.getSuggestWhichBrokerId(), response.getBody());&#125;</code></pre><p><u><strong>PullResult类</strong></u></p><pre><code class="java">private final PullStatus pullStatus;//拉取结果private final long nextBeginOffset;//下次拉取偏移量private final long minOffset;//消息队列最小偏移量private final long maxOffset;//消息队列最大偏移量private List&lt;MessageExt&gt; msgFoundList;//拉取的消息列表</code></pre><p><img src="/../imgs/blog20/PullStatus.png"></p><p><em><strong>代码：DefaultMQPushConsumerImpl$PullCallback#OnSuccess</strong></em></p><pre><code class="java">//将拉取到的消息存入processQueueboolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList());//将processQueue提交到consumeMessageService中供消费者消费DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(    pullResult.getMsgFoundList(),    processQueue,    pullRequest.getMessageQueue(),    dispatchToConsume);//如果pullInterval大于0,则等待pullInterval毫秒后将pullRequest对象放入到PullMessageService中的pullRequestQueue队列中if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123;    DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest,        DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval());&#125; else &#123;    DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);&#125;</code></pre><h5 id="4-消息拉取总结"><a href="#4-消息拉取总结" class="headerlink" title="4.消息拉取总结"></a>4.消息拉取总结</h5><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93.png"></p><h4 id="4）消息拉取长轮询机制分析"><a href="#4）消息拉取长轮询机制分析" class="headerlink" title="4）消息拉取长轮询机制分析"></a>4）消息拉取长轮询机制分析</h4><p>RocketMQ未真正实现消息推模式，而是消费者主动向消息服务器拉取消息，RocketMQ推模式是循环向消息服务端发起消息拉取请求，如果消息消费者向RocketMQ拉取消息时，消息未到达消费队列时，如果不启用长轮询机制，则会在服务端等待shortPollingTimeMills时间后（挂起）再去判断消息是否已经到达指定消息队列，如果消息仍未到达则提示拉取消息客户端PULL—NOT—FOUND（消息不存在）；如果开启长轮询模式，RocketMQ一方面会每隔5s轮询检查一次消息是否可达，同时一有消息达到后立马通知挂起线程再次验证消息是否是自己感兴趣的消息，如果是则从CommitLog文件中提取消息返回给消息拉取客户端，否则直到挂起超时，超时时间由消息拉取方在消息拉取是封装在请求参数中，PUSH模式为15s，PULL模式通过DefaultMQPullConsumer#setBrokerSuspendMaxTimeMillis设置。RocketMQ通过在Broker客户端配置longPollingEnable为true来开启长轮询模式。</p><p><em><strong>代码：PullMessageProcessor#processRequest</strong></em></p><pre><code class="java">//当没有拉取到消息时，通过长轮询方式继续拉取消息case ResponseCode.PULL_NOT_FOUND:    if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123;        long pollingTimeMills = suspendTimeoutMillisLong;        if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;            pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();        &#125;        String topic = requestHeader.getTopic();        long offset = requestHeader.getQueueOffset();        int queueId = requestHeader.getQueueId();        //构建拉取请求对象        PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,            this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);        //处理拉取请求        this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);        response = null;        break;    &#125;</code></pre><p><strong><u>PullRequestHoldService方式实现长轮询</u></strong></p><p><em><strong>代码：PullRequestHoldService#suspendPullRequest</strong></em></p><pre><code class="java">//将拉取消息请求，放置在ManyPullRequest集合中public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123;    String key = this.buildKey(topic, queueId);    ManyPullRequest mpr = this.pullRequestTable.get(key);    if (null == mpr) &#123;        mpr = new ManyPullRequest();        ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr);        if (prev != null) &#123;            mpr = prev;        &#125;    &#125;    mpr.addPullRequest(pullRequest);&#125;</code></pre><p><em><strong>代码：PullRequestHoldService#run</strong></em></p><pre><code class="java">public void run() &#123;    log.info(&quot;&#123;&#125; service started&quot;, this.getServiceName());    while (!this.isStopped()) &#123;        try &#123;            //如果开启长轮询每隔5秒判断消息是否到达            if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;                this.waitForRunning(5 * 1000);            &#125; else &#123;                //没有开启长轮询,每隔1s再次尝试              this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills());            &#125;            long beginLockTimestamp = this.systemClock.now();            this.checkHoldRequest();            long costTime = this.systemClock.now() - beginLockTimestamp;            if (costTime &gt; 5 * 1000) &#123;                log.info(&quot;[NOTIFYME] check hold request cost &#123;&#125; ms.&quot;, costTime);            &#125;        &#125; catch (Throwable e) &#123;            log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    log.info(&quot;&#123;&#125; service end&quot;, this.getServiceName());&#125;</code></pre><p><em><strong>代码：PullRequestHoldService#checkHoldRequest</strong></em></p><pre><code class="java">//遍历拉取任务private void checkHoldRequest() &#123;    for (String key : this.pullRequestTable.keySet()) &#123;        String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR);        if (2 == kArray.length) &#123;            String topic = kArray[0];            int queueId = Integer.parseInt(kArray[1]);            //获得消息偏移量            final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId);            try &#123;                //通知有消息达到                this.notifyMessageArriving(topic, queueId, offset);            &#125; catch (Throwable e) &#123;                log.error(&quot;check hold request failed. topic=&#123;&#125;, queueId=&#123;&#125;&quot;, topic, queueId, e);            &#125;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：PullRequestHoldService#notifyMessageArriving</strong></em></p><pre><code class="java">//如果拉取消息偏移大于请求偏移量,如果消息匹配调用executeRequestWhenWakeup处理消息if (newestOffset &gt; request.getPullFromThisOffset()) &#123;    boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode,        new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap));    // match by bit map, need eval again when properties is not null.    if (match &amp;&amp; properties != null) &#123;        match = request.getMessageFilter().isMatchedByCommitLog(null, properties);    &#125;    if (match) &#123;        try &#123;            this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),                request.getRequestCommand());        &#125; catch (Throwable e) &#123;            log.error(&quot;execute request when wakeup failed.&quot;, e);        &#125;        continue;    &#125;&#125;//如果过期时间超时,则不继续等待将直接返回给客户端消息未找到if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123;    try &#123;        this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),            request.getRequestCommand());    &#125; catch (Throwable e) &#123;        log.error(&quot;execute request when wakeup failed.&quot;, e);    &#125;    continue;&#125;</code></pre><p>如果开启了长轮询机制，PullRequestHoldService会每隔5s被唤醒去尝试检测是否有新的消息的到来才给客户端响应，或者直到超时才给客户端进行响应，消息实时性比较差，为了避免这种情况，RocketMQ引入另外一种机制：当消息到达时唤醒挂起线程触发一次检查。</p><p><strong><u>DefaultMessageStore$ReputMessageService机制</u></strong></p><p><em><strong>代码：DefaultMessageStore#start</strong></em></p><pre><code class="java">//长轮询入口this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);this.reputMessageService.start();</code></pre><p><em><strong>代码：DefaultMessageStore$ReputMessageService#run</strong></em></p><pre><code class="java">public void run() &#123;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service started&quot;);    while (!this.isStopped()) &#123;        try &#123;            Thread.sleep(1);            //长轮询核心逻辑代码入口            this.doReput();        &#125; catch (Exception e) &#123;            DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><em><strong>代码：DefaultMessageStore$ReputMessageService#deReput</strong></em></p><pre><code class="java">//当新消息达到是,进行通知监听器进行处理if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole()    &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123;    DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());&#125;</code></pre><p><em><strong>代码：NotifyMessageArrivingListener#arriving</strong></em></p><pre><code class="java">public void arriving(String topic, int queueId, long logicOffset, long tagsCode,    long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123;    this.pullRequestHoldService.notifyMessageArriving(topic, queueId, logicOffset, tagsCode,        msgStoreTime, filterBitMap, properties);&#125;</code></pre><h3 id="2-5-5-消息队列负载与重新分布机制"><a href="#2-5-5-消息队列负载与重新分布机制" class="headerlink" title="2.5.5 消息队列负载与重新分布机制"></a>2.5.5 消息队列负载与重新分布机制</h3><p>RocketMQ消息队列重新分配是由RebalanceService线程来实现。一个MQClientInstance持有一个RebalanceService实现，并随着MQClientInstance的启动而启动。</p><p><em><strong>代码：RebalanceService#run</strong></em></p><pre><code class="java">public void run() &#123;    log.info(this.getServiceName() + &quot; service started&quot;);    //RebalanceService线程默认每隔20s执行一次mqClientFactory.doRebalance方法    while (!this.isStopped()) &#123;        this.waitForRunning(waitInterval);        this.mqClientFactory.doRebalance();    &#125;    log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><em><strong>代码：MQClientInstance#doRebalance</strong></em></p><pre><code class="java">public void doRebalance() &#123;    //MQClientInstance遍历以注册的消费者,对消费者执行doRebalance()方法    for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123;        MQConsumerInner impl = entry.getValue();        if (impl != null) &#123;            try &#123;                impl.doRebalance();            &#125; catch (Throwable e) &#123;                log.error(&quot;doRebalance exception&quot;, e);            &#125;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：RebalanceImpl#doRebalance</strong></em></p><pre><code class="java">//遍历订阅消息对每个主题的订阅的队列进行重新负载public void doRebalance(final boolean isOrder) &#123;    Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner();    if (subTable != null) &#123;        for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123;            final String topic = entry.getKey();            try &#123;                this.rebalanceByTopic(topic, isOrder);            &#125; catch (Throwable e) &#123;                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;                    log.warn(&quot;rebalanceByTopic Exception&quot;, e);                &#125;            &#125;        &#125;    &#125;    this.truncateMessageQueueNotMyTopic();&#125;</code></pre><p><em><strong>代码：RebalanceImpl#rebalanceByTopic</strong></em></p><pre><code class="java">//从主题订阅消息缓存表中获取主题的队列信息Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);//查找该主题订阅组所有的消费者IDList&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);//给消费者重新分配队列if (mqSet != null &amp;&amp; cidAll != null) &#123;    List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;();    mqAll.addAll(mqSet);    Collections.sort(mqAll);    Collections.sort(cidAll);    AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;    List&lt;MessageQueue&gt; allocateResult = null;    try &#123;        allocateResult = strategy.allocate(            this.consumerGroup,            this.mQClientFactory.getClientId(),            mqAll,            cidAll);    &#125; catch (Throwable e) &#123;        log.error(&quot;AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName=&#123;&#125;&quot;, strategy.getName(),            e);        return;    &#125;</code></pre><p>RocketMQ默认提供5中负载均衡分配算法</p><pre><code class="java">AllocateMessageQueueAveragely:平均分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q2,q3c2:q4,q5,a6c3:q7,q8AllocateMessageQueueAveragelyByCircle:平均轮询分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q4,q7c2:q2,q5,a8c3:q3,q6</code></pre><p>注意：消息队列的分配遵循一个消费者可以分配到多个队列，但同一个消息队列只会分配给一个消费者，故如果出现消费者个数大于消息队列数量，则有些消费者无法消费消息。</p><h3 id="2-5-6-消息消费过程"><a href="#2-5-6-消息消费过程" class="headerlink" title="2.5.6 消息消费过程"></a>2.5.6 消息消费过程</h3><p>PullMessageService负责对消息队列进行消息拉取，从远端服务器拉取消息后将消息存储ProcessQueue消息队列处理队列中，然后调用ConsumeMessageService#submitConsumeRequest方法进行消息消费，使用线程池来消费消息，确保了消息拉取与消息消费的解耦。ConsumeMessageService支持顺序消息和并发消息，核心类图如下：</p><p><img src="/../imgs/blog20/ConsumeMessageService.png"></p><p><strong><u>并发消息消费</u></strong></p><p><em><strong>代码：ConsumeMessageConcurrentlyService#submitConsumeRequest</strong></em></p><pre><code class="java">//消息批次单次final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize();//msgs.size()默认最多为32条。//如果msgs.size()小于consumeBatchSize,则直接将拉取到的消息放入到consumeRequest,然后将consumeRequest提交到消费者线程池中if (msgs.size() &lt;= consumeBatchSize) &#123;    ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue);    try &#123;        this.consumeExecutor.submit(consumeRequest);    &#125; catch (RejectedExecutionException e) &#123;        this.submitConsumeRequestLater(consumeRequest);    &#125;&#125;else&#123;//如果拉取的消息条数大于consumeBatchSize,则对拉取消息进行分页       for (int total = 0; total &lt; msgs.size(); ) &#123;               List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize);               for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123;                   if (total &lt; msgs.size()) &#123;                       msgThis.add(msgs.get(total));                   &#125; else &#123;                       break;                   &#125;                          ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue);               try &#123;                   this.consumeExecutor.submit(consumeRequest);               &#125; catch (RejectedExecutionException e) &#123;                   for (; total &lt; msgs.size(); total++) &#123;                       msgThis.add(msgs.get(total));                               this.submitConsumeRequestLater(consumeRequest);               &#125;           &#125;&#125;</code></pre><p><em><strong>代码：ConsumeMessageConcurrentlyService$ConsumeRequest#run</strong></em></p><pre><code class="java">//检查processQueue的dropped,如果为true,则停止该队列消费。if (this.processQueue.isDropped()) &#123;    log.info(&quot;the message queue not be able to consume, because it&#39;s dropped. group=&#123;&#125; &#123;&#125;&quot;, ConsumeMessageConcurrentlyService.this.consumerGroup, this.messageQueue);    return;&#125;...//执行消息处理的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123;    consumeMessageContext = new ConsumeMessageContext();    consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace());    consumeMessageContext.setConsumerGroup(defaultMQPushConsumer.getConsumerGroup());    consumeMessageContext.setProps(new HashMap&lt;String, String&gt;());    consumeMessageContext.setMq(messageQueue);    consumeMessageContext.setMsgList(msgs);    consumeMessageContext.setSuccess(false);    ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext);&#125;...//调用应用程序消息监听器的consumeMessage方法,进入到具体的消息消费业务处理逻辑status = listener.consumeMessage(Collections.unmodifiableList(msgs), context);//执行消息处理后的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123;    consumeMessageContext.setStatus(status.toString());    consumeMessageContext.setSuccess(ConsumeConcurrentlyStatus.CONSUME_SUCCESS == status);    ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext);&#125;</code></pre><h3 id="2-5-7-定时消息机制"><a href="#2-5-7-定时消息机制" class="headerlink" title="2.5.7 定时消息机制"></a>2.5.7 定时消息机制</h3><p>定时消息是消息发送到Broker后，并不立即被消费者消费而是要等到特定的时间后才能被消费，RocketMQ并不支持任意的时间精度，如果要支持任意时间精度定时调度，不可避免地需要在Broker层做消息排序，再加上持久化方面的考量，将不可避免的带来巨大的性能消耗，所以RocketMQ只支持特定级别的延迟消息。消息延迟级别在Broker端通过messageDelayLevel配置，默认为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，delayLevel&#x3D;1表示延迟消息1s,delayLevel&#x3D;2表示延迟5s,依次类推。</p><p>RocketMQ定时消息实现类为ScheduleMessageService，该类在DefaultMessageStore中创建。通过在DefaultMessageStore中调用load方法加载该类并调用start方法启动。</p><p><em><strong>代码：ScheduleMessageService#load</strong></em></p><pre><code class="java">//加载延迟消息消费进度的加载与delayLevelTable的构造。延迟消息的进度默认存储路径为/store/config/delayOffset.jsonpublic boolean load() &#123;    boolean result = super.load();    result = result &amp;&amp; this.parseDelayLevel();    return result;&#125;</code></pre><p><em><strong>代码：ScheduleMessageService#start</strong></em></p><pre><code class="java">//遍历延迟队列创建定时任务,遍历延迟级别，根据延迟级别level从offsetTable中获取消费队列的消费进度。如果不存在，则使用0for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123;    Integer level = entry.getKey();    Long timeDelay = entry.getValue();    Long offset = this.offsetTable.get(level);    if (null == offset) &#123;        offset = 0L;    &#125;    if (timeDelay != null) &#123;        this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME);    &#125;&#125;//每隔10s持久化一次延迟队列的消息消费进度this.timer.scheduleAtFixedRate(new TimerTask() &#123;    @Override    public void run() &#123;        try &#123;            if (started.get()) ScheduleMessageService.this.persist();        &#125; catch (Throwable e) &#123;            log.error(&quot;scheduleAtFixedRate flush exception&quot;, e);        &#125;    &#125;&#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval());</code></pre><p><strong><u>调度机制</u></strong></p><p>ScheduleMessageService的start方法启动后，会为每一个延迟级别创建一个调度任务，每一个延迟级别对应SCHEDULE_TOPIC_XXXX主题下的一个消息消费队列。定时调度任务的实现类为DeliverDelayedMessageTimerTask，核心实现方法为executeOnTimeup</p><p><em><strong>代码：ScheduleMessageService$DeliverDelayedMessageTimerTask#executeOnTimeup</strong></em></p><pre><code class="java">//根据队列ID与延迟主题查找消息消费队列ConsumeQueue cq =    ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(SCHEDULE_TOPIC,        delayLevel2QueueId(delayLevel));...//根据偏移量从消息消费队列中获取当前队列中所有有效的消息SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset);...//遍历ConsumeQueue,解析消息队列中消息for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123;    long offsetPy = bufferCQ.getByteBuffer().getLong();    int sizePy = bufferCQ.getByteBuffer().getInt();    long tagsCode = bufferCQ.getByteBuffer().getLong();    if (cq.isExtAddr(tagsCode)) &#123;        if (cq.getExt(tagsCode, cqExtUnit)) &#123;            tagsCode = cqExtUnit.getTagsCode();        &#125; else &#123;            //can&#39;t find ext content.So re compute tags code.            log.error(&quot;[BUG] can&#39;t find consume queue extend file content!addr=&#123;&#125;, offsetPy=&#123;&#125;, sizePy=&#123;&#125;&quot;,                tagsCode, offsetPy, sizePy);            long msgStoreTime = defaultMessageStore.getCommitLog().pickupStoreTimestamp(offsetPy, sizePy);            tagsCode = computeDeliverTimestamp(delayLevel, msgStoreTime);        &#125;    &#125;    long now = System.currentTimeMillis();    long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode);        ...    //根据消息偏移量与消息大小,从CommitLog中查找消息.      MessageExt msgExt =   ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(       offsetPy, sizePy);&#125; </code></pre><h3 id="2-5-8-顺序消息"><a href="#2-5-8-顺序消息" class="headerlink" title="2.5.8 顺序消息"></a>2.5.8 顺序消息</h3><p>顺序消息实现类是org.apache.rocketmq.client.impl.consumer.ConsumeMessageOrderlyService</p><p><em><strong>代码：ConsumeMessageOrderlyService#start</strong></em></p><pre><code class="java">public void start() &#123;    //如果消息模式为集群模式，启动定时任务，默认每隔20s执行一次锁定分配给自己的消息消费队列    if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123;        this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                ConsumeMessageOrderlyService.this.lockMQPeriodically();            &#125;        &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS);    &#125;&#125;</code></pre><p><em><strong>代码：ConsumeMessageOrderlyService#submitConsumeRequest</strong></em></p><pre><code class="java">//构建消息任务,并提交消费线程池中public void submitConsumeRequest(    final List&lt;MessageExt&gt; msgs,    final ProcessQueue processQueue,    final MessageQueue messageQueue,    final boolean dispathToConsume) &#123;    if (dispathToConsume) &#123;        ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue);        this.consumeExecutor.submit(consumeRequest);    &#125;&#125;</code></pre><p><em><strong>代码：ConsumeMessageOrderlyService$ConsumeRequest#run</strong></em></p><pre><code class="java">//如果消息队列为丢弃,则停止本次消费任务if (this.processQueue.isDropped()) &#123;    log.warn(&quot;run, the message queue not be able to consume, because it&#39;s dropped. &#123;&#125;&quot;, this.messageQueue);    return;&#125;//从消息队列中获取一个对象。然后消费消息时先申请独占objLock锁。顺序消息一个消息消费队列同一时刻只会被一个消费线程池处理final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue);synchronized (objLock) &#123;    ...&#125;</code></pre><h3 id="2-5-9-小结"><a href="#2-5-9-小结" class="headerlink" title="2.5.9 小结"></a>2.5.9 小结</h3><p>RocketMQ消息消费方式分别为集群模式、广播模式。</p><p>消息队列负载由RebalanceService线程默认每隔20s进行一次消息队列负载，根据当前消费者组内消费者个数与主题队列数量按照某一种负载算法进行队列分配，分配原则为同一个消费者可以分配多个消息消费队列，同一个消息消费队列同一个时间只会分配给一个消费者。</p><p>消息拉取由PullMessageService线程根据RebalanceService线程创建的拉取任务进行拉取，默认每次拉取32条消息，提交给消费者消费线程后继续下一次消息拉取。如果消息消费过慢产生消息堆积会触发消息消费拉取流控。 </p><p>并发消息消费指消费线程池中的线程可以并发对同一个消息队列的消息进行消费，消费成功后，取出消息队列中最小的消息偏移量作为消息消费进度偏移量存储在于消息消费进度存储文件中，集群模式消息消费进度存储在Broker（消息服务器），广播模式消息消费进度存储在消费者端。</p><p>RocketMQ不支持任意精度的定时调度消息，只支持自定义的消息延迟级别，例如1s、2s、5s等，可通过在broker配置文件中设置messageDelayLevel。</p><p>顺序消息一般使用集群模式，是指对消息消费者内的线程池中的线程对消息消费队列只能串行消费。并并发消息消费最本质的区别是消息消费时必须成功锁定消息消费队列，在Broker端会存储消息消费队列的锁占用情况。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ消费者负载均衡</title>
      <link href="/2023/06/19/blog19/"/>
      <url>/2023/06/19/blog19/</url>
      
        <content type="html"><![CDATA[<h1 id="消费者负载均衡"><a href="#消费者负载均衡" class="headerlink" title="消费者负载均衡"></a>消费者负载均衡</h1><p>消费者从 Apache RocketMQ 获取消息消费时，通过消费者负载均衡策略，可将主题内的消息分配给指定消费者分组中的多个消费者共同分担，提高消费并发能力和消费者的水平扩展能力。本文介绍 Apache RocketMQ 消费者的负载均衡策略。</p><h2 id="背景信息"><a href="#背景信息" class="headerlink" title="背景信息"></a>背景信息</h2><p>了解消费者负载均衡策略，可以帮助您解决以下问题：</p><ul><li>消息消费处理的容灾策略：您可以根据消费者负载均衡策略，明确当局部节点出现故障时，消息如何进行消费重试和容灾切换。</li><li>消息消费的顺序性机制：通过消费者负载均衡策略，您可以进一步了解消息消费时，如何保证同一消息组内消息的先后顺序。</li><li>消息分配的水平拆分策略：了解消费者负载均衡策略，您可以明确消息消费压力如何被分配到不同节点，有针对性地进行流量迁移和水平扩缩容。</li></ul><h2 id="广播消费和共享消费"><a href="#广播消费和共享消费" class="headerlink" title="广播消费和共享消费"></a>广播消费和共享消费</h2><p>在 Apache RocketMQ 领域模型中，同一条消息支持被多个消费者分组订阅，同时，对于每个消费者分组可以初始化多个消费者。您可以根据消费者分组和消费者的不同组合，实现以下两种不同的消费效果：<img src="/../imgs/blog19/consumemode-74d53c59b3266f1f633b1392f5a0f279.png" alt="消费方式"></p><ul><li><p><strong>消费组间广播消费</strong> ：如上图所示，每个消费者分组只初始化唯一一个消费者，每个消费者可消费到消费者分组内所有的消息，各消费者分组都订阅相同的消息，以此实现单客户端级别的广播一对多推送效果。</p><p>该方式一般可用于网关推送、配置推送等场景。</p></li><li><p><strong>消费组内共享消费</strong> ：如上图所示，每个消费者分组下初始化了多个消费者，这些消费者共同分担消费者分组内的所有消息，实现消费者分组内流量的水平拆分和均衡负载。</p><p>该方式一般可用于微服务解耦场景。</p></li></ul><h2 id="什么是消费者负载均衡"><a href="#什么是消费者负载均衡" class="headerlink" title="什么是消费者负载均衡"></a>什么是消费者负载均衡</h2><p>如上文所述，消费组间广播消费场景下，每个消费者分组内只有一个消费者，因此不涉及消费者的负载均衡。</p><p>消费组内共享消费场景下，消费者分组内多个消费者共同分担消息，消息按照哪种逻辑分配给哪个消费者，就是由消费者负载均衡策略所决定的。</p><p>根据消费者类型的不同，消费者负载均衡策略分为以下两种模式：</p><ul><li><a href="https://rocketmq.apache.org/zh/docs/featureBehavior/08consumerloadbalance#section-x2b-2cu-gpf">消息粒度负载均衡</a>：PushConsumer和SimpleConsumer默认负载策略</li><li><a href="https://rocketmq.apache.org/zh/docs/featureBehavior/08consumerloadbalance#section-n9m-6xy-y77">队列粒度负载均衡</a>：PullConsumer默认负载策略</li></ul><h2 id="消息粒度负载均衡"><a href="#消息粒度负载均衡" class="headerlink" title="消息粒度负载均衡"></a>消息粒度负载均衡</h2><p><strong>使用范围</strong></p><p>对于PushConsumer和SimpleConsumer类型的消费者，默认且仅使用消息粒度负载均衡策略。</p><p>备注</p><p>上述说明是指5.0 SDK下，PushConsumer默认使用消息粒度负载均衡，对于3.x&#x2F;4.x等Remoting协议SDK 仍然使用了队列粒度负载均衡。业务集成如无特殊需求，建议使用新版本机制。</p><p><strong>策略原理</strong></p><p>消息粒度负载均衡策略中，同一消费者分组内的多个消费者将按照消息粒度平均分摊主题中的所有消息，即同一个队列中的消息，可被平均分配给多个消费者共同消费。 <img src="/../imgs/blog19/clustermode-dfd781d08bc0c69111841bda537aa302.png" alt="消息粒度负载"></p><p>如上图所示，消费者分组Group A中有三个消费者A1、A2和A3，这三个消费者将共同消费主题中同一队列Queue1中的多条消息。 <strong>注意</strong> 消息粒度负载均衡策略保证同一个队列的消息可以被多个消费者共同处理，但是该策略使用的消息分配算法结果是随机的，并不能指定消息被哪一个特定的消费者处理。</p><p>消息粒度的负载均衡机制，是基于内部的单条消息确认语义实现的。消费者获取某条消息后，服务端会将该消息加锁，保证这条消息对其他消费者不可见，直到该消息消费成功或消费超时。因此，即使多个消费者同时消费同一队列的消息，服务端也可保证消息不会被多个消费者重复消费。</p><p><strong>顺序消息负载机制</strong></p><p>在顺序消息中，消息的顺序性指的是同一消息组内的多个消息之间的先后顺序。因此，顺序消息场景下，消息粒度负载均衡策略还需要保证同一消息组内的消息，按照服务端存储的先后顺序进行消费。不同消费者处理同一个消息组内的消息时，会严格按照先后顺序锁定消息状态，确保同一消息组的消息串行消费。 <img src="/../imgs/blog19/fifoinclustermode-60b2f917ab49333f93029cee178b13f0.png" alt="顺序消息负载策略"></p><p>如上图所述，队列Queue1中有4条顺序消息，这4条消息属于同一消息组G1，存储顺序由M1到M4。在消费过程中，前面的消息M1、M2被消费者Consumer A1处理时，只要消费状态没有提交，消费者A2是无法并行消费后续的M3、M4消息的，必须等前面的消息提交消费状态后才能消费后面的消息。</p><p><strong>策略特点</strong></p><p>相对于队列粒度负载均衡策略，消息粒度负载均衡策略有以下特点：</p><ul><li>消费分摊更均衡传统队列级的负载均衡策略中，如果队列数量和消费者数量不均衡，则可能会出现部分消费者空闲，或部分消费者处理过多消息的情况。消息粒度负载均衡策略无需关注消费者和队列的相对数量，能够更均匀地分摊消息。</li><li>对非对等消费者更友好对于线上生产环境，由于网络机房分区延迟、消费者物理资源规格不一致等原因，消费者的处理能力可能会不一致，如果按照队列分配消息，则可能出现部分消费者消息堆积、部分消费者空闲的情况。消息粒度负载均衡策略按需分配，消费者处理任务更均衡。</li><li>队列分配运维更方便传统基于绑定队列的负载均衡策略，必须保证队列数量大于等于消费者数量，以免产生部分消费者获取不到队列出现空转的情况，而消息粒度负载均衡策略则无需关注队列数。</li></ul><p><strong>适用场景</strong></p><p>消息粒度消费负载均衡策略下，同一队列内的消息离散地分布于多个消费者，适用于绝大多数在线事件处理的场景。只需要基本的消息处理能力，对消息之间没有批量聚合的诉求。而对于流式处理、聚合计算场景，需要明确地对消息进行聚合、批处理时，更适合使用队列粒度的负载均衡策略。</p><p><strong>使用示例</strong></p><p>消息粒度负载均衡策略不需要额外设置，对于PushConsumer和SimpleConsumer消费者类型默认启用。</p><pre><code class="java">SimpleConsumer simpleConsumer = null;        //消费示例一：使用PushConsumer消费普通消息，只需要在消费监听器处理即可，无需关注消息负载均衡。        MessageListener messageListener = new MessageListener() &#123;            @Override            public ConsumeResult consume(MessageView messageView) &#123;                System.out.println(messageView);                //根据消费结果返回状态。                return ConsumeResult.SUCCESS;            &#125;        &#125;;        //消费示例二：使用SimpleConsumer消费普通消息，主动获取消息处理并提交。会按照订阅的主题自动获取，无需关注消息负载均衡。        List&lt;MessageView&gt; messageViewList = null;        try &#123;            messageViewList = simpleConsumer.receive(10, Duration.ofSeconds(30));            messageViewList.forEach(messageView -&gt; &#123;                System.out.println(messageView);                //消费处理完成后，需要主动调用ACK提交消费结果。                try &#123;                    simpleConsumer.ack(messageView);                &#125; catch (ClientException e) &#123;                    e.printStackTrace();                &#125;            &#125;);        &#125; catch (ClientException e) &#123;            //如果遇到系统流控等原因造成拉取失败，需要重新发起获取消息请求。            e.printStackTrace();        &#125;            </code></pre><h2 id="队列粒度负载均衡"><a href="#队列粒度负载均衡" class="headerlink" title="队列粒度负载均衡"></a>队列粒度负载均衡</h2><p><strong>使用范围</strong></p><p>对于历史版本（服务端4.x&#x2F;3.x版本）的消费者，包括PullConsumer、DefaultPushConsumer、DefaultPullConsumer、LitePullConsumer等，默认且仅能使用队列粒度负载均衡策略。</p><p><strong>策略原理</strong></p><p>队列粒度负载均衡策略中，同一消费者分组内的多个消费者将按照队列粒度消费消息，即每个队列仅被一个消费者消费。 <img src="/../imgs/blog19/clusterqueuemode-ce4f88dc594c1237ba95db2fa9146b8c.png" alt="队列级负载均衡原理"></p><p>如上图所示，主题中的三个队列Queue1、Queue2、Queue3被分配给消费者分组中的两个消费者，每个队列只能分配给一个消费者消费，该示例中由于队列数大于消费者数，因此，消费者A2被分配了两个队列。若队列数小于消费者数量，可能会出现部分消费者无绑定队列的情况。</p><p>队列粒度的负载均衡，基于队列数量、消费者数量等运行数据进行统一的算法分配，将每个队列绑定到特定的消费者，然后每个消费者按照取消息&gt;提交消费位点&gt;持久化消费位点的消费语义处理消息，取消息过程不提交消费状态，因此，为了避免消息被多个消费者重复消费，每个队列仅支持被一个消费者消费。</p><p>备注</p><p>队列粒度负载均衡策略保证同一个队列仅被一个消费者处理，该策略的实现依赖消费者和服务端的信息协商机制，Apache RocketMQ 并不能保证协商结果完全强一致。因此，在消费者数量、队列数量发生变化时，可能会出现短暂的队列分配结果不一致，从而导致少量消息被重复处理。</p><p><strong>策略特点</strong></p><p>相对于消息粒度负载均衡策略，队列粒度负载均衡策略分配粒度较大，不够灵活。但该策略在流式处理场景下有天然优势，能够保证同一队列的消息被相同的消费者处理，对于批量处理、聚合处理更友好。</p><p><strong>适用场景</strong></p><p>队列粒度负载均衡策略适用于流式计算、数据聚合等需要明确对消息进行聚合、批处理的场景。</p><p><strong>使用示例</strong></p><p>队列粒度负载均衡策略不需要额外设置，对于历史版本（服务端4.x&#x2F;3.x版本）的消费者类型PullConsumer默认启用。</p><p>具体示例代码，请访问<a href="https://github.com/apache/rocketmq/blob/develop/example/src/main/java/org/apache/rocketmq/example/simple/LitePullConsumerAssign.java">RocketMQ代码库</a>获取。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ事务消息</title>
      <link href="/2023/06/19/blog18/"/>
      <url>/2023/06/19/blog18/</url>
      
        <content type="html"><![CDATA[<h1 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h1><p>事务消息为 Apache RocketMQ 中的高级特性消息，本文为您介绍事务消息的应用场景、功能原理、使用限制、使用方法和使用建议。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p><strong>分布式事务的诉求</strong></p><p>分布式系统调用的特点为一个核心业务逻辑的执行，同时需要调用多个下游业务进行处理。因此，如何保证核心业务和多个下游业务的执行结果完全一致，是分布式事务需要解决的主要问题。 <img src="/../imgs/blog18/tradetrans01-636d42fb6584de6c51692d0889af5c2d.png" alt="事务消息诉求"></p><p>以电商交易场景为例，用户支付订单这一核心操作的同时会涉及到下游物流发货、积分变更、购物车状态清空等多个子系统的变更。当前业务的处理分支包括：</p><ul><li>主分支订单系统状态更新：由未支付变更为支付成功。</li><li>物流系统状态新增：新增待发货物流记录，创建订单物流记录。</li><li>积分系统状态变更：变更用户积分，更新用户积分表。</li><li>购物车系统状态变更：清空购物车，更新用户购物车记录。</li></ul><p><strong>传统XA事务方案：性能不足</strong></p><p>为了保证上述四个分支的执行结果一致性，典型方案是基于XA协议的分布式事务系统来实现。将四个调用分支封装成包含四个独立事务分支的大事务。基于XA分布式事务的方案可以满足业务处理结果的正确性，但最大的缺点是多分支环境下资源锁定范围大，并发度低，随着下游分支的增加，系统性能会越来越差。</p><p><strong>基于普通消息方案：一致性保障困难</strong></p><p>将上述基于XA事务的方案进行简化，将订单系统变更作为本地事务，剩下的系统变更作为普通消息的下游来执行，事务分支简化成普通消息+订单表事务，充分利用消息异步化的能力缩短链路，提高并发度。 <img src="/../imgs/blog18/transwithnormal-f7d951385520fc18aea8d85f0cd86c27.png" alt="普通消息方案"></p><p>该方案中消息下游分支和订单系统变更的主分支很容易出现不一致的现象，例如：</p><ul><li>消息发送成功，订单没有执行成功，需要回滚整个事务。</li><li>订单执行成功，消息没有发送成功，需要额外补偿才能发现不一致。</li><li>消息发送超时未知，此时无法判断需要回滚订单还是提交订单变更。</li></ul><p><strong>基于Apache RocketMQ分布式事务消息：支持最终一致性</strong></p><p>上述普通消息方案中，普通消息和订单事务无法保证一致的原因，本质上是由于普通消息无法像单机数据库事务一样，具备提交、回滚和统一协调的能力。</p><p>而基于Apache RocketMQ实现的分布式事务消息功能，在普通消息基础上，支持二阶段的提交能力。将二阶段提交和本地事务绑定，实现全局提交结果的一致性。 <img src="/../imgs/blog18/tradewithtrans-25be17fcdedb8343a0d2633e693d126d.png" alt="事务消息"></p><p>Apache RocketMQ事务消息的方案，具备高性能、可扩展、业务开发简单的优势。具体事务消息的原理和流程，请参见下文的功能原理。</p><h2 id="功能原理"><a href="#功能原理" class="headerlink" title="功能原理"></a>功能原理</h2><p><strong>什么是事务消息</strong></p><p>事务消息是 Apache RocketMQ 提供的一种高级消息类型，支持在分布式场景下保障消息生产和本地事务的最终一致性。</p><p><strong>事务消息处理流程</strong></p><p>事务消息交互流程如下图所示。<img src="/../imgs/blog18/transflow-0b07236d124ddb814aeaf5f6b5f3f72c.png" alt="事务消息"></p><ol><li>生产者将消息发送至Apache RocketMQ服务端。</li><li>Apache RocketMQ服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息被标记为”暂不能投递”，这种状态下的消息即为半事务消息。</li><li>生产者开始执行本地事务逻辑。</li><li>生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：<ul><li>二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。</li><li>二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。</li></ul></li><li>在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 <strong>说明</strong> 服务端回查的间隔时间和最大回查次数，请参见<a href="https://rocketmq.apache.org/zh/docs/introduction/03limits">参数限制</a>。</li><li>生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li><li>生产者根据检查到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。</li></ol><p><strong>事务消息生命周期</strong> <img src="/../imgs/blog18/lifecyclefortrans-fe4a49f1c9fdae5d590a64546722036f.png" alt="事务消息"></p><ul><li>初始化：半事务消息被生产者构建并完成初始化，待发送到服务端的状态。</li><li>事务待提交：半事务消息被发送到服务端，和普通消息不同，并不会直接被服务端持久化，而是会被单独存储到事务存储系统中，等待第二阶段本地事务返回执行结果后再提交。此时消息对下游消费者不可见。</li><li>消息回滚：第二阶段如果事务执行结果明确为回滚，服务端会将半事务消息回滚，该事务消息流程终止。</li><li>提交待消费：第二阶段如果事务执行结果明确为提交，服务端会将半事务消息重新存储到普通存储系统中，此时消息对下游消费者可见，等待被消费者获取并消费。</li><li>消费中：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。 此时服务端会等待消费者完成消费并提交消费结果，如果一定时间后没有收到消费者的响应，Apache RocketMQ会对消息进行重试处理。具体信息，请参见<a href="https://rocketmq.apache.org/zh/docs/featureBehavior/10consumerretrypolicy">消费重试</a>。</li><li>消费提交：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。 Apache RocketMQ默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。</li><li>消息删除：Apache RocketMQ按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。更多信息，请参见<a href="https://rocketmq.apache.org/zh/docs/featureBehavior/11messagestorepolicy">消息存储和清理机制</a>。</li></ul><h2 id="使用限制"><a href="#使用限制" class="headerlink" title="使用限制"></a>使用限制</h2><p><strong>消息类型一致性</strong></p><p>事务消息仅支持在 MessageType 为 Transaction 的主题内使用，即事务消息只能发送至类型为事务消息的主题中，发送的消息的类型必须和主题的类型一致。</p><p><strong>消费事务性</strong></p><p>Apache RocketMQ 事务消息保证本地主分支事务和下游消息发送事务的一致性，但不保证消息消费结果和上游事务的一致性。因此需要下游业务分支自行保证消息正确处理，建议消费端做好<a href="https://rocketmq.apache.org/zh/docs/featureBehavior/10consumerretrypolicy">消费重试</a>，如果有短暂失败可以利用重试机制保证最终处理成功。</p><p><strong>中间状态可见性</strong></p><p>Apache RocketMQ 事务消息为最终一致性，即在消息提交到下游消费端处理完成之前，下游分支和上游事务之间的状态会不一致。因此，事务消息仅适合接受异步执行的事务场景。</p><p><strong>事务超时机制</strong></p><p>Apache RocketMQ 事务消息的命周期存在超时机制，即半事务消息被生产者发送服务端后，如果在指定时间内服务端无法确认提交或者回滚状态，则消息默认会被回滚。</p><h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><p><strong>创建主题</strong></p><p>Apache RocketMQ 5.0版本下创建主题操作，推荐使用mqadmin工具，需要注意的是，对于消息类型需要通过属性参数添加。示例如下：</p><pre><code class="shell">sh mqadmin updateTopic -n &lt;nameserver_address&gt; -t &lt;topic_name&gt; -c &lt;cluster_name&gt; -a +message.type=Transaction</code></pre><p><strong>发送消息</strong></p><p>事务消息相比普通消息发送时需要修改以下几点：</p><ul><li>发送事务消息前，需要开启事务并关联本地的事务执行。</li><li>为保证事务一致性，在构建生产者时，必须设置事务检查器和预绑定事务消息发送的主题列表，客户端内置的事务检查器会对绑定的事务主题做异常状态恢复。</li></ul><p><strong>创建事务主题</strong></p><p><em>NORMAL类型Topic不支持TRANSACTION类型消息，生产消息会报错。</em></p><pre><code class="bash">./bin/mqadmin updatetopic -n localhost:9876 -t TestTopic -c DefaultCluster -a +message.type=TRANSACTION</code></pre><ul><li>-c 集群名称</li><li>-t Topic名称</li><li>-n nameserver地址</li><li>-a 额外属性，本例给主题添加了<code>message.type</code>为<code>TRANSACTION</code>的属性用来支持事务消息</li></ul><p>以Java语言为例，使用事务消息示例参考如下：</p><pre><code class="java">    //演示demo，模拟订单表查询服务，用来确认订单事务是否提交成功。    private static boolean checkOrderById(String orderId) &#123;        return true;    &#125;    //演示demo，模拟本地事务的执行结果。    private static boolean doLocalTransaction() &#123;        return true;    &#125;    public static void main(String[] args) throws ClientException &#123;        ClientServiceProvider provider = new ClientServiceProvider();        MessageBuilder messageBuilder = new MessageBuilder();        //构造事务生产者：事务消息需要生产者构建一个事务检查器，用于检查确认异常半事务的中间状态。        Producer producer = provider.newProducerBuilder()                .setTransactionChecker(messageView -&gt; &#123;                    /**                     * 事务检查器一般是根据业务的ID去检查本地事务是否正确提交还是回滚，此处以订单ID属性为例。                     * 在订单表找到了这个订单，说明本地事务插入订单的操作已经正确提交；如果订单表没有订单，说明本地事务已经回滚。                     */                    final String orderId = messageView.getProperties().get(&quot;OrderId&quot;);                    if (Strings.isNullOrEmpty(orderId)) &#123;                        // 错误的消息，直接返回Rollback。                        return TransactionResolution.ROLLBACK;                    &#125;                    return checkOrderById(orderId) ? TransactionResolution.COMMIT : TransactionResolution.ROLLBACK;                &#125;)                .build();        //开启事务分支。        final Transaction transaction;        try &#123;            transaction = producer.beginTransaction();        &#125; catch (ClientException e) &#123;            e.printStackTrace();            //事务分支开启失败，直接退出。            return;        &#125;        Message message = messageBuilder.setTopic(&quot;topic&quot;)                //设置消息索引键，可根据关键字精确查找某条消息。                .setKeys(&quot;messageKey&quot;)                //设置消息Tag，用于消费端根据指定Tag过滤消息。                .setTag(&quot;messageTag&quot;)                //一般事务消息都会设置一个本地事务关联的唯一ID，用来做本地事务回查的校验。                .addProperty(&quot;OrderId&quot;, &quot;xxx&quot;)                //消息体。                .setBody(&quot;messageBody&quot;.getBytes())                .build();        //发送半事务消息        final SendReceipt sendReceipt;        try &#123;            sendReceipt = producer.send(message, transaction);        &#125; catch (ClientException e) &#123;            //半事务消息发送失败，事务可以直接退出并回滚。            return;        &#125;        /**         * 执行本地事务，并确定本地事务结果。         * 1. 如果本地事务提交成功，则提交消息事务。         * 2. 如果本地事务提交失败，则回滚消息事务。         * 3. 如果本地事务未知异常，则不处理，等待事务消息回查。         *         */        boolean localTransactionOk = doLocalTransaction();        if (localTransactionOk) &#123;            try &#123;                transaction.commit();            &#125; catch (ClientException e) &#123;                // 业务可以自身对实时性的要求选择是否重试，如果放弃重试，可以依赖事务消息回查机制进行事务状态的提交。                e.printStackTrace();            &#125;        &#125; else &#123;            try &#123;                transaction.rollback();            &#125; catch (ClientException e) &#123;                // 建议记录异常信息，回滚异常时可以无需重试，依赖事务消息回查机制进行事务状态的提交。                e.printStackTrace();            &#125;        &#125;    &#125;</code></pre><h2 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h2><p><strong>避免大量未决事务导致超时</strong></p><p>Apache RocketMQ支持在事务提交阶段异常的情况下发起事务回查，保证事务一致性。但生产者应该尽量避免本地事务返回未知结果。大量的事务检查会导致系统性能受损，容易导致事务处理延迟。</p><p><strong>正确处理”进行中”的事务</strong></p><p>消息回查时，对于正在进行中的事务不要返回Rollback或Commit结果，应继续保持Unknown的状态。 一般出现消息回查时事务正在处理的原因为：事务执行较慢，消息回查太快。解决方案如下：</p><ul><li>将第一次事务回查时间设置较大一些，但可能导致依赖回查的事务提交延迟较大。</li><li>程序能正确识别正在进行中的事务。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内存屏障</title>
      <link href="/2023/06/18/blog17/"/>
      <url>/2023/06/18/blog17/</url>
      
        <content type="html"><![CDATA[<h2 id="初识volatile"><a href="#初识volatile" class="headerlink" title="初识volatile"></a>初识volatile</h2><p>Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。<br>这个概念听起来有些抽象，我们先看下面一个示例：</p><pre><code class="text">package com.zwx.concurrent;public class VolatileDemo &#123;    public static boolean finishFlag = false;    public static void main(String[] args) throws InterruptedException &#123;        new Thread(()-&gt;&#123;            int i = 0;            while (!finishFlag)&#123;                i++;            &#125;        &#125;,&quot;t1&quot;).start();        Thread.sleep(1000);//确保t1先进入while循环后主线程才修改finishFlag        finishFlag = true;    &#125;&#125;</code></pre><p>这里运行之后他t1线程中的while循环是停不下来的，因为我们是在主线程修改了finishFlag的值，而此值对t1线程不可见，如果我们把变量finishFlag加上volatile修饰:</p><pre><code class="text">public static volatile boolean finishFlag = false;</code></pre><p>这时候再去运行就会发现while循环很快就可以停下来了。<br>从这个例子中我们可以知道<strong>volatile可以解决线程间变量可见性问题</strong>。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。</p><h2 id="volatile如何保证可见性"><a href="#volatile如何保证可见性" class="headerlink" title="volatile如何保证可见性"></a>volatile如何保证可见性</h2><p>利用工具hsdis，打印出汇编指令，可以发现，加了volatile修饰之后打印出来的汇编指令多了下面一行：</p><p><img src="/../imgs/blog17/v2-dbb6b3be2159ff96baaf7738422ba37d_720w.webp" alt="img"></p><p>lock是一种控制指令，在多处理器环境下，lock 汇编指令可以基于总线锁或者缓存锁的机制来达到可见性的一个效果。</p><h2 id="可见性的本质"><a href="#可见性的本质" class="headerlink" title="可见性的本质"></a>可见性的本质</h2><h2 id="硬件层面"><a href="#硬件层面" class="headerlink" title="硬件层面"></a>硬件层面</h2><p>线程是CPU调度的最小单元，线程设计的目的最终仍然是更充分的利用计算机处理的效能，但是绝大部分的运算任务不能只依靠处理器“计算”就能完成，处理器还需要与内存交互，比如读取运算数据、存储运算结果，这个 I&#x2F;O 操作是很难消除的。而由于计算机的存储设备与处理器的运算速度差距非常大，所以现代计算机系统都会增加一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存和处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中。<br>查看我们个人电脑的配置可以看到，CPU有L1,L2,L3三级缓存,大致粗略的结构如下图所示:</p><p><img src="/../imgs/blog17/v2-ac2a8ea5a4d6da53a25317de508b93a5_720w.webp" alt="img"></p><p>从上图可以知道，L1和L2缓存为各个CPU独有，而有了高速缓存的存在以后，每个 CPU 的处理过程是，先将计算需要用到的数据缓存在 CPU 高速缓存中，在 CPU进行计算时，直接从高速缓存中读取数据并且在计算完成之后写入到缓存中。在整个运算过程完成后，再把缓存中的数据同步到主内存。<br>由于在多 CPU 中，每个线程可能会运行在不同的 CPU 内，并且每个线程拥有自己的高速缓存。同一份数据可能会被缓存到多个 CPU 中，如果在不同 CPU 中运行的不同线程看到同一份内存的缓存值不一样就会存在缓存不一致的问题，那么怎么解决缓存一致性问题呢？CPU层面提供了两种解决方法：<strong>总线锁</strong>和<strong>缓存锁</strong></p><h2 id="总线锁"><a href="#总线锁" class="headerlink" title="总线锁"></a>总线锁</h2><p>总线锁，简单来说就是，在多CPU下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个 LOCK#信号，这个信号使得其他处理器无法通过总线来访问到共享内存中的数据，总线锁定把 CPU 和内存之间的通信锁住了(CPU和内存之间通过总线进行通讯)，这使得锁定期间，其他处理器不能操作其他内存地址的数据。然而这种做法的代价显然太大，那么如何优化呢？优化的办法就是降低锁的粒度，所以CPU就引入了缓存锁。</p><h2 id="缓存锁"><a href="#缓存锁" class="headerlink" title="缓存锁"></a>缓存锁</h2><p>缓存锁的核心机制是基于缓存一致性协议来实现的，一个处理器的缓存回写到内存会导致其他处理器的缓存无效，IA-32处理器和Intel 64处理器使用MESI实现缓存一致性协议(注意，<strong>缓存一致性协议不仅仅是通过MESI实现的，不同处理器实现了不同的缓存一致性协议</strong>)</p><h2 id="MESI（缓存一致性协议）"><a href="#MESI（缓存一致性协议）" class="headerlink" title="MESI（缓存一致性协议）"></a>MESI（缓存一致性协议）</h2><p>MESI是一种比较常用的缓存一致性协议，MESI表示缓存行的四种状态，分别是：<br>1、M(Modify) 表示共享数据只缓存在当前 CPU 缓存中，并且是被修改状态，也就是缓存的数据和主内存中的数据不一致<br>2、E(Exclusive) 表示缓存的独占状态，数据只缓存在当前CPU缓存中，并且没有被修改<br>3、S(Shared) 表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致<br>4、I(Invalid) 表示缓存已经失效<br>在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且也监听(snoop)其它CPU的读写操作。<br>对于 MESI 协议，从 CPU 读写角度来说会遵循以下原则：<br><strong>CPU读请求</strong>：缓存处于 M、E、S 状态都可以被读取，I 状态CPU 只能从主存中读取数据<br><strong>CPU写请求</strong>：缓存处于 M、E 状态才可以被写。对于S状态的写，需要将其他CPU中缓存行置为无效才行。</p><h2 id="CPU工作流程"><a href="#CPU工作流程" class="headerlink" title="CPU工作流程"></a>CPU工作流程</h2><p>使用总线锁和缓存锁机制之后，CPU 对于内存的操作大概可以抽象成下面这样的结构。从而达到缓存一致性效果：</p><p><img src="/../imgs/blog17/v2-70c17b191e415d8c836f69756ea390c0_720w.webp" alt="img"></p><h2 id="MESI协议带来的问题"><a href="#MESI协议带来的问题" class="headerlink" title="MESI协议带来的问题"></a>MESI协议带来的问题</h2><p>MESI协议虽然可以实现缓存的一致性，但是也会存在一些问题：就是各个CPU缓存行的状态是通过消息传递来进行的。如果CPU0要对一个在缓存中共享的变量进行写入，首先需要发送一个失效的消息给到其他缓存了该数据的 CPU。并且要等到他们的确认回执。CPU0在这段时间内都会处于阻塞状态。为了避免阻塞带来的资源浪费。CPU中又引入了store bufferes：</p><p><img src="/../imgs/blog17/v2-bd53c745fd2151e273a7d5975ac58089_720w.webp" alt="img"></p><p>如上图，CPU0 只需要在写入共享数据时，直接把数据写入到 store bufferes中，同时发送invalidate消息，然后继续去处理其他指令（异步） 当收到其他所有 CPU 发送了invalidate acknowledge消息时，再将store bufferes中的数据数据存储至缓存行中，最后再从缓存行同步到主内存。但是这种优化就会带来了可见性问题，也可以认为是CPU的乱序执行引起的或者说是指令重排序(指令重排序不仅仅在CPU层面存在，编译器层面也存在指令重排序)。<br>我们通过下面一个简单的示例来看一下指令重排序带来的问题。</p><pre><code class="text">package com.zwx.concurrent;public class ReSortDemo &#123;    int value;    boolean isFinish;    void cpu0()&#123;        value = 10;//S-&gt;I状态，将value写入store bufferes，通知其他CPU当前value的缓存失效        isFinish=true;//E状态    &#125;    void cpu1()&#123;        if (isFinish)&#123;//true            System.out.println(value == 10);//可能为false        &#125;    &#125;&#125;</code></pre><p>这时候理论上当isFinish为true时，value也要等于10，然而由于当value修改为10之后，发送消息通知其他CPU还没有收到响应时，当前CPU0继续执行了isFinish&#x3D;true，所以就可能存在isFinsh为true时，而value并不等于10的问题。<br>我们想一想，其实从硬件层面很难去知道软件层面上的这种前后依赖关系，所以没有办法通过某种手段自动去解决，故而CPU层面就提供了内存屏障(Memory Barrier，Intel称之为 Memory Fence),使得软件层面可以决定在适当的地方来插入内存屏障来禁止指令重排序。</p><h2 id="CPU层面的内存屏障"><a href="#CPU层面的内存屏障" class="headerlink" title="CPU层面的内存屏障"></a>CPU层面的内存屏障</h2><p>CPU内存屏障主要分为以下三类：<br>**写屏障(Store Memory Barrier)**：告诉处理器在写屏障之前的所有已经存储在存储缓存(store bufferes)中的数据同步到主内存，简单来说就是使得写屏障之前的指令的结果对写屏障之后的读或者写是可见的。<br>**读屏障(Load Memory Barrier)**：处理器在读屏障之后的读操作,都在读屏障之后执行。配合写屏障，使得写屏障之前的内存更新对于读屏障之后的读操作是可见的。<br>**全屏障(Full Memory Barrier)**：确保屏障前的内存读写操作的结果提交到内存之后，再执行屏障后的读写操作。<br>这些概念听起来可能有点模糊，我们通过将上面的例子改写一下来说明：</p><pre><code class="text">package com.zwx.concurrent;public class ReSortDemo &#123;    int value;    boolean isFinish;    void cpu0()&#123;        value = 10;//S-&gt;I状态，将value写入store bufferes，通知其他CPU当前value的缓存失效        storeMemoryBarrier();//伪代码，插入一个写屏障，使得value=10这个值强制写入主内存        isFinish=true;//E状态    &#125;    void cpu1()&#123;        if (isFinish)&#123;//true            loadMemoryBarrier();//伪代码，插入一个读屏障，强制cpu1从主内存中获取最新数据            System.out.println(value == 10);//true        &#125;    &#125;    void storeMemoryBarrier()&#123;//写屏障    &#125;    void loadMemoryBarrier()&#123;//读屏障    &#125;&#125;</code></pre><p>通过以上内存屏障，我们就可以防止了指令重排序，得到我们预期的结果。<br>总的来说，内存屏障的作用可以通过防止 CPU 对内存的乱序访问来保证共享数据在多线程并行执行下的可见性，但是这个屏障怎么来加呢？回到最开始我们讲 volatile关键字的代码，这个关键字会生成一个 lock 的汇编指令，这个就相当于实现了一种内存屏障。接下来我们进入volatile原理分析的正题</p><h2 id="JVM层面"><a href="#JVM层面" class="headerlink" title="JVM层面"></a>JVM层面</h2><p>在JVM层面，定义了一种抽象的内存模型(JMM)来规范并控制重排序，从而解决可见性问题。</p><h2 id="JMM-Java内存模型"><a href="#JMM-Java内存模型" class="headerlink" title="JMM(Java内存模型)"></a>JMM(Java内存模型)</h2><p>JMM全称是Java Memory Model(Java内存模型),什么是JMM呢？通过前面的分析发现，导致可见性问题的根本原因是缓存以及指令重排序。 而JMM 实际上就是提供了合理的禁用缓存以及禁止重排序的方法。所以<strong>JMM最核心的价值在于解决可见性和有序性</strong>。<br>JMM属于语言级别的抽象内存模型，可以简单理解为对硬件模型的抽象，它定义了共享内存中多线程程序读写操作的行为规范，通过这些规则来规范对内存的读写操作从而保证指令的正确性，它解决了CPU 多级缓存、处理器优化、指令重排序导致的内存访问问题，保证了并发场景下的可见性。<br>需要注意的是，JMM并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序，也就是说在JMM中，也会存在缓存一致性问题和指令重排序问题。只是JMM把底层的问题抽象到JVM层面，再基于CPU层面提供的内存屏障指令，以及限制编译器的重排序来解决并发问题。</p><h2 id="JMM抽象模型结构"><a href="#JMM抽象模型结构" class="headerlink" title="JMM抽象模型结构"></a>JMM抽象模型结构</h2><p>JMM 抽象模型分为主内存、工作内存；主内存是所有线程共享的，一般是实例对象、静态字段、数组对象等存储在堆内存中的变量。工作内存是每个线程独占的，线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量，线程之间的共享变量值的传递都是基于主内存来完成，可以抽象为下图：</p><p><img src="/../imgs/blog17/v2-73fdde2b306840cdba458748dc1092ba_720w.webp" alt="img"></p><h2 id="JMM如何解决可见性问题"><a href="#JMM如何解决可见性问题" class="headerlink" title="JMM如何解决可见性问题"></a>JMM如何解决可见性问题</h2><p>从JMM的抽象模型结构图来看，如果线程A与线程B之间要通信的话，必须要经历下面2个步骤。<br>1）线程A把本地内存A中更新过的共享变量刷新到主内存中去。<br>2）线程B到主内存中去读取线程A之前已更新过的共享变量。<br>下面通过示意图来说明这两个步骤：</p><p><img src="/../imgs/blog17/v2-f7939f8a4fcc07624718f417bf320021_720w.webp" alt="img"></p><p>结合上图，假设初始时，这3个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存 A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内 存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。<strong>JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。</strong></p><h2 id="编译器的指令重排序"><a href="#编译器的指令重排序" class="headerlink" title="编译器的指令重排序"></a>编译器的指令重排序</h2><p>综合上面从硬件层面和JVM层面的分析，我们知道在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型：<br>1）<strong>编译器优化的重排序</strong>。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。<br>2）<strong>指令级并行的重排序</strong>。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。<br>3）<strong>内存系统的重排序</strong>。由于处理器使用缓存和读&#x2F;写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。<br>从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序，如下图：</p><p><img src="/../imgs/blog17/v2-f1f9a499565d9286778775e0d1a502e9_720w.webp" alt="img"></p><p>其中2和3属于处理器重排序(前面硬件层面已经分析过了)。而这些重排序都可能会导致可见性问题（编译器和处理器在重排序时会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序，编译器会遵守happens-before规则和as-if-serial语义）。<br>对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排 序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。<strong>JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证</strong>。正是因为volatile的这个特性，所以单例模式中可以通过volatile关键字来解决双重检查锁(DCL)写法中所存在的问题。</p><h2 id="JMM层面的内存屏障"><a href="#JMM层面的内存屏障" class="headerlink" title="JMM层面的内存屏障"></a>JMM层面的内存屏障</h2><p>在JMM 中把内存屏障分为四类：</p><p><img src="/../imgs/blog17/v2-dd126df57da384b42693fe00c8a85451_720w.webp" alt="img"></p><p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多数处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。</p><h2 id="happens-before规则"><a href="#happens-before规则" class="headerlink" title="happens-before规则"></a>happens-before规则</h2><p>happens-before表示的是前一个操作的结果对于后续操作是可见的，它是一种表达多个线程之间对于内存的可见性。所以我们可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在happens-before关系。这两个操作可以是同一个线程，也可以是不同的线程，如果想详细了解happens-before规则，可以点击这里。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>并发编程中有三大特性：<strong>原子性</strong>、<strong>可见性</strong>、<strong>有序性</strong>，volatile通过内存屏障禁止指令重排序，主要遵循以下三个规则：</p><ol><li>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</li><li>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</li><li>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</li></ol><p>为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略：</p><ul><li><strong>在每个volatile写操作的前面插入一个StoreStore屏障</strong>。</li><li><strong>在每个volatile写操作的后面插入一个StoreLoad屏障</strong>。</li><li><strong>在每个volatile读操作的后面插入一个LoadLoad屏障</strong>。</li><li><strong>在每个volatile读操作的后面插入一个LoadStore屏障</strong>。</li></ul><p>最后需要特别提一下原子性，Java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的写操作具有原子性。当JVM在这种处理器上运行时，可能会把一个64位long&#x2F;double型变量的写操作拆分为两个32位的写操作来执行，这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。<br>锁的语义决定了临界区代码的执行具有原子性。但是因为一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入，所以<strong>即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读&#x2F;写就具有原子性。但是多个volatile操作或类似于i++这种复合操作，这些操作整体上不具有原子性</strong>。针对于复合操作如i++这种，如果要保证原子性，需要通过synchronized关键字或者加其他锁来处理。<br>注意：在JSR-133之前的旧内存模型中，一个64位long&#x2F;double型变量的读&#x2F;写操作可以被拆分为两个32位的读&#x2F;写操作来执行。从JSR-133内存模型开始（即从JDK5开始），仅仅只允许把一个64位long&#x2F;double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR-133中都必须具有原子性（即任意读操作必须要在单个读事务中执行）。</p><blockquote><p>作者：双子孤狼<br>原文链接：<a href="https://link.zhihu.com/?target=https://blog.csdn.net/zwx900102/article/details/106306915">https://blog.csdn.net/zwx900102</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MyBatis的动态SQL实现原理</title>
      <link href="/2023/06/17/blog16/"/>
      <url>/2023/06/17/blog16/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>MyBatis</strong>提供了强大的动态<strong>SQL</strong>语句生成功能，以应对复杂的业务场景，本篇文章将结合<strong>MyBatis</strong>解析<strong>SQL</strong>语句的过程对<strong>MyBatis</strong>中对&lt;<strong>if**&gt;，&lt;**where**&gt;，&lt;**foreach**&gt;等动态</strong>SQL**标签的支持进行分析。</p><p><strong>MyBatis</strong>版本：<strong>3.5.6</strong></p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="一-XML文档中的节点概念"><a href="#一-XML文档中的节点概念" class="headerlink" title="一. XML文档中的节点概念"></a>一. XML文档中的节点概念</h3><p>在分析<strong>MyBatis</strong>如何支持<strong>SQL</strong>语句之前，本小节先分析<strong>XML</strong>文档中的节点概念。<strong>XML</strong>文档中的每个成分都是一个节点，<strong>DOM</strong>对<strong>XML</strong>节点的规定如下所示。</p><ul><li>整个文档是一个<strong>文档节点</strong>；</li><li>每个<strong>XML</strong>标签是一个<strong>元素节点</strong>；</li><li>包含在元素节点中的文本是<strong>文本节点</strong>。</li></ul><p>以一个<strong>XML</strong>文档进行说明，如下所示。</p><pre><code class="xml">xml复制代码&lt;provinces&gt;    &lt;province name=&quot;四川&quot;&gt;        &lt;capital&gt;成都&lt;/capital&gt;    &lt;/province&gt;    &lt;province name=&quot;湖北&quot;&gt;        &lt;capital&gt;武汉&lt;/capital&gt;    &lt;/province&gt;&lt;/provinces&gt;</code></pre><p>如上所示，整个<strong>XML</strong>文档是一个文档节点，这个文档节点有一个子节点，就是&lt;**provinces**&gt;元素节点，&lt;**provinces**&gt;元素节点有五个子节点，分别是：</p><ol><li>文本节点；</li><li>&lt;**province**&gt;元素节点；</li><li>文本节点，</li><li>&lt;**province**&gt;元素节点；</li><li>文本节点。</li></ol><p>注意，在&lt;**provinces**&gt;元素节点的子节点中的文本节点的文本值均是<code>\n</code>，表示换行符。</p><p>同样，&lt;**province**&gt;元素节点有三个子节点，分别是：</p><ol><li>文本节点；</li><li>&lt;**capital**&gt;元素节点；</li><li>文本节点。</li></ol><p>这里的文本节点的文本值也是<code>\n</code>。</p><p>然后&lt;<strong>capital**&gt;元素节点只有一个子节点，为一个文本节点。节点的子节点之间互为兄弟节点，例如&lt;**provinces**&gt;元素的五个子节点之间互为兄弟节点，</strong>name**为”<strong>四川</strong>“的&lt;**province**&gt;元素节点的上一个兄弟节点为文本节点，下一个兄弟节点也为文本节点。</p><h3 id="二-动态SQL解析流程说明"><a href="#二-动态SQL解析流程说明" class="headerlink" title="二. 动态SQL解析流程说明"></a>二. 动态SQL解析流程说明</h3><p>整体的一个解析流程如下所示。</p><p><img src="/../imgs/blog16/1aaaae5311a34af08caa8246cf4e6910tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="Mybatis-动态SQL解析图"></p><p>**也就是写在映射文件中的一条<code>SQL</code>，会最终被解析为<code>DynamicSqlSource</code>或者<code>RawSqlSource</code>，前者表示动态<code>SQL</code>，后者表示静态<code>SQL</code>**。</p><p>上图中的<strong>MixedSqlNode</strong>，其通常的包含关系可以由下图定义。</p><p><img src="/../imgs/blog16/f58a38d43a2b4c6981f8c692011a4355tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="Mybatis-动态SQL组合图"></p><p>也就是映射文件中定义一条<strong>SQL</strong>语句的<strong>CRUD</strong>标签里的各种子元素，均会被解析为一个<strong>SqlNode</strong>，比如包含了<code>$&#123;&#125;</code>的文本，会被解析为<strong>TextSqlNode</strong>，不包含<code>$&#123;&#125;</code>的文本，会被解析为<strong>StaticTextSqlNode</strong>，&lt;<strong>choose**&gt;标签会被解析为</strong>ChooseSqlNode<strong>等，同时又因为&lt;**choose**&gt;标签中会再有&lt;**when**&gt;和&lt;**otherwise**&gt;子标签，所以</strong>ChooseSqlNode<strong>中又会持有这些子标签的</strong>SqlNode**。</p><p><strong>所以一条<code>SQL</code>最终就是由这条<code>SQL</code>对应的<code>CRUD</code>标签解析成的各种<code>SqlNode</code>组合而成</strong>。</p><h3 id="三-MyBatis解析动态SQL源码分析"><a href="#三-MyBatis解析动态SQL源码分析" class="headerlink" title="三. MyBatis解析动态SQL源码分析"></a>三. MyBatis解析动态SQL源码分析</h3><p>在<a href="https://juejin.cn/post/7203925850398883896">详解MyBatis加载映射文件和动态代理</a>中已经知道，在<strong>XMLStatementBuilder</strong>的<strong>parseStatementNode()</strong> 方法中，会解析映射文件中的&lt;<strong>select**&gt;，&lt;**insert**&gt;，&lt;**update**&gt;和&lt;**delete**&gt;标签（后续统一称为</strong>CURD<strong>标签），并生成</strong>MappedStatement<strong>然后缓存到</strong>Configuration**中。</p><p><strong>CURD</strong>标签的解析由<strong>XMLLanguageDriver</strong>完成，每个标签解析之后会生成一个<strong>SqlSource</strong>，可以理解为<strong>SQL</strong>语句，本小节将对<strong>XMLLanguageDriver</strong>如何完成<strong>CURD</strong>标签的解析进行讨论。</p><p><strong>XMLLanguageDriver</strong>创建<strong>SqlSource</strong>的<strong>createSqlSource()</strong> 方法如下所示。</p><pre><code class="java">java复制代码public SqlSource createSqlSource(Configuration configuration,         XNode script, Class&lt;?&gt; parameterType) &#123;    XMLScriptBuilder builder = new XMLScriptBuilder(            configuration, script, parameterType);    return builder.parseScriptNode();&#125;</code></pre><p>如上所示，<strong>createSqlSource()</strong> 方法的入参中，<strong>XNode</strong>就是<strong>CURD</strong>标签对应的节点，在<strong>createSqlSource()</strong> 方法中先是创建了一个<strong>XMLScriptBuilder</strong>，然后通过<strong>XMLScriptBuilder</strong>来生成<strong>SqlSource</strong>。先看一下<strong>XMLScriptBuilder</strong>的构造方法，如下所示。</p><pre><code class="java">java复制代码public XMLScriptBuilder(Configuration configuration, XNode context,                     Class&lt;?&gt; parameterType) &#123;    super(configuration);    this.context = context;    this.parameterType = parameterType;    initNodeHandlerMap();&#125;</code></pre><p>在<strong>XMLScriptBuilder</strong>的构造方法中，主要是将<strong>CURD</strong>标签对应的节点缓存起来，然后初始化<strong>nodeHandlerMap</strong>，<strong>nodeHandlerMap</strong>中存放着处理<strong>MyBatis</strong>提供的支持动态<strong>SQL</strong>的标签的处理器，<strong>initNodeHandlerMap()</strong> 方法如下所示。</p><pre><code class="java">java复制代码private void initNodeHandlerMap() &#123;    nodeHandlerMap.put(&quot;trim&quot;, new TrimHandler());    nodeHandlerMap.put(&quot;where&quot;, new WhereHandler());    nodeHandlerMap.put(&quot;set&quot;, new SetHandler());    nodeHandlerMap.put(&quot;foreach&quot;, new ForEachHandler());    nodeHandlerMap.put(&quot;if&quot;, new IfHandler());    nodeHandlerMap.put(&quot;choose&quot;, new ChooseHandler());    nodeHandlerMap.put(&quot;when&quot;, new IfHandler());    nodeHandlerMap.put(&quot;otherwise&quot;, new OtherwiseHandler());    nodeHandlerMap.put(&quot;bind&quot;, new BindHandler());&#125;</code></pre><p>现在分析<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法，该方法会创建<strong>SqlSource</strong>，如下所示。</p><pre><code class="java">java复制代码public SqlSource parseScriptNode() &#123;    // 解析动态标签    MixedSqlNode rootSqlNode = parseDynamicTags(context);    SqlSource sqlSource;    if (isDynamic) &#123;        // 创建DynamicSqlSource并返回        sqlSource = new DynamicSqlSource(configuration, rootSqlNode);    &#125; else &#123;        // 创建RawSqlSource并返回        sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType);    &#125;    return sqlSource;&#125;</code></pre><p>在<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法中，会根据<strong>XMLScriptBuilder</strong>中的<strong>isDynamic</strong>属性判断是创建<strong>DynamicSqlSource</strong>还是<strong>RawSqlSource</strong>，在这里暂时不分析<strong>DynamicSqlSource</strong>与<strong>RawSqlSource</strong>的区别，但是可以推测在<strong>parseDynamicTags()</strong> 方法中会改变<strong>isDynamic</strong>属性的值，即在<strong>parseDynamicTags()</strong> 方法中会根据<strong>CURD</strong>标签的节点生成一个<strong>MixedSqlNode</strong>，同时还会改变<strong>isDynamic</strong>属性的值以指示当前<strong>CURD</strong>标签中的<strong>SQL</strong>语句是否是动态的。</p><p><strong>MixedSqlNode</strong>是什么，<strong>isDynamic</strong>属性值在什么情况下会变为<strong>true</strong>，带着这些疑问，继续看<strong>parseDynamicTags()</strong> 方法，如下所示。</p><pre><code class="java">java复制代码protected MixedSqlNode parseDynamicTags(XNode node) &#123;    List&lt;SqlNode&gt; contents = new ArrayList&lt;&gt;();    // 获取节点的子节点    NodeList children = node.getNode().getChildNodes();    // 遍历所有子节点    for (int i = 0; i &lt; children.getLength(); i++) &#123;        XNode child = node.newXNode(children.item(i));        if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE                     || child.getNode().getNodeType() == Node.TEXT_NODE) &#123;            // 子节点为文本节点            String data = child.getStringBody(&quot;&quot;);            // 基于文本节点的值并创建TextSqlNode            TextSqlNode textSqlNode = new TextSqlNode(data);            // isDynamic()方法可以判断文本节点值是否有$&#123;&#125;占位符            if (textSqlNode.isDynamic()) &#123;                // 文本节点值有$&#123;&#125;占位符                // 添加TextSqlNode到集合中                contents.add(textSqlNode);                // 设置isDynamic为true                isDynamic = true;            &#125; else &#123;                // 文本节点值没有占位符                // 创建StaticTextSqlNode并添加到集合中                contents.add(new StaticTextSqlNode(data));            &#125;        &#125; else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) &#123;            // 子节点为元素节点            // CURD节点的子节点中的元素节点只可能为&lt;if&gt;，&lt;foreach&gt;等动态Sql标签节点            String nodeName = child.getNode().getNodeName();            // 根据动态Sql标签节点的名称获取对应的处理器            NodeHandler handler = nodeHandlerMap.get(nodeName);            if (handler == null) &#123;                throw new BuilderException(&quot;Unknown element &lt;&quot; + nodeName + &quot;&gt; in SQL statement.&quot;);            &#125;            // 处理动态Sql标签节点            handler.handleNode(child, contents);            // 设置isDynamic为true            isDynamic = true;        &#125;    &#125;    // 创建MixedSqlNode    return new MixedSqlNode(contents);&#125;</code></pre><p>按照正常执行流程调用<strong>parseDynamicTags()</strong> 时，入参是<strong>CURD</strong>标签节点，此时会遍历<strong>CURD</strong>标签节点的所有子节点，基于每个子节点都会创建一个<strong>SqlNode</strong>然后添加到<strong>SqlNode</strong>集合<strong>contents</strong>中，最后将<strong>contents</strong>作为入参创建<strong>MixedSqlNode</strong>并返回。</p><p><strong>SqlNode</strong>是一个接口，在<strong>parseDynamicTags()</strong> 方法中，可以知道，<strong>TextSqlNode</strong>实现了<strong>SqlNode</strong>接口，<strong>StaticTextSqlNode</strong>实现了<strong>SqlNode</strong>接口，所以当节点的子节点是文本节点时，如果文本值包含有<code>$&#123;&#125;</code>占位符，则创建<strong>TextSqlNode</strong>添加到<strong>contents</strong>中并设置<strong>isDynamic</strong>为<strong>true</strong>，如果文本值不包含<code>$&#123;&#125;</code>占位符，则创建<strong>StaticTextSqlNode</strong>并添加到<strong>contents</strong>中。</p><p>如果<strong>CURD</strong>标签节点的子节点是元素节点，由于<strong>CURD</strong>标签节点的元素节点只可能为&lt;<strong>if**&gt;，&lt;**foreach**&gt;等动态</strong>SQL<strong>标签节点，所以直接会设置</strong>isDynamic<strong>为</strong>true<strong>，同时还会调用动态</strong>SQL<strong>标签节点对应的处理器来生成</strong>SqlNode<strong>并添加到</strong>contents<strong>中。这里以&lt;**if**&gt;标签节点对应的处理器的</strong>handleNode()** 方法为例进行说明，如下所示。</p><pre><code class="java">java复制代码public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123;    // 递归调用parseDynamicTags()解析&lt;if&gt;标签节点    MixedSqlNode mixedSqlNode = parseDynamicTags(nodeToHandle);    String test = nodeToHandle.getStringAttribute(&quot;test&quot;);    // 创建IfSqlNode    IfSqlNode ifSqlNode = new IfSqlNode(mixedSqlNode, test);    // 将IfSqlNode添加到contents中    targetContents.add(ifSqlNode);&#125;</code></pre><p>在&lt;<strong>if**&gt;标签节点对应的处理器的</strong>handleNode()** 方法中，递归的调用了<strong>parseDynamicTags()</strong> 方法来解析&lt;<strong>if**&gt;标签节点，例如&lt;**where**&gt;，&lt;**foreach**&gt;等标签节点对应的处理器的</strong>handleNode()** 方法中也会递归调用<strong>parseDynamicTags()</strong> 方法，这是因为这些动态<strong>SQL</strong>标签是可以嵌套使用的，比如&lt;<strong>where**&gt;标签节点的子节点可以为&lt;**if**&gt;标签节点。通过上面的</strong>handleNode()** 方法，大致可以知道<strong>MixedSqlNode</strong>和<strong>IfSqlNode</strong>也实现了<strong>SqlNode</strong>接口，下面看一下<strong>MixedSqlNode</strong>和<strong>IfSqlNode</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class MixedSqlNode implements SqlNode &#123;    private final List&lt;SqlNode&gt; contents;    public MixedSqlNode(List&lt;SqlNode&gt; contents) &#123;        this.contents = contents;    &#125;    @Override    public boolean apply(DynamicContext context) &#123;        contents.forEach(node -&gt; node.apply(context));        return true;    &#125;    &#125;public class IfSqlNode implements SqlNode &#123;    private final ExpressionEvaluator evaluator;    private final String test;    private final SqlNode contents;    public IfSqlNode(SqlNode contents, String test) &#123;        this.test = test;        this.contents = contents;        this.evaluator = new ExpressionEvaluator();    &#125;    @Override    public boolean apply(DynamicContext context) &#123;        if (evaluator.evaluateBoolean(test, context.getBindings())) &#123;            contents.apply(context);            return true;        &#125;        return false;    &#125;&#125;</code></pre><p>其实到这里已经逐渐清晰明了了，按照正常执行流程调用<strong>parseDynamicTags()</strong> 方法时，是为了将<strong>CURD</strong>标签节点的所有子节点根据子节点类型生成不同的<strong>SqlNode</strong>并放在<strong>MixedSqlNode</strong>中，然后将<strong>MixedSqlNode</strong>返回，但是<strong>CURD</strong>标签节点的子节点中如果存在动态<strong>SQL</strong>标签节点，因为这些动态<strong>SQL</strong>标签节点也会有子节点，所以此时会递归的调用<strong>parseDynamicTags()</strong> 方法，以解析动态<strong>SQL</strong>标签节点的子节点，同样会将这些子节点生成<strong>SqlNode</strong>并放在<strong>MixedSqlNode</strong>中然后将<strong>MixedSqlNode</strong>返回，递归调用<strong>parseDynamicTags()</strong> 方法时得到的<strong>MixedSqlNode</strong>会保存在动态<strong>SQL</strong>标签节点对应的<strong>SqlNode</strong>中，比如<strong>IfSqlNode</strong>中就会将递归调用<strong>parseDynamicTags()</strong> 生成的<strong>MixedSqlNode</strong>赋值给<strong>IfSqlNode</strong>的<strong>contents</strong>字段。</p><p>不同的<strong>SqlNode</strong>都是可以包含彼此的，这是<strong>组合设计模式</strong>的应用，<strong>SqlNode</strong>之间的关系如下所示。</p><p><img src="/../imgs/blog16/220c3d1140904b3aafaa40b4206c5740tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="SqlNode类图"></p><p><strong>SqlNode</strong>接口定义了一个方法，如下所示。</p><pre><code class="java">java复制代码public interface SqlNode &#123;    boolean apply(DynamicContext context);&#125;</code></pre><p>每个<strong>SqlNode</strong>的<strong>apply()</strong> 方法中，除了实现自己本身的逻辑外，还会调用自己所持有的所有<strong>SqlNode</strong>的<strong>apply()</strong> 方法，最终逐层调用下去，所有<strong>SqlNode</strong>的<strong>apply()</strong> 方法均会被执行。</p><h3 id="四-DynamicSqlSource和RawSqlSource源码分析"><a href="#四-DynamicSqlSource和RawSqlSource源码分析" class="headerlink" title="四. DynamicSqlSource和RawSqlSource源码分析"></a>四. DynamicSqlSource和RawSqlSource源码分析</h3><p>回到<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法，该方法中会调用<strong>parseDynamicTags()</strong> 方法以解析<strong>CURD</strong>标签节点并得到<strong>MixedSqlNode</strong>，<strong>MixedSqlNode</strong>中含有被解析的<strong>CURD</strong>标签节点的所有子节点对应的<strong>SqlNode</strong>，最后会基于<strong>MixedSqlNode</strong>创建<strong>DynamicSqlSource</strong>或者<strong>RawSqlSource</strong>，如果<strong>CURD</strong>标签中含有动态<strong>SQL</strong>标签或者<strong>SQL</strong>语句中含有<code>$&#123;&#125;</code>占位符，则创建<strong>DynamicSqlSource</strong>，否则创建<strong>RawSqlSource</strong>。下面分别对<strong>DynamicSqlSource</strong>和<strong>RawSqlSource</strong>的实现进行分析。</p><h4 id="1-DynamicSqlSource源码分析"><a href="#1-DynamicSqlSource源码分析" class="headerlink" title="1. DynamicSqlSource源码分析"></a>1. DynamicSqlSource源码分析</h4><p><strong>DynamicSqlSource</strong>的实现如下所示。</p><pre><code class="java">java复制代码public class DynamicSqlSource implements SqlSource &#123;    private final Configuration configuration;    private final SqlNode rootSqlNode;    public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123;        // 构造函数只是进行了简单的赋值操作        this.configuration = configuration;        this.rootSqlNode = rootSqlNode;    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        DynamicContext context = new DynamicContext(configuration, parameterObject);        // 调用SqlNode的apply()方法完成Sql语句的生成        rootSqlNode.apply(context);        // SqlSourceBuilder可以将Sql语句中的#&#123;&#125;占位符替换为?        SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);        Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass();        // 将Sql语句中的#&#123;&#125;占位符替换为?，并生成一个StaticSqlSource        SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings());        // StaticSqlSource中保存有动态生成好的Sql语句，并且#&#123;&#125;占位符全部替换成了?        BoundSql boundSql = sqlSource.getBoundSql(parameterObject);        // 生成有序参数映射列表        context.getBindings().forEach(boundSql::setAdditionalParameter);        return boundSql;    &#125;&#125;</code></pre><p><strong>DynamicSqlSource</strong>的构造函数只是进行了简单的赋值操作，重点在于其<strong>getBoundSql()</strong> 方法，在<strong>getBoundSql()</strong> 方法中，先是调用<strong>DynamicSqlSource</strong>中的<strong>SqlNode</strong>的<strong>apply()</strong> 方法以完成动态<strong>SQL</strong>语句的生成，此时生成的<strong>SQL</strong>语句中的占位符（如果有的话）为<code>#&#123;&#125;</code>，然后再调用<strong>SqlSourceBuilder</strong>的<strong>parse()</strong> 方法将<strong>SQL</strong>语句中的占位符从<code>#&#123;&#125;</code>替换为<code>?</code>并基于替换占位符后的<strong>SQL</strong>语句生成一个<strong>StaticSqlSource</strong>并返回，这里可以看一下<strong>StaticSqlSource</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class StaticSqlSource implements SqlSource &#123;    private final String sql;    private final List&lt;ParameterMapping&gt; parameterMappings;    private final Configuration configuration;    public StaticSqlSource(Configuration configuration, String sql) &#123;        this(configuration, sql, null);    &#125;    public StaticSqlSource(Configuration configuration, String sql,                            List&lt;ParameterMapping&gt; parameterMappings) &#123;        // 构造函数只是进行简单的赋值操作        this.sql = sql;        this.parameterMappings = parameterMappings;        this.configuration = configuration;    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        // 基于Sql语句创建一个BoundSql并返回        return new BoundSql(configuration, sql, parameterMappings, parameterObject);    &#125;&#125;</code></pre><p>所以分析到这里，可以知道<strong>DynamicSqlSource</strong>的<strong>getBoundSql()</strong> 方法实际上会完成动态<strong>SQL</strong>语句的生成和<code>#&#123;&#125;</code>占位符替换，然后基于生成好的<strong>SQL</strong>语句创建<strong>BoundSql</strong>并返回。<strong>BoundSql</strong>对象的类图如下所示。</p><p><img src="/../imgs/blog16/f035a68cdbf943cfa477c26e217baf4dtplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="BoundSql类图"></p><p>实际上，<strong>MyBatis</strong>中执行<strong>SQL</strong>语句时，如果映射文件中的<strong>SQL</strong>使用到了动态<strong>SQL</strong>标签，那么<strong>MyBatis</strong>中的<strong>Executor</strong>（执行器，后续文章中会进行介绍）会调用<strong>MappedStatement</strong>的<strong>getBoundSql()</strong> 方法，然后在<strong>MappedStatement</strong>的<strong>getBoundSql()</strong> 方法中又会调用<strong>DynamicSqlSource</strong>的<strong>getBoundSql()</strong> 方法，所以<strong>MyBatis</strong>中的动态<strong>SQL</strong>语句会在这条语句实际要执行时才会生成。</p><h4 id="2-RawSqlSource源码分析"><a href="#2-RawSqlSource源码分析" class="headerlink" title="2. RawSqlSource源码分析"></a>2. RawSqlSource源码分析</h4><p>现在看一下<strong>RawSqlSource</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class RawSqlSource implements SqlSource &#123;    private final SqlSource sqlSource;    public RawSqlSource(Configuration configuration, SqlNode rootSqlNode, Class&lt;?&gt; parameterType) &#123;        // 先调用getSql()方法获取Sql语句        // 然后再执行构造函数        this(configuration, getSql(configuration, rootSqlNode), parameterType);    &#125;    public RawSqlSource(Configuration configuration, String sql, Class&lt;?&gt; parameterType) &#123;        SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);        Class&lt;?&gt; clazz = parameterType == null ? Object.class : parameterType;        // 将Sql语句中的#&#123;&#125;占位符替换为?，生成一个StaticSqlSource并赋值给sqlSource        sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;&gt;());    &#125;    private static String getSql(Configuration configuration, SqlNode rootSqlNode) &#123;        DynamicContext context = new DynamicContext(configuration, null);        rootSqlNode.apply(context);        return context.getSql();    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        // 实际是调用StaticSqlSource的getBoundSql()方法        return sqlSource.getBoundSql(parameterObject);    &#125;&#125;</code></pre><p><strong>RawSqlSource</strong>会在构造函数中就将<strong>SQL</strong>语句生成好并替换<code>#&#123;&#125;</code>占位符，在<strong>SQL</strong>语句实际要执行时，就直接将生成好的<strong>SQL</strong>语句返回。所以<strong>MyBatis</strong>中，静态<strong>SQL</strong>语句的执行通常要快于动态<strong>SQL</strong>语句的执行，这在<strong>RawSqlSource</strong>类的注释中也有提及，如下所示。</p><blockquote><p><strong>Static SqlSource. It is faster than {@link DynamicSqlSource} because mappings are calculated during startup.</strong></p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>MyBatis</strong>会为映射文件中的每个<strong>CURD</strong>标签节点里的<strong>SQL</strong>语句生成一个<strong>SqlSource</strong>：</p><ol><li>如果是静态<strong>SQL</strong>语句，那么会生成<strong>RawSqlSource</strong>；</li><li>如果是动态<strong>SQL</strong>语句，则会生成<strong>DynamicSqlSource</strong>。</li></ol><p><strong>MyBatis</strong>在生成<strong>SqlSource</strong>时，会为<strong>CURD</strong>标签节点的每个子节点都生成一个<strong>SqlNode</strong>，无论子节点是文本值节点还是动态<strong>SQL</strong>元素节点，最终所有子节点对应的<strong>SqlNode</strong>都会放在<strong>SqlSource</strong>中以供生成<strong>SQL</strong>语句使用。</p><p>如果是静态<strong>SQL</strong>语句，那么在创建<strong>RawSqlSource</strong>时就会使用<strong>SqlNode</strong>完成<strong>SQL</strong>语句的生成以及将<strong>SQL</strong>语句中的<code>#&#123;&#125;</code>占位符替换为<code>?</code>，然后保存在<strong>RawSqlSource</strong>中，等到这条静态<strong>SQL</strong>语句要被执行时，就直接返回这条静态<strong>SQL</strong>语句。</p><p>如果是动态<strong>SQL</strong>语句，在创建<strong>DynamicSqlSource</strong>时只会简单的将<strong>SqlNode</strong>保存下来，等到这条动态<strong>SQL</strong>语句要被执行时，才会使用<strong>SqlNode</strong>完成<strong>SQL</strong>语句的生成以及将<strong>SQL</strong>语句中的<code>#&#123;&#125;</code>占位符替换为<code>?</code>，最后返回<strong>SQL</strong>语句。</p><p><strong>所以<code>MyBatis</code>中，静态<code>SQL</code>语句的获取要快于动态<code>SQL</code>语句</strong>。</p><p>原文链接：<a href="https://juejin.cn/post/7204115174412238907">https://juejin.cn/post/7204115174412238907</a><br>来源：稀土掘金        作者：半夏之沫</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO模型</title>
      <link href="/2023/06/16/blog15/"/>
      <url>/2023/06/16/blog15/</url>
      
        <content type="html"><![CDATA[<p>本文讨论的背景是Linux环境下的network IO。本文最重要的参考文献是Richard Stevens 的 “UNIX? Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I&#x2F;O Models ”，Stevens在这节中详细说明了各种IO的特点和区别，如果英文够好的话，推荐直接阅读。Stevens的文风是有名的深入浅出，所以不用担心看不懂。本文中的流程图也是截取自参考文献。</p><p>Stevens在文章中一共比较了五种IO Model：</p><p>* blocking IO</p><p>* nonblocking IO</p><p>* IO multiplexing</p><p>* signal driven IO</p><p>* asynchronous IO</p><p>由于signal driven IO在实际中并不常用，所以主要介绍其余四种IO Model。</p><p>再说一下IO发生时涉及的对象和步骤。对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：</p><p>1） 等 待 数 据 准 备  (Waiting  for  the  data  to  be   ready) </p><p>2）将数据从内核拷贝到进程中(Copying the data from the kernel to the process)</p><p>记住这两点很重要，因为这些IO模型的区别就是在两个阶段上各有不同的情况。</p><h1 id="1、阻塞IO（blocking-IO）"><a href="#1、阻塞IO（blocking-IO）" class="headerlink" title="1、阻塞IO（blocking IO）"></a>1、阻塞IO（blocking IO）</h1><p>在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：</p><p><img src="/../imgs/blog15/clip_image002.jpg" alt="img"></p><p>当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。</p><p><strong>所以，blocking  IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。</strong></p><p>几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv() 等接口开始的，这些接口都是阻塞型的。使用这些接口可以很方便的构建服务器&#x2F;客户机的模型。下面是一个简单地“一问一答”的服务器。</p><p><img src="/../imgs/blog15/clip_image004.jpg" alt="img"></p><p>我们注意到，大部分的socket接口都是阻塞型的。所谓阻塞型接口是指系统调用（一般是IO接口）不返回调用结果并让当前线程一直阻塞，只有当该系统调用获得结果或者超时出错时才返回。</p><p>实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的。这给网络编程带来了一个很大的问题，如在调用send()的同时，线程将被阻塞，在  此期间，线程将无法执行任何运算或响应任何的网络请求。</p><p>一个简单的改进方案是在服务器端使用多线程（或多进程）。多线程（或多进  程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。具体使用多进程还是多线程，并没有一个特定的模式。</p><p>传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户机提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的CPU资源，譬如需要进行大规模或长时间的数据运算或文件访问，则进程较为安全。**通常，使用pthread_create ()创建新线程，fork()创建新进程。</p><p>我们假设对上述的服务器 &#x2F; 客户机模型，提出更高的要求，即让服务器同时为多个客户机提供一问一答的服务。于是有了如下的模型。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image006.jpg" alt="img"></td></tr></tbody></table><p>在上述的线程 &#x2F; 时间图例中，主线程持续等待客户端的连接请求，如果有连接， 则创建新线程，并在新线程中提供为前例同样的问答服务。</p><p>很多初学者可能不明白为何一个socket可以accept多次。实际上socket的设计者  可能特意为多客户机的情况留留下了伏笔，让accept()能够返回一个新的socket。下面是 accept 接口的原型：</p><pre><code>int accept(int s, struct sockaddr *addr, socklen_t *addrlen);</code></pre><p>输入参数s是从socket()，bind()和listen()中沿用下来的socket句柄值。执行完bind()和listen()后，操作系统已经开始在指定的端口处监听所有的连接请求，如果 有请求，则将该连接请求加入请求队列。调用accept()接口正是从 socket s 的请求队列抽取第一个连接信息，创建一个与s同类的新的socket返回句柄。新的socket 句柄即是后续read()和recv()的输入参数。如果请求队列当前没有请求，则accept() 将进入阻塞状态直到有请求进入队列。</p><p>上述多线程的服务器模型似乎完美的解决了为多个客户机提供问答服务的要   求，但其实并不尽然。如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而线程与进程本身也更容易进入假死状态。</p><p>很多程序员可能会考虑使用线程池或连接池。“线程池”旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。“连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统，如websphere、tomcat和各种数据库等。但是，“线程池”和“连接池”技术也只是在一定程度上缓解了频繁调用IO接口带来的资源占用。而且，所谓“池”始终有其上  限，当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有池的时候效果好多少。所以使用“池”必须考虑其面临的响应规模，并根据响应规模调整“池”的大小。</p><p>对应上例中的所面临的可能同时出现的上千甚至上万次的客户端请求，“线程池”或“连接池”或许可以缓解部分压力，但是不能解决所有问题。总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞接口来尝试解决这个问题。</p><h1 id="2、非阻塞IO（non-blocking-IO）"><a href="#2、非阻塞IO（non-blocking-IO）" class="headerlink" title="2、非阻塞IO（non-blocking IO）"></a>2、非阻塞IO（non-blocking IO）</h1><p>Linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：</p><p><img src="/../imgs/blog15/clip_image008.jpg" alt="img"></p><p>从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ， 它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read 操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call， 那么它马上就将数据拷贝到了用户内存，然后返回。</p><p><strong>所以，在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有。</strong></p><p>非阻塞的接口相比于阻塞型接口的显著差异在于，在被调用之后立即返回。使用如下的函数可以将某句柄fd设为非阻塞状态。</p><pre><code>fcntl( fd, F_SETFL, O_NONBLOCK );</code></pre><p>下面将给出只用一个线程，但能够同时从多个连接中检测数据是否送达，并且接受数据的模型。</p><p><img src="/../imgs/blog15/clip_image010.jpg" alt="img"></p><p>在非阻塞状态下，recv() 接口在被调用后立即返回，返回值代表了不同的含义。如在本例中，</p><p>* recv() 返回值大于 0，表示接受数据完毕，返回值即是接受到的字节数；</p><p>* recv() 返回 0，表示连接已经正常断开；</p><p>* recv() 返回 -1，且 errno 等于 EAGAIN，表示 recv 操作还没执行完成；</p><p>* recv() 返回 -1，且 errno 不等于 EAGAIN，表示 recv 操作遇到系统错误errno。</p><p>可以看到服务器线程可以通过循环调用recv()接口，可以在单个线程内实现对所有连接的数据接收工作。但是上述模型绝不被推荐。因为，循环调用recv()将大幅度推高CPU 占用率；此外，在这个方案中recv()更多的是起到检测“操作是否完成”的作用，实际操作系统提供了更为高效的检测“操作是否完成“作用的接口，例如select()多路复用模式，可以一次检测多个连接是否活跃。</p><h1 id="3、多路复用IO（IO-multiplexing）"><a href="#3、多路复用IO（IO-multiplexing）" class="headerlink" title="3、多路复用IO（IO multiplexing）"></a>3、多路复用IO（IO multiplexing）</h1><p> IO multiplexing这个词可能有点陌生，但是如果我说select&#x2F;epoll，大概就都能明白了。有些地方也称这种IO方式为<strong>事件驱动IO</strong>(event driven IO)。我们都知道， select&#x2F;epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基  本原理就是select&#x2F;epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image012.jpg" alt="img"></td></tr></tbody></table><p>当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所  有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。  这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。</p><p>这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一局：所以，如果处理的连接数不是很高的话，使用select&#x2F;epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select&#x2F;epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）</p><p><strong>在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。</strong>只不过process是被select这个函数block，而不是被socket  IO给block。因此select()与非阻塞IO类似。大部分Unix&#x2F;Linux都支持select函数，该函数用于探测多个文件句柄的状态变化。下面给出select接口的原型：</p><pre><code>FD_ZERO(int fd, fd_set* fds) FD_SET(int fd, fd_set* fds) FD_ISSET(int fd, fd_set* fds) FD_CLR(int fd, fd_set* fds)int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout)</code></pre><p>这里，fd_set 类型可以简单的理解为按 bit 位标记句柄的队列，例如要在某fd_set  中标记一个值为16的句柄，则该fd_set的第16个bit位被标记为1。具体的置位、验证可使用 FD_SET、FD_ISSET等宏实现。在select()函数中，readfds、writefds和exceptfds同时作为输入参数和输出参数。如果输入的readfds标记了16  号句柄，则select()将检测16号句柄是否可读。在select()返回后，可以通过检查readfds有否标记16号句柄，来判断该“可读”事件是否发生。另外，用户可以设置timeout时间。</p><p>下面将重新模拟上例中从多个客户端接收数据的模型。</p><p><img src="/../imgs/blog15/clip_image014.jpg" alt="img"></p><p>该模型只是描述了使用select()接口同时从多个客户端接收数据的过程；由于select()接口可以同时对多个句柄进行读状态、写状态和错误状态的探测，所以可以很容易易构建为多个客户端提供独立问答服务的服务器系统。如下图。</p><p><img src="/../imgs/blog15/clip_image016.jpg" alt="img"></p><p>这里需要指出的是，客户端的一个 connect() 操作，将在服务器端激发一个“可读事件”，所以 select() 也能探测来自客户端的 connect() 行为。</p><p>上述模型中，最关键的地方是如何动态维护select()的三个参数readfds、writefds和exceptfds。作为输入参数，readfds应该标记所有的需要探测的“可读事件”的句柄，其中永远包括那个探测 connect() 的那个“母”句柄；同时，writefds 和exceptfds 应该标记所有需要探测的“可写事件”和“错误事件”的句柄 ( 使用FD_SET() 标记 )。作为输出参数，readfds、writefds和exceptfds中的保存了 select() 捕捉到的所有事件的句柄值。程序员需要检查的所有的标记位 ( 使用FD_ISSET()检查 )，以确定到底哪些句柄发生了事件。</p><p>上述模型主要模拟的是“一问一答”的服务流程，所以如果select()发现某句柄捕捉到了“可读事件”，服务器程序应及时做recv()操作，并根据接收到的数据准备好待发送数据，并将对应的句柄值加入writefds，准备下一次的“可写事件”的select()  探测。同样，如果select()发现某句柄捕捉到“可写事件”，则程序应及时做send()操  作，并准备好下一次的“可读事件”探测准备。下图描述的是上述模型中的一个执行周期。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image018.jpg" alt="img"></td></tr></tbody></table><p>这种模型的特征在于每一个执行周期都会探测一次或一组事件，一个特定的事  件会触发某个特定的响应。我们可以将这种模型归类为“<strong>事件驱动模型</strong>”。</p><p>相比其他模型，使用select() 的事件驱动模型只用单线程（进程）执行，占用资源少，不消耗太多  CPU，同时能够为多客户端提供服务。如果试图建立一个简单的事件驱动的服务器程序，这个模型有一定的参考价值。</p><p>但这个模型依旧有着很多问题。首先select()接口并不是实现“事件驱动”的最好选择。因为当需要探测的句柄值较大时，select()接口本身需要消耗大量量时间去轮询各个句柄。很多操作系统提供了更为高效的接口，如linux提供了epoll，BSD提供了kqueue， Solaris提供了&#x2F;dev&#x2F;poll，…。如果需要实现更高效的服务器程序，类似epoll这样的接口更被推荐。遗憾的是不同的操作系统特供的epoll接口有很大差异，所以使用类似于epoll的接口实现具有较好跨平台能力力的服务器会比较困难。其次，该模型将事件探测和事件响应夹杂在一起，一旦事件响应的执行体庞大，则对整个模型是灾难性的。如下例，庞大的执行体1的将直接导致响应事件2的执行体迟迟得不到执行，并在很大程度上降低了事件探测的及时性。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image020.jpg" alt="img"></td></tr></tbody></table><p>幸运的是，有很多高效的事件驱动库可以屏蔽上述的困难，常见的事件驱动库有<strong>libevent库</strong>，还有作为libevent替代者的<strong>libev库</strong>。这些库会根据操作系统的特点选 择最合适的事件探测接口，并且加入了信号(signal) 等技术以支持异步响应，这使得这些库成为构建事件驱动模型的不二选择。下章将介绍如何使用libev库替换select或epoll接口，实现高效稳定的服务器模型。</p><p>实际上，Linux内核从2.6开始，也引入了支持异步响应的IO操作，如aio_read, aio_write，这就是异步IO。</p><h1 id="4、异步IO（Asynchronous-I-x2F-O）"><a href="#4、异步IO（Asynchronous-I-x2F-O）" class="headerlink" title="4、异步IO（Asynchronous I&#x2F;O）"></a>4、异步IO（Asynchronous I&#x2F;O）</h1><p> Linux下的asynchronous  IO其实用得不多，从内核2.6版本才开始引入。先看一下它的流程：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image022.jpg" alt="img"></td></tr></tbody></table><p>用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据  拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。</p><p>用异步IO实现的服务器这里就不举例了，以后有时间另开文章来讲述。异步IO 是真正非阻塞的，它不会对请求进程产生任何的阻塞，因此对高并发的网络服务器实现至关重要。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>到目前为止，已经将四个IO模型都介绍完了。现在回过头来回答最初的那几个问题：blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪。</p><p>先回答最简单的这个：blocking与non-blocking。前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成， 而non-blocking IO在kernel还在准备数据的情况下会立刻返回。</p><p>在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的：</p><p>* A synchronous I&#x2F;O operation causes the requesting process to be blocked until that I&#x2F;O operation completes;</p><p>* An asynchronous I&#x2F;O operation does not cause the requesting process to be blocked;</p><p><strong>两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。</strong>按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个系统调用。non-blocking   IO在执行recvfrom这个系统调用的时候，如果kernel的数据没有准备好，这时候不会block进程。但是当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内进程是被block的。而asynchronous IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。</p><p>还有一种不常用的signal driven IO，即信号驱动IO。总的来说，UNP中总结的IO模型有5种之多：阻塞IO，非阻塞IO，IO复用，信号驱动IO，异步IO。前四种都属于同步IO。阻塞IO不必说了。非阻塞IO ，IO请求时加上O_NONBLOCK一类的标志位，立刻返回，IO没有就绪会返回错误，需要请求进程主动轮询不断发IO请求直到返回正确。IO复用同非阻塞IO本质一样，不过利利用了新的select系统调用，   由内核来负责本来是请求进程该做的轮询操作。看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才算提高了效率。信号驱动IO，调用sigaltion系统调用，当内核中IO数据就绪时以SIGIO信号通知请求进程，请求进程再把数据从内核读入到用户空间，这一步是阻塞的。异步IO，如定义所说，不会因为IO操作阻塞，IO操作全部完成才通知请求进程。  各个IO Model的比较如图所示：</p><p><img src="/../imgs/blog15/clip_image024.jpg" alt="img"></p><p>经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。</p><p>参考文献：</p><p>IO - 同步，异步，阻塞，非阻塞 ：<a href="http://blog.csdn.net/historyasamirror/article/details/5778378">http://blog.csdn.net/historyasamirror/article/details/5778378 </a></p><p>使用事件驱动模型实现高效稳定的网络服务器程序：<a href="http://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/">http://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/</a></p><p><a href="http://blog.chinaunix.net/uid-28458801-id-4464639.html">http://blog.chinaunix.net/uid-28458801-id-4464639.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从链表中删去总和值为零的连续节点</title>
      <link href="/2023/06/12/blog14/"/>
      <url>/2023/06/12/blog14/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><p><a href="https://leetcode.cn/problems/remove-zero-sum-consecutive-nodes-from-linked-list/description/">1171. 从链表中删去总和值为零的连续节点 - 力扣（Leetcode）</a></p><p>给你一个链表的头节点 <code>head</code>，请你编写代码，反复删去链表中由 <strong>总和</strong> 值为 <code>0</code> 的连续节点组成的序列，直到不存在这样的序列为止。</p><p>删除完毕后，请你返回最终结果链表的头节点。</p><p>你可以返回任何满足题目要求的答案。</p><p>（注意，下面示例中的所有序列，都是对 <code>ListNode</code> 对象序列化的表示。）</p><p><strong>示例 1：</strong></p><pre><code>输入：head = [1,2,-3,3,1]输出：[3,1]提示：答案 [1,2,1] 也是正确的。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：head = [1,2,3,-3,4]输出：[1,2,4]</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：head = [1,2,3,-3,-2]输出：[1]</code></pre><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>若链表节点的两个前缀和相等，说明两个前缀和之间的连续节点序列的和为 0，那么可以消去这部分连续节点。</p><p>我们第一次遍历链表，用哈希表 last记录前缀和以及对应的链表节点，对于同一前缀和s，后面出现的节点覆盖前面的节点。</p><p>接下来，我们再次遍历链表，若当前节点 cur 的前缀和 s在 last出现，说明 cur与 last[s]之间的所有节点和为 0，我们直接修改 cur 的指向，即 <code>cur.next=last[s].next</code>，这样就删去了这部分和为 000 的连续节点。继续往后遍历，删除所有和为 0的连续节点。</p><p>最后返回链表的头节点 <code>dummy.next</code>。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code class="java">class Solution &#123;  public ListNode removeZeroSumSublists(ListNode head) &#123;​    ListNode dummy = new ListNode(0, head);​    Map&lt;Integer, ListNode&gt; last = new HashMap&lt;&gt;();​    int s = 0;​    ListNode cur = dummy;​    while(cur!=null)&#123;​      s+=cur.val;​      last.put(s, cur);​      cur = cur.next;​    &#125;​    s=0;​    cur=dummy;​    while(cur!=null)&#123;​      s+=cur.val;​      cur.next = last.get(s).next;​      cur = cur.next;​    &#125;​    return dummy.next;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>老鼠和奶酪</title>
      <link href="/2023/06/07/blog13/"/>
      <url>/2023/06/07/blog13/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><p><a href="https://leetcode.cn/problems/mice-and-cheese/description/">2611. 老鼠和奶酪 - 力扣（Leetcode）</a></p><p>有两只老鼠和 <code>n</code> 块不同类型的奶酪，每块奶酪都只能被其中一只老鼠吃掉。</p><p>下标为 <code>i</code> 处的奶酪被吃掉的得分为：</p><ul><li>如果第一只老鼠吃掉，则得分为 <code>reward1[i]</code> 。</li><li>如果第二只老鼠吃掉，则得分为 <code>reward2[i]</code> 。</li></ul><p>给你一个正整数数组 <code>reward1</code> ，一个正整数数组 <code>reward2</code> ，和一个非负整数 <code>k</code> 。</p><p>请你返回第一只老鼠恰好吃掉 <code>k</code> 块奶酪的情况下，<strong>最大</strong> 得分为多少。</p><p><strong>示例 1：</strong></p><pre><code>输入：reward1 = [1,1,3,4], reward2 = [4,4,1,1], k = 2输出：15解释：这个例子中，第一只老鼠吃掉第 2 和 3 块奶酪（下标从 0 开始），第二只老鼠吃掉第 0 和 1 块奶酪。总得分为 4 + 4 + 3 + 4 = 15 。15 是最高得分。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：reward1 = [1,1], reward2 = [1,1], k = 2输出：2解释：这个例子中，第一只老鼠吃掉第 0 和 1 块奶酪（下标从 0 开始），第二只老鼠不吃任何奶酪。总得分为 1 + 1 = 2 。2 是最高得分。</code></pre><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>​假设所有的奶酪都被第二只老鼠吃掉，记录下此时得分<code>res</code>。若第<code>i</code>块奶酪被第一只老鼠吃掉，得分变化为<code>reward1[i]-reward2[i]</code>，建立数组reward，其中<code>reward[i]=rewar1d[i]-reward2[i]</code>，并对reward数组排序，res加上reward后k个元素（也就是第一只老鼠吃k块的最大值变化）即为最终结果。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code class="java">class Solution &#123;  public int miceAndCheese(int[] reward1, int[] reward2, int k) &#123;​    int ans = 0;​    int n = reward1.length;​    int[] diffs = new int[n];​    for (int i = 0; i &lt; n; i++) &#123;​      ans += reward2[i];​      diffs[i] = reward1[i] - reward2[i];​    &#125;​    Arrays.sort(diffs);​    for (int i = 1; i &lt;= k; i++) &#123;​      ans += diffs[n - i];​    &#125;​    return ans;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch面试题</title>
      <link href="/2023/06/06/blog12/"/>
      <url>/2023/06/06/blog12/</url>
      
        <content type="html"><![CDATA[<h2 id="1-为什么要使用ElasticSearch"><a href="#1-为什么要使用ElasticSearch" class="headerlink" title="1 为什么要使用ElasticSearch?"></a>1 为什么要使用ElasticSearch?</h2><p>​系统中的数据，随着业务的发展，时间的推移，将会非常多，而业务中往往采用模糊查询进行数据的搜索，而模糊查询会导致查询引擎放弃索引，导致系统查询数据时都是全表扫描，在百万级别的数据库中，查询效率是非常低下的，而我们使用ES做一个全文索引，将经常查询的系统功能的某些字段，比如说电商系统的商品表中商品名，描述、价格还有id这些字段我们放入ES索引库里，可以提高查询速度。</p><h2 id="2-ElasticSearch的master选举流程？"><a href="#2-ElasticSearch的master选举流程？" class="headerlink" title="2 ElasticSearch的master选举流程？"></a>2 ElasticSearch的master选举流程？</h2><p>​ElasticSearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分</p><p>​对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</p><p>​如果对某个节点的投票数达到一定的值（可以成为master节点数n&#x2F;2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。</p><p>​master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</p><h2 id="3-ElasticSearch集群脑裂问题？"><a href="#3-ElasticSearch集群脑裂问题？" class="headerlink" title="3 ElasticSearch集群脑裂问题？"></a>3 ElasticSearch集群脑裂问题？</h2><p><strong>“脑裂”问题可能的成因</strong><strong>:</strong></p><p>​ <strong>网络问题</strong>：集群间的网络延迟导致一些节点访问不到master，认为master挂掉了从而选举出新的master，并对master上的分片和副本标红，分配新的主分片</p><p>​<strong>节点负载</strong>：主节点的角色既为master又为data，访问量较大时可能会导致ES停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。</p><p>​<strong>内存回收</strong>：data节点上的ES进程占用的内存较大，引发JVM的大规模内存回收，造成ES进程失去响应。</p><p><strong>脑裂问题解决方案：</strong></p><p>​<strong>减少误判：</strong>discovery.zen.ping_timeout节点状态的响应时间，默认为3s，可以适当调大，如果master在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如6s，discovery.zen.ping_timeout:6），可适当减少误判。</p><p>​<strong>选举触发</strong>: discovery.zen.minimum_master_nodes:1</p><p>该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值， 且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为（n&#x2F;2）+1，n为主节点个数 （即有资格成为主节点的节点个数）</p><p>​<strong>角色分离</strong>：即master节点与data节点分离，限制角色</p><p>主节点配置为：node.master: true node.data: false</p><p>从节点配置为：node.master: false node.data: true</p><h2 id="4-ElasticSearch索引文档的流程？"><a href="#4-ElasticSearch索引文档的流程？" class="headerlink" title="4 ElasticSearch索引文档的流程？"></a>4 ElasticSearch索引文档的流程？</h2><p><img src="/imgs/blog12/clip_image002.jpg" alt="img"></p><p>​ 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片：</p><p><strong>shard &#x3D; hash(document_id) % (num_of_primary_shards)</strong></p><p>​ 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Memory Buffer到Filesystem Cache的过程就叫做refresh；</p><p>​ 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；</p><p>​在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。</p><p>​flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；</p><h2 id="5-ElasticSearch更新和删除文档的流程？"><a href="#5-ElasticSearch更新和删除文档的流程？" class="headerlink" title="5 ElasticSearch更新和删除文档的流程？"></a>5 ElasticSearch更新和删除文档的流程？</h2><p>​删除和更新也都是写操作，但是ElasticSearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；</p><p>​磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。</p><p>​在新的文档被创建时，ElasticSearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</p><h2 id="6-ElasticSearch搜索的流程？"><a href="#6-ElasticSearch搜索的流程？" class="headerlink" title="6 ElasticSearch搜索的流程？"></a>6 ElasticSearch搜索的流程？</h2><p><img src="/imgs/blog12/clip_image004.jpg" alt="img"></p><p>​ 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；</p><p>​ 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。</p><p>​每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</p><p>​接下来就是取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</p><p>​Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。</p><h2 id="7-ElasticSearch-在部署时，对-Linux-的设置有哪些优化方法？"><a href="#7-ElasticSearch-在部署时，对-Linux-的设置有哪些优化方法？" class="headerlink" title="7 ElasticSearch 在部署时，对 Linux 的设置有哪些优化方法？"></a>7 ElasticSearch 在部署时，对 Linux 的设置有哪些优化方法？</h2><p>​64 GB 内存的机器是非常理想的， 但是32 GB 和16 GB 机器也是很常见的。少于8 GB 会适得其反。</p><p>​如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。</p><p>​如果你负担得起 SSD，它将远远超出任何旋转介质。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起，SSD 是一个好的选择。</p><p>​即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。</p><p>​请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。 在 ElasticSearch 的几个地方，使用 Java 的本地序列化。</p><p>​通过设置gateway.recover_after_nodes、gateway.expected_nodes、gateway.recover_after_time可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。</p><p>​ElasticSearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。最好使用单播代替组播。</p><p>​不要随意修改垃圾回收器（CMS）和各个线程池的大小。</p><p>​把你的内存的（少于）一半给 Lucene（但不要超过 32 GB！），通过ES_HEAP_SIZE 环境变量设置。</p><p>​内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。 再想想那么多 10 微秒的操作时延累加起来。 不难看出 swapping 对于性能是多么可怕。</p><p>​Lucene 使用了大量的文件。同时，ElasticSearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字。 所有这一切都需要足够的文件描述符。你应该增加你的文件描述符，设置一个很大的值，如 64,000。</p><p><strong>补充：索引阶段性能提升方法</strong></p><p>​使用批量请求并调整其大小：每次批量数据 5–15 MB 大是个不错的起始点。</p><p>​存储：使用 SSD</p><p>​段和合并：ElasticSearch 默认值是 20 MB&#x2F;s，对机械磁盘应该是个不错的设置。如果你用的是 SSD，可以考虑提高到 100–200 MB&#x2F;s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。另外还可以增加 index.translog.flush_threshold_size 设置，从默认的 512 MB 到更大一些的值，比如 1 GB，这可以在一次清空触发的时候在事务日志里积累出更大的段。</p><p>​如果你的搜索结果不需要近实时的准确度，考虑把每个索引的index.refresh_interval 改到30s。</p><p>​如果你在做大批量导入，考虑通过设置index.number_of_replicas: 0 关闭副本。</p><h2 id="8-GC方面，在使用ElasticSearch时要注意什么？"><a href="#8-GC方面，在使用ElasticSearch时要注意什么？" class="headerlink" title="8 GC方面，在使用ElasticSearch时要注意什么？"></a>8 GC方面，在使用ElasticSearch时要注意什么？</h2><p>​倒排词典的索引需要常驻内存，无法GC，需要监控data node上segment memory增长趋势。</p><p>​各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小，并且要应该根据最坏的情况来看heap是否够用，也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？避免采用clear cache等“自欺欺人”的方式来释放内存。</p><p>​避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan &amp; scroll api来实现。</p><p>​cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。</p><p>​想知道heap够不够，必须结合实际应用场景，并对集群的heap使用情况做持续的监控。</p><h2 id="9-ElasticSearch对于大数据量（上亿量级）的聚合如何实现？"><a href="#9-ElasticSearch对于大数据量（上亿量级）的聚合如何实现？" class="headerlink" title="9 ElasticSearch对于大数据量（上亿量级）的聚合如何实现？"></a>9 ElasticSearch对于大数据量（上亿量级）的聚合如何实现？</h2><p>ElasticSearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 </p><h2 id="10-在并发情况下，ElasticSearch如果保证读写一致？"><a href="#10-在并发情况下，ElasticSearch如果保证读写一致？" class="headerlink" title="10 在并发情况下，ElasticSearch如果保证读写一致？"></a>10 在并发情况下，ElasticSearch如果保证读写一致？</h2><p>​可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；</p><p>​另外对于写操作，一致性级别支持quorum&#x2F;one&#x2F;all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。</p><p>​对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。</p><h2 id="11-如何监控-ElasticSearch-集群状态？"><a href="#11-如何监控-ElasticSearch-集群状态？" class="headerlink" title="11 如何监控 ElasticSearch 集群状态？"></a>11 如何监控 ElasticSearch 集群状态？</h2><p>​ElasticSearch-head插件</p><p>​通过 Kibana 监控 ElasticSearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标</p><h2 id="12-是否了解字典树？"><a href="#12-是否了解字典树？" class="headerlink" title="12 是否了解字典树？"></a>12 是否了解字典树？</h2><p>​常用字典数据结构如下所示:</p><p><img src="/imgs/blog12/clip_image006.jpg" alt="img"></p><p>​字典树又称单词查找树，<a href="https://baike.baidu.com/item/Trie%E6%A0%91">Trie树</a>，是一种<a href="https://baike.baidu.com/item/%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84/9663807">树形结构</a>，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的<a href="https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6">字符</a>串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。</p><p>​Trie的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有3个基本性质:</p><p>​①根节点不包含字符，除根节点外每一个节点都只包含一个字符。</p><p>​②从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。</p><p>​③每个节点的所有子节点包含的字符都不相同。</p><p>​对于中文的字典树，每个节点的子节点用一个哈希表存储，这样就不用浪费太大的空间，而且查询速度上可以保留哈希的复杂度O(1)。</p><h2 id="13-ElasticSearch中的集群、节点、索引、文档、类型是什么？"><a href="#13-ElasticSearch中的集群、节点、索引、文档、类型是什么？" class="headerlink" title="13 ElasticSearch中的集群、节点、索引、文档、类型是什么？"></a>13 ElasticSearch中的集群、节点、索引、文档、类型是什么？</h2><p>​集群是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“ElasticSearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。</p><p>​节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。</p><p>​索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL &#x3D;&gt;数据库 ElasticSearch &#x3D;&gt;索引</p><p>​文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL &#x3D;&gt; Databases &#x3D;&gt; Tables &#x3D;&gt; Columns &#x2F; Rows ElasticSearch &#x3D;&gt; Indices &#x3D;&gt; Types &#x3D;&gt;具有属性的文档</p><p>​类型是索引的逻辑类别&#x2F;分区，其语义完全取决于用户。</p><h2 id="14-ElasticSearch中的倒排索引是什么？"><a href="#14-ElasticSearch中的倒排索引是什么？" class="headerlink" title="14 ElasticSearch中的倒排索引是什么？"></a>14 ElasticSearch中的倒排索引是什么？</h2><p>​倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。ES中的倒排索引其实就是lucene的倒排索引，区别于传统的正向索引，倒排索引会再存储数据时将关键词和数据进行关联，保存到倒排表中，然后查询时，将查询内容进行分词后在倒排表中进行查询，最后匹配数据即可。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch分片集群</title>
      <link href="/2023/06/06/blog11/"/>
      <url>/2023/06/06/blog11/</url>
      
        <content type="html"><![CDATA[<h2 id="1-分布式集群"><a href="#1-分布式集群" class="headerlink" title="1 分布式集群"></a>1 分布式集群</h2><h3 id="1-1-单节点集群"><a href="#1-1-单节点集群" class="headerlink" title="1.1 单节点集群"></a>1.1 单节点集群</h3><p>我们在包含一个空节点的集群内创建名为 users 的索引，为了演示目的，我们将分配3个主分片和一份副本（每个主分片拥有一个副本分片）</p><p>{</p><p>  “settings” : {</p><p>   “number_of_shards” : 3,</p><p>   “number_of_replicas” : 1</p><p>  }</p><p>}</p><p><img src="/imgs/blog11/clip_image002-16860529743441.jpg" alt="img"></p><p>我们的集群现在是拥有一个索引的单节点集群。所有3个主分片都被分配在 node-1 。</p><p><img src="/imgs/blog11/clip_image004-16860529743442.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image006.jpg" alt="img"></p><p>  集群健康值:yellow( 3 of 6 ) : 表示当前集群的全部主分片都正常运行，但是副本分片没有全部处在正常状态  <img src="/imgs/blog11/clip_image008.jpg" alt="img">: 3个主分片正常  <img src="/imgs/blog11/clip_image010.jpg" alt="img">: 3个副本分片都是  Unassigned —— 它们都没有被分配到任何节点。 在同一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点上的所有副本数据。  </p><p>当前我们的集群是正常运行的，但是在硬件故障时有丢失数据的风险。</p><h3 id="1-2-故障转移"><a href="#1-2-故障转移" class="headerlink" title="1.2 故障转移"></a>1.2 故障转移</h3><p>当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。 但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。</p><p>如果启动了第二个节点，我们的集群将会拥有两个节点的集群 : 所有主分片和副本分片都已被分配</p><p><img src="/imgs/blog11/clip_image012.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image014.jpg" alt="img"></p><p>  集群健康值:green( 6 of 6 ) : 表示所有6个分片（包括3个主分片和3个副本分片）都在正常运行。  <img src="/imgs/blog11/clip_image008.jpg" alt="img">: 3个主分片正常  <img src="/imgs/blog11/clip_image016.jpg" alt="img">: 当第二个节点加入到集群后，3个副本分片将会分配到这个节点上——每个主分片对应一个副本分片。这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。所有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们既可以从主分片又可以从副本分片上获得文档。  </p><h3 id="1-3-水平扩容"><a href="#1-3-水平扩容" class="headerlink" title="1.3 水平扩容"></a>1.3 水平扩容</h3><p>怎样为我们的正在增长中的应用程序按需扩容呢？当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配</p><p><img src="/imgs/blog11/clip_image018.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image020.jpg" alt="img"></p><p>  集群健康值:green( 6 of 6 ) : 表示所有6个分片（包括3个主分片和3个副本分片）都在正常运行。  <img src="/imgs/blog11/clip_image022.jpg" alt="img">  <img src="/imgs/blog11/clip_image024.jpg" alt="img">  <img src="/imgs/blog11/clip_image026.jpg" alt="img">  Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点，现在每个节点上都拥有2个分片，而不是之前的3个。 这表示每个节点的硬件资源（CPU, RAM, I&#x2F;O）将被更少的分片所共享，每个分片的性能将会得到提升。  分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。  </p><p>**<img src="/imgs/blog11/clip_image028.jpg" alt="img"><strong><strong>但是如果我们想要扩容超过6</strong></strong>个节点怎么办呢？**</p><p>主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。</p><p>在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 1 增加到 2</p><p>{</p><p>  “number_of_replicas” : 2</p><p>}</p><p><img src="/imgs/blog11/clip_image030.jpg" alt="img"></p><p>users索引现在拥有9个分片：3个主分片和6个副本分片。 这意味着我们可以将集群扩容到9个节点，每个节点上一个分片。相比原来3个节点时，集群搜索性能可以提升 3 倍。</p><p><img src="/imgs/blog11/clip_image032.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image034.jpg" alt="img"></p><p>当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。</p><p>但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去2个节点的情况下不丢失任何数据。</p><h3 id="1-4-应对故障"><a href="#1-4-应对故障" class="headerlink" title="1.4 应对故障"></a>1.4 应对故障</h3><p>我们关闭第一个节点，这时集群的状态为:关闭了一个节点后的集群。</p><p><img src="/imgs/blog11/clip_image036.jpg" alt="img"><img src="/imgs/blog11/clip_image038.jpg" alt="img"></p><p><img src="/imgs/blog11/clip_image040.jpg" alt="img"></p><p>我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： Node 2 。在我们关闭 Node 1 的同时也失去了主分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。</p><p><img src="/imgs/blog11/clip_image042.jpg" alt="img"></p><p>幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为 yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。</p><p>**<img src="/imgs/blog11/clip_image043.jpg" alt="img">**<strong>为什么我们集群状态是 yellow</strong> <strong>而不是 green</strong> <strong>呢</strong>？ </p><p>虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应2份副本分片，而此时只存在一份副本分片。 所以集群不能为 green 的状态，不过我们不必过于担心：如果我们同样关闭了 Node 2 ，我们的程序 依然 可以保持在不丢任何数据的情况下运行，因为 Node 3 为每一个分片都保留着一份副本。</p><p>如果我们重新启动 Node 1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。 如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是Master节点切换了。</p><p><img src="/imgs/blog11/clip_image045.jpg" alt="img"></p><h2 id="2路由计算"><a href="#2路由计算" class="headerlink" title="2路由计算"></a>2路由计算</h2><p>当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：</p><p><img src="/imgs/blog11/clip_image047.jpg" alt="img"></p><p>routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。</p><p>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</p><p>所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。</p><h2 id="3分片控制"><a href="#3分片控制" class="headerlink" title="3分片控制"></a>3分片控制</h2><p>我们假设有一个集群由三个节点组成。 它包含一个叫 emps 的索引，有两个主分片，每个主分片有两个副本分片。相同分片的副本不会放在同一节点。</p><p><img src="/imgs/blog11/clip_image049.jpg" alt="img"></p><p><img src="/imgs/blog11/clip_image051.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况，所以我们的集群是一个有三个节点和一个索引的集群。</p><p><img src="/imgs/blog11/clip_image053.jpg" alt="img"></p><p>我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 在下面的例子中，将所有的请求发送到 Node 1，我们将其称为 <strong>协调节点</strong>(coordinating node) 。</p><p><img src="/imgs/blog11/clip_image055.jpg" alt="img">：<strong>当发送请求的时候，</strong> <strong>为了扩展负载，更好的做法是轮询集群中所有的节点。</strong></p><h3 id="3-1-写流程"><a href="#3-1-写流程" class="headerlink" title="3.1 写流程"></a>3.1 写流程</h3><p>新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片</p><p><img src="/imgs/blog11/clip_image057.jpg" alt="img"></p><p><strong>新建，索引和删除文档所需要的步骤顺序</strong>：</p><p>\1.     客户端向 Node 1 发送新建、索引或者删除请求。</p><p>\2.     节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。</p><p>\3.     Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。</p><p>在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。</p><p>有一些可选的请求参数允许您影响这个过程，可能以数据安全为代价提升性能。这些选项很少使用，因为Elasticsearch已经很快，但是为了完整起见，请参考下面表格：</p><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>consistency</td><td>consistency，即一致性。在默认设置下，即使仅仅是在试图执行一个_写_操作之前，主分片都会要求 必须要有 规定数量(quorum)（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行_写_操作(其中分片副本可以是主分片或者副本分片)。这是为了避免在发生网络分区故障（network partition）的时候进行_写_操作，进而导致数据不一致。_规定数量_即：  <strong>int( (primary  + number_of_replicas) &#x2F; 2 ) + 1</strong>  consistency 参数的值可以设为 one （只要主分片状态 ok 就允许执行_写_操作）,all（必须要主分片和所有副本分片的状态没问题才允许执行_写_操作）, 或 quorum 。默认值为  quorum , 即大多数的分片副本状态没问题就允许执行_写_操作。  注意，规定数量 的计算公式中 number_of_replicas 指的是在索引设置中的设定副本分片数，而不是指当前处理活动状态的副本分片数。如果你的索引设置中指定了当前索引拥有三个副本分片，那规定数量的计算结果即：  <strong>int( (primary  + 3 replicas) &#x2F; 2 ) + 1 &#x3D; 3</strong>  如果此时你只启动两个节点，那么处于活跃状态的分片副本数量就达不到规定数量，也因此您将无法索引和删除任何文档。</td></tr><tr><td>timeout</td><td>如果没有足够的副本分片会发生什么？ Elasticsearch会等待，希望更多的分片出现。默认情况下，它最多等待1分钟。 如果你需要，你可以使用 timeout 参数 使它更早终止： 100 100毫秒，30s 是30秒。</td></tr></tbody></table><p><img src="/imgs/blog11/clip_image059.jpg" alt="img">新索引默认有 1 个副本分片，这意味着为满足规定数量应该需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当 number_of_replicas 大于1的时候，规定数量才会执行。</p><h3 id="3-2-读流程"><a href="#3-2-读流程" class="headerlink" title="3.2 读流程"></a>3.2 读流程</h3><p>我们可以从主分片或者从其它任意副本分片检索文档</p><p><img src="/imgs/blog11/clip_image061.jpg" alt="img"></p><p><strong>从主分片或者副本分片检索文档的步骤顺序</strong>：</p><p>\1.     客户端向 Node 1 发送获取请求。</p><p>\2.     节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。</p><p>\3.     Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。</p><p>在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p><h3 id="3-3-更新流程"><a href="#3-3-更新流程" class="headerlink" title="3.3 更新流程"></a>3.3 更新流程</h3><p>部分更新一个文档结合了先前说明的读取和写入流程：</p><p><img src="/imgs/blog11/clip_image063.jpg" alt="img"></p><p><strong>部分更新一个文档的步骤如下</strong>：</p><p>\1.     客户端向 Node 1 发送更新请求。</p><p>\2.     它将请求转发到主分片所在的 Node 3 。</p><p>\3.     Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。</p><p>\4.     如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。</p><p>当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果Elasticsearch仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。</p><h3 id="3-4-多文档操作流程"><a href="#3-4-多文档操作流程" class="headerlink" title="3.4 多文档操作流程"></a>3.4 多文档操作流程</h3><p>mget 和 bulk API 的模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成 每个分片 的多文档请求，并且将这些请求并行转发到每个参与节点。</p><p>协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端</p><p><img src="/imgs/blog11/clip_image065.jpg" alt="img"></p><p><strong>用单个 mget</strong> <strong>请求取回多个文档所需的步骤顺序</strong>:</p><p>\1.     客户端向 Node 1 发送 mget 请求。</p><p>\2.     Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。</p><p>可以对 docs 数组中每个文档设置 routing 参数。</p><p><strong>bulk API</strong>， 允许在单个批量请求中执行多个创建、索引、删除和更新请求。</p><p><img src="/imgs/blog11/clip_image067.jpg" alt="img"></p><p>bulk API 按如下步骤顺序执行：</p><p>\1.     客户端向 Node 1 发送 bulk 请求。</p><p>\2.     Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</p><p>\3.     主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud常用组件对比</title>
      <link href="/2023/06/04/blog10/"/>
      <url>/2023/06/04/blog10/</url>
      
        <content type="html"><![CDATA[<h1 id="Eurka和Nacos"><a href="#Eurka和Nacos" class="headerlink" title="Eurka和Nacos"></a>Eurka和Nacos</h1><p>Nacos和Eureka都是服务注册和发现的开源项目，用于构建分布式系统和微服务架构。它们的主要区别如下：</p><h2 id="服务注册和发现机制："><a href="#服务注册和发现机制：" class="headerlink" title="服务注册和发现机制："></a>服务注册和发现机制：</h2><ul><li>Nacos：Nacos提供了基于实例的服务注册和发现机制。服务提供者在启动时向Nacos注册自己的服务实例，并定期发送心跳来保持注册。服务消费者通过向Nacos查询服务列表来发现可用的服务实例。</li><li>Eureka：Eureka采用了基于中心化的服务注册和发现模式。服务提供者在启动时向Eureka注册自己的服务实例，并周期性地发送心跳来保持注册。服务消费者通过向Eureka服务器获取服务注册表来发现可用的服务实例。</li><li>Nacos支持服务端主动检测提供者状态:临时实例采用心跳模式，非临时实例采用主动检测模式临时实例心跳不正常会被剔除，非临时实例则不会被剔除。另外Nacos支持服务列表变更的消息推送模式，服务列表更新更及时</li></ul><h2 id="容错性和高可用性："><a href="#容错性和高可用性：" class="headerlink" title="容错性和高可用性："></a>容错性和高可用性：</h2><ul><li>Nacos：Nacos支持多节点的集群部署，具有高可用性和容错性。它使用Raft算法来保证数据的一致性和可用性，并支持自动的主从切换和故障恢复。</li><li>Eureka：Eureka的设计目标是在AWS云平台上实现高可用性。它使用了主从架构，其中一个Eureka服务器作为主服务器，其他服务器作为从服务器。当主服务器失效时，会触发Eureka客户端的自我保护机制，但这可能导致注册信息的延迟和不一致。</li><li>Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式。Eureka只有AP模式</li></ul><h2 id="配置管理："><a href="#配置管理：" class="headerlink" title="配置管理："></a>配置管理：</h2><ul><li>Nacos：Nacos提供了功能强大的配置管理功能。它支持动态配置的发布、监听和刷新，可以动态地修改配置参数而无需重启服务。Nacos还提供了命名空间、配置组和配置版本等概念，可以对配置进行灵活的管理和隔离。</li><li>Eureka：Eureka本身并没有内置的配置管理功能。如果需要配置管理，可以结合其他的配置中心（如Spring Cloud Config）与Eureka一起使用。</li></ul><h2 id="自我保护机制"><a href="#自我保护机制" class="headerlink" title="自我保护机制"></a>自我保护机制</h2><p>​        相同点: 保护阈值都是个比例，0-1 范围，表示健康的 instance 占全部instance 的比例。<br>​        不同点:<br>​        (1)保护方式不同<br>​        Eureka保护方式:当在短时间内，统计续约失败的比例，如果达到一定阈值，则会触发自我保护的机制，在该机制下Eureka Server不会别除任何的微服务，等到正常后，再退出自我保护机制。自我保护开关(eureka.server.enable-self.preservation. false)<br>​        Nacos保护方式: 当域名健康实例 (nstance) 占总服务实例(nstance)的比例小于阈值时，无论实例(Instance) 是否健康，都会将这个实例 (instance)返回给客户端。这样做虽然损失了一部分流量，但是保证了集群的剩余健康实例(Instance)能正常工作。<br>​        (2)范围不同<br>​        Nacos 的阈值是针对某个具体 Service 的，而不是针对所有服务的。但 Eureka的自我保护阈值是针对所有服务的.</p><h2 id="社区支持和集成："><a href="#社区支持和集成：" class="headerlink" title="社区支持和集成："></a>社区支持和集成：</h2><ul><li>Nacos：Nacos由阿里巴巴开源，得到了广泛的社区支持。它与Spring Cloud紧密集成，并提供了丰富的文档和示例来帮助开发者使用。</li><li>Eureka：Eureka最初由Netflix开发，虽然已经开源并得到了一定的社区支持，但相比Nacos而言，社区支持相对较少。然而，Eureka与Netflix的开源项目（如Ribbon和Hystrix）紧密集成，并在Netflix的生态系统中被广泛应用。</li></ul><h1 id="Hystrix和Sentinel"><a href="#Hystrix和Sentinel" class="headerlink" title="Hystrix和Sentinel"></a>Hystrix和Sentinel</h1><p>​        Sentinel和Hystrix都是用于实现服务容错和熔断的开源项目。 Hystrix 的关注点在于以 <em>隔离</em> 和 <em>熔断</em> 为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。而 Sentinel 的侧重点在于：多样化的流量控制、熔断降级、系统负载保护、实时监控和控制台。</p><h2 id="资源模型和执行模型上的对比"><a href="#资源模型和执行模型上的对比" class="headerlink" title="资源模型和执行模型上的对比"></a>资源模型和执行模型上的对比</h2><p>​        Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象（<code>HystrixCommand</code> &#x2F; <code>HystrixObservableCommand</code>），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。</p><p>​        Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流&#x2F;降级&#x2F;负载保护策略。在 Sentinel 中资源定义和规则配置是分离的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则。埋点方式有两种：</p><ul><li>try-catch 方式（通过 <code>SphU.entry(...)</code>），用户在 catch 块中执行异常处理 &#x2F; fallback</li><li>if-else 方式（通过 <code>SphO.entry(...)</code>），当返回 false 时执行异常处理 &#x2F; fallback</li></ul><p>​        Sentinel 还支持基于注解的资源定义方式，可以通过 <code>@SentinelResource</code> 注解参数指定异常处理函数和 fallback 函数。</p><h2 id="隔离设计上的对比"><a href="#隔离设计上的对比" class="headerlink" title="隔离设计上的对比"></a>隔离设计上的对比</h2><p>​        隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。</p><p>​        但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的线程池会非常影响性能。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。</p><p>​        Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。</p><h2 id="熔断降级对比"><a href="#熔断降级对比" class="headerlink" title="熔断降级对比"></a>熔断降级对比</h2><p>​        Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。</p><h2 id="实时指标统计实现对比"><a href="#实时指标统计实现对比" class="headerlink" title="实时指标统计实现对比"></a>实时指标统计实现对比</h2><p>​        Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功&#x2F;失败&#x2F;超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。</p><p>​        Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 <code>LeapArray</code> 的高性能滑动窗口，后续根据需要可能会引入 reactive stream 等实现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th></th><th>Sentinel</th><th>Hystrix</th></tr></thead><tbody><tr><td>隔离策略</td><td>信号量隔离</td><td>线程池隔离&#x2F;信号量隔离</td></tr><tr><td>熔断降级策略</td><td>基于慢调用比例或异常比例</td><td>基于失败比率</td></tr><tr><td>实时指标实现</td><td>滑动窗口</td><td>滑动窗口（基于 RxJava）</td></tr><tr><td>规则配置</td><td>支持多种数据源</td><td>支持多种数据源</td></tr><tr><td>扩展性</td><td>多个扩展点</td><td>插件的形式</td></tr><tr><td>基于注解的支持</td><td>支持</td><td>支持</td></tr><tr><td>限流</td><td>基于 QPS，支持基于调用关系的限流</td><td>有限的支持</td></tr><tr><td>流量整形</td><td>支持慢启动、匀速排队模式</td><td>不支持</td></tr><tr><td>系统自适应保护</td><td>支持</td><td>不支持</td></tr><tr><td>控制台</td><td>开箱即用，可配置规则、查看秒级监控、机器发现等</td><td>不完善</td></tr><tr><td>常见框架的适配</td><td>Servlet、Spring Cloud、Dubbo、gRPC 等</td><td>Servlet、Spring Cloud Netflix</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hystrix简介</title>
      <link href="/2023/06/03/blog9/"/>
      <url>/2023/06/03/blog9/</url>
      
        <content type="html"><![CDATA[<h1 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h1><p>​Hystrix是一个用于构建弹性和容错系统的Java库，由Netflix开发和维护。它旨在帮助开发者构建具有容错能力的分布式系统，特别是在处理复杂的网络通信时。</p><p>​Hystrix主要解决的问题是在分布式系统中的服务之间进行通信时可能出现的故障和延迟。这些问题可能导致级联故障，即一个服务的故障传递到其他服务，最终导致整个系统不可用。Hystrix通过引入隔离、断路器和回退机制来解决这些问题。</p><p>​隔离是Hystrix的核心概念之一。它通过将每个服务调用封装在独立的线程池中运行，实现了请求的隔离。这样，当某个服务调用失败或延迟较高时，不会对其他服务产生负面影响。</p><p>​断路器是Hystrix的另一个重要概念。它监控服务调用的错误率和延迟情况。当错误率或延迟超过预设的阈值时，断路器会打开，停止对该服务的调用，并快速失败。这样可以防止级联故障，并且当服务恢复正常后，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>此外，Hystrix还提供了回退机制，用于在服务调用失败时提供备选方案。开发者可以定义回退逻辑，当服务调用失败时，Hystrix会自动调用回退逻辑来返回预先定义的备选结果，保证系统的稳定性和可用性。</p><p>​Hystrix还提供了丰富的监控和度量功能，开发者可以实时监控服务调用的成功率、失败率、延迟等指标，并通过配置仪表盘和报警机制来及时发现和处理故障。</p><p>​总而言之，Hystrix是一个弹性和容错库，可以帮助开发者构建可靠的分布式系统。它通过隔离、断路器和回退机制来处理故障和延迟，并提供监控和度量功能来帮助开发者实时了解系统的健康状态。</p><h1 id="Hystrix服务降级"><a href="#Hystrix服务降级" class="headerlink" title="Hystrix服务降级"></a>Hystrix服务降级</h1><p>​Hystrix中的服务降级是指在系统出现故障或异常情况时，为了保证系统的可用性和稳定性，临时替代原本的服务调用，返回一个备选的响应结果。</p><p>​服务降级是通过定义回退逻辑来实现的。在使用Hystrix时，开发者可以为每个服务调用定义一个回退方法（Fallback Method），该方法在服务调用失败或超时时被触发，返回一个备选结果。</p><p>​回退方法的实现应尽量快速且轻量级，避免引入新的故障点。它可以返回一个默认值、预先计算的结果、缓存的数据或静态错误页面等，具体根据业务需求而定。通过合理定义回退逻辑，可以提供用户友好的响应或保证系统的基本功能仍能正常运行。</p><p>​Hystrix提供了多种方式来实现服务降级：</p><ol><li>注解方式：通过在服务调用的方法上添加@HystrixCommand注解，指定回退方法。当服务调用发生异常、超时或熔断时，会触发回退方法。</li><li>编程方式：通过Hystrix提供的命令模式（HystrixCommand）或可观察者模式（HystrixObservableCommand）进行服务调用，并在调用链中指定回退方法。</li><li>信号量隔离：除了使用线程池隔离外，Hystrix还支持信号量隔离，可以在同一线程中执行服务调用和回退方法，减少线程切换和上下文切换的开销。</li></ol><p>通过服务降级，Hystrix可以在服务故障或不可用时，提供一种临时替代方案，保证系统的可用性和稳定性。开发者可以根据具体情况定义合适的回退逻辑，提供良好的用户体验或保持基本功能的正常运行。</p><h1 id="Hystrix服务熔断"><a href="#Hystrix服务熔断" class="headerlink" title="Hystrix服务熔断"></a>Hystrix服务熔断</h1><p>​Hystrix中的服务熔断是一种用于防止故障扩散和快速恢复的机制。当服务调用失败率超过一定阈值时，Hystrix会打开断路器，停止对该服务的调用，并且在一段时间内直接返回预先设定的备选结果，而不去执行实际的服务调用。</p><p>​服务熔断的目的是防止级联故障，当一个服务出现问题时，避免对依赖它的其他服务造成更大的影响。通过断路器的打开，可以快速失败并迅速恢复正常。当断路器处于打开状态时，Hystrix会定期允许一部分流量通过，以便检测服务是否恢复正常。如果服务调用成功率达到一定阈值，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>​Hystrix中的服务熔断通过以下方式实现：</p><ol><li>错误百分比阈值：开发者可以配置一个错误百分比阈值，当在一个统计窗口内的请求错误率超过该阈值时，断路器将打开。</li><li>请求阈值：开发者可以配置一个请求阈值，当在一个统计窗口内的请求数量低于该阈值时，不会触发断路器。这是为了避免在服务启动初期的误判。</li><li>熔断器状态：断路器有三种状态：关闭、打开和半开。初始状态为关闭。当错误百分比超过阈值时，断路器打开；在打开状态下，所有请求都会直接返回备选结果；在一段时间后，断路器进入半开状态，允许一部分流量通过以检测服务的健康状态；如果半开状态下的请求成功，则断路器闭合；否则，重新打开断路器。</li></ol><p>通过服务熔断，Hystrix可以及时停止对不可用的服务的调用，防止故障的扩散，并通过快速失败和自动恢复的机制来提高系统的稳定性和可用性。开发者可以根据具体需求，配置合适的错误百分比阈值和请求阈值，以及定义适当的备选结果，从而保护系统免受不可用服务的影响。</p><h1 id="Hystrix服务限流"><a href="#Hystrix服务限流" class="headerlink" title="Hystrix服务限流"></a>Hystrix服务限流</h1><p>​Hystrix中的服务限流是一种控制系统资源使用的机制，用于保护系统免受过多请求的影响。通过限制对某个服务的并发请求量，可以防止系统资源被过度消耗，确保系统的稳定性和可用性。</p><p>​在Hystrix中，可以通过以下方式来实现服务限流：</p><ol><li>线程池隔离：Hystrix将每个服务调用封装在独立的线程池中运行，通过配置线程池的大小和队列容量，可以限制同时执行的并发请求数量。当线程池满了，新的请求将被拒绝或排队等待。</li><li>信号量隔离：除了线程池隔离外，Hystrix还支持使用信号量来限制并发请求的数量。开发者可以在服务调用的方法上添加@HystrixCommand注解，并指定一个信号量的数量作为参数，从而限制对该服务的并发访问。</li><li>请求队列：线程池隔离模式下，可以设置一个请求队列，用于缓冲未能立即执行的请求。请求队列的大小也可以作为限制并发请求的一种手段。当队列已满时，新的请求将被拒绝。</li></ol><p>​通过配置线程池大小、队列容量和信号量数量，开发者可以根据系统的资源情况和负载情况，灵活地控制并发请求的数量。适当的限流策略可以保护系统免受过载的影响，避免资源耗尽和性能下降。</p><p>​需要注意的是，服务限流只是一种保护机制，不能替代系统的容量规划和性能优化。合理的限流策略应结合实际情况进行调整，以达到最佳的系统性能和用户体验。</p><h1 id="Hystrix工作流程"><a href="#Hystrix工作流程" class="headerlink" title="Hystrix工作流程"></a>Hystrix工作流程</h1><p>​Hystrix的工作流程可以概括为以下几个步骤：</p><ol><li>发起服务调用：应用程序通过调用封装了服务调用的Hystrix命令（HystrixCommand）或可观察者（HystrixObservableCommand）来发起服务调用。这些命令包含了要执行的服务逻辑以及相关的配置信息。</li><li>降级检查：在服务调用之前，Hystrix会检查是否配置了回退逻辑（Fallback），以应对服务调用失败或超时的情况。如果配置了回退逻辑，Hystrix会将其与原始服务调用绑定。</li><li>断路器判断：在发起服务调用之前，Hystrix会检查断路器的状态。如果断路器处于打开状态（Open），Hystrix会立即触发回退逻辑，不会实际发起服务调用。</li><li>服务调用：如果降级检查和断路器判断通过，Hystrix会尝试发起实际的服务调用。根据配置，服务调用可能会在一个独立的线程池中执行，以实现请求隔离。Hystrix还可以通过信号量来控制并发请求数量。</li><li>容错处理：在服务调用过程中，Hystrix会监控请求的结果。如果请求发生故障、超时或异常，Hystrix会根据配置的容错策略执行相应的操作，例如打开断路器、触发回退逻辑等。</li><li>回退逻辑执行：当服务调用失败或超时时，Hystrix会执行与之绑定的回退逻辑。回退逻辑可以是预先定义的备选结果、缓存数据、静态错误页面等，以提供系统的基本功能或友好的用户体验。</li><li>断路器状态更新：根据服务调用的结果，Hystrix会更新断路器的状态。如果服务调用成功，断路器会逐渐闭合；如果服务调用失败或发生故障，断路器会打开，停止对该服务的调用。断路器在一段时间后会尝试半开状态，允许一部分流量通过以检测服务的健康状态。</li></ol><p>​通过以上的工作流程，Hystrix能够提供服务的容错和弹性处理，防止故障的扩散和级联故障的发生。它通过断路器、降级逻辑和线程隔离等机制来保护系统的可用性和稳定性，并提供监控和度量功能来实时了解系统的健康状况。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ribbon、Gateway、Nginx</title>
      <link href="/2023/06/03/blog8/"/>
      <url>/2023/06/03/blog8/</url>
      
        <content type="html"><![CDATA[<h1 id="Ribbon、Gateway、Nginx区别"><a href="#Ribbon、Gateway、Nginx区别" class="headerlink" title="Ribbon、Gateway、Nginx区别"></a>Ribbon、Gateway、Nginx区别</h1><h2 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h2><p>​Ribbon 是一个用于客户端负载均衡的开源项目，最初由 Netflix 开发并开源。它主要用于在分布式系统中选择合适的服务实例并进行负载均衡。</p><p>​在微服务架构中，服务通常以多个实例运行，这些实例可能分布在不同的主机或容器中。Ribbon 可以与服务注册中心（如 Eureka、Consul 等）集成，通过查询注册中心获取可用的服务实例列表。</p><p>​Ribbon 在客户端应用内部工作，作为一个负载均衡组件，它会根据一定的负载均衡策略选择一个合适的服务实例来发送请求。这些负载均衡策略包括轮询、随机、加权随机、最少连接等。选择的服务实例将接收客户端的请求，并将响应返回给客户端。</p><p>​Ribbon 还提供了一些其他功能，如超时设置、重试机制、服务实例健康检查等。它可以根据服务实例的健康状态和负载情况动态地选择合适的实例，以实现负载均衡和故障恢复。</p><p>​Ribbon 的优点是简单轻量、易于集成和扩展。它与多种服务注册中心和开发框架兼容，适用于各种微服务架构中的负载均衡需求。</p><h2 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h2><p>​Gateway是一种在分布式系统中充当入口点的中间层组件。它位于客户端和后端服务之间，负责接收来自客户端的请求，并将请求转发到适当的后端服务进行处理。</p><p>​网关的主要功能包括：</p><ol><li><p>请求路由：网关根据预定义的路由规则将请求路由到相应的后端服务。路由规则可以基于请求的路径、请求方法、请求头等进行匹配和转发。</p></li><li><p>协议转换：网关可以根据需要将请求和响应从一种协议转换为另一种协议。例如，可以将传入的请求从 HTTP 转换为 gRPC，或将响应从 gRPC 转换为 JSON。</p></li><li><p>负载均衡：网关可以实现负载均衡策略，将请求均匀地分发到多个后端服务实例。这可以通过集成服务发现组件（如 Eureka、Consul 等）来实现，并根据服务实例的健康状态和负载情况进行动态选择。</p></li><li><p>安全认证与授权：网关可以提供身份验证和授权功能，保护后端服务免受未经授权的访问。它可以验证请求的身份信息（如令牌、证书等），并根据配置的权限规则控制访问权限。</p></li><li><p>监控与日志记录：网关可以记录请求和响应的日志，并提供监控指标和统计信息，用于系统性能分析、故障排查和流量监控。</p></li><li><p>缓存：网关可以缓存经常请求的响应，以提高系统的响应速度和吞吐量。这可以减少后端服务的负载，并提供更快的响应时间。</p></li></ol><p>​网关在微服务架构中扮演着重要的角色，它提供了一种集中管理和处理请求的方式，简化了客户端和后端服务之间的通信和协调。常见的网关实现包括 Spring Cloud Gateway、Netflix Zuul、Kong 等。这些网关可以与其他微服务组件集成，并提供丰富的功能来支持复杂的系统架构和需求。</p><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><p>​Nginx是一个高性能的开源反向代理服务器、负载均衡器和Web服务器。它具有轻量级、高效率和可扩展性的特点，被广泛应用于构建高性能的Web应用和服务。</p><ol><li><p>反向代理：<br>Nginx作为反向代理服务器，接收客户端请求，并将请求转发到后端服务器。它可以隐藏后端服务器的细节，并提供负载均衡功能，将请求分发到多个后端服务器上，从而提高系统的可用性和性能。</p></li><li><p>负载均衡：<br>Nginx支持多种负载均衡算法，如轮询、IP哈希、最少连接等。它可以根据配置的负载均衡策略将请求均匀地分发到多个后端服务器，以实现负载均衡和故障恢复。</p></li><li><p>静态文件服务：<br>Nginx可以快速高效地提供静态文件的服务，如HTML、CSS、JavaScript、图像文件等。它通过使用异步非阻塞的方式处理请求，以及内置的缓存机制，提供了出色的性能和可扩展性。</p></li><li><p>SSL&#x2F;TLS加密：<br>Nginx支持SSL&#x2F;TLS协议，可以用于配置安全的HTTPS连接，为网站和应用程序提供加密和安全传输的功能。它可以作为SSL终端点，处理与客户端之间的加密通信。</p></li><li><p>动态请求转发：<br>Nginx还可以根据请求的内容或规则将请求转发到不同的后端服务。它支持配置灵活的反向代理规则，根据URL路径、请求头、参数等条件进行请求转发和路由。</p></li><li><p>高性能和可扩展性：<br>Nginx采用事件驱动、非阻塞的架构设计，可以处理大量并发连接和高流量的请求，具有出色的性能表现。它还支持多进程、多线程的部署模式，可以根据需求进行水平扩展。</p></li><li><p>日志记录和监控：<br>Nginx提供详细的访问日志记录，记录请求和响应的信息，便于故障排查和性能优化。它还支持实时监控和统计指标的收集，可以与其他监控工具集成，实现对系统的监控和管理。</p></li></ol><p>​Nginx是一个强大而灵活的服务器软件，广泛应用于Web应用、反向代理、负载均衡、缓存、媒体流服务等多个领域。</p><h2 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a>三者区别</h2><ol><li>功能定位：<ul><li>Gateway: 网关是一个完整的请求路由和代理解决方案，通常用于构建微服务架构中的入口点，负责请求的接收、路由、转发、安全性、监控等。</li><li>Ribbon: Ribbon是一个客户端负载均衡组件，用于在客户端应用内部选择合适的服务实例，主要负责服务实例的选择和负载均衡算法的应用。</li><li>Nginx: Nginx是一个高性能的反向代理服务器，可以作为负载均衡器，接收客户端请求并将其转发到后端服务器，主要负责请求转发和负载均衡算法的实现。</li></ul></li><li>部署位置：<ul><li>Gateway: 网关通常位于整个架构的边界，作为对外的入口点，接收外部请求并路由到内部的服务实例。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，嵌入在客户端应用中，与应用共存于同一个进程内。</li><li>Nginx: Nginx作为反向代理服务器，通常部署在服务器端，位于客户端与后端服务之间，接收客户端请求并将其转发到后端服务器。</li></ul></li><li>负载均衡算法：<ul><li>Gateway: 网关可以结合多种负载均衡算法，如轮询、权重、哈希等，根据不同的路由规则和服务实例情况进行选择。</li><li>Ribbon: Ribbon提供了丰富的负载均衡算法选择，如轮询、随机、加权随机、最少连接等，可以根据需要选择合适的算法。</li><li>Nginx: Nginx也支持多种负载均衡算法，如轮询、IP哈希、最少连接等，可以根据需求进行配置。</li></ul></li><li>扩展性和灵活性：<ul><li>Gateway: 网关通常提供了更多的功能，如认证、授权、监控等，以及自定义路由规则的灵活性，可以根据具体需求进行定制开发。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，对于客户端应用来说，具有更高的扩展性和灵活性，可以根据业务需求进行自定义的负载均衡逻辑实现。</li><li>Nginx: Nginx作为反向代理服务器，可以灵活配置代理规则和负载均衡算法，同时也支持自定义的扩展模块。</li></ul></li></ol><p>​</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​在项目中同时使用到这三者的情况时候，可以这么理解，用户请求进来是先过Nginx网关，这里的Nginx就相当于一个流量网关，是属于用户访问的一个入口。 然后在进入到gateway网关中，这里的getway网关属于一个业务网关，通过对应的属性配置将请求传递到每一个业务微服务中去。而Ribbon负责微服务之间调用时的负载均衡。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>统计范围内的元音字符串数</title>
      <link href="/2023/06/02/blog7/"/>
      <url>/2023/06/02/blog7/</url>
      
        <content type="html"><![CDATA[<h2 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h2><p><a href="https://leetcode.cn/problems/count-vowel-strings-in-ranges/description/">2559. 统计范围内的元音字符串数 - 力扣（Leetcode）</a></p><p>给你一个下标从 <strong>0</strong> 开始的字符串数组 <code>words</code> 以及一个二维整数数组 <code>queries</code> 。</p><p>每个查询 <code>queries[i] = [li, ri]</code> 会要求我们统计在 <code>words</code> 中下标在 <code>li</code> 到 <code>ri</code> 范围内（<strong>包含</strong> 这两个值）并且以元音开头和结尾的字符串的数目。</p><p>返回一个整数数组，其中数组的第 <code>i</code> 个元素对应第 <code>i</code> 个查询的答案。</p><p><strong>注意：</strong>元音字母是 <code>&#39;a&#39;</code>、<code>&#39;e&#39;</code>、<code>&#39;i&#39;</code>、<code>&#39;o&#39;</code> 和 <code>&#39;u&#39;</code> 。</p><p><strong>示例 1：</strong></p><pre><code>输入：words = [&quot;aba&quot;,&quot;bcb&quot;,&quot;ece&quot;,&quot;aa&quot;,&quot;e&quot;], queries = [[0,2],[1,4],[1,1]]输出：[2,3,0]解释：以元音开头和结尾的字符串是 &quot;aba&quot;、&quot;ece&quot;、&quot;aa&quot; 和 &quot;e&quot; 。查询 [0,2] 结果为 2（字符串 &quot;aba&quot; 和 &quot;ece&quot;）。查询 [1,4] 结果为 3（字符串 &quot;ece&quot;、&quot;aa&quot;、&quot;e&quot;）。查询 [1,1] 结果为 0 。返回结果 [2,3,0] 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：words = [&quot;a&quot;,&quot;e&quot;,&quot;i&quot;], queries = [[0,2],[0,1],[2,2]]输出：[3,2,1]解释：每个字符串都满足这一条件，所以返回 [3,2,1] 。</code></pre><h2 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h2><p>​简单啊，直接暴力求解就完了</p><p>​写代码，测试，提交，，，，然后就超时了，，，，emmmmmmmmmm</p><p>​前缀和优化下，通过</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre><code class="java">class Solution &#123;    public int[] vowelStrings(String[] words, int[][] queries) &#123;        Set&lt;Character&gt; vowels = Set.of(&#39;a&#39;, &#39;e&#39;, &#39;i&#39;, &#39;o&#39;, &#39;u&#39;);        int n = words.length;        int[] prefixSums = new int[n + 1];        for (int i = 0; i &lt; n; ++i) &#123;            char a = words[i].charAt(0), b = words[i].charAt(words[i].length() - 1);            if (vowels.contains(a) &amp;&amp; vowels.contains(b)) &#123;                prefixSums[i+1] = prefixSums[i] + 1;            &#125;else&#123;                prefixSums[i+1] = prefixSums[i];            &#125;        &#125;        int q = queries.length;        int[] ans = new int[q];        for (int i = 0; i &lt; q; i++) &#123;            int start = queries[i][0], end = queries[i][1];            ans[i] = prefixSums[end + 1] - prefixSums[start];        &#125;        return ans;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis主从同步</title>
      <link href="/2023/06/02/blog6/"/>
      <url>/2023/06/02/blog6/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis主从同步"><a href="#Redis主从同步" class="headerlink" title="Redis主从同步"></a>Redis主从同步</h1><h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p><p><img src="/../imgs/blog6/image-20210725152222497.png" alt="image-20210725152222497"></p><p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p><p>有几个概念，可以作为判断依据：</p><ul><li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</li><li><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</li></ul><p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p><p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p><p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p><p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p><p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p><p>如图：</p><p><img src="/../imgs/blog6/image-20210725152700914.png" alt="image-20210725152700914"></p><p>完整流程描述：</p><ul><li>slave节点请求增量同步</li><li>master节点判断replid，发现不一致，拒绝增量同步</li><li>master将完整内存数据生成RDB，发送RDB到slave</li><li>slave清空本地数据，加载master的RDB</li><li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li><li>slave执行接收到的命令，保持与master之间的同步</li></ul><h3 id="2-2-2-增量同步"><a href="#2-2-2-增量同步" class="headerlink" title="2.2.2.增量同步"></a>2.2.2.增量同步</h3><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p><p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p><p><img src="/../imgs/blog6/image-20210725153201086.png" alt="image-20210725153201086"></p><p>那么master怎么知道slave与自己的数据差异在哪里呢?</p><h3 id="repl-backlog原理"><a href="#repl-backlog原理" class="headerlink" title="repl_backlog原理"></a>repl_backlog原理</h3><p>master怎么知道slave与自己的数据差异在哪里呢?</p><p>这就要说到全量同步时的repl_baklog文件了。</p><p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p><p>repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p><p><img src="/../imgs/blog6/image-20210725153359022.png" alt="image-20210725153359022"> </p><p>slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。</p><p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p><p><img src="/../imgs/blog6/image-20210725153524190.png" alt="image-20210725153524190"> </p><p>直到数组被填满：</p><p><img src="/../imgs/blog6/image-20210725153715910.png" alt="image-20210725153715910"> </p><p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p><p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset： </p><p><img src="/../imgs/blog6/image-20210725153937031.png" alt="image-20210725153937031"> </p><p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p><p><img src="/../imgs/blog6/image-20210725154155984.png" alt="image-20210725154155984"> </p><p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p><p><img src="/../imgs/blog6/image-20210725154216392.png" alt="image-20210725154216392"></p><h3 id="主从同步优化"><a href="#主从同步优化" class="headerlink" title="主从同步优化"></a>主从同步优化</h3><p>主从同步可以保证主从数据的一致性，非常重要。</p><p>可以从以下几个方面来优化Redis主从就集群：</p><ul><li>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。</li><li>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</li><li>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</li><li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</li></ul><p>主从从架构图：</p><p><img src="/../imgs/blog6/image-20210725154405899.png" alt="image-20210725154405899"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>简述全量同步和增量同步区别？</p><ul><li>全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。</li><li>增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave</li></ul><p>什么时候执行全量同步？</p><ul><li>slave节点第一次连接master节点时</li><li>slave节点断开时间太久，repl_baklog中的offset已经被覆盖时</li></ul><p>什么时候执行增量同步？</p><ul><li>slave节点断开又恢复，并且在repl_baklog中能找到offset时</li></ul><p>转载自：黑马程序员Redis教程（【黑马程序员Redis入门到实战教程，深度透析redis底层原理+redis分布式锁+企业解决方案+黑马点评实战项目】 <a href="https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web%EF%BC%89">https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web）</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>礼盒的最大甜蜜度</title>
      <link href="/2023/06/01/blog5/"/>
      <url>/2023/06/01/blog5/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/"><a href="https://leetcode.cn/problems/maximum-tastiness-of-candy-basket/description/">2517. 礼盒的最大甜蜜度 - 力扣（Leetcode）</a></a></p><p>​给你一个正整数数组 <code>price</code> ，其中 <code>price[i]</code> 表示第 <code>i</code> 类糖果的价格，另给你一个正整数 <code>k</code> 。</p><p>商店组合 <code>k</code> 类 <strong>不同</strong> 糖果打包成礼盒出售。礼盒的 <strong>甜蜜度</strong> 是礼盒中任意两种糖果 <strong>价格</strong> 绝对差的最小值。</p><p>返回礼盒的 <strong>最大</strong> 甜蜜度<em>。</em></p><p><strong>示例 1：</strong></p><pre><code>输入：price = [13,5,1,8,21,2], k = 3输出：8解释：选出价格分别为 [13,5,21] 的三类糖果。礼盒的甜蜜度为 min(|13 - 5|, |13 - 21|, |5 - 21|) = min(8, 8, 16) = 8 。可以证明能够取得的最大甜蜜度就是 8 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：price = [1,3,1], k = 2输出：2解释：选出价格分别为 [1,3] 的两类糖果。 礼盒的甜蜜度为 min(|1 - 3|) = min(2) = 2 。可以证明能够取得的最大甜蜜度就是 2 。</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：price = [7,7,7,7], k = 2输出：0解释：从现有的糖果中任选两类糖果，甜蜜度都会是 0 。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​最小最大，基本要想到二分了，直接二分甜蜜值，因为选择的差值跟顺序无关，我们可以排序后贪心，当前选择大于之前选择加甜蜜值就统计答案一次，如果最终次数大于等于tastiness，说明甜蜜值还可以更大，收缩左边界，否则收缩右边界。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int maximumTastiness(int[] price, int k) &#123;​    Arrays.sort(price);​    int left = 0, right = price[price.length - 1];​    while (left +1 != right) &#123;​      int mid = (left + right) / 2;​      if (check(price, k, mid)) &#123;​        left = mid;​      &#125; else &#123;​        right = mid;​      &#125;​    &#125;​    return left;  &#125;  public boolean check(int[] price, int k, int tastiness) &#123;​    int prev = Integer.MIN_VALUE / 2;​    int cnt = 0;​    for (int p : price) &#123;​      if (p - prev &gt;= tastiness) &#123;​        cnt++;​        prev = p;​      &#125;​    &#125;​    return cnt &gt;= k;  &#125;&#125;</code></pre><p>甜蜜的祝自己节日快乐</p>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么Redis集群分片最大槽数是16384个</title>
      <link href="/2023/06/01/blog4/"/>
      <url>/2023/06/01/blog4/</url>
      
        <content type="html"><![CDATA[<h4 id="为什么Redis集群分片最大槽数是16384个？"><a href="#为什么Redis集群分片最大槽数是16384个？" class="headerlink" title="为什么Redis集群分片最大槽数是16384个？"></a>为什么Redis集群分片最大槽数是16384个？</h4><p>​GitHub上已有关于这个问题的解答，<a href="https://github.com/redis/redis/issues/2576">why redis-cluster use 16384 slots? · Issue #2576 · redis&#x2F;redis (github.com)</a>，这里只做大概解释</p><p>​Redis集群通过CRC16算法对key进行哈希并对16384取模来决定该key具体放在哪个槽位，而该算法的hash结果有16位，也就是65536个值，那为啥不分配65536个槽而是16384（2^14）个？</p><p>​首先翻译一下作者的解答：</p><p>​正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间(使用65K的插槽)。同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot &#x2F; N位占设置位的很大百分比。</p><p>​翻译了又好像没翻译，还是没看懂，，，</p><p>​其实总结起来就是以下三个因素的考虑。</p><p>（1）如果槽位个数为65536，发送的心跳信息头达到8k，发送的心跳包过大。</p><p><img src="/imgs/blog4/image-20230601095147944.png"></p><p>上图即为Redis节点发送的信息头结构，其中占据最大空间的就是myslots[CLUSTER_SLOTS&#x2F;8]。如果槽位为65536个，大小为65536 &#x2F; 8 &#x2F; 1024 &#x3D; 8 kb。如果槽位为16384个，大小为16384 &#x2F; 8 &#x2F; 1024 &#x3D; 2 kb。在Redis集群中，Redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536个，发送的消息头太大，浪费带宽。</p><p>（2）Redis的集群主节点数量基本不可能超过1000个，16384个槽位已经够用<br>集群节点越多，心跳包的消息体内携带的数据越多。如果节点超过1000个，也会导致网络拥堵。因此Redis作者不建议Redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。</p><p>（3）节点一定的情况下，槽位越少，压缩比越高，容易传输<br>Redis主节点的配置信息中它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中会对bitmap进行压缩，但是如果bitmap的填充率slots &#x2F;N很高的话(N表示节点数)，bitmap的压缩率就很低。也就是说当节点数一定时，哈希槽数量很多的话，bitmap的压缩率就很低，不易传输。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无重复字符的最长子串</title>
      <link href="/2023/05/31/blog3/"/>
      <url>/2023/05/31/blog3/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/">3. 无重复字符的最长子串 - 力扣（Leetcode）</a></p><p>​给定一个字符串 <code>s</code> ，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。</p><p><strong>示例 1:</strong></p><pre><code>输入: s = &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: s = &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。</code></pre><p><strong>示例 3:</strong></p><pre><code>输入: s = &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。     请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​没啥好说的，一眼滑动窗口。。。</p><p>​以示例1为例，对于“abcabcbb”，定义两个指针（ left 和 right ），初始都指向字符串0位置，两个指针之间的字符串即为当前找到的子串，right指针向右遍历，使用hashmap记录出现过的字符和字符最后一次出现的位置，当前字串出现重复字符时（即hashmap中存在当前right指向的字符），将left指针移动到重复字符的下一个位置即可（map.get(s.charAt(i)) + 1），遍历过程中记录字串长度最大值。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int lengthOfLongestSubstring(String s) &#123;​    if (s.length() &lt;=  1)&#123;​      return s.length();​    &#125;​    HashMap&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;();​    int ans = 0;​    int left = 0;​    for(int i = 0; i &lt; s.length(); i++)&#123;​      if(map.containsKey(s.charAt(i)))&#123;​        left = Math.max(left, map.get(s.charAt(i)) + 1);​      &#125;​      map.put(s.charAt(i), i);​      ans = Math.max(ans, i-left+1);​    &#125;​    return ans;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引失效情况</title>
      <link href="/2023/05/31/blog2/"/>
      <url>/2023/05/31/blog2/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL索引失效"><a href="#MySQL索引失效" class="headerlink" title="MySQL索引失效"></a>MySQL索引失效</h1><p>​简单介绍下几种MySQL索引失效的常见情况。</p><h3 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1.数据准备"></a>1.数据准备</h3><p>​首先准备一张数据表user_info并建立索引</p><pre><code class="mysql">`CREATE TABLE `user_info` ( `id` int(8) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;, `number` varchar(12) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;编号&#39;, `username` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;用户名&#39;, `age` int(11) DEFAULT NULL COMMENT &#39;年龄&#39;, `birthday` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &#39;生日&#39;, PRIMARY KEY (`id`), KEY `union_idx` (`number`,`username`,`age`), KEY `create_time_idx` (`birthday`) );`</code></pre><p>该表包含3个索引：</p><p>主键：id</p><p>联合索引：number、username、age</p><p>普通索引：birthday</p><p>然后插入一些数据</p><pre><code class="mysql">INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1244&#39;, &#39;Mercury&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3546&#39;, &#39;Diana&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1124&#39;, &#39;Mars&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6426&#39;, &#39;Saturn&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3525&#39;, &#39;Eureka&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;5245&#39;, &#39;Mercury1&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3235246&#39;, &#39;Diana1&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6346&#39;, &#39;Mars1&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;623461&#39;, &#39;Saturn1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;235&#39;, &#39;Eureka1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;11244&#39;, &#39;Mercury3&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;13546&#39;, &#39;Diana3&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;112244&#39;, &#39;Mars3&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;643126&#39;, &#39;Saturn3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;35215&#39;, &#39;Eureka3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;52145&#39;, &#39;Mercury4&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;32235246&#39;, &#39;Diana4&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6332446&#39;, &#39;Mars4&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6231461&#39;, &#39;Saturn4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;231115&#39;, &#39;Eureka4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);</code></pre><p>注：测试MySQL版本为8.0.28</p><h3 id="2-案例测试"><a href="#2-案例测试" class="headerlink" title="2.案例测试"></a>2.案例测试</h3><h4 id="2-1-联合索引不满足最左匹配原则"><a href="#2-1-联合索引不满足最左匹配原则" class="headerlink" title="2.1 联合索引不满足最左匹配原则"></a>2.1 联合索引不满足最左匹配原则</h4><p>​最左前缀匹配原则：在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左列开始匹配。如本例中联合索引（number，username，age），若想查询走该索引，查询条件中应出现最左边的列，即number。</p><p>测试1：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39;;</code></pre><p>运行结果：</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%951.png"></p><p>key为“union_idx”说明查询走了联合索引。</p><p>测试2：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39; and age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%952.png"></p><p>测试2结果中‘key_len’与测试1相同，说明该查询虽然走了联合索引，但因未满足最左匹配原则（查询条件中未出现username），导致username之后的联合索引失效。若number使用范围查询如number&gt;‘1244’，后面的查询条件即使有username也不会生效，这里不做测试。</p><p>但是where后面查询列出现顺序不会影响索引，如</p><p>测试3：</p><pre><code class="mysql">explain select * from user_info where username = &#39;Mercury&#39; and number = &#39;1244&#39;;explain select * from user_info where number = &#39;1244&#39; and username = &#39;Mercury&#39;;</code></pre><p>上面两条语句‘ken_len’相同</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%953.png" alt="image-20230531203957562"></p><h4 id="2-2-索引列使用数学运算"><a href="#2-2-索引列使用数学运算" class="headerlink" title="2.2 索引列使用数学运算"></a>2.2 索引列使用数学运算</h4><p>测试4：</p><pre><code class="mysql">explain select * from user_info where id + 1 = 2;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%954.png"></p><p>查询类型为全表扫面，并未使用索引</p><h4 id="2-3-隐式类型转换"><a href="#2-3-隐式类型转换" class="headerlink" title="2.3 隐式类型转换"></a>2.3 隐式类型转换</h4><p>测试5：</p><pre><code class="mysql">explain select * from user_info where number = 1244;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%955.png" alt="测试5"></p><p>number字段为varchar类型，而查询条件为int，类型不匹配导致索引失效。</p><h4 id="2-4模糊查询以-开头"><a href="#2-4模糊查询以-开头" class="headerlink" title="2.4模糊查询以%开头"></a>2.4模糊查询以%开头</h4><p>测试6：</p><pre><code class="mysql">explain select * from user_info where number like &#39;%2&#39;;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%956.png" alt="测试6"></p><h4 id="2-5-使用or"><a href="#2-5-使用or" class="headerlink" title="2.5 使用or"></a>2.5 使用or</h4><p>测试7：</p><pre><code class="mysql">explain select * from user_info where id = 1 or age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%957.png" alt="测试7"></p><p>age列无索引，导致前面id列索引失效。使用or时切记两边查询条件都要有索引。</p><h4 id="2-6索引列使用函数"><a href="#2-6索引列使用函数" class="headerlink" title="2.6索引列使用函数"></a>2.6索引列使用函数</h4><p>测试8：</p><p>explain select * from user_info where SUBSTR(number, 2,3) &#x3D; ‘12’;</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%958.png" alt="测试8"></p><h4 id="2-7两列作比较或者运算"><a href="#2-7两列作比较或者运算" class="headerlink" title="2.7两列作比较或者运算"></a>2.7两列作比较或者运算</h4><p>测试9：</p><pre><code class="mysql">explain select * from user_info where id &lt; age;explain select * from user_info where id + age = 25;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%959.png" alt="测试9"></p><h4 id="2-8其他"><a href="#2-8其他" class="headerlink" title="2.8其他"></a>2.8其他</h4><p>​使用不等于&lt;&gt;，not in， not exists， is not null 以及MySQL优化器认为走全表扫描效率更高的查询。好累啊不想做测试了，开摆。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化</title>
      <link href="/2023/05/31/blog1/"/>
      <url>/2023/05/31/blog1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Redis持久化"><a href="#1-Redis持久化" class="headerlink" title="1.Redis持久化"></a>1.Redis持久化</h1><p>Redis有两种持久化方案：</p><ul><li>RDB持久化</li><li>AOF持久化</li></ul><h2 id="1-1-RDB"><a href="#1-1-RDB" class="headerlink" title="1.1.RDB"></a>1.1.RDB</h2><p>RDB全称Redis Database Backup file（Redis数据备份文件），RDB其实就是把数据以快照的形式保存在磁盘上。什么是快照呢，你可以理解成把当前时刻的数据拍成一张照片保存下来。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。</p><h3 id="1-1-1-RDB执行"><a href="#1-1-1-RDB执行" class="headerlink" title="1.1.1.RDB执行"></a>1.1.1.RDB执行</h3><p>RDB持久化在四种情况下会执行：</p><ul><li>执行save命令</li><li>执行bgsave命令</li><li>Redis停机时</li><li>触发RDB条件时</li></ul><p><strong>1）save命令</strong></p><p>save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。</p><p><strong>2）bgsave命令</strong></p><p>bgsave命令执行后Redis执行fork操作创建子进程完成RDB，主进程可以继续处理用户请求，不会阻塞。</p><p><strong>3）停机时</strong></p><p>Redis停机时会执行一次save命令，实现RDB持久化。</p><p><strong>4）触发RDB条件</strong></p><p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p><pre><code class="properties"># 下面的配置代表600秒内如果至少有10个key被修改，则执行bgsavesave 600 10  </code></pre><p>RDB的其它配置也可以在redis.conf文件中设置：</p><pre><code class="properties"># 是否进行压缩（会耗费cpu资源）rdbcompression yes# RDB文件保存名称（默认为dump.rdb）dbfilename dump.rdb  </code></pre><h3 id="1-1-2-RDB原理"><a href="#1-1-2-RDB原理" class="headerlink" title="1.1.2.RDB原理"></a>1.1.2.RDB原理</h3><p>bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。</p><p>fork采用的是copy-on-write技术：</p><ul><li>当主进程执行读操作时，访问共享内存；</li><li>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</li></ul><p><img src="/imgs/blog1/image-20210725151319695-16855170885551.png"></p><h2 id="1-2-AOF"><a href="#1-2-AOF" class="headerlink" title="1.2.AOF"></a>1.2.AOF</h2><h3 id="1-2-1-AOF原理"><a href="#1-2-1-AOF原理" class="headerlink" title="1.2.1.AOF原理"></a>1.2.1.AOF原理</h3><p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。</p><h3 id="1-2-2-AOF配置"><a href="#1-2-2-AOF配置" class="headerlink" title="1.2.2.AOF配置"></a>1.2.2.AOF配置</h3><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p><pre><code class="properties"># 是否开启AOF功能，默认是noappendonly yes</code></pre><p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p><pre><code class="properties"># 每执行一次写命令，立即记录appendfsync always # 每隔1秒将缓冲区数据写到AOF文件（默认）appendfsync everysec # 由操作系统决定何时将缓冲区内容写回磁盘appendfsync no</code></pre><p>三种策略对比：</p><p><img src="/imgs/blog1/image-20210725151654046-16855171063852.png"></p><h3 id="1-2-3-AOF文件重写"><a href="#1-2-3-AOF文件重写" class="headerlink" title="1.2.3.AOF文件重写"></a>1.2.3.AOF文件重写</h3><p>AOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。</p><p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p><pre><code class="properties"># AOF文件相比上次增长超过多少百分比则触发bgrewriteaofauto-aof-rewrite-percentage 100# AOF文件达到一定大小触发bgrewriteaofauto-aof-rewrite-min-size 64mb </code></pre><p>重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。</p><h2 id="1-3-RDB与AOF对比"><a href="#1-3-RDB与AOF对比" class="headerlink" title="1.3.RDB与AOF对比"></a>1.3.RDB与AOF对比</h2><p>RDB和AOF各有优缺点，在实际开发中一般会<strong>结合</strong>两者来使用。</p><p><img src="/imgs/blog1/image-20210725151940515-16855171206073.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
