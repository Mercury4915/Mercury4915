<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>SpringCloud常用组件对比</title>
      <link href="/2023/06/04/blog10/"/>
      <url>/2023/06/04/blog10/</url>
      
        <content type="html"><![CDATA[<h1 id="Eurka和Nacos"><a href="#Eurka和Nacos" class="headerlink" title="Eurka和Nacos"></a>Eurka和Nacos</h1><p>Nacos和Eureka都是服务注册和发现的开源项目，用于构建分布式系统和微服务架构。它们的主要区别如下：</p><h2 id="服务注册和发现机制："><a href="#服务注册和发现机制：" class="headerlink" title="服务注册和发现机制："></a>服务注册和发现机制：</h2><ul><li>Nacos：Nacos提供了基于实例的服务注册和发现机制。服务提供者在启动时向Nacos注册自己的服务实例，并定期发送心跳来保持注册。服务消费者通过向Nacos查询服务列表来发现可用的服务实例。</li><li>Eureka：Eureka采用了基于中心化的服务注册和发现模式。服务提供者在启动时向Eureka注册自己的服务实例，并周期性地发送心跳来保持注册。服务消费者通过向Eureka服务器获取服务注册表来发现可用的服务实例。</li><li>Nacos支持服务端主动检测提供者状态:临时实例采用心跳模式，非临时实例采用主动检测模式临时实例心跳不正常会被剔除，非临时实例则不会被剔除。另外Nacos支持服务列表变更的消息推送模式，服务列表更新更及时</li></ul><h2 id="容错性和高可用性："><a href="#容错性和高可用性：" class="headerlink" title="容错性和高可用性："></a>容错性和高可用性：</h2><ul><li>Nacos：Nacos支持多节点的集群部署，具有高可用性和容错性。它使用Raft算法来保证数据的一致性和可用性，并支持自动的主从切换和故障恢复。</li><li>Eureka：Eureka的设计目标是在AWS云平台上实现高可用性。它使用了主从架构，其中一个Eureka服务器作为主服务器，其他服务器作为从服务器。当主服务器失效时，会触发Eureka客户端的自我保护机制，但这可能导致注册信息的延迟和不一致。</li><li>Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式。Eureka只有AP模式</li></ul><h2 id="配置管理："><a href="#配置管理：" class="headerlink" title="配置管理："></a>配置管理：</h2><ul><li>Nacos：Nacos提供了功能强大的配置管理功能。它支持动态配置的发布、监听和刷新，可以动态地修改配置参数而无需重启服务。Nacos还提供了命名空间、配置组和配置版本等概念，可以对配置进行灵活的管理和隔离。</li><li>Eureka：Eureka本身并没有内置的配置管理功能。如果需要配置管理，可以结合其他的配置中心（如Spring Cloud Config）与Eureka一起使用。</li></ul><h2 id="自我保护机制"><a href="#自我保护机制" class="headerlink" title="自我保护机制"></a>自我保护机制</h2><p>​        相同点: 保护阈值都是个比例，0-1 范围，表示健康的 instance 占全部instance 的比例。<br>​        不同点:<br>​        (1)保护方式不同<br>​        Eureka保护方式:当在短时间内，统计续约失败的比例，如果达到一定阈值，则会触发自我保护的机制，在该机制下Eureka Server不会别除任何的微服务，等到正常后，再退出自我保护机制。自我保护开关(eureka.server.enable-self.preservation. false)<br>​        Nacos保护方式: 当域名健康实例 (nstance) 占总服务实例(nstance)的比例小于阈值时，无论实例(Instance) 是否健康，都会将这个实例 (instance)返回给客户端。这样做虽然损失了一部分流量，但是保证了集群的剩余健康实例(Instance)能正常工作。<br>​        (2)范围不同<br>​        Nacos 的阈值是针对某个具体 Service 的，而不是针对所有服务的。但 Eureka的自我保护阈值是针对所有服务的.</p><h2 id="社区支持和集成："><a href="#社区支持和集成：" class="headerlink" title="社区支持和集成："></a>社区支持和集成：</h2><ul><li>Nacos：Nacos由阿里巴巴开源，得到了广泛的社区支持。它与Spring Cloud紧密集成，并提供了丰富的文档和示例来帮助开发者使用。</li><li>Eureka：Eureka最初由Netflix开发，虽然已经开源并得到了一定的社区支持，但相比Nacos而言，社区支持相对较少。然而，Eureka与Netflix的开源项目（如Ribbon和Hystrix）紧密集成，并在Netflix的生态系统中被广泛应用。</li></ul><h1 id="Hystrix和Sentinel"><a href="#Hystrix和Sentinel" class="headerlink" title="Hystrix和Sentinel"></a>Hystrix和Sentinel</h1><p>​        Sentinel和Hystrix都是用于实现服务容错和熔断的开源项目。 Hystrix 的关注点在于以 <em>隔离</em> 和 <em>熔断</em> 为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。而 Sentinel 的侧重点在于：多样化的流量控制、熔断降级、系统负载保护、实时监控和控制台。</p><h2 id="资源模型和执行模型上的对比"><a href="#资源模型和执行模型上的对比" class="headerlink" title="资源模型和执行模型上的对比"></a>资源模型和执行模型上的对比</h2><p>​        Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象（<code>HystrixCommand</code> &#x2F; <code>HystrixObservableCommand</code>），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。</p><p>​        Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流&#x2F;降级&#x2F;负载保护策略。在 Sentinel 中资源定义和规则配置是分离的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则。埋点方式有两种：</p><ul><li>try-catch 方式（通过 <code>SphU.entry(...)</code>），用户在 catch 块中执行异常处理 &#x2F; fallback</li><li>if-else 方式（通过 <code>SphO.entry(...)</code>），当返回 false 时执行异常处理 &#x2F; fallback</li></ul><p>​        Sentinel 还支持基于注解的资源定义方式，可以通过 <code>@SentinelResource</code> 注解参数指定异常处理函数和 fallback 函数。</p><h2 id="隔离设计上的对比"><a href="#隔离设计上的对比" class="headerlink" title="隔离设计上的对比"></a>隔离设计上的对比</h2><p>​        隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。</p><p>​        但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的线程池会非常影响性能。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。</p><p>​        Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。</p><h2 id="熔断降级对比"><a href="#熔断降级对比" class="headerlink" title="熔断降级对比"></a>熔断降级对比</h2><p>​        Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。</p><h2 id="实时指标统计实现对比"><a href="#实时指标统计实现对比" class="headerlink" title="实时指标统计实现对比"></a>实时指标统计实现对比</h2><p>​        Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功&#x2F;失败&#x2F;超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。</p><p>​        Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 <code>LeapArray</code> 的高性能滑动窗口，后续根据需要可能会引入 reactive stream 等实现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th></th><th>Sentinel</th><th>Hystrix</th></tr></thead><tbody><tr><td>隔离策略</td><td>信号量隔离</td><td>线程池隔离&#x2F;信号量隔离</td></tr><tr><td>熔断降级策略</td><td>基于慢调用比例或异常比例</td><td>基于失败比率</td></tr><tr><td>实时指标实现</td><td>滑动窗口</td><td>滑动窗口（基于 RxJava）</td></tr><tr><td>规则配置</td><td>支持多种数据源</td><td>支持多种数据源</td></tr><tr><td>扩展性</td><td>多个扩展点</td><td>插件的形式</td></tr><tr><td>基于注解的支持</td><td>支持</td><td>支持</td></tr><tr><td>限流</td><td>基于 QPS，支持基于调用关系的限流</td><td>有限的支持</td></tr><tr><td>流量整形</td><td>支持慢启动、匀速排队模式</td><td>不支持</td></tr><tr><td>系统自适应保护</td><td>支持</td><td>不支持</td></tr><tr><td>控制台</td><td>开箱即用，可配置规则、查看秒级监控、机器发现等</td><td>不完善</td></tr><tr><td>常见框架的适配</td><td>Servlet、Spring Cloud、Dubbo、gRPC 等</td><td>Servlet、Spring Cloud Netflix</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hystrix简介</title>
      <link href="/2023/06/03/blog9/"/>
      <url>/2023/06/03/blog9/</url>
      
        <content type="html"><![CDATA[<h1 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h1><p>​Hystrix是一个用于构建弹性和容错系统的Java库，由Netflix开发和维护。它旨在帮助开发者构建具有容错能力的分布式系统，特别是在处理复杂的网络通信时。</p><p>​Hystrix主要解决的问题是在分布式系统中的服务之间进行通信时可能出现的故障和延迟。这些问题可能导致级联故障，即一个服务的故障传递到其他服务，最终导致整个系统不可用。Hystrix通过引入隔离、断路器和回退机制来解决这些问题。</p><p>​隔离是Hystrix的核心概念之一。它通过将每个服务调用封装在独立的线程池中运行，实现了请求的隔离。这样，当某个服务调用失败或延迟较高时，不会对其他服务产生负面影响。</p><p>​断路器是Hystrix的另一个重要概念。它监控服务调用的错误率和延迟情况。当错误率或延迟超过预设的阈值时，断路器会打开，停止对该服务的调用，并快速失败。这样可以防止级联故障，并且当服务恢复正常后，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>此外，Hystrix还提供了回退机制，用于在服务调用失败时提供备选方案。开发者可以定义回退逻辑，当服务调用失败时，Hystrix会自动调用回退逻辑来返回预先定义的备选结果，保证系统的稳定性和可用性。</p><p>​Hystrix还提供了丰富的监控和度量功能，开发者可以实时监控服务调用的成功率、失败率、延迟等指标，并通过配置仪表盘和报警机制来及时发现和处理故障。</p><p>​总而言之，Hystrix是一个弹性和容错库，可以帮助开发者构建可靠的分布式系统。它通过隔离、断路器和回退机制来处理故障和延迟，并提供监控和度量功能来帮助开发者实时了解系统的健康状态。</p><h1 id="Hystrix服务降级"><a href="#Hystrix服务降级" class="headerlink" title="Hystrix服务降级"></a>Hystrix服务降级</h1><p>​Hystrix中的服务降级是指在系统出现故障或异常情况时，为了保证系统的可用性和稳定性，临时替代原本的服务调用，返回一个备选的响应结果。</p><p>​服务降级是通过定义回退逻辑来实现的。在使用Hystrix时，开发者可以为每个服务调用定义一个回退方法（Fallback Method），该方法在服务调用失败或超时时被触发，返回一个备选结果。</p><p>​回退方法的实现应尽量快速且轻量级，避免引入新的故障点。它可以返回一个默认值、预先计算的结果、缓存的数据或静态错误页面等，具体根据业务需求而定。通过合理定义回退逻辑，可以提供用户友好的响应或保证系统的基本功能仍能正常运行。</p><p>​Hystrix提供了多种方式来实现服务降级：</p><ol><li>注解方式：通过在服务调用的方法上添加@HystrixCommand注解，指定回退方法。当服务调用发生异常、超时或熔断时，会触发回退方法。</li><li>编程方式：通过Hystrix提供的命令模式（HystrixCommand）或可观察者模式（HystrixObservableCommand）进行服务调用，并在调用链中指定回退方法。</li><li>信号量隔离：除了使用线程池隔离外，Hystrix还支持信号量隔离，可以在同一线程中执行服务调用和回退方法，减少线程切换和上下文切换的开销。</li></ol><p>通过服务降级，Hystrix可以在服务故障或不可用时，提供一种临时替代方案，保证系统的可用性和稳定性。开发者可以根据具体情况定义合适的回退逻辑，提供良好的用户体验或保持基本功能的正常运行。</p><h1 id="Hystrix服务熔断"><a href="#Hystrix服务熔断" class="headerlink" title="Hystrix服务熔断"></a>Hystrix服务熔断</h1><p>​Hystrix中的服务熔断是一种用于防止故障扩散和快速恢复的机制。当服务调用失败率超过一定阈值时，Hystrix会打开断路器，停止对该服务的调用，并且在一段时间内直接返回预先设定的备选结果，而不去执行实际的服务调用。</p><p>​服务熔断的目的是防止级联故障，当一个服务出现问题时，避免对依赖它的其他服务造成更大的影响。通过断路器的打开，可以快速失败并迅速恢复正常。当断路器处于打开状态时，Hystrix会定期允许一部分流量通过，以便检测服务是否恢复正常。如果服务调用成功率达到一定阈值，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>​Hystrix中的服务熔断通过以下方式实现：</p><ol><li>错误百分比阈值：开发者可以配置一个错误百分比阈值，当在一个统计窗口内的请求错误率超过该阈值时，断路器将打开。</li><li>请求阈值：开发者可以配置一个请求阈值，当在一个统计窗口内的请求数量低于该阈值时，不会触发断路器。这是为了避免在服务启动初期的误判。</li><li>熔断器状态：断路器有三种状态：关闭、打开和半开。初始状态为关闭。当错误百分比超过阈值时，断路器打开；在打开状态下，所有请求都会直接返回备选结果；在一段时间后，断路器进入半开状态，允许一部分流量通过以检测服务的健康状态；如果半开状态下的请求成功，则断路器闭合；否则，重新打开断路器。</li></ol><p>通过服务熔断，Hystrix可以及时停止对不可用的服务的调用，防止故障的扩散，并通过快速失败和自动恢复的机制来提高系统的稳定性和可用性。开发者可以根据具体需求，配置合适的错误百分比阈值和请求阈值，以及定义适当的备选结果，从而保护系统免受不可用服务的影响。</p><h1 id="Hystrix服务限流"><a href="#Hystrix服务限流" class="headerlink" title="Hystrix服务限流"></a>Hystrix服务限流</h1><p>​Hystrix中的服务限流是一种控制系统资源使用的机制，用于保护系统免受过多请求的影响。通过限制对某个服务的并发请求量，可以防止系统资源被过度消耗，确保系统的稳定性和可用性。</p><p>​在Hystrix中，可以通过以下方式来实现服务限流：</p><ol><li>线程池隔离：Hystrix将每个服务调用封装在独立的线程池中运行，通过配置线程池的大小和队列容量，可以限制同时执行的并发请求数量。当线程池满了，新的请求将被拒绝或排队等待。</li><li>信号量隔离：除了线程池隔离外，Hystrix还支持使用信号量来限制并发请求的数量。开发者可以在服务调用的方法上添加@HystrixCommand注解，并指定一个信号量的数量作为参数，从而限制对该服务的并发访问。</li><li>请求队列：线程池隔离模式下，可以设置一个请求队列，用于缓冲未能立即执行的请求。请求队列的大小也可以作为限制并发请求的一种手段。当队列已满时，新的请求将被拒绝。</li></ol><p>​通过配置线程池大小、队列容量和信号量数量，开发者可以根据系统的资源情况和负载情况，灵活地控制并发请求的数量。适当的限流策略可以保护系统免受过载的影响，避免资源耗尽和性能下降。</p><p>​需要注意的是，服务限流只是一种保护机制，不能替代系统的容量规划和性能优化。合理的限流策略应结合实际情况进行调整，以达到最佳的系统性能和用户体验。</p><h1 id="Hystrix工作流程"><a href="#Hystrix工作流程" class="headerlink" title="Hystrix工作流程"></a>Hystrix工作流程</h1><p>​Hystrix的工作流程可以概括为以下几个步骤：</p><ol><li>发起服务调用：应用程序通过调用封装了服务调用的Hystrix命令（HystrixCommand）或可观察者（HystrixObservableCommand）来发起服务调用。这些命令包含了要执行的服务逻辑以及相关的配置信息。</li><li>降级检查：在服务调用之前，Hystrix会检查是否配置了回退逻辑（Fallback），以应对服务调用失败或超时的情况。如果配置了回退逻辑，Hystrix会将其与原始服务调用绑定。</li><li>断路器判断：在发起服务调用之前，Hystrix会检查断路器的状态。如果断路器处于打开状态（Open），Hystrix会立即触发回退逻辑，不会实际发起服务调用。</li><li>服务调用：如果降级检查和断路器判断通过，Hystrix会尝试发起实际的服务调用。根据配置，服务调用可能会在一个独立的线程池中执行，以实现请求隔离。Hystrix还可以通过信号量来控制并发请求数量。</li><li>容错处理：在服务调用过程中，Hystrix会监控请求的结果。如果请求发生故障、超时或异常，Hystrix会根据配置的容错策略执行相应的操作，例如打开断路器、触发回退逻辑等。</li><li>回退逻辑执行：当服务调用失败或超时时，Hystrix会执行与之绑定的回退逻辑。回退逻辑可以是预先定义的备选结果、缓存数据、静态错误页面等，以提供系统的基本功能或友好的用户体验。</li><li>断路器状态更新：根据服务调用的结果，Hystrix会更新断路器的状态。如果服务调用成功，断路器会逐渐闭合；如果服务调用失败或发生故障，断路器会打开，停止对该服务的调用。断路器在一段时间后会尝试半开状态，允许一部分流量通过以检测服务的健康状态。</li></ol><p>​通过以上的工作流程，Hystrix能够提供服务的容错和弹性处理，防止故障的扩散和级联故障的发生。它通过断路器、降级逻辑和线程隔离等机制来保护系统的可用性和稳定性，并提供监控和度量功能来实时了解系统的健康状况。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ribbon、Gateway、Nginx</title>
      <link href="/2023/06/03/blog8/"/>
      <url>/2023/06/03/blog8/</url>
      
        <content type="html"><![CDATA[<h1 id="Ribbon、Gateway、Nginx区别"><a href="#Ribbon、Gateway、Nginx区别" class="headerlink" title="Ribbon、Gateway、Nginx区别"></a>Ribbon、Gateway、Nginx区别</h1><h2 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h2><p>​Ribbon 是一个用于客户端负载均衡的开源项目，最初由 Netflix 开发并开源。它主要用于在分布式系统中选择合适的服务实例并进行负载均衡。</p><p>​在微服务架构中，服务通常以多个实例运行，这些实例可能分布在不同的主机或容器中。Ribbon 可以与服务注册中心（如 Eureka、Consul 等）集成，通过查询注册中心获取可用的服务实例列表。</p><p>​Ribbon 在客户端应用内部工作，作为一个负载均衡组件，它会根据一定的负载均衡策略选择一个合适的服务实例来发送请求。这些负载均衡策略包括轮询、随机、加权随机、最少连接等。选择的服务实例将接收客户端的请求，并将响应返回给客户端。</p><p>​Ribbon 还提供了一些其他功能，如超时设置、重试机制、服务实例健康检查等。它可以根据服务实例的健康状态和负载情况动态地选择合适的实例，以实现负载均衡和故障恢复。</p><p>​Ribbon 的优点是简单轻量、易于集成和扩展。它与多种服务注册中心和开发框架兼容，适用于各种微服务架构中的负载均衡需求。</p><h2 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h2><p>​Gateway是一种在分布式系统中充当入口点的中间层组件。它位于客户端和后端服务之间，负责接收来自客户端的请求，并将请求转发到适当的后端服务进行处理。</p><p>​网关的主要功能包括：</p><ol><li><p>请求路由：网关根据预定义的路由规则将请求路由到相应的后端服务。路由规则可以基于请求的路径、请求方法、请求头等进行匹配和转发。</p></li><li><p>协议转换：网关可以根据需要将请求和响应从一种协议转换为另一种协议。例如，可以将传入的请求从 HTTP 转换为 gRPC，或将响应从 gRPC 转换为 JSON。</p></li><li><p>负载均衡：网关可以实现负载均衡策略，将请求均匀地分发到多个后端服务实例。这可以通过集成服务发现组件（如 Eureka、Consul 等）来实现，并根据服务实例的健康状态和负载情况进行动态选择。</p></li><li><p>安全认证与授权：网关可以提供身份验证和授权功能，保护后端服务免受未经授权的访问。它可以验证请求的身份信息（如令牌、证书等），并根据配置的权限规则控制访问权限。</p></li><li><p>监控与日志记录：网关可以记录请求和响应的日志，并提供监控指标和统计信息，用于系统性能分析、故障排查和流量监控。</p></li><li><p>缓存：网关可以缓存经常请求的响应，以提高系统的响应速度和吞吐量。这可以减少后端服务的负载，并提供更快的响应时间。</p></li></ol><p>​网关在微服务架构中扮演着重要的角色，它提供了一种集中管理和处理请求的方式，简化了客户端和后端服务之间的通信和协调。常见的网关实现包括 Spring Cloud Gateway、Netflix Zuul、Kong 等。这些网关可以与其他微服务组件集成，并提供丰富的功能来支持复杂的系统架构和需求。</p><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><p>​Nginx是一个高性能的开源反向代理服务器、负载均衡器和Web服务器。它具有轻量级、高效率和可扩展性的特点，被广泛应用于构建高性能的Web应用和服务。</p><ol><li><p>反向代理：<br>Nginx作为反向代理服务器，接收客户端请求，并将请求转发到后端服务器。它可以隐藏后端服务器的细节，并提供负载均衡功能，将请求分发到多个后端服务器上，从而提高系统的可用性和性能。</p></li><li><p>负载均衡：<br>Nginx支持多种负载均衡算法，如轮询、IP哈希、最少连接等。它可以根据配置的负载均衡策略将请求均匀地分发到多个后端服务器，以实现负载均衡和故障恢复。</p></li><li><p>静态文件服务：<br>Nginx可以快速高效地提供静态文件的服务，如HTML、CSS、JavaScript、图像文件等。它通过使用异步非阻塞的方式处理请求，以及内置的缓存机制，提供了出色的性能和可扩展性。</p></li><li><p>SSL&#x2F;TLS加密：<br>Nginx支持SSL&#x2F;TLS协议，可以用于配置安全的HTTPS连接，为网站和应用程序提供加密和安全传输的功能。它可以作为SSL终端点，处理与客户端之间的加密通信。</p></li><li><p>动态请求转发：<br>Nginx还可以根据请求的内容或规则将请求转发到不同的后端服务。它支持配置灵活的反向代理规则，根据URL路径、请求头、参数等条件进行请求转发和路由。</p></li><li><p>高性能和可扩展性：<br>Nginx采用事件驱动、非阻塞的架构设计，可以处理大量并发连接和高流量的请求，具有出色的性能表现。它还支持多进程、多线程的部署模式，可以根据需求进行水平扩展。</p></li><li><p>日志记录和监控：<br>Nginx提供详细的访问日志记录，记录请求和响应的信息，便于故障排查和性能优化。它还支持实时监控和统计指标的收集，可以与其他监控工具集成，实现对系统的监控和管理。</p></li></ol><p>​Nginx是一个强大而灵活的服务器软件，广泛应用于Web应用、反向代理、负载均衡、缓存、媒体流服务等多个领域。</p><h2 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a>三者区别</h2><ol><li>功能定位：<ul><li>Gateway: 网关是一个完整的请求路由和代理解决方案，通常用于构建微服务架构中的入口点，负责请求的接收、路由、转发、安全性、监控等。</li><li>Ribbon: Ribbon是一个客户端负载均衡组件，用于在客户端应用内部选择合适的服务实例，主要负责服务实例的选择和负载均衡算法的应用。</li><li>Nginx: Nginx是一个高性能的反向代理服务器，可以作为负载均衡器，接收客户端请求并将其转发到后端服务器，主要负责请求转发和负载均衡算法的实现。</li></ul></li><li>部署位置：<ul><li>Gateway: 网关通常位于整个架构的边界，作为对外的入口点，接收外部请求并路由到内部的服务实例。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，嵌入在客户端应用中，与应用共存于同一个进程内。</li><li>Nginx: Nginx作为反向代理服务器，通常部署在服务器端，位于客户端与后端服务之间，接收客户端请求并将其转发到后端服务器。</li></ul></li><li>负载均衡算法：<ul><li>Gateway: 网关可以结合多种负载均衡算法，如轮询、权重、哈希等，根据不同的路由规则和服务实例情况进行选择。</li><li>Ribbon: Ribbon提供了丰富的负载均衡算法选择，如轮询、随机、加权随机、最少连接等，可以根据需要选择合适的算法。</li><li>Nginx: Nginx也支持多种负载均衡算法，如轮询、IP哈希、最少连接等，可以根据需求进行配置。</li></ul></li><li>扩展性和灵活性：<ul><li>Gateway: 网关通常提供了更多的功能，如认证、授权、监控等，以及自定义路由规则的灵活性，可以根据具体需求进行定制开发。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，对于客户端应用来说，具有更高的扩展性和灵活性，可以根据业务需求进行自定义的负载均衡逻辑实现。</li><li>Nginx: Nginx作为反向代理服务器，可以灵活配置代理规则和负载均衡算法，同时也支持自定义的扩展模块。</li></ul></li></ol><p>​</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​在项目中同时使用到这三者的情况时候，可以这么理解，用户请求进来是先过Nginx网关，这里的Nginx就相当于一个流量网关，是属于用户访问的一个入口。 然后在进入到gateway网关中，这里的getway网关属于一个业务网关，通过对应的属性配置将请求传递到每一个业务微服务中去。而Ribbon负责微服务之间调用时的负载均衡。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>统计范围内的元音字符串数</title>
      <link href="/2023/06/02/blog7/"/>
      <url>/2023/06/02/blog7/</url>
      
        <content type="html"><![CDATA[<h2 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h2><p><a href="https://leetcode.cn/problems/count-vowel-strings-in-ranges/description/">2559. 统计范围内的元音字符串数 - 力扣（Leetcode）</a></p><p>给你一个下标从 <strong>0</strong> 开始的字符串数组 <code>words</code> 以及一个二维整数数组 <code>queries</code> 。</p><p>每个查询 <code>queries[i] = [li, ri]</code> 会要求我们统计在 <code>words</code> 中下标在 <code>li</code> 到 <code>ri</code> 范围内（<strong>包含</strong> 这两个值）并且以元音开头和结尾的字符串的数目。</p><p>返回一个整数数组，其中数组的第 <code>i</code> 个元素对应第 <code>i</code> 个查询的答案。</p><p><strong>注意：</strong>元音字母是 <code>&#39;a&#39;</code>、<code>&#39;e&#39;</code>、<code>&#39;i&#39;</code>、<code>&#39;o&#39;</code> 和 <code>&#39;u&#39;</code> 。</p><p><strong>示例 1：</strong></p><pre><code>输入：words = [&quot;aba&quot;,&quot;bcb&quot;,&quot;ece&quot;,&quot;aa&quot;,&quot;e&quot;], queries = [[0,2],[1,4],[1,1]]输出：[2,3,0]解释：以元音开头和结尾的字符串是 &quot;aba&quot;、&quot;ece&quot;、&quot;aa&quot; 和 &quot;e&quot; 。查询 [0,2] 结果为 2（字符串 &quot;aba&quot; 和 &quot;ece&quot;）。查询 [1,4] 结果为 3（字符串 &quot;ece&quot;、&quot;aa&quot;、&quot;e&quot;）。查询 [1,1] 结果为 0 。返回结果 [2,3,0] 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：words = [&quot;a&quot;,&quot;e&quot;,&quot;i&quot;], queries = [[0,2],[0,1],[2,2]]输出：[3,2,1]解释：每个字符串都满足这一条件，所以返回 [3,2,1] 。</code></pre><h2 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h2><p>​简单啊，直接暴力求解就完了</p><p>​写代码，测试，提交，，，，然后就超时了，，，，emmmmmmmmmm</p><p>​前缀和优化下，通过</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre><code class="java">class Solution &#123;    public int[] vowelStrings(String[] words, int[][] queries) &#123;        Set&lt;Character&gt; vowels = Set.of(&#39;a&#39;, &#39;e&#39;, &#39;i&#39;, &#39;o&#39;, &#39;u&#39;);        int n = words.length;        int[] prefixSums = new int[n + 1];        for (int i = 0; i &lt; n; ++i) &#123;            char a = words[i].charAt(0), b = words[i].charAt(words[i].length() - 1);            if (vowels.contains(a) &amp;&amp; vowels.contains(b)) &#123;                prefixSums[i+1] = prefixSums[i] + 1;            &#125;else&#123;                prefixSums[i+1] = prefixSums[i];            &#125;        &#125;        int q = queries.length;        int[] ans = new int[q];        for (int i = 0; i &lt; q; i++) &#123;            int start = queries[i][0], end = queries[i][1];            ans[i] = prefixSums[end + 1] - prefixSums[start];        &#125;        return ans;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis主从同步</title>
      <link href="/2023/06/02/blog6/"/>
      <url>/2023/06/02/blog6/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis主从同步"><a href="#Redis主从同步" class="headerlink" title="Redis主从同步"></a>Redis主从同步</h1><h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p><p><img src="/../imgs/blog6/image-20210725152222497.png" alt="image-20210725152222497"></p><p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p><p>有几个概念，可以作为判断依据：</p><ul><li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</li><li><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</li></ul><p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p><p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p><p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p><p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p><p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p><p>如图：</p><p><img src="/../imgs/blog6/image-20210725152700914.png" alt="image-20210725152700914"></p><p>完整流程描述：</p><ul><li>slave节点请求增量同步</li><li>master节点判断replid，发现不一致，拒绝增量同步</li><li>master将完整内存数据生成RDB，发送RDB到slave</li><li>slave清空本地数据，加载master的RDB</li><li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li><li>slave执行接收到的命令，保持与master之间的同步</li></ul><h3 id="2-2-2-增量同步"><a href="#2-2-2-增量同步" class="headerlink" title="2.2.2.增量同步"></a>2.2.2.增量同步</h3><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p><p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p><p><img src="/../imgs/blog6/image-20210725153201086.png" alt="image-20210725153201086"></p><p>那么master怎么知道slave与自己的数据差异在哪里呢?</p><h3 id="repl-backlog原理"><a href="#repl-backlog原理" class="headerlink" title="repl_backlog原理"></a>repl_backlog原理</h3><p>master怎么知道slave与自己的数据差异在哪里呢?</p><p>这就要说到全量同步时的repl_baklog文件了。</p><p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p><p>repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p><p><img src="/../imgs/blog6/image-20210725153359022.png" alt="image-20210725153359022"> </p><p>slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。</p><p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p><p><img src="/../imgs/blog6/image-20210725153524190.png" alt="image-20210725153524190"> </p><p>直到数组被填满：</p><p><img src="/../imgs/blog6/image-20210725153715910.png" alt="image-20210725153715910"> </p><p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p><p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset： </p><p><img src="/../imgs/blog6/image-20210725153937031.png" alt="image-20210725153937031"> </p><p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p><p><img src="/../imgs/blog6/image-20210725154155984.png" alt="image-20210725154155984"> </p><p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p><p><img src="/../imgs/blog6/image-20210725154216392.png" alt="image-20210725154216392"></p><h3 id="主从同步优化"><a href="#主从同步优化" class="headerlink" title="主从同步优化"></a>主从同步优化</h3><p>主从同步可以保证主从数据的一致性，非常重要。</p><p>可以从以下几个方面来优化Redis主从就集群：</p><ul><li>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。</li><li>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</li><li>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</li><li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</li></ul><p>主从从架构图：</p><p><img src="/../imgs/blog6/image-20210725154405899.png" alt="image-20210725154405899"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>简述全量同步和增量同步区别？</p><ul><li>全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。</li><li>增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave</li></ul><p>什么时候执行全量同步？</p><ul><li>slave节点第一次连接master节点时</li><li>slave节点断开时间太久，repl_baklog中的offset已经被覆盖时</li></ul><p>什么时候执行增量同步？</p><ul><li>slave节点断开又恢复，并且在repl_baklog中能找到offset时</li></ul><p>转载自：黑马程序员Redis教程（【黑马程序员Redis入门到实战教程，深度透析redis底层原理+redis分布式锁+企业解决方案+黑马点评实战项目】 <a href="https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web%EF%BC%89">https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web）</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>礼盒的最大甜蜜度</title>
      <link href="/2023/06/01/blog5/"/>
      <url>/2023/06/01/blog5/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/"><a href="https://leetcode.cn/problems/maximum-tastiness-of-candy-basket/description/">2517. 礼盒的最大甜蜜度 - 力扣（Leetcode）</a></a></p><p>​给你一个正整数数组 <code>price</code> ，其中 <code>price[i]</code> 表示第 <code>i</code> 类糖果的价格，另给你一个正整数 <code>k</code> 。</p><p>商店组合 <code>k</code> 类 <strong>不同</strong> 糖果打包成礼盒出售。礼盒的 <strong>甜蜜度</strong> 是礼盒中任意两种糖果 <strong>价格</strong> 绝对差的最小值。</p><p>返回礼盒的 <strong>最大</strong> 甜蜜度<em>。</em></p><p><strong>示例 1：</strong></p><pre><code>输入：price = [13,5,1,8,21,2], k = 3输出：8解释：选出价格分别为 [13,5,21] 的三类糖果。礼盒的甜蜜度为 min(|13 - 5|, |13 - 21|, |5 - 21|) = min(8, 8, 16) = 8 。可以证明能够取得的最大甜蜜度就是 8 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：price = [1,3,1], k = 2输出：2解释：选出价格分别为 [1,3] 的两类糖果。 礼盒的甜蜜度为 min(|1 - 3|) = min(2) = 2 。可以证明能够取得的最大甜蜜度就是 2 。</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：price = [7,7,7,7], k = 2输出：0解释：从现有的糖果中任选两类糖果，甜蜜度都会是 0 。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​最小最大，基本要想到二分了，直接二分甜蜜值，因为选择的差值跟顺序无关，我们可以排序后贪心，当前选择大于之前选择加甜蜜值就统计答案一次，如果最终次数大于等于tastiness，说明甜蜜值还可以更大，收缩左边界，否则收缩右边界。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int maximumTastiness(int[] price, int k) &#123;​    Arrays.sort(price);​    int left = 0, right = price[price.length - 1];​    while (left +1 != right) &#123;​      int mid = (left + right) / 2;​      if (check(price, k, mid)) &#123;​        left = mid;​      &#125; else &#123;​        right = mid;​      &#125;​    &#125;​    return left;  &#125;  public boolean check(int[] price, int k, int tastiness) &#123;​    int prev = Integer.MIN_VALUE / 2;​    int cnt = 0;​    for (int p : price) &#123;​      if (p - prev &gt;= tastiness) &#123;​        cnt++;​        prev = p;​      &#125;​    &#125;​    return cnt &gt;= k;  &#125;&#125;</code></pre><p>甜蜜的祝自己节日快乐</p>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么Redis集群分片最大槽数是16384个</title>
      <link href="/2023/06/01/blog4/"/>
      <url>/2023/06/01/blog4/</url>
      
        <content type="html"><![CDATA[<h4 id="为什么Redis集群分片最大槽数是16384个？"><a href="#为什么Redis集群分片最大槽数是16384个？" class="headerlink" title="为什么Redis集群分片最大槽数是16384个？"></a>为什么Redis集群分片最大槽数是16384个？</h4><p>​GitHub上已有关于这个问题的解答，<a href="https://github.com/redis/redis/issues/2576">why redis-cluster use 16384 slots? · Issue #2576 · redis&#x2F;redis (github.com)</a>，这里只做大概解释</p><p>​Redis集群通过CRC16算法对key进行哈希并对16384取模来决定该key具体放在哪个槽位，而该算法的hash结果有16位，也就是65536个值，那为啥不分配65536个槽而是16384（2^14）个？</p><p>​首先翻译一下作者的解答：</p><p>​正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间(使用65K的插槽)。同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot &#x2F; N位占设置位的很大百分比。</p><p>​翻译了又好像没翻译，还是没看懂，，，</p><p>​其实总结起来就是以下三个因素的考虑。</p><p>（1）如果槽位个数为65536，发送的心跳信息头达到8k，发送的心跳包过大。</p><p><img src="/imgs/blog4/image-20230601095147944.png"></p><p>上图即为Redis节点发送的信息头结构，其中占据最大空间的就是myslots[CLUSTER_SLOTS&#x2F;8]。如果槽位为65536个，大小为65536 &#x2F; 8 &#x2F; 1024 &#x3D; 8 kb。如果槽位为16384个，大小为16384 &#x2F; 8 &#x2F; 1024 &#x3D; 2 kb。在Redis集群中，Redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536个，发送的消息头太大，浪费带宽。</p><p>（2）Redis的集群主节点数量基本不可能超过1000个，16384个槽位已经够用<br>集群节点越多，心跳包的消息体内携带的数据越多。如果节点超过1000个，也会导致网络拥堵。因此Redis作者不建议Redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。</p><p>（3）节点一定的情况下，槽位越少，压缩比越高，容易传输<br>Redis主节点的配置信息中它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中会对bitmap进行压缩，但是如果bitmap的填充率slots &#x2F;N很高的话(N表示节点数)，bitmap的压缩率就很低。也就是说当节点数一定时，哈希槽数量很多的话，bitmap的压缩率就很低，不易传输。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无重复字符的最长子串</title>
      <link href="/2023/05/31/blog3/"/>
      <url>/2023/05/31/blog3/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/">3. 无重复字符的最长子串 - 力扣（Leetcode）</a></p><p>​给定一个字符串 <code>s</code> ，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。</p><p><strong>示例 1:</strong></p><pre><code>输入: s = &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: s = &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。</code></pre><p><strong>示例 3:</strong></p><pre><code>输入: s = &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。     请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​没啥好说的，一眼滑动窗口。。。</p><p>​以示例1为例，对于“abcabcbb”，定义两个指针（ left 和 right ），初始都指向字符串0位置，两个指针之间的字符串即为当前找到的子串，right指针向右遍历，使用hashmap记录出现过的字符和字符最后一次出现的位置，当前字串出现重复字符时（即hashmap中存在当前right指向的字符），将left指针移动到重复字符的下一个位置即可（map.get(s.charAt(i)) + 1），遍历过程中记录字串长度最大值。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int lengthOfLongestSubstring(String s) &#123;​    if (s.length() &lt;=  1)&#123;​      return s.length();​    &#125;​    HashMap&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;();​    int ans = 0;​    int left = 0;​    for(int i = 0; i &lt; s.length(); i++)&#123;​      if(map.containsKey(s.charAt(i)))&#123;​        left = Math.max(left, map.get(s.charAt(i)) + 1);​      &#125;​      map.put(s.charAt(i), i);​      ans = Math.max(ans, i-left+1);​    &#125;​    return ans;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引失效情况</title>
      <link href="/2023/05/31/blog2/"/>
      <url>/2023/05/31/blog2/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL索引失效"><a href="#MySQL索引失效" class="headerlink" title="MySQL索引失效"></a>MySQL索引失效</h1><p>​简单介绍下几种MySQL索引失效的常见情况。</p><h3 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1.数据准备"></a>1.数据准备</h3><p>​首先准备一张数据表user_info并建立索引</p><pre><code class="mysql">`CREATE TABLE `user_info` ( `id` int(8) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;, `number` varchar(12) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;编号&#39;, `username` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;用户名&#39;, `age` int(11) DEFAULT NULL COMMENT &#39;年龄&#39;, `birthday` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &#39;生日&#39;, PRIMARY KEY (`id`), KEY `union_idx` (`number`,`username`,`age`), KEY `create_time_idx` (`birthday`) );`</code></pre><p>该表包含3个索引：</p><p>主键：id</p><p>联合索引：number、username、age</p><p>普通索引：birthday</p><p>然后插入一些数据</p><pre><code class="mysql">INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1244&#39;, &#39;Mercury&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3546&#39;, &#39;Diana&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1124&#39;, &#39;Mars&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6426&#39;, &#39;Saturn&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3525&#39;, &#39;Eureka&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;5245&#39;, &#39;Mercury1&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3235246&#39;, &#39;Diana1&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6346&#39;, &#39;Mars1&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;623461&#39;, &#39;Saturn1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;235&#39;, &#39;Eureka1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;11244&#39;, &#39;Mercury3&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;13546&#39;, &#39;Diana3&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;112244&#39;, &#39;Mars3&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;643126&#39;, &#39;Saturn3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;35215&#39;, &#39;Eureka3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;52145&#39;, &#39;Mercury4&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;32235246&#39;, &#39;Diana4&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6332446&#39;, &#39;Mars4&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6231461&#39;, &#39;Saturn4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;231115&#39;, &#39;Eureka4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);</code></pre><p>注：测试MySQL版本为8.0.28</p><h3 id="2-案例测试"><a href="#2-案例测试" class="headerlink" title="2.案例测试"></a>2.案例测试</h3><h4 id="2-1-联合索引不满足最左匹配原则"><a href="#2-1-联合索引不满足最左匹配原则" class="headerlink" title="2.1 联合索引不满足最左匹配原则"></a>2.1 联合索引不满足最左匹配原则</h4><p>​最左前缀匹配原则：在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左列开始匹配。如本例中联合索引（number，username，age），若想查询走该索引，查询条件中应出现最左边的列，即number。</p><p>测试1：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39;;</code></pre><p>运行结果：</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%951.png"></p><p>key为“union_idx”说明查询走了联合索引。</p><p>测试2：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39; and age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%952.png"></p><p>测试2结果中‘key_len’与测试1相同，说明该查询虽然走了联合索引，但因未满足最左匹配原则（查询条件中未出现username），导致username之后的联合索引失效。若number使用范围查询如number&gt;‘1244’，后面的查询条件即使有username也不会生效，这里不做测试。</p><p>但是where后面查询列出现顺序不会影响索引，如</p><p>测试3：</p><pre><code class="mysql">explain select * from user_info where username = &#39;Mercury&#39; and number = &#39;1244&#39;;explain select * from user_info where number = &#39;1244&#39; and username = &#39;Mercury&#39;;</code></pre><p>上面两条语句‘ken_len’相同</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%953.png" alt="image-20230531203957562"></p><h4 id="2-2-索引列使用数学运算"><a href="#2-2-索引列使用数学运算" class="headerlink" title="2.2 索引列使用数学运算"></a>2.2 索引列使用数学运算</h4><p>测试4：</p><pre><code class="mysql">explain select * from user_info where id + 1 = 2;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%954.png"></p><p>查询类型为全表扫面，并未使用索引</p><h4 id="2-3-隐式类型转换"><a href="#2-3-隐式类型转换" class="headerlink" title="2.3 隐式类型转换"></a>2.3 隐式类型转换</h4><p>测试5：</p><pre><code class="mysql">explain select * from user_info where number = 1244;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%955.png" alt="测试5"></p><p>number字段为varchar类型，而查询条件为int，类型不匹配导致索引失效。</p><h4 id="2-4模糊查询以-开头"><a href="#2-4模糊查询以-开头" class="headerlink" title="2.4模糊查询以%开头"></a>2.4模糊查询以%开头</h4><p>测试6：</p><pre><code class="mysql">explain select * from user_info where number like &#39;%2&#39;;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%956.png" alt="测试6"></p><h4 id="2-5-使用or"><a href="#2-5-使用or" class="headerlink" title="2.5 使用or"></a>2.5 使用or</h4><p>测试7：</p><pre><code class="mysql">explain select * from user_info where id = 1 or age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%957.png" alt="测试7"></p><p>age列无索引，导致前面id列索引失效。使用or时切记两边查询条件都要有索引。</p><h4 id="2-6索引列使用函数"><a href="#2-6索引列使用函数" class="headerlink" title="2.6索引列使用函数"></a>2.6索引列使用函数</h4><p>测试8：</p><p>explain select * from user_info where SUBSTR(number, 2,3) &#x3D; ‘12’;</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%958.png" alt="测试8"></p><h4 id="2-7两列作比较或者运算"><a href="#2-7两列作比较或者运算" class="headerlink" title="2.7两列作比较或者运算"></a>2.7两列作比较或者运算</h4><p>测试9：</p><pre><code class="mysql">explain select * from user_info where id &lt; age;explain select * from user_info where id + age = 25;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%959.png" alt="测试9"></p><h4 id="2-8其他"><a href="#2-8其他" class="headerlink" title="2.8其他"></a>2.8其他</h4><p>​使用不等于&lt;&gt;，not in， not exists， is not null 以及MySQL优化器认为走全表扫描效率更高的查询。好累啊不想做测试了，开摆。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化</title>
      <link href="/2023/05/31/blog1/"/>
      <url>/2023/05/31/blog1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Redis持久化"><a href="#1-Redis持久化" class="headerlink" title="1.Redis持久化"></a>1.Redis持久化</h1><p>Redis有两种持久化方案：</p><ul><li>RDB持久化</li><li>AOF持久化</li></ul><h2 id="1-1-RDB"><a href="#1-1-RDB" class="headerlink" title="1.1.RDB"></a>1.1.RDB</h2><p>RDB全称Redis Database Backup file（Redis数据备份文件），RDB其实就是把数据以快照的形式保存在磁盘上。什么是快照呢，你可以理解成把当前时刻的数据拍成一张照片保存下来。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。</p><h3 id="1-1-1-RDB执行"><a href="#1-1-1-RDB执行" class="headerlink" title="1.1.1.RDB执行"></a>1.1.1.RDB执行</h3><p>RDB持久化在四种情况下会执行：</p><ul><li>执行save命令</li><li>执行bgsave命令</li><li>Redis停机时</li><li>触发RDB条件时</li></ul><p><strong>1）save命令</strong></p><p>save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。</p><p><strong>2）bgsave命令</strong></p><p>bgsave命令执行后Redis执行fork操作创建子进程完成RDB，主进程可以继续处理用户请求，不会阻塞。</p><p><strong>3）停机时</strong></p><p>Redis停机时会执行一次save命令，实现RDB持久化。</p><p><strong>4）触发RDB条件</strong></p><p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p><pre><code class="properties"># 下面的配置代表600秒内如果至少有10个key被修改，则执行bgsavesave 600 10  </code></pre><p>RDB的其它配置也可以在redis.conf文件中设置：</p><pre><code class="properties"># 是否进行压缩（会耗费cpu资源）rdbcompression yes# RDB文件保存名称（默认为dump.rdb）dbfilename dump.rdb  </code></pre><h3 id="1-1-2-RDB原理"><a href="#1-1-2-RDB原理" class="headerlink" title="1.1.2.RDB原理"></a>1.1.2.RDB原理</h3><p>bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。</p><p>fork采用的是copy-on-write技术：</p><ul><li>当主进程执行读操作时，访问共享内存；</li><li>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</li></ul><p><img src="/imgs/blog1/image-20210725151319695-16855170885551.png"></p><h2 id="1-2-AOF"><a href="#1-2-AOF" class="headerlink" title="1.2.AOF"></a>1.2.AOF</h2><h3 id="1-2-1-AOF原理"><a href="#1-2-1-AOF原理" class="headerlink" title="1.2.1.AOF原理"></a>1.2.1.AOF原理</h3><p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。</p><h3 id="1-2-2-AOF配置"><a href="#1-2-2-AOF配置" class="headerlink" title="1.2.2.AOF配置"></a>1.2.2.AOF配置</h3><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p><pre><code class="properties"># 是否开启AOF功能，默认是noappendonly yes</code></pre><p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p><pre><code class="properties"># 每执行一次写命令，立即记录appendfsync always # 每隔1秒将缓冲区数据写到AOF文件（默认）appendfsync everysec # 由操作系统决定何时将缓冲区内容写回磁盘appendfsync no</code></pre><p>三种策略对比：</p><p><img src="/imgs/blog1/image-20210725151654046-16855171063852.png"></p><h3 id="1-2-3-AOF文件重写"><a href="#1-2-3-AOF文件重写" class="headerlink" title="1.2.3.AOF文件重写"></a>1.2.3.AOF文件重写</h3><p>AOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。</p><p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p><pre><code class="properties"># AOF文件相比上次增长超过多少百分比则触发bgrewriteaofauto-aof-rewrite-percentage 100# AOF文件达到一定大小触发bgrewriteaofauto-aof-rewrite-min-size 64mb </code></pre><p>重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。</p><h2 id="1-3-RDB与AOF对比"><a href="#1-3-RDB与AOF对比" class="headerlink" title="1.3.RDB与AOF对比"></a>1.3.RDB与AOF对比</h2><p>RDB和AOF各有优缺点，在实际开发中一般会<strong>结合</strong>两者来使用。</p><p><img src="/imgs/blog1/image-20210725151940515-16855171206073.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
