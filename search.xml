<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>blog17</title>
      <link href="/2023/06/18/blog17/"/>
      <url>/2023/06/18/blog17/</url>
      
        <content type="html"><![CDATA[<h2 id="初识volatile"><a href="#初识volatile" class="headerlink" title="初识volatile"></a>初识volatile</h2><p>Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。<br>这个概念听起来有些抽象，我们先看下面一个示例：</p><pre><code class="text">package com.zwx.concurrent;public class VolatileDemo &#123;    public static boolean finishFlag = false;    public static void main(String[] args) throws InterruptedException &#123;        new Thread(()-&gt;&#123;            int i = 0;            while (!finishFlag)&#123;                i++;            &#125;        &#125;,&quot;t1&quot;).start();        Thread.sleep(1000);//确保t1先进入while循环后主线程才修改finishFlag        finishFlag = true;    &#125;&#125;</code></pre><p>这里运行之后他t1线程中的while循环是停不下来的，因为我们是在主线程修改了finishFlag的值，而此值对t1线程不可见，如果我们把变量finishFlag加上volatile修饰:</p><pre><code class="text">public static volatile boolean finishFlag = false;</code></pre><p>这时候再去运行就会发现while循环很快就可以停下来了。<br>从这个例子中我们可以知道<strong>volatile可以解决线程间变量可见性问题</strong>。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。</p><h2 id="volatile如何保证可见性"><a href="#volatile如何保证可见性" class="headerlink" title="volatile如何保证可见性"></a>volatile如何保证可见性</h2><p>利用工具hsdis，打印出汇编指令，可以发现，加了volatile修饰之后打印出来的汇编指令多了下面一行：</p><p><img src="/../imgs/blog17/v2-dbb6b3be2159ff96baaf7738422ba37d_720w.webp" alt="img"></p><p>lock是一种控制指令，在多处理器环境下，lock 汇编指令可以基于总线锁或者缓存锁的机制来达到可见性的一个效果。</p><h2 id="可见性的本质"><a href="#可见性的本质" class="headerlink" title="可见性的本质"></a>可见性的本质</h2><h2 id="硬件层面"><a href="#硬件层面" class="headerlink" title="硬件层面"></a>硬件层面</h2><p>线程是CPU调度的最小单元，线程设计的目的最终仍然是更充分的利用计算机处理的效能，但是绝大部分的运算任务不能只依靠处理器“计算”就能完成，处理器还需要与内存交互，比如读取运算数据、存储运算结果，这个 I&#x2F;O 操作是很难消除的。而由于计算机的存储设备与处理器的运算速度差距非常大，所以现代计算机系统都会增加一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存和处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中。<br>查看我们个人电脑的配置可以看到，CPU有L1,L2,L3三级缓存,大致粗略的结构如下图所示:</p><p><img src="/../imgs/blog17/v2-ac2a8ea5a4d6da53a25317de508b93a5_720w.webp" alt="img"></p><p>从上图可以知道，L1和L2缓存为各个CPU独有，而有了高速缓存的存在以后，每个 CPU 的处理过程是，先将计算需要用到的数据缓存在 CPU 高速缓存中，在 CPU进行计算时，直接从高速缓存中读取数据并且在计算完成之后写入到缓存中。在整个运算过程完成后，再把缓存中的数据同步到主内存。<br>由于在多 CPU 中，每个线程可能会运行在不同的 CPU 内，并且每个线程拥有自己的高速缓存。同一份数据可能会被缓存到多个 CPU 中，如果在不同 CPU 中运行的不同线程看到同一份内存的缓存值不一样就会存在缓存不一致的问题，那么怎么解决缓存一致性问题呢？CPU层面提供了两种解决方法：<strong>总线锁</strong>和<strong>缓存锁</strong></p><h2 id="总线锁"><a href="#总线锁" class="headerlink" title="总线锁"></a>总线锁</h2><p>总线锁，简单来说就是，在多CPU下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个 LOCK#信号，这个信号使得其他处理器无法通过总线来访问到共享内存中的数据，总线锁定把 CPU 和内存之间的通信锁住了(CPU和内存之间通过总线进行通讯)，这使得锁定期间，其他处理器不能操作其他内存地址的数据。然而这种做法的代价显然太大，那么如何优化呢？优化的办法就是降低锁的粒度，所以CPU就引入了缓存锁。</p><h2 id="缓存锁"><a href="#缓存锁" class="headerlink" title="缓存锁"></a>缓存锁</h2><p>缓存锁的核心机制是基于缓存一致性协议来实现的，一个处理器的缓存回写到内存会导致其他处理器的缓存无效，IA-32处理器和Intel 64处理器使用MESI实现缓存一致性协议(注意，<strong>缓存一致性协议不仅仅是通过MESI实现的，不同处理器实现了不同的缓存一致性协议</strong>)</p><h2 id="MESI（缓存一致性协议）"><a href="#MESI（缓存一致性协议）" class="headerlink" title="MESI（缓存一致性协议）"></a>MESI（缓存一致性协议）</h2><p>MESI是一种比较常用的缓存一致性协议，MESI表示缓存行的四种状态，分别是：<br>1、M(Modify) 表示共享数据只缓存在当前 CPU 缓存中，并且是被修改状态，也就是缓存的数据和主内存中的数据不一致<br>2、E(Exclusive) 表示缓存的独占状态，数据只缓存在当前CPU缓存中，并且没有被修改<br>3、S(Shared) 表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致<br>4、I(Invalid) 表示缓存已经失效<br>在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且也监听(snoop)其它CPU的读写操作。<br>对于 MESI 协议，从 CPU 读写角度来说会遵循以下原则：<br><strong>CPU读请求</strong>：缓存处于 M、E、S 状态都可以被读取，I 状态CPU 只能从主存中读取数据<br><strong>CPU写请求</strong>：缓存处于 M、E 状态才可以被写。对于S状态的写，需要将其他CPU中缓存行置为无效才行。</p><h2 id="CPU工作流程"><a href="#CPU工作流程" class="headerlink" title="CPU工作流程"></a>CPU工作流程</h2><p>使用总线锁和缓存锁机制之后，CPU 对于内存的操作大概可以抽象成下面这样的结构。从而达到缓存一致性效果：</p><p><img src="/../imgs/blog17/v2-70c17b191e415d8c836f69756ea390c0_720w.webp" alt="img"></p><h2 id="MESI协议带来的问题"><a href="#MESI协议带来的问题" class="headerlink" title="MESI协议带来的问题"></a>MESI协议带来的问题</h2><p>MESI协议虽然可以实现缓存的一致性，但是也会存在一些问题：就是各个CPU缓存行的状态是通过消息传递来进行的。如果CPU0要对一个在缓存中共享的变量进行写入，首先需要发送一个失效的消息给到其他缓存了该数据的 CPU。并且要等到他们的确认回执。CPU0在这段时间内都会处于阻塞状态。为了避免阻塞带来的资源浪费。CPU中又引入了store bufferes：</p><p><img src="/../imgs/blog17/v2-bd53c745fd2151e273a7d5975ac58089_720w.webp" alt="img"></p><p>如上图，CPU0 只需要在写入共享数据时，直接把数据写入到 store bufferes中，同时发送invalidate消息，然后继续去处理其他指令（异步） 当收到其他所有 CPU 发送了invalidate acknowledge消息时，再将store bufferes中的数据数据存储至缓存行中，最后再从缓存行同步到主内存。但是这种优化就会带来了可见性问题，也可以认为是CPU的乱序执行引起的或者说是指令重排序(指令重排序不仅仅在CPU层面存在，编译器层面也存在指令重排序)。<br>我们通过下面一个简单的示例来看一下指令重排序带来的问题。</p><pre><code class="text">package com.zwx.concurrent;public class ReSortDemo &#123;    int value;    boolean isFinish;    void cpu0()&#123;        value = 10;//S-&gt;I状态，将value写入store bufferes，通知其他CPU当前value的缓存失效        isFinish=true;//E状态    &#125;    void cpu1()&#123;        if (isFinish)&#123;//true            System.out.println(value == 10);//可能为false        &#125;    &#125;&#125;</code></pre><p>这时候理论上当isFinish为true时，value也要等于10，然而由于当value修改为10之后，发送消息通知其他CPU还没有收到响应时，当前CPU0继续执行了isFinish&#x3D;true，所以就可能存在isFinsh为true时，而value并不等于10的问题。<br>我们想一想，其实从硬件层面很难去知道软件层面上的这种前后依赖关系，所以没有办法通过某种手段自动去解决，故而CPU层面就提供了内存屏障(Memory Barrier，Intel称之为 Memory Fence),使得软件层面可以决定在适当的地方来插入内存屏障来禁止指令重排序。</p><h2 id="CPU层面的内存屏障"><a href="#CPU层面的内存屏障" class="headerlink" title="CPU层面的内存屏障"></a>CPU层面的内存屏障</h2><p>CPU内存屏障主要分为以下三类：<br>**写屏障(Store Memory Barrier)**：告诉处理器在写屏障之前的所有已经存储在存储缓存(store bufferes)中的数据同步到主内存，简单来说就是使得写屏障之前的指令的结果对写屏障之后的读或者写是可见的。<br>**读屏障(Load Memory Barrier)**：处理器在读屏障之后的读操作,都在读屏障之后执行。配合写屏障，使得写屏障之前的内存更新对于读屏障之后的读操作是可见的。<br>**全屏障(Full Memory Barrier)**：确保屏障前的内存读写操作的结果提交到内存之后，再执行屏障后的读写操作。<br>这些概念听起来可能有点模糊，我们通过将上面的例子改写一下来说明：</p><pre><code class="text">package com.zwx.concurrent;public class ReSortDemo &#123;    int value;    boolean isFinish;    void cpu0()&#123;        value = 10;//S-&gt;I状态，将value写入store bufferes，通知其他CPU当前value的缓存失效        storeMemoryBarrier();//伪代码，插入一个写屏障，使得value=10这个值强制写入主内存        isFinish=true;//E状态    &#125;    void cpu1()&#123;        if (isFinish)&#123;//true            loadMemoryBarrier();//伪代码，插入一个读屏障，强制cpu1从主内存中获取最新数据            System.out.println(value == 10);//true        &#125;    &#125;    void storeMemoryBarrier()&#123;//写屏障    &#125;    void loadMemoryBarrier()&#123;//读屏障    &#125;&#125;</code></pre><p>通过以上内存屏障，我们就可以防止了指令重排序，得到我们预期的结果。<br>总的来说，内存屏障的作用可以通过防止 CPU 对内存的乱序访问来保证共享数据在多线程并行执行下的可见性，但是这个屏障怎么来加呢？回到最开始我们讲 volatile关键字的代码，这个关键字会生成一个 lock 的汇编指令，这个就相当于实现了一种内存屏障。接下来我们进入volatile原理分析的正题</p><h2 id="JVM层面"><a href="#JVM层面" class="headerlink" title="JVM层面"></a>JVM层面</h2><p>在JVM层面，定义了一种抽象的内存模型(JMM)来规范并控制重排序，从而解决可见性问题。</p><h2 id="JMM-Java内存模型"><a href="#JMM-Java内存模型" class="headerlink" title="JMM(Java内存模型)"></a>JMM(Java内存模型)</h2><p>JMM全称是Java Memory Model(Java内存模型),什么是JMM呢？通过前面的分析发现，导致可见性问题的根本原因是缓存以及指令重排序。 而JMM 实际上就是提供了合理的禁用缓存以及禁止重排序的方法。所以<strong>JMM最核心的价值在于解决可见性和有序性</strong>。<br>JMM属于语言级别的抽象内存模型，可以简单理解为对硬件模型的抽象，它定义了共享内存中多线程程序读写操作的行为规范，通过这些规则来规范对内存的读写操作从而保证指令的正确性，它解决了CPU 多级缓存、处理器优化、指令重排序导致的内存访问问题，保证了并发场景下的可见性。<br>需要注意的是，JMM并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序，也就是说在JMM中，也会存在缓存一致性问题和指令重排序问题。只是JMM把底层的问题抽象到JVM层面，再基于CPU层面提供的内存屏障指令，以及限制编译器的重排序来解决并发问题。</p><h2 id="JMM抽象模型结构"><a href="#JMM抽象模型结构" class="headerlink" title="JMM抽象模型结构"></a>JMM抽象模型结构</h2><p>JMM 抽象模型分为主内存、工作内存；主内存是所有线程共享的，一般是实例对象、静态字段、数组对象等存储在堆内存中的变量。工作内存是每个线程独占的，线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量，线程之间的共享变量值的传递都是基于主内存来完成，可以抽象为下图：</p><p><img src="/../imgs/blog17/v2-73fdde2b306840cdba458748dc1092ba_720w.webp" alt="img"></p><h2 id="JMM如何解决可见性问题"><a href="#JMM如何解决可见性问题" class="headerlink" title="JMM如何解决可见性问题"></a>JMM如何解决可见性问题</h2><p>从JMM的抽象模型结构图来看，如果线程A与线程B之间要通信的话，必须要经历下面2个步骤。<br>1）线程A把本地内存A中更新过的共享变量刷新到主内存中去。<br>2）线程B到主内存中去读取线程A之前已更新过的共享变量。<br>下面通过示意图来说明这两个步骤：</p><p><img src="/../imgs/blog17/v2-f7939f8a4fcc07624718f417bf320021_720w.webp" alt="img"></p><p>结合上图，假设初始时，这3个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存 A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内 存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。<strong>JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。</strong></p><h2 id="编译器的指令重排序"><a href="#编译器的指令重排序" class="headerlink" title="编译器的指令重排序"></a>编译器的指令重排序</h2><p>综合上面从硬件层面和JVM层面的分析，我们知道在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型：<br>1）<strong>编译器优化的重排序</strong>。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。<br>2）<strong>指令级并行的重排序</strong>。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。<br>3）<strong>内存系统的重排序</strong>。由于处理器使用缓存和读&#x2F;写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。<br>从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序，如下图：</p><p><img src="/../imgs/blog17/v2-f1f9a499565d9286778775e0d1a502e9_720w.webp" alt="img"></p><p>其中2和3属于处理器重排序(前面硬件层面已经分析过了)。而这些重排序都可能会导致可见性问题（编译器和处理器在重排序时会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序，编译器会遵守happens-before规则和as-if-serial语义）。<br>对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排 序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。<strong>JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证</strong>。正是因为volatile的这个特性，所以单例模式中可以通过volatile关键字来解决双重检查锁(DCL)写法中所存在的问题。</p><h2 id="JMM层面的内存屏障"><a href="#JMM层面的内存屏障" class="headerlink" title="JMM层面的内存屏障"></a>JMM层面的内存屏障</h2><p>在JMM 中把内存屏障分为四类：</p><p><img src="/../imgs/blog17/v2-dd126df57da384b42693fe00c8a85451_720w.webp" alt="img"></p><p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多数处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。</p><h2 id="happens-before规则"><a href="#happens-before规则" class="headerlink" title="happens-before规则"></a>happens-before规则</h2><p>happens-before表示的是前一个操作的结果对于后续操作是可见的，它是一种表达多个线程之间对于内存的可见性。所以我们可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在happens-before关系。这两个操作可以是同一个线程，也可以是不同的线程，如果想详细了解happens-before规则，可以点击这里。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>并发编程中有三大特性：<strong>原子性</strong>、<strong>可见性</strong>、<strong>有序性</strong>，volatile通过内存屏障禁止指令重排序，主要遵循以下三个规则：</p><ol><li>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</li><li>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</li><li>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</li></ol><p>为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略：</p><ul><li><strong>在每个volatile写操作的前面插入一个StoreStore屏障</strong>。</li><li><strong>在每个volatile写操作的后面插入一个StoreLoad屏障</strong>。</li><li><strong>在每个volatile读操作的后面插入一个LoadLoad屏障</strong>。</li><li><strong>在每个volatile读操作的后面插入一个LoadStore屏障</strong>。</li></ul><p>最后需要特别提一下原子性，Java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的写操作具有原子性。当JVM在这种处理器上运行时，可能会把一个64位long&#x2F;double型变量的写操作拆分为两个32位的写操作来执行，这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。<br>锁的语义决定了临界区代码的执行具有原子性。但是因为一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入，所以<strong>即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读&#x2F;写就具有原子性。但是多个volatile操作或类似于i++这种复合操作，这些操作整体上不具有原子性</strong>。针对于复合操作如i++这种，如果要保证原子性，需要通过synchronized关键字或者加其他锁来处理。<br>注意：在JSR-133之前的旧内存模型中，一个64位long&#x2F;double型变量的读&#x2F;写操作可以被拆分为两个32位的读&#x2F;写操作来执行。从JSR-133内存模型开始（即从JDK5开始），仅仅只允许把一个64位long&#x2F;double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR-133中都必须具有原子性（即任意读操作必须要在单个读事务中执行）。</p><blockquote><p>作者：双子孤狼<br>原文链接：<a href="https://link.zhihu.com/?target=https://blog.csdn.net/zwx900102/article/details/106306915">https://blog.csdn.net/zwx900102</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MyBatis的动态SQL实现原理</title>
      <link href="/2023/06/17/blog16/"/>
      <url>/2023/06/17/blog16/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>MyBatis</strong>提供了强大的动态<strong>SQL</strong>语句生成功能，以应对复杂的业务场景，本篇文章将结合<strong>MyBatis</strong>解析<strong>SQL</strong>语句的过程对<strong>MyBatis</strong>中对&lt;<strong>if**&gt;，&lt;**where**&gt;，&lt;**foreach**&gt;等动态</strong>SQL**标签的支持进行分析。</p><p><strong>MyBatis</strong>版本：<strong>3.5.6</strong></p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="一-XML文档中的节点概念"><a href="#一-XML文档中的节点概念" class="headerlink" title="一. XML文档中的节点概念"></a>一. XML文档中的节点概念</h3><p>在分析<strong>MyBatis</strong>如何支持<strong>SQL</strong>语句之前，本小节先分析<strong>XML</strong>文档中的节点概念。<strong>XML</strong>文档中的每个成分都是一个节点，<strong>DOM</strong>对<strong>XML</strong>节点的规定如下所示。</p><ul><li>整个文档是一个<strong>文档节点</strong>；</li><li>每个<strong>XML</strong>标签是一个<strong>元素节点</strong>；</li><li>包含在元素节点中的文本是<strong>文本节点</strong>。</li></ul><p>以一个<strong>XML</strong>文档进行说明，如下所示。</p><pre><code class="xml">xml复制代码&lt;provinces&gt;    &lt;province name=&quot;四川&quot;&gt;        &lt;capital&gt;成都&lt;/capital&gt;    &lt;/province&gt;    &lt;province name=&quot;湖北&quot;&gt;        &lt;capital&gt;武汉&lt;/capital&gt;    &lt;/province&gt;&lt;/provinces&gt;</code></pre><p>如上所示，整个<strong>XML</strong>文档是一个文档节点，这个文档节点有一个子节点，就是&lt;**provinces**&gt;元素节点，&lt;**provinces**&gt;元素节点有五个子节点，分别是：</p><ol><li>文本节点；</li><li>&lt;**province**&gt;元素节点；</li><li>文本节点，</li><li>&lt;**province**&gt;元素节点；</li><li>文本节点。</li></ol><p>注意，在&lt;**provinces**&gt;元素节点的子节点中的文本节点的文本值均是<code>\n</code>，表示换行符。</p><p>同样，&lt;**province**&gt;元素节点有三个子节点，分别是：</p><ol><li>文本节点；</li><li>&lt;**capital**&gt;元素节点；</li><li>文本节点。</li></ol><p>这里的文本节点的文本值也是<code>\n</code>。</p><p>然后&lt;<strong>capital**&gt;元素节点只有一个子节点，为一个文本节点。节点的子节点之间互为兄弟节点，例如&lt;**provinces**&gt;元素的五个子节点之间互为兄弟节点，</strong>name**为”<strong>四川</strong>“的&lt;**province**&gt;元素节点的上一个兄弟节点为文本节点，下一个兄弟节点也为文本节点。</p><h3 id="二-动态SQL解析流程说明"><a href="#二-动态SQL解析流程说明" class="headerlink" title="二. 动态SQL解析流程说明"></a>二. 动态SQL解析流程说明</h3><p>整体的一个解析流程如下所示。</p><p><img src="/../imgs/blog16/1aaaae5311a34af08caa8246cf4e6910tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="Mybatis-动态SQL解析图"></p><p>**也就是写在映射文件中的一条<code>SQL</code>，会最终被解析为<code>DynamicSqlSource</code>或者<code>RawSqlSource</code>，前者表示动态<code>SQL</code>，后者表示静态<code>SQL</code>**。</p><p>上图中的<strong>MixedSqlNode</strong>，其通常的包含关系可以由下图定义。</p><p><img src="/../imgs/blog16/f58a38d43a2b4c6981f8c692011a4355tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="Mybatis-动态SQL组合图"></p><p>也就是映射文件中定义一条<strong>SQL</strong>语句的<strong>CRUD</strong>标签里的各种子元素，均会被解析为一个<strong>SqlNode</strong>，比如包含了<code>$&#123;&#125;</code>的文本，会被解析为<strong>TextSqlNode</strong>，不包含<code>$&#123;&#125;</code>的文本，会被解析为<strong>StaticTextSqlNode</strong>，&lt;<strong>choose**&gt;标签会被解析为</strong>ChooseSqlNode<strong>等，同时又因为&lt;**choose**&gt;标签中会再有&lt;**when**&gt;和&lt;**otherwise**&gt;子标签，所以</strong>ChooseSqlNode<strong>中又会持有这些子标签的</strong>SqlNode**。</p><p><strong>所以一条<code>SQL</code>最终就是由这条<code>SQL</code>对应的<code>CRUD</code>标签解析成的各种<code>SqlNode</code>组合而成</strong>。</p><h3 id="三-MyBatis解析动态SQL源码分析"><a href="#三-MyBatis解析动态SQL源码分析" class="headerlink" title="三. MyBatis解析动态SQL源码分析"></a>三. MyBatis解析动态SQL源码分析</h3><p>在<a href="https://juejin.cn/post/7203925850398883896">详解MyBatis加载映射文件和动态代理</a>中已经知道，在<strong>XMLStatementBuilder</strong>的<strong>parseStatementNode()</strong> 方法中，会解析映射文件中的&lt;<strong>select**&gt;，&lt;**insert**&gt;，&lt;**update**&gt;和&lt;**delete**&gt;标签（后续统一称为</strong>CURD<strong>标签），并生成</strong>MappedStatement<strong>然后缓存到</strong>Configuration**中。</p><p><strong>CURD</strong>标签的解析由<strong>XMLLanguageDriver</strong>完成，每个标签解析之后会生成一个<strong>SqlSource</strong>，可以理解为<strong>SQL</strong>语句，本小节将对<strong>XMLLanguageDriver</strong>如何完成<strong>CURD</strong>标签的解析进行讨论。</p><p><strong>XMLLanguageDriver</strong>创建<strong>SqlSource</strong>的<strong>createSqlSource()</strong> 方法如下所示。</p><pre><code class="java">java复制代码public SqlSource createSqlSource(Configuration configuration,         XNode script, Class&lt;?&gt; parameterType) &#123;    XMLScriptBuilder builder = new XMLScriptBuilder(            configuration, script, parameterType);    return builder.parseScriptNode();&#125;</code></pre><p>如上所示，<strong>createSqlSource()</strong> 方法的入参中，<strong>XNode</strong>就是<strong>CURD</strong>标签对应的节点，在<strong>createSqlSource()</strong> 方法中先是创建了一个<strong>XMLScriptBuilder</strong>，然后通过<strong>XMLScriptBuilder</strong>来生成<strong>SqlSource</strong>。先看一下<strong>XMLScriptBuilder</strong>的构造方法，如下所示。</p><pre><code class="java">java复制代码public XMLScriptBuilder(Configuration configuration, XNode context,                     Class&lt;?&gt; parameterType) &#123;    super(configuration);    this.context = context;    this.parameterType = parameterType;    initNodeHandlerMap();&#125;</code></pre><p>在<strong>XMLScriptBuilder</strong>的构造方法中，主要是将<strong>CURD</strong>标签对应的节点缓存起来，然后初始化<strong>nodeHandlerMap</strong>，<strong>nodeHandlerMap</strong>中存放着处理<strong>MyBatis</strong>提供的支持动态<strong>SQL</strong>的标签的处理器，<strong>initNodeHandlerMap()</strong> 方法如下所示。</p><pre><code class="java">java复制代码private void initNodeHandlerMap() &#123;    nodeHandlerMap.put(&quot;trim&quot;, new TrimHandler());    nodeHandlerMap.put(&quot;where&quot;, new WhereHandler());    nodeHandlerMap.put(&quot;set&quot;, new SetHandler());    nodeHandlerMap.put(&quot;foreach&quot;, new ForEachHandler());    nodeHandlerMap.put(&quot;if&quot;, new IfHandler());    nodeHandlerMap.put(&quot;choose&quot;, new ChooseHandler());    nodeHandlerMap.put(&quot;when&quot;, new IfHandler());    nodeHandlerMap.put(&quot;otherwise&quot;, new OtherwiseHandler());    nodeHandlerMap.put(&quot;bind&quot;, new BindHandler());&#125;</code></pre><p>现在分析<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法，该方法会创建<strong>SqlSource</strong>，如下所示。</p><pre><code class="java">java复制代码public SqlSource parseScriptNode() &#123;    // 解析动态标签    MixedSqlNode rootSqlNode = parseDynamicTags(context);    SqlSource sqlSource;    if (isDynamic) &#123;        // 创建DynamicSqlSource并返回        sqlSource = new DynamicSqlSource(configuration, rootSqlNode);    &#125; else &#123;        // 创建RawSqlSource并返回        sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType);    &#125;    return sqlSource;&#125;</code></pre><p>在<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法中，会根据<strong>XMLScriptBuilder</strong>中的<strong>isDynamic</strong>属性判断是创建<strong>DynamicSqlSource</strong>还是<strong>RawSqlSource</strong>，在这里暂时不分析<strong>DynamicSqlSource</strong>与<strong>RawSqlSource</strong>的区别，但是可以推测在<strong>parseDynamicTags()</strong> 方法中会改变<strong>isDynamic</strong>属性的值，即在<strong>parseDynamicTags()</strong> 方法中会根据<strong>CURD</strong>标签的节点生成一个<strong>MixedSqlNode</strong>，同时还会改变<strong>isDynamic</strong>属性的值以指示当前<strong>CURD</strong>标签中的<strong>SQL</strong>语句是否是动态的。</p><p><strong>MixedSqlNode</strong>是什么，<strong>isDynamic</strong>属性值在什么情况下会变为<strong>true</strong>，带着这些疑问，继续看<strong>parseDynamicTags()</strong> 方法，如下所示。</p><pre><code class="java">java复制代码protected MixedSqlNode parseDynamicTags(XNode node) &#123;    List&lt;SqlNode&gt; contents = new ArrayList&lt;&gt;();    // 获取节点的子节点    NodeList children = node.getNode().getChildNodes();    // 遍历所有子节点    for (int i = 0; i &lt; children.getLength(); i++) &#123;        XNode child = node.newXNode(children.item(i));        if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE                     || child.getNode().getNodeType() == Node.TEXT_NODE) &#123;            // 子节点为文本节点            String data = child.getStringBody(&quot;&quot;);            // 基于文本节点的值并创建TextSqlNode            TextSqlNode textSqlNode = new TextSqlNode(data);            // isDynamic()方法可以判断文本节点值是否有$&#123;&#125;占位符            if (textSqlNode.isDynamic()) &#123;                // 文本节点值有$&#123;&#125;占位符                // 添加TextSqlNode到集合中                contents.add(textSqlNode);                // 设置isDynamic为true                isDynamic = true;            &#125; else &#123;                // 文本节点值没有占位符                // 创建StaticTextSqlNode并添加到集合中                contents.add(new StaticTextSqlNode(data));            &#125;        &#125; else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) &#123;            // 子节点为元素节点            // CURD节点的子节点中的元素节点只可能为&lt;if&gt;，&lt;foreach&gt;等动态Sql标签节点            String nodeName = child.getNode().getNodeName();            // 根据动态Sql标签节点的名称获取对应的处理器            NodeHandler handler = nodeHandlerMap.get(nodeName);            if (handler == null) &#123;                throw new BuilderException(&quot;Unknown element &lt;&quot; + nodeName + &quot;&gt; in SQL statement.&quot;);            &#125;            // 处理动态Sql标签节点            handler.handleNode(child, contents);            // 设置isDynamic为true            isDynamic = true;        &#125;    &#125;    // 创建MixedSqlNode    return new MixedSqlNode(contents);&#125;</code></pre><p>按照正常执行流程调用<strong>parseDynamicTags()</strong> 时，入参是<strong>CURD</strong>标签节点，此时会遍历<strong>CURD</strong>标签节点的所有子节点，基于每个子节点都会创建一个<strong>SqlNode</strong>然后添加到<strong>SqlNode</strong>集合<strong>contents</strong>中，最后将<strong>contents</strong>作为入参创建<strong>MixedSqlNode</strong>并返回。</p><p><strong>SqlNode</strong>是一个接口，在<strong>parseDynamicTags()</strong> 方法中，可以知道，<strong>TextSqlNode</strong>实现了<strong>SqlNode</strong>接口，<strong>StaticTextSqlNode</strong>实现了<strong>SqlNode</strong>接口，所以当节点的子节点是文本节点时，如果文本值包含有<code>$&#123;&#125;</code>占位符，则创建<strong>TextSqlNode</strong>添加到<strong>contents</strong>中并设置<strong>isDynamic</strong>为<strong>true</strong>，如果文本值不包含<code>$&#123;&#125;</code>占位符，则创建<strong>StaticTextSqlNode</strong>并添加到<strong>contents</strong>中。</p><p>如果<strong>CURD</strong>标签节点的子节点是元素节点，由于<strong>CURD</strong>标签节点的元素节点只可能为&lt;<strong>if**&gt;，&lt;**foreach**&gt;等动态</strong>SQL<strong>标签节点，所以直接会设置</strong>isDynamic<strong>为</strong>true<strong>，同时还会调用动态</strong>SQL<strong>标签节点对应的处理器来生成</strong>SqlNode<strong>并添加到</strong>contents<strong>中。这里以&lt;**if**&gt;标签节点对应的处理器的</strong>handleNode()** 方法为例进行说明，如下所示。</p><pre><code class="java">java复制代码public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123;    // 递归调用parseDynamicTags()解析&lt;if&gt;标签节点    MixedSqlNode mixedSqlNode = parseDynamicTags(nodeToHandle);    String test = nodeToHandle.getStringAttribute(&quot;test&quot;);    // 创建IfSqlNode    IfSqlNode ifSqlNode = new IfSqlNode(mixedSqlNode, test);    // 将IfSqlNode添加到contents中    targetContents.add(ifSqlNode);&#125;</code></pre><p>在&lt;<strong>if**&gt;标签节点对应的处理器的</strong>handleNode()** 方法中，递归的调用了<strong>parseDynamicTags()</strong> 方法来解析&lt;<strong>if**&gt;标签节点，例如&lt;**where**&gt;，&lt;**foreach**&gt;等标签节点对应的处理器的</strong>handleNode()** 方法中也会递归调用<strong>parseDynamicTags()</strong> 方法，这是因为这些动态<strong>SQL</strong>标签是可以嵌套使用的，比如&lt;<strong>where**&gt;标签节点的子节点可以为&lt;**if**&gt;标签节点。通过上面的</strong>handleNode()** 方法，大致可以知道<strong>MixedSqlNode</strong>和<strong>IfSqlNode</strong>也实现了<strong>SqlNode</strong>接口，下面看一下<strong>MixedSqlNode</strong>和<strong>IfSqlNode</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class MixedSqlNode implements SqlNode &#123;    private final List&lt;SqlNode&gt; contents;    public MixedSqlNode(List&lt;SqlNode&gt; contents) &#123;        this.contents = contents;    &#125;    @Override    public boolean apply(DynamicContext context) &#123;        contents.forEach(node -&gt; node.apply(context));        return true;    &#125;    &#125;public class IfSqlNode implements SqlNode &#123;    private final ExpressionEvaluator evaluator;    private final String test;    private final SqlNode contents;    public IfSqlNode(SqlNode contents, String test) &#123;        this.test = test;        this.contents = contents;        this.evaluator = new ExpressionEvaluator();    &#125;    @Override    public boolean apply(DynamicContext context) &#123;        if (evaluator.evaluateBoolean(test, context.getBindings())) &#123;            contents.apply(context);            return true;        &#125;        return false;    &#125;&#125;</code></pre><p>其实到这里已经逐渐清晰明了了，按照正常执行流程调用<strong>parseDynamicTags()</strong> 方法时，是为了将<strong>CURD</strong>标签节点的所有子节点根据子节点类型生成不同的<strong>SqlNode</strong>并放在<strong>MixedSqlNode</strong>中，然后将<strong>MixedSqlNode</strong>返回，但是<strong>CURD</strong>标签节点的子节点中如果存在动态<strong>SQL</strong>标签节点，因为这些动态<strong>SQL</strong>标签节点也会有子节点，所以此时会递归的调用<strong>parseDynamicTags()</strong> 方法，以解析动态<strong>SQL</strong>标签节点的子节点，同样会将这些子节点生成<strong>SqlNode</strong>并放在<strong>MixedSqlNode</strong>中然后将<strong>MixedSqlNode</strong>返回，递归调用<strong>parseDynamicTags()</strong> 方法时得到的<strong>MixedSqlNode</strong>会保存在动态<strong>SQL</strong>标签节点对应的<strong>SqlNode</strong>中，比如<strong>IfSqlNode</strong>中就会将递归调用<strong>parseDynamicTags()</strong> 生成的<strong>MixedSqlNode</strong>赋值给<strong>IfSqlNode</strong>的<strong>contents</strong>字段。</p><p>不同的<strong>SqlNode</strong>都是可以包含彼此的，这是<strong>组合设计模式</strong>的应用，<strong>SqlNode</strong>之间的关系如下所示。</p><p><img src="/../imgs/blog16/220c3d1140904b3aafaa40b4206c5740tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="SqlNode类图"></p><p><strong>SqlNode</strong>接口定义了一个方法，如下所示。</p><pre><code class="java">java复制代码public interface SqlNode &#123;    boolean apply(DynamicContext context);&#125;</code></pre><p>每个<strong>SqlNode</strong>的<strong>apply()</strong> 方法中，除了实现自己本身的逻辑外，还会调用自己所持有的所有<strong>SqlNode</strong>的<strong>apply()</strong> 方法，最终逐层调用下去，所有<strong>SqlNode</strong>的<strong>apply()</strong> 方法均会被执行。</p><h3 id="四-DynamicSqlSource和RawSqlSource源码分析"><a href="#四-DynamicSqlSource和RawSqlSource源码分析" class="headerlink" title="四. DynamicSqlSource和RawSqlSource源码分析"></a>四. DynamicSqlSource和RawSqlSource源码分析</h3><p>回到<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法，该方法中会调用<strong>parseDynamicTags()</strong> 方法以解析<strong>CURD</strong>标签节点并得到<strong>MixedSqlNode</strong>，<strong>MixedSqlNode</strong>中含有被解析的<strong>CURD</strong>标签节点的所有子节点对应的<strong>SqlNode</strong>，最后会基于<strong>MixedSqlNode</strong>创建<strong>DynamicSqlSource</strong>或者<strong>RawSqlSource</strong>，如果<strong>CURD</strong>标签中含有动态<strong>SQL</strong>标签或者<strong>SQL</strong>语句中含有<code>$&#123;&#125;</code>占位符，则创建<strong>DynamicSqlSource</strong>，否则创建<strong>RawSqlSource</strong>。下面分别对<strong>DynamicSqlSource</strong>和<strong>RawSqlSource</strong>的实现进行分析。</p><h4 id="1-DynamicSqlSource源码分析"><a href="#1-DynamicSqlSource源码分析" class="headerlink" title="1. DynamicSqlSource源码分析"></a>1. DynamicSqlSource源码分析</h4><p><strong>DynamicSqlSource</strong>的实现如下所示。</p><pre><code class="java">java复制代码public class DynamicSqlSource implements SqlSource &#123;    private final Configuration configuration;    private final SqlNode rootSqlNode;    public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123;        // 构造函数只是进行了简单的赋值操作        this.configuration = configuration;        this.rootSqlNode = rootSqlNode;    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        DynamicContext context = new DynamicContext(configuration, parameterObject);        // 调用SqlNode的apply()方法完成Sql语句的生成        rootSqlNode.apply(context);        // SqlSourceBuilder可以将Sql语句中的#&#123;&#125;占位符替换为?        SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);        Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass();        // 将Sql语句中的#&#123;&#125;占位符替换为?，并生成一个StaticSqlSource        SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings());        // StaticSqlSource中保存有动态生成好的Sql语句，并且#&#123;&#125;占位符全部替换成了?        BoundSql boundSql = sqlSource.getBoundSql(parameterObject);        // 生成有序参数映射列表        context.getBindings().forEach(boundSql::setAdditionalParameter);        return boundSql;    &#125;&#125;</code></pre><p><strong>DynamicSqlSource</strong>的构造函数只是进行了简单的赋值操作，重点在于其<strong>getBoundSql()</strong> 方法，在<strong>getBoundSql()</strong> 方法中，先是调用<strong>DynamicSqlSource</strong>中的<strong>SqlNode</strong>的<strong>apply()</strong> 方法以完成动态<strong>SQL</strong>语句的生成，此时生成的<strong>SQL</strong>语句中的占位符（如果有的话）为<code>#&#123;&#125;</code>，然后再调用<strong>SqlSourceBuilder</strong>的<strong>parse()</strong> 方法将<strong>SQL</strong>语句中的占位符从<code>#&#123;&#125;</code>替换为<code>?</code>并基于替换占位符后的<strong>SQL</strong>语句生成一个<strong>StaticSqlSource</strong>并返回，这里可以看一下<strong>StaticSqlSource</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class StaticSqlSource implements SqlSource &#123;    private final String sql;    private final List&lt;ParameterMapping&gt; parameterMappings;    private final Configuration configuration;    public StaticSqlSource(Configuration configuration, String sql) &#123;        this(configuration, sql, null);    &#125;    public StaticSqlSource(Configuration configuration, String sql,                            List&lt;ParameterMapping&gt; parameterMappings) &#123;        // 构造函数只是进行简单的赋值操作        this.sql = sql;        this.parameterMappings = parameterMappings;        this.configuration = configuration;    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        // 基于Sql语句创建一个BoundSql并返回        return new BoundSql(configuration, sql, parameterMappings, parameterObject);    &#125;&#125;</code></pre><p>所以分析到这里，可以知道<strong>DynamicSqlSource</strong>的<strong>getBoundSql()</strong> 方法实际上会完成动态<strong>SQL</strong>语句的生成和<code>#&#123;&#125;</code>占位符替换，然后基于生成好的<strong>SQL</strong>语句创建<strong>BoundSql</strong>并返回。<strong>BoundSql</strong>对象的类图如下所示。</p><p><img src="/../imgs/blog16/f035a68cdbf943cfa477c26e217baf4dtplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="BoundSql类图"></p><p>实际上，<strong>MyBatis</strong>中执行<strong>SQL</strong>语句时，如果映射文件中的<strong>SQL</strong>使用到了动态<strong>SQL</strong>标签，那么<strong>MyBatis</strong>中的<strong>Executor</strong>（执行器，后续文章中会进行介绍）会调用<strong>MappedStatement</strong>的<strong>getBoundSql()</strong> 方法，然后在<strong>MappedStatement</strong>的<strong>getBoundSql()</strong> 方法中又会调用<strong>DynamicSqlSource</strong>的<strong>getBoundSql()</strong> 方法，所以<strong>MyBatis</strong>中的动态<strong>SQL</strong>语句会在这条语句实际要执行时才会生成。</p><h4 id="2-RawSqlSource源码分析"><a href="#2-RawSqlSource源码分析" class="headerlink" title="2. RawSqlSource源码分析"></a>2. RawSqlSource源码分析</h4><p>现在看一下<strong>RawSqlSource</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class RawSqlSource implements SqlSource &#123;    private final SqlSource sqlSource;    public RawSqlSource(Configuration configuration, SqlNode rootSqlNode, Class&lt;?&gt; parameterType) &#123;        // 先调用getSql()方法获取Sql语句        // 然后再执行构造函数        this(configuration, getSql(configuration, rootSqlNode), parameterType);    &#125;    public RawSqlSource(Configuration configuration, String sql, Class&lt;?&gt; parameterType) &#123;        SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);        Class&lt;?&gt; clazz = parameterType == null ? Object.class : parameterType;        // 将Sql语句中的#&#123;&#125;占位符替换为?，生成一个StaticSqlSource并赋值给sqlSource        sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;&gt;());    &#125;    private static String getSql(Configuration configuration, SqlNode rootSqlNode) &#123;        DynamicContext context = new DynamicContext(configuration, null);        rootSqlNode.apply(context);        return context.getSql();    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        // 实际是调用StaticSqlSource的getBoundSql()方法        return sqlSource.getBoundSql(parameterObject);    &#125;&#125;</code></pre><p><strong>RawSqlSource</strong>会在构造函数中就将<strong>SQL</strong>语句生成好并替换<code>#&#123;&#125;</code>占位符，在<strong>SQL</strong>语句实际要执行时，就直接将生成好的<strong>SQL</strong>语句返回。所以<strong>MyBatis</strong>中，静态<strong>SQL</strong>语句的执行通常要快于动态<strong>SQL</strong>语句的执行，这在<strong>RawSqlSource</strong>类的注释中也有提及，如下所示。</p><blockquote><p><strong>Static SqlSource. It is faster than {@link DynamicSqlSource} because mappings are calculated during startup.</strong></p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>MyBatis</strong>会为映射文件中的每个<strong>CURD</strong>标签节点里的<strong>SQL</strong>语句生成一个<strong>SqlSource</strong>：</p><ol><li>如果是静态<strong>SQL</strong>语句，那么会生成<strong>RawSqlSource</strong>；</li><li>如果是动态<strong>SQL</strong>语句，则会生成<strong>DynamicSqlSource</strong>。</li></ol><p><strong>MyBatis</strong>在生成<strong>SqlSource</strong>时，会为<strong>CURD</strong>标签节点的每个子节点都生成一个<strong>SqlNode</strong>，无论子节点是文本值节点还是动态<strong>SQL</strong>元素节点，最终所有子节点对应的<strong>SqlNode</strong>都会放在<strong>SqlSource</strong>中以供生成<strong>SQL</strong>语句使用。</p><p>如果是静态<strong>SQL</strong>语句，那么在创建<strong>RawSqlSource</strong>时就会使用<strong>SqlNode</strong>完成<strong>SQL</strong>语句的生成以及将<strong>SQL</strong>语句中的<code>#&#123;&#125;</code>占位符替换为<code>?</code>，然后保存在<strong>RawSqlSource</strong>中，等到这条静态<strong>SQL</strong>语句要被执行时，就直接返回这条静态<strong>SQL</strong>语句。</p><p>如果是动态<strong>SQL</strong>语句，在创建<strong>DynamicSqlSource</strong>时只会简单的将<strong>SqlNode</strong>保存下来，等到这条动态<strong>SQL</strong>语句要被执行时，才会使用<strong>SqlNode</strong>完成<strong>SQL</strong>语句的生成以及将<strong>SQL</strong>语句中的<code>#&#123;&#125;</code>占位符替换为<code>?</code>，最后返回<strong>SQL</strong>语句。</p><p><strong>所以<code>MyBatis</code>中，静态<code>SQL</code>语句的获取要快于动态<code>SQL</code>语句</strong>。</p><p>原文链接：<a href="https://juejin.cn/post/7204115174412238907">https://juejin.cn/post/7204115174412238907</a><br>来源：稀土掘金        作者：半夏之沫</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO模型</title>
      <link href="/2023/06/16/blog15/"/>
      <url>/2023/06/16/blog15/</url>
      
        <content type="html"><![CDATA[<p>本文讨论的背景是Linux环境下的network IO。本文最重要的参考文献是Richard Stevens 的 “UNIX? Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I&#x2F;O Models ”，Stevens在这节中详细说明了各种IO的特点和区别，如果英文够好的话，推荐直接阅读。Stevens的文风是有名的深入浅出，所以不用担心看不懂。本文中的流程图也是截取自参考文献。</p><p>Stevens在文章中一共比较了五种IO Model：</p><p>* blocking IO</p><p>* nonblocking IO</p><p>* IO multiplexing</p><p>* signal driven IO</p><p>* asynchronous IO</p><p>由于signal driven IO在实际中并不常用，所以主要介绍其余四种IO Model。</p><p>再说一下IO发生时涉及的对象和步骤。对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：</p><p>1） 等 待 数 据 准 备  (Waiting  for  the  data  to  be   ready) </p><p>2）将数据从内核拷贝到进程中(Copying the data from the kernel to the process)</p><p>记住这两点很重要，因为这些IO模型的区别就是在两个阶段上各有不同的情况。</p><h1 id="1、阻塞IO（blocking-IO）"><a href="#1、阻塞IO（blocking-IO）" class="headerlink" title="1、阻塞IO（blocking IO）"></a>1、阻塞IO（blocking IO）</h1><p>在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：</p><p><img src="/../imgs/blog15/clip_image002.jpg" alt="img"></p><p>当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。</p><p><strong>所以，blocking  IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。</strong></p><p>几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv() 等接口开始的，这些接口都是阻塞型的。使用这些接口可以很方便的构建服务器&#x2F;客户机的模型。下面是一个简单地“一问一答”的服务器。</p><p><img src="/../imgs/blog15/clip_image004.jpg" alt="img"></p><p>我们注意到，大部分的socket接口都是阻塞型的。所谓阻塞型接口是指系统调用（一般是IO接口）不返回调用结果并让当前线程一直阻塞，只有当该系统调用获得结果或者超时出错时才返回。</p><p>实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的。这给网络编程带来了一个很大的问题，如在调用send()的同时，线程将被阻塞，在  此期间，线程将无法执行任何运算或响应任何的网络请求。</p><p>一个简单的改进方案是在服务器端使用多线程（或多进程）。多线程（或多进  程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。具体使用多进程还是多线程，并没有一个特定的模式。</p><p>传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户机提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的CPU资源，譬如需要进行大规模或长时间的数据运算或文件访问，则进程较为安全。**通常，使用pthread_create ()创建新线程，fork()创建新进程。</p><p>我们假设对上述的服务器 &#x2F; 客户机模型，提出更高的要求，即让服务器同时为多个客户机提供一问一答的服务。于是有了如下的模型。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image006.jpg" alt="img"></td></tr></tbody></table><p>在上述的线程 &#x2F; 时间图例中，主线程持续等待客户端的连接请求，如果有连接， 则创建新线程，并在新线程中提供为前例同样的问答服务。</p><p>很多初学者可能不明白为何一个socket可以accept多次。实际上socket的设计者  可能特意为多客户机的情况留留下了伏笔，让accept()能够返回一个新的socket。下面是 accept 接口的原型：</p><pre><code>int accept(int s, struct sockaddr *addr, socklen_t *addrlen);</code></pre><p>输入参数s是从socket()，bind()和listen()中沿用下来的socket句柄值。执行完bind()和listen()后，操作系统已经开始在指定的端口处监听所有的连接请求，如果 有请求，则将该连接请求加入请求队列。调用accept()接口正是从 socket s 的请求队列抽取第一个连接信息，创建一个与s同类的新的socket返回句柄。新的socket 句柄即是后续read()和recv()的输入参数。如果请求队列当前没有请求，则accept() 将进入阻塞状态直到有请求进入队列。</p><p>上述多线程的服务器模型似乎完美的解决了为多个客户机提供问答服务的要   求，但其实并不尽然。如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而线程与进程本身也更容易进入假死状态。</p><p>很多程序员可能会考虑使用线程池或连接池。“线程池”旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。“连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统，如websphere、tomcat和各种数据库等。但是，“线程池”和“连接池”技术也只是在一定程度上缓解了频繁调用IO接口带来的资源占用。而且，所谓“池”始终有其上  限，当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有池的时候效果好多少。所以使用“池”必须考虑其面临的响应规模，并根据响应规模调整“池”的大小。</p><p>对应上例中的所面临的可能同时出现的上千甚至上万次的客户端请求，“线程池”或“连接池”或许可以缓解部分压力，但是不能解决所有问题。总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞接口来尝试解决这个问题。</p><h1 id="2、非阻塞IO（non-blocking-IO）"><a href="#2、非阻塞IO（non-blocking-IO）" class="headerlink" title="2、非阻塞IO（non-blocking IO）"></a>2、非阻塞IO（non-blocking IO）</h1><p>Linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：</p><p><img src="/../imgs/blog15/clip_image008.jpg" alt="img"></p><p>从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ， 它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read 操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call， 那么它马上就将数据拷贝到了用户内存，然后返回。</p><p><strong>所以，在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有。</strong></p><p>非阻塞的接口相比于阻塞型接口的显著差异在于，在被调用之后立即返回。使用如下的函数可以将某句柄fd设为非阻塞状态。</p><pre><code>fcntl( fd, F_SETFL, O_NONBLOCK );</code></pre><p>下面将给出只用一个线程，但能够同时从多个连接中检测数据是否送达，并且接受数据的模型。</p><p><img src="/../imgs/blog15/clip_image010.jpg" alt="img"></p><p>在非阻塞状态下，recv() 接口在被调用后立即返回，返回值代表了不同的含义。如在本例中，</p><p>* recv() 返回值大于 0，表示接受数据完毕，返回值即是接受到的字节数；</p><p>* recv() 返回 0，表示连接已经正常断开；</p><p>* recv() 返回 -1，且 errno 等于 EAGAIN，表示 recv 操作还没执行完成；</p><p>* recv() 返回 -1，且 errno 不等于 EAGAIN，表示 recv 操作遇到系统错误errno。</p><p>可以看到服务器线程可以通过循环调用recv()接口，可以在单个线程内实现对所有连接的数据接收工作。但是上述模型绝不被推荐。因为，循环调用recv()将大幅度推高CPU 占用率；此外，在这个方案中recv()更多的是起到检测“操作是否完成”的作用，实际操作系统提供了更为高效的检测“操作是否完成“作用的接口，例如select()多路复用模式，可以一次检测多个连接是否活跃。</p><h1 id="3、多路复用IO（IO-multiplexing）"><a href="#3、多路复用IO（IO-multiplexing）" class="headerlink" title="3、多路复用IO（IO multiplexing）"></a>3、多路复用IO（IO multiplexing）</h1><p> IO multiplexing这个词可能有点陌生，但是如果我说select&#x2F;epoll，大概就都能明白了。有些地方也称这种IO方式为<strong>事件驱动IO</strong>(event driven IO)。我们都知道， select&#x2F;epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基  本原理就是select&#x2F;epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image012.jpg" alt="img"></td></tr></tbody></table><p>当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所  有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。  这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。</p><p>这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一局：所以，如果处理的连接数不是很高的话，使用select&#x2F;epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select&#x2F;epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）</p><p><strong>在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。</strong>只不过process是被select这个函数block，而不是被socket  IO给block。因此select()与非阻塞IO类似。大部分Unix&#x2F;Linux都支持select函数，该函数用于探测多个文件句柄的状态变化。下面给出select接口的原型：</p><pre><code>FD_ZERO(int fd, fd_set* fds) FD_SET(int fd, fd_set* fds) FD_ISSET(int fd, fd_set* fds) FD_CLR(int fd, fd_set* fds)int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout)</code></pre><p>这里，fd_set 类型可以简单的理解为按 bit 位标记句柄的队列，例如要在某fd_set  中标记一个值为16的句柄，则该fd_set的第16个bit位被标记为1。具体的置位、验证可使用 FD_SET、FD_ISSET等宏实现。在select()函数中，readfds、writefds和exceptfds同时作为输入参数和输出参数。如果输入的readfds标记了16  号句柄，则select()将检测16号句柄是否可读。在select()返回后，可以通过检查readfds有否标记16号句柄，来判断该“可读”事件是否发生。另外，用户可以设置timeout时间。</p><p>下面将重新模拟上例中从多个客户端接收数据的模型。</p><p><img src="/../imgs/blog15/clip_image014.jpg" alt="img"></p><p>该模型只是描述了使用select()接口同时从多个客户端接收数据的过程；由于select()接口可以同时对多个句柄进行读状态、写状态和错误状态的探测，所以可以很容易易构建为多个客户端提供独立问答服务的服务器系统。如下图。</p><p><img src="/../imgs/blog15/clip_image016.jpg" alt="img"></p><p>这里需要指出的是，客户端的一个 connect() 操作，将在服务器端激发一个“可读事件”，所以 select() 也能探测来自客户端的 connect() 行为。</p><p>上述模型中，最关键的地方是如何动态维护select()的三个参数readfds、writefds和exceptfds。作为输入参数，readfds应该标记所有的需要探测的“可读事件”的句柄，其中永远包括那个探测 connect() 的那个“母”句柄；同时，writefds 和exceptfds 应该标记所有需要探测的“可写事件”和“错误事件”的句柄 ( 使用FD_SET() 标记 )。作为输出参数，readfds、writefds和exceptfds中的保存了 select() 捕捉到的所有事件的句柄值。程序员需要检查的所有的标记位 ( 使用FD_ISSET()检查 )，以确定到底哪些句柄发生了事件。</p><p>上述模型主要模拟的是“一问一答”的服务流程，所以如果select()发现某句柄捕捉到了“可读事件”，服务器程序应及时做recv()操作，并根据接收到的数据准备好待发送数据，并将对应的句柄值加入writefds，准备下一次的“可写事件”的select()  探测。同样，如果select()发现某句柄捕捉到“可写事件”，则程序应及时做send()操  作，并准备好下一次的“可读事件”探测准备。下图描述的是上述模型中的一个执行周期。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image018.jpg" alt="img"></td></tr></tbody></table><p>这种模型的特征在于每一个执行周期都会探测一次或一组事件，一个特定的事  件会触发某个特定的响应。我们可以将这种模型归类为“<strong>事件驱动模型</strong>”。</p><p>相比其他模型，使用select() 的事件驱动模型只用单线程（进程）执行，占用资源少，不消耗太多  CPU，同时能够为多客户端提供服务。如果试图建立一个简单的事件驱动的服务器程序，这个模型有一定的参考价值。</p><p>但这个模型依旧有着很多问题。首先select()接口并不是实现“事件驱动”的最好选择。因为当需要探测的句柄值较大时，select()接口本身需要消耗大量量时间去轮询各个句柄。很多操作系统提供了更为高效的接口，如linux提供了epoll，BSD提供了kqueue， Solaris提供了&#x2F;dev&#x2F;poll，…。如果需要实现更高效的服务器程序，类似epoll这样的接口更被推荐。遗憾的是不同的操作系统特供的epoll接口有很大差异，所以使用类似于epoll的接口实现具有较好跨平台能力力的服务器会比较困难。其次，该模型将事件探测和事件响应夹杂在一起，一旦事件响应的执行体庞大，则对整个模型是灾难性的。如下例，庞大的执行体1的将直接导致响应事件2的执行体迟迟得不到执行，并在很大程度上降低了事件探测的及时性。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image020.jpg" alt="img"></td></tr></tbody></table><p>幸运的是，有很多高效的事件驱动库可以屏蔽上述的困难，常见的事件驱动库有<strong>libevent库</strong>，还有作为libevent替代者的<strong>libev库</strong>。这些库会根据操作系统的特点选 择最合适的事件探测接口，并且加入了信号(signal) 等技术以支持异步响应，这使得这些库成为构建事件驱动模型的不二选择。下章将介绍如何使用libev库替换select或epoll接口，实现高效稳定的服务器模型。</p><p>实际上，Linux内核从2.6开始，也引入了支持异步响应的IO操作，如aio_read, aio_write，这就是异步IO。</p><h1 id="4、异步IO（Asynchronous-I-x2F-O）"><a href="#4、异步IO（Asynchronous-I-x2F-O）" class="headerlink" title="4、异步IO（Asynchronous I&#x2F;O）"></a>4、异步IO（Asynchronous I&#x2F;O）</h1><p> Linux下的asynchronous  IO其实用得不多，从内核2.6版本才开始引入。先看一下它的流程：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image022.jpg" alt="img"></td></tr></tbody></table><p>用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据  拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。</p><p>用异步IO实现的服务器这里就不举例了，以后有时间另开文章来讲述。异步IO 是真正非阻塞的，它不会对请求进程产生任何的阻塞，因此对高并发的网络服务器实现至关重要。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>到目前为止，已经将四个IO模型都介绍完了。现在回过头来回答最初的那几个问题：blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪。</p><p>先回答最简单的这个：blocking与non-blocking。前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成， 而non-blocking IO在kernel还在准备数据的情况下会立刻返回。</p><p>在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的：</p><p>* A synchronous I&#x2F;O operation causes the requesting process to be blocked until that I&#x2F;O operation completes;</p><p>* An asynchronous I&#x2F;O operation does not cause the requesting process to be blocked;</p><p><strong>两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。</strong>按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个系统调用。non-blocking   IO在执行recvfrom这个系统调用的时候，如果kernel的数据没有准备好，这时候不会block进程。但是当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内进程是被block的。而asynchronous IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。</p><p>还有一种不常用的signal driven IO，即信号驱动IO。总的来说，UNP中总结的IO模型有5种之多：阻塞IO，非阻塞IO，IO复用，信号驱动IO，异步IO。前四种都属于同步IO。阻塞IO不必说了。非阻塞IO ，IO请求时加上O_NONBLOCK一类的标志位，立刻返回，IO没有就绪会返回错误，需要请求进程主动轮询不断发IO请求直到返回正确。IO复用同非阻塞IO本质一样，不过利利用了新的select系统调用，   由内核来负责本来是请求进程该做的轮询操作。看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才算提高了效率。信号驱动IO，调用sigaltion系统调用，当内核中IO数据就绪时以SIGIO信号通知请求进程，请求进程再把数据从内核读入到用户空间，这一步是阻塞的。异步IO，如定义所说，不会因为IO操作阻塞，IO操作全部完成才通知请求进程。  各个IO Model的比较如图所示：</p><p><img src="/../imgs/blog15/clip_image024.jpg" alt="img"></p><p>经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。</p><p>参考文献：</p><p>IO - 同步，异步，阻塞，非阻塞 ：<a href="http://blog.csdn.net/historyasamirror/article/details/5778378">http://blog.csdn.net/historyasamirror/article/details/5778378 </a></p><p>使用事件驱动模型实现高效稳定的网络服务器程序：<a href="http://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/">http://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/</a></p><p><a href="http://blog.chinaunix.net/uid-28458801-id-4464639.html">http://blog.chinaunix.net/uid-28458801-id-4464639.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从链表中删去总和值为零的连续节点</title>
      <link href="/2023/06/12/blog14/"/>
      <url>/2023/06/12/blog14/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><p><a href="https://leetcode.cn/problems/remove-zero-sum-consecutive-nodes-from-linked-list/description/">1171. 从链表中删去总和值为零的连续节点 - 力扣（Leetcode）</a></p><p>给你一个链表的头节点 <code>head</code>，请你编写代码，反复删去链表中由 <strong>总和</strong> 值为 <code>0</code> 的连续节点组成的序列，直到不存在这样的序列为止。</p><p>删除完毕后，请你返回最终结果链表的头节点。</p><p>你可以返回任何满足题目要求的答案。</p><p>（注意，下面示例中的所有序列，都是对 <code>ListNode</code> 对象序列化的表示。）</p><p><strong>示例 1：</strong></p><pre><code>输入：head = [1,2,-3,3,1]输出：[3,1]提示：答案 [1,2,1] 也是正确的。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：head = [1,2,3,-3,4]输出：[1,2,4]</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：head = [1,2,3,-3,-2]输出：[1]</code></pre><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>若链表节点的两个前缀和相等，说明两个前缀和之间的连续节点序列的和为 0，那么可以消去这部分连续节点。</p><p>我们第一次遍历链表，用哈希表 last记录前缀和以及对应的链表节点，对于同一前缀和s，后面出现的节点覆盖前面的节点。</p><p>接下来，我们再次遍历链表，若当前节点 cur 的前缀和 s在 last出现，说明 cur与 last[s]之间的所有节点和为 0，我们直接修改 cur 的指向，即 <code>cur.next=last[s].next</code>，这样就删去了这部分和为 000 的连续节点。继续往后遍历，删除所有和为 0的连续节点。</p><p>最后返回链表的头节点 <code>dummy.next</code>。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code class="java">class Solution &#123;  public ListNode removeZeroSumSublists(ListNode head) &#123;​    ListNode dummy = new ListNode(0, head);​    Map&lt;Integer, ListNode&gt; last = new HashMap&lt;&gt;();​    int s = 0;​    ListNode cur = dummy;​    while(cur!=null)&#123;​      s+=cur.val;​      last.put(s, cur);​      cur = cur.next;​    &#125;​    s=0;​    cur=dummy;​    while(cur!=null)&#123;​      s+=cur.val;​      cur.next = last.get(s).next;​      cur = cur.next;​    &#125;​    return dummy.next;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>老鼠和奶酪</title>
      <link href="/2023/06/07/blog13/"/>
      <url>/2023/06/07/blog13/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><p><a href="https://leetcode.cn/problems/mice-and-cheese/description/">2611. 老鼠和奶酪 - 力扣（Leetcode）</a></p><p>有两只老鼠和 <code>n</code> 块不同类型的奶酪，每块奶酪都只能被其中一只老鼠吃掉。</p><p>下标为 <code>i</code> 处的奶酪被吃掉的得分为：</p><ul><li>如果第一只老鼠吃掉，则得分为 <code>reward1[i]</code> 。</li><li>如果第二只老鼠吃掉，则得分为 <code>reward2[i]</code> 。</li></ul><p>给你一个正整数数组 <code>reward1</code> ，一个正整数数组 <code>reward2</code> ，和一个非负整数 <code>k</code> 。</p><p>请你返回第一只老鼠恰好吃掉 <code>k</code> 块奶酪的情况下，<strong>最大</strong> 得分为多少。</p><p><strong>示例 1：</strong></p><pre><code>输入：reward1 = [1,1,3,4], reward2 = [4,4,1,1], k = 2输出：15解释：这个例子中，第一只老鼠吃掉第 2 和 3 块奶酪（下标从 0 开始），第二只老鼠吃掉第 0 和 1 块奶酪。总得分为 4 + 4 + 3 + 4 = 15 。15 是最高得分。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：reward1 = [1,1], reward2 = [1,1], k = 2输出：2解释：这个例子中，第一只老鼠吃掉第 0 和 1 块奶酪（下标从 0 开始），第二只老鼠不吃任何奶酪。总得分为 1 + 1 = 2 。2 是最高得分。</code></pre><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>​假设所有的奶酪都被第二只老鼠吃掉，记录下此时得分<code>res</code>。若第<code>i</code>块奶酪被第一只老鼠吃掉，得分变化为<code>reward1[i]-reward2[i]</code>，建立数组reward，其中<code>reward[i]=rewar1d[i]-reward2[i]</code>，并对reward数组排序，res加上reward后k个元素（也就是第一只老鼠吃k块的最大值变化）即为最终结果。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code class="java">class Solution &#123;  public int miceAndCheese(int[] reward1, int[] reward2, int k) &#123;​    int ans = 0;​    int n = reward1.length;​    int[] diffs = new int[n];​    for (int i = 0; i &lt; n; i++) &#123;​      ans += reward2[i];​      diffs[i] = reward1[i] - reward2[i];​    &#125;​    Arrays.sort(diffs);​    for (int i = 1; i &lt;= k; i++) &#123;​      ans += diffs[n - i];​    &#125;​    return ans;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch面试题</title>
      <link href="/2023/06/06/blog12/"/>
      <url>/2023/06/06/blog12/</url>
      
        <content type="html"><![CDATA[<h2 id="1-为什么要使用ElasticSearch"><a href="#1-为什么要使用ElasticSearch" class="headerlink" title="1 为什么要使用ElasticSearch?"></a>1 为什么要使用ElasticSearch?</h2><p>​系统中的数据，随着业务的发展，时间的推移，将会非常多，而业务中往往采用模糊查询进行数据的搜索，而模糊查询会导致查询引擎放弃索引，导致系统查询数据时都是全表扫描，在百万级别的数据库中，查询效率是非常低下的，而我们使用ES做一个全文索引，将经常查询的系统功能的某些字段，比如说电商系统的商品表中商品名，描述、价格还有id这些字段我们放入ES索引库里，可以提高查询速度。</p><h2 id="2-ElasticSearch的master选举流程？"><a href="#2-ElasticSearch的master选举流程？" class="headerlink" title="2 ElasticSearch的master选举流程？"></a>2 ElasticSearch的master选举流程？</h2><p>​ElasticSearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分</p><p>​对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</p><p>​如果对某个节点的投票数达到一定的值（可以成为master节点数n&#x2F;2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。</p><p>​master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</p><h2 id="3-ElasticSearch集群脑裂问题？"><a href="#3-ElasticSearch集群脑裂问题？" class="headerlink" title="3 ElasticSearch集群脑裂问题？"></a>3 ElasticSearch集群脑裂问题？</h2><p><strong>“脑裂”问题可能的成因</strong><strong>:</strong></p><p>​ <strong>网络问题</strong>：集群间的网络延迟导致一些节点访问不到master，认为master挂掉了从而选举出新的master，并对master上的分片和副本标红，分配新的主分片</p><p>​<strong>节点负载</strong>：主节点的角色既为master又为data，访问量较大时可能会导致ES停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。</p><p>​<strong>内存回收</strong>：data节点上的ES进程占用的内存较大，引发JVM的大规模内存回收，造成ES进程失去响应。</p><p><strong>脑裂问题解决方案：</strong></p><p>​<strong>减少误判：</strong>discovery.zen.ping_timeout节点状态的响应时间，默认为3s，可以适当调大，如果master在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如6s，discovery.zen.ping_timeout:6），可适当减少误判。</p><p>​<strong>选举触发</strong>: discovery.zen.minimum_master_nodes:1</p><p>该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值， 且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为（n&#x2F;2）+1，n为主节点个数 （即有资格成为主节点的节点个数）</p><p>​<strong>角色分离</strong>：即master节点与data节点分离，限制角色</p><p>主节点配置为：node.master: true node.data: false</p><p>从节点配置为：node.master: false node.data: true</p><h2 id="4-ElasticSearch索引文档的流程？"><a href="#4-ElasticSearch索引文档的流程？" class="headerlink" title="4 ElasticSearch索引文档的流程？"></a>4 ElasticSearch索引文档的流程？</h2><p><img src="/imgs/blog12/clip_image002.jpg" alt="img"></p><p>​ 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片：</p><p><strong>shard &#x3D; hash(document_id) % (num_of_primary_shards)</strong></p><p>​ 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Memory Buffer到Filesystem Cache的过程就叫做refresh；</p><p>​ 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；</p><p>​在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。</p><p>​flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；</p><h2 id="5-ElasticSearch更新和删除文档的流程？"><a href="#5-ElasticSearch更新和删除文档的流程？" class="headerlink" title="5 ElasticSearch更新和删除文档的流程？"></a>5 ElasticSearch更新和删除文档的流程？</h2><p>​删除和更新也都是写操作，但是ElasticSearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；</p><p>​磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。</p><p>​在新的文档被创建时，ElasticSearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</p><h2 id="6-ElasticSearch搜索的流程？"><a href="#6-ElasticSearch搜索的流程？" class="headerlink" title="6 ElasticSearch搜索的流程？"></a>6 ElasticSearch搜索的流程？</h2><p><img src="/imgs/blog12/clip_image004.jpg" alt="img"></p><p>​ 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；</p><p>​ 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。</p><p>​每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</p><p>​接下来就是取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</p><p>​Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。</p><h2 id="7-ElasticSearch-在部署时，对-Linux-的设置有哪些优化方法？"><a href="#7-ElasticSearch-在部署时，对-Linux-的设置有哪些优化方法？" class="headerlink" title="7 ElasticSearch 在部署时，对 Linux 的设置有哪些优化方法？"></a>7 ElasticSearch 在部署时，对 Linux 的设置有哪些优化方法？</h2><p>​64 GB 内存的机器是非常理想的， 但是32 GB 和16 GB 机器也是很常见的。少于8 GB 会适得其反。</p><p>​如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。</p><p>​如果你负担得起 SSD，它将远远超出任何旋转介质。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起，SSD 是一个好的选择。</p><p>​即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。</p><p>​请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。 在 ElasticSearch 的几个地方，使用 Java 的本地序列化。</p><p>​通过设置gateway.recover_after_nodes、gateway.expected_nodes、gateway.recover_after_time可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。</p><p>​ElasticSearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。最好使用单播代替组播。</p><p>​不要随意修改垃圾回收器（CMS）和各个线程池的大小。</p><p>​把你的内存的（少于）一半给 Lucene（但不要超过 32 GB！），通过ES_HEAP_SIZE 环境变量设置。</p><p>​内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。 再想想那么多 10 微秒的操作时延累加起来。 不难看出 swapping 对于性能是多么可怕。</p><p>​Lucene 使用了大量的文件。同时，ElasticSearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字。 所有这一切都需要足够的文件描述符。你应该增加你的文件描述符，设置一个很大的值，如 64,000。</p><p><strong>补充：索引阶段性能提升方法</strong></p><p>​使用批量请求并调整其大小：每次批量数据 5–15 MB 大是个不错的起始点。</p><p>​存储：使用 SSD</p><p>​段和合并：ElasticSearch 默认值是 20 MB&#x2F;s，对机械磁盘应该是个不错的设置。如果你用的是 SSD，可以考虑提高到 100–200 MB&#x2F;s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。另外还可以增加 index.translog.flush_threshold_size 设置，从默认的 512 MB 到更大一些的值，比如 1 GB，这可以在一次清空触发的时候在事务日志里积累出更大的段。</p><p>​如果你的搜索结果不需要近实时的准确度，考虑把每个索引的index.refresh_interval 改到30s。</p><p>​如果你在做大批量导入，考虑通过设置index.number_of_replicas: 0 关闭副本。</p><h2 id="8-GC方面，在使用ElasticSearch时要注意什么？"><a href="#8-GC方面，在使用ElasticSearch时要注意什么？" class="headerlink" title="8 GC方面，在使用ElasticSearch时要注意什么？"></a>8 GC方面，在使用ElasticSearch时要注意什么？</h2><p>​倒排词典的索引需要常驻内存，无法GC，需要监控data node上segment memory增长趋势。</p><p>​各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小，并且要应该根据最坏的情况来看heap是否够用，也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？避免采用clear cache等“自欺欺人”的方式来释放内存。</p><p>​避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan &amp; scroll api来实现。</p><p>​cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。</p><p>​想知道heap够不够，必须结合实际应用场景，并对集群的heap使用情况做持续的监控。</p><h2 id="9-ElasticSearch对于大数据量（上亿量级）的聚合如何实现？"><a href="#9-ElasticSearch对于大数据量（上亿量级）的聚合如何实现？" class="headerlink" title="9 ElasticSearch对于大数据量（上亿量级）的聚合如何实现？"></a>9 ElasticSearch对于大数据量（上亿量级）的聚合如何实现？</h2><p>ElasticSearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 </p><h2 id="10-在并发情况下，ElasticSearch如果保证读写一致？"><a href="#10-在并发情况下，ElasticSearch如果保证读写一致？" class="headerlink" title="10 在并发情况下，ElasticSearch如果保证读写一致？"></a>10 在并发情况下，ElasticSearch如果保证读写一致？</h2><p>​可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；</p><p>​另外对于写操作，一致性级别支持quorum&#x2F;one&#x2F;all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。</p><p>​对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。</p><h2 id="11-如何监控-ElasticSearch-集群状态？"><a href="#11-如何监控-ElasticSearch-集群状态？" class="headerlink" title="11 如何监控 ElasticSearch 集群状态？"></a>11 如何监控 ElasticSearch 集群状态？</h2><p>​ElasticSearch-head插件</p><p>​通过 Kibana 监控 ElasticSearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标</p><h2 id="12-是否了解字典树？"><a href="#12-是否了解字典树？" class="headerlink" title="12 是否了解字典树？"></a>12 是否了解字典树？</h2><p>​常用字典数据结构如下所示:</p><p><img src="/imgs/blog12/clip_image006.jpg" alt="img"></p><p>​字典树又称单词查找树，<a href="https://baike.baidu.com/item/Trie%E6%A0%91">Trie树</a>，是一种<a href="https://baike.baidu.com/item/%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84/9663807">树形结构</a>，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的<a href="https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6">字符</a>串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。</p><p>​Trie的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有3个基本性质:</p><p>​①根节点不包含字符，除根节点外每一个节点都只包含一个字符。</p><p>​②从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。</p><p>​③每个节点的所有子节点包含的字符都不相同。</p><p>​对于中文的字典树，每个节点的子节点用一个哈希表存储，这样就不用浪费太大的空间，而且查询速度上可以保留哈希的复杂度O(1)。</p><h2 id="13-ElasticSearch中的集群、节点、索引、文档、类型是什么？"><a href="#13-ElasticSearch中的集群、节点、索引、文档、类型是什么？" class="headerlink" title="13 ElasticSearch中的集群、节点、索引、文档、类型是什么？"></a>13 ElasticSearch中的集群、节点、索引、文档、类型是什么？</h2><p>​集群是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“ElasticSearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。</p><p>​节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。</p><p>​索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL &#x3D;&gt;数据库 ElasticSearch &#x3D;&gt;索引</p><p>​文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL &#x3D;&gt; Databases &#x3D;&gt; Tables &#x3D;&gt; Columns &#x2F; Rows ElasticSearch &#x3D;&gt; Indices &#x3D;&gt; Types &#x3D;&gt;具有属性的文档</p><p>​类型是索引的逻辑类别&#x2F;分区，其语义完全取决于用户。</p><h2 id="14-ElasticSearch中的倒排索引是什么？"><a href="#14-ElasticSearch中的倒排索引是什么？" class="headerlink" title="14 ElasticSearch中的倒排索引是什么？"></a>14 ElasticSearch中的倒排索引是什么？</h2><p>​倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。ES中的倒排索引其实就是lucene的倒排索引，区别于传统的正向索引，倒排索引会再存储数据时将关键词和数据进行关联，保存到倒排表中，然后查询时，将查询内容进行分词后在倒排表中进行查询，最后匹配数据即可。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch分片集群</title>
      <link href="/2023/06/06/blog11/"/>
      <url>/2023/06/06/blog11/</url>
      
        <content type="html"><![CDATA[<h2 id="1-分布式集群"><a href="#1-分布式集群" class="headerlink" title="1 分布式集群"></a>1 分布式集群</h2><h3 id="1-1-单节点集群"><a href="#1-1-单节点集群" class="headerlink" title="1.1 单节点集群"></a>1.1 单节点集群</h3><p>我们在包含一个空节点的集群内创建名为 users 的索引，为了演示目的，我们将分配3个主分片和一份副本（每个主分片拥有一个副本分片）</p><p>{</p><p>  “settings” : {</p><p>   “number_of_shards” : 3,</p><p>   “number_of_replicas” : 1</p><p>  }</p><p>}</p><p><img src="/imgs/blog11/clip_image002-16860529743441.jpg" alt="img"></p><p>我们的集群现在是拥有一个索引的单节点集群。所有3个主分片都被分配在 node-1 。</p><p><img src="/imgs/blog11/clip_image004-16860529743442.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image006.jpg" alt="img"></p><p>  集群健康值:yellow( 3 of 6 ) : 表示当前集群的全部主分片都正常运行，但是副本分片没有全部处在正常状态  <img src="/imgs/blog11/clip_image008.jpg" alt="img">: 3个主分片正常  <img src="/imgs/blog11/clip_image010.jpg" alt="img">: 3个副本分片都是  Unassigned —— 它们都没有被分配到任何节点。 在同一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点上的所有副本数据。  </p><p>当前我们的集群是正常运行的，但是在硬件故障时有丢失数据的风险。</p><h3 id="1-2-故障转移"><a href="#1-2-故障转移" class="headerlink" title="1.2 故障转移"></a>1.2 故障转移</h3><p>当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。 但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。</p><p>如果启动了第二个节点，我们的集群将会拥有两个节点的集群 : 所有主分片和副本分片都已被分配</p><p><img src="/imgs/blog11/clip_image012.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image014.jpg" alt="img"></p><p>  集群健康值:green( 6 of 6 ) : 表示所有6个分片（包括3个主分片和3个副本分片）都在正常运行。  <img src="/imgs/blog11/clip_image008.jpg" alt="img">: 3个主分片正常  <img src="/imgs/blog11/clip_image016.jpg" alt="img">: 当第二个节点加入到集群后，3个副本分片将会分配到这个节点上——每个主分片对应一个副本分片。这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。所有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们既可以从主分片又可以从副本分片上获得文档。  </p><h3 id="1-3-水平扩容"><a href="#1-3-水平扩容" class="headerlink" title="1.3 水平扩容"></a>1.3 水平扩容</h3><p>怎样为我们的正在增长中的应用程序按需扩容呢？当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配</p><p><img src="/imgs/blog11/clip_image018.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image020.jpg" alt="img"></p><p>  集群健康值:green( 6 of 6 ) : 表示所有6个分片（包括3个主分片和3个副本分片）都在正常运行。  <img src="/imgs/blog11/clip_image022.jpg" alt="img">  <img src="/imgs/blog11/clip_image024.jpg" alt="img">  <img src="/imgs/blog11/clip_image026.jpg" alt="img">  Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点，现在每个节点上都拥有2个分片，而不是之前的3个。 这表示每个节点的硬件资源（CPU, RAM, I&#x2F;O）将被更少的分片所共享，每个分片的性能将会得到提升。  分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。  </p><p>**<img src="/imgs/blog11/clip_image028.jpg" alt="img"><strong><strong>但是如果我们想要扩容超过6</strong></strong>个节点怎么办呢？**</p><p>主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。</p><p>在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 1 增加到 2</p><p>{</p><p>  “number_of_replicas” : 2</p><p>}</p><p><img src="/imgs/blog11/clip_image030.jpg" alt="img"></p><p>users索引现在拥有9个分片：3个主分片和6个副本分片。 这意味着我们可以将集群扩容到9个节点，每个节点上一个分片。相比原来3个节点时，集群搜索性能可以提升 3 倍。</p><p><img src="/imgs/blog11/clip_image032.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image034.jpg" alt="img"></p><p>当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。</p><p>但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去2个节点的情况下不丢失任何数据。</p><h3 id="1-4-应对故障"><a href="#1-4-应对故障" class="headerlink" title="1.4 应对故障"></a>1.4 应对故障</h3><p>我们关闭第一个节点，这时集群的状态为:关闭了一个节点后的集群。</p><p><img src="/imgs/blog11/clip_image036.jpg" alt="img"><img src="/imgs/blog11/clip_image038.jpg" alt="img"></p><p><img src="/imgs/blog11/clip_image040.jpg" alt="img"></p><p>我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： Node 2 。在我们关闭 Node 1 的同时也失去了主分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。</p><p><img src="/imgs/blog11/clip_image042.jpg" alt="img"></p><p>幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为 yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。</p><p>**<img src="/imgs/blog11/clip_image043.jpg" alt="img">**<strong>为什么我们集群状态是 yellow</strong> <strong>而不是 green</strong> <strong>呢</strong>？ </p><p>虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应2份副本分片，而此时只存在一份副本分片。 所以集群不能为 green 的状态，不过我们不必过于担心：如果我们同样关闭了 Node 2 ，我们的程序 依然 可以保持在不丢任何数据的情况下运行，因为 Node 3 为每一个分片都保留着一份副本。</p><p>如果我们重新启动 Node 1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。 如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是Master节点切换了。</p><p><img src="/imgs/blog11/clip_image045.jpg" alt="img"></p><h2 id="2路由计算"><a href="#2路由计算" class="headerlink" title="2路由计算"></a>2路由计算</h2><p>当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：</p><p><img src="/imgs/blog11/clip_image047.jpg" alt="img"></p><p>routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。</p><p>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</p><p>所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。</p><h2 id="3分片控制"><a href="#3分片控制" class="headerlink" title="3分片控制"></a>3分片控制</h2><p>我们假设有一个集群由三个节点组成。 它包含一个叫 emps 的索引，有两个主分片，每个主分片有两个副本分片。相同分片的副本不会放在同一节点。</p><p><img src="/imgs/blog11/clip_image049.jpg" alt="img"></p><p><img src="/imgs/blog11/clip_image051.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况，所以我们的集群是一个有三个节点和一个索引的集群。</p><p><img src="/imgs/blog11/clip_image053.jpg" alt="img"></p><p>我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 在下面的例子中，将所有的请求发送到 Node 1，我们将其称为 <strong>协调节点</strong>(coordinating node) 。</p><p><img src="/imgs/blog11/clip_image055.jpg" alt="img">：<strong>当发送请求的时候，</strong> <strong>为了扩展负载，更好的做法是轮询集群中所有的节点。</strong></p><h3 id="3-1-写流程"><a href="#3-1-写流程" class="headerlink" title="3.1 写流程"></a>3.1 写流程</h3><p>新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片</p><p><img src="/imgs/blog11/clip_image057.jpg" alt="img"></p><p><strong>新建，索引和删除文档所需要的步骤顺序</strong>：</p><p>\1.     客户端向 Node 1 发送新建、索引或者删除请求。</p><p>\2.     节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。</p><p>\3.     Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。</p><p>在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。</p><p>有一些可选的请求参数允许您影响这个过程，可能以数据安全为代价提升性能。这些选项很少使用，因为Elasticsearch已经很快，但是为了完整起见，请参考下面表格：</p><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>consistency</td><td>consistency，即一致性。在默认设置下，即使仅仅是在试图执行一个_写_操作之前，主分片都会要求 必须要有 规定数量(quorum)（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行_写_操作(其中分片副本可以是主分片或者副本分片)。这是为了避免在发生网络分区故障（network partition）的时候进行_写_操作，进而导致数据不一致。_规定数量_即：  <strong>int( (primary  + number_of_replicas) &#x2F; 2 ) + 1</strong>  consistency 参数的值可以设为 one （只要主分片状态 ok 就允许执行_写_操作）,all（必须要主分片和所有副本分片的状态没问题才允许执行_写_操作）, 或 quorum 。默认值为  quorum , 即大多数的分片副本状态没问题就允许执行_写_操作。  注意，规定数量 的计算公式中 number_of_replicas 指的是在索引设置中的设定副本分片数，而不是指当前处理活动状态的副本分片数。如果你的索引设置中指定了当前索引拥有三个副本分片，那规定数量的计算结果即：  <strong>int( (primary  + 3 replicas) &#x2F; 2 ) + 1 &#x3D; 3</strong>  如果此时你只启动两个节点，那么处于活跃状态的分片副本数量就达不到规定数量，也因此您将无法索引和删除任何文档。</td></tr><tr><td>timeout</td><td>如果没有足够的副本分片会发生什么？ Elasticsearch会等待，希望更多的分片出现。默认情况下，它最多等待1分钟。 如果你需要，你可以使用 timeout 参数 使它更早终止： 100 100毫秒，30s 是30秒。</td></tr></tbody></table><p><img src="/imgs/blog11/clip_image059.jpg" alt="img">新索引默认有 1 个副本分片，这意味着为满足规定数量应该需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当 number_of_replicas 大于1的时候，规定数量才会执行。</p><h3 id="3-2-读流程"><a href="#3-2-读流程" class="headerlink" title="3.2 读流程"></a>3.2 读流程</h3><p>我们可以从主分片或者从其它任意副本分片检索文档</p><p><img src="/imgs/blog11/clip_image061.jpg" alt="img"></p><p><strong>从主分片或者副本分片检索文档的步骤顺序</strong>：</p><p>\1.     客户端向 Node 1 发送获取请求。</p><p>\2.     节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。</p><p>\3.     Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。</p><p>在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p><h3 id="3-3-更新流程"><a href="#3-3-更新流程" class="headerlink" title="3.3 更新流程"></a>3.3 更新流程</h3><p>部分更新一个文档结合了先前说明的读取和写入流程：</p><p><img src="/imgs/blog11/clip_image063.jpg" alt="img"></p><p><strong>部分更新一个文档的步骤如下</strong>：</p><p>\1.     客户端向 Node 1 发送更新请求。</p><p>\2.     它将请求转发到主分片所在的 Node 3 。</p><p>\3.     Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。</p><p>\4.     如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。</p><p>当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果Elasticsearch仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。</p><h3 id="3-4-多文档操作流程"><a href="#3-4-多文档操作流程" class="headerlink" title="3.4 多文档操作流程"></a>3.4 多文档操作流程</h3><p>mget 和 bulk API 的模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成 每个分片 的多文档请求，并且将这些请求并行转发到每个参与节点。</p><p>协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端</p><p><img src="/imgs/blog11/clip_image065.jpg" alt="img"></p><p><strong>用单个 mget</strong> <strong>请求取回多个文档所需的步骤顺序</strong>:</p><p>\1.     客户端向 Node 1 发送 mget 请求。</p><p>\2.     Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。</p><p>可以对 docs 数组中每个文档设置 routing 参数。</p><p><strong>bulk API</strong>， 允许在单个批量请求中执行多个创建、索引、删除和更新请求。</p><p><img src="/imgs/blog11/clip_image067.jpg" alt="img"></p><p>bulk API 按如下步骤顺序执行：</p><p>\1.     客户端向 Node 1 发送 bulk 请求。</p><p>\2.     Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</p><p>\3.     主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud常用组件对比</title>
      <link href="/2023/06/04/blog10/"/>
      <url>/2023/06/04/blog10/</url>
      
        <content type="html"><![CDATA[<h1 id="Eurka和Nacos"><a href="#Eurka和Nacos" class="headerlink" title="Eurka和Nacos"></a>Eurka和Nacos</h1><p>Nacos和Eureka都是服务注册和发现的开源项目，用于构建分布式系统和微服务架构。它们的主要区别如下：</p><h2 id="服务注册和发现机制："><a href="#服务注册和发现机制：" class="headerlink" title="服务注册和发现机制："></a>服务注册和发现机制：</h2><ul><li>Nacos：Nacos提供了基于实例的服务注册和发现机制。服务提供者在启动时向Nacos注册自己的服务实例，并定期发送心跳来保持注册。服务消费者通过向Nacos查询服务列表来发现可用的服务实例。</li><li>Eureka：Eureka采用了基于中心化的服务注册和发现模式。服务提供者在启动时向Eureka注册自己的服务实例，并周期性地发送心跳来保持注册。服务消费者通过向Eureka服务器获取服务注册表来发现可用的服务实例。</li><li>Nacos支持服务端主动检测提供者状态:临时实例采用心跳模式，非临时实例采用主动检测模式临时实例心跳不正常会被剔除，非临时实例则不会被剔除。另外Nacos支持服务列表变更的消息推送模式，服务列表更新更及时</li></ul><h2 id="容错性和高可用性："><a href="#容错性和高可用性：" class="headerlink" title="容错性和高可用性："></a>容错性和高可用性：</h2><ul><li>Nacos：Nacos支持多节点的集群部署，具有高可用性和容错性。它使用Raft算法来保证数据的一致性和可用性，并支持自动的主从切换和故障恢复。</li><li>Eureka：Eureka的设计目标是在AWS云平台上实现高可用性。它使用了主从架构，其中一个Eureka服务器作为主服务器，其他服务器作为从服务器。当主服务器失效时，会触发Eureka客户端的自我保护机制，但这可能导致注册信息的延迟和不一致。</li><li>Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式。Eureka只有AP模式</li></ul><h2 id="配置管理："><a href="#配置管理：" class="headerlink" title="配置管理："></a>配置管理：</h2><ul><li>Nacos：Nacos提供了功能强大的配置管理功能。它支持动态配置的发布、监听和刷新，可以动态地修改配置参数而无需重启服务。Nacos还提供了命名空间、配置组和配置版本等概念，可以对配置进行灵活的管理和隔离。</li><li>Eureka：Eureka本身并没有内置的配置管理功能。如果需要配置管理，可以结合其他的配置中心（如Spring Cloud Config）与Eureka一起使用。</li></ul><h2 id="自我保护机制"><a href="#自我保护机制" class="headerlink" title="自我保护机制"></a>自我保护机制</h2><p>​        相同点: 保护阈值都是个比例，0-1 范围，表示健康的 instance 占全部instance 的比例。<br>​        不同点:<br>​        (1)保护方式不同<br>​        Eureka保护方式:当在短时间内，统计续约失败的比例，如果达到一定阈值，则会触发自我保护的机制，在该机制下Eureka Server不会别除任何的微服务，等到正常后，再退出自我保护机制。自我保护开关(eureka.server.enable-self.preservation. false)<br>​        Nacos保护方式: 当域名健康实例 (nstance) 占总服务实例(nstance)的比例小于阈值时，无论实例(Instance) 是否健康，都会将这个实例 (instance)返回给客户端。这样做虽然损失了一部分流量，但是保证了集群的剩余健康实例(Instance)能正常工作。<br>​        (2)范围不同<br>​        Nacos 的阈值是针对某个具体 Service 的，而不是针对所有服务的。但 Eureka的自我保护阈值是针对所有服务的.</p><h2 id="社区支持和集成："><a href="#社区支持和集成：" class="headerlink" title="社区支持和集成："></a>社区支持和集成：</h2><ul><li>Nacos：Nacos由阿里巴巴开源，得到了广泛的社区支持。它与Spring Cloud紧密集成，并提供了丰富的文档和示例来帮助开发者使用。</li><li>Eureka：Eureka最初由Netflix开发，虽然已经开源并得到了一定的社区支持，但相比Nacos而言，社区支持相对较少。然而，Eureka与Netflix的开源项目（如Ribbon和Hystrix）紧密集成，并在Netflix的生态系统中被广泛应用。</li></ul><h1 id="Hystrix和Sentinel"><a href="#Hystrix和Sentinel" class="headerlink" title="Hystrix和Sentinel"></a>Hystrix和Sentinel</h1><p>​        Sentinel和Hystrix都是用于实现服务容错和熔断的开源项目。 Hystrix 的关注点在于以 <em>隔离</em> 和 <em>熔断</em> 为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。而 Sentinel 的侧重点在于：多样化的流量控制、熔断降级、系统负载保护、实时监控和控制台。</p><h2 id="资源模型和执行模型上的对比"><a href="#资源模型和执行模型上的对比" class="headerlink" title="资源模型和执行模型上的对比"></a>资源模型和执行模型上的对比</h2><p>​        Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象（<code>HystrixCommand</code> &#x2F; <code>HystrixObservableCommand</code>），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。</p><p>​        Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流&#x2F;降级&#x2F;负载保护策略。在 Sentinel 中资源定义和规则配置是分离的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则。埋点方式有两种：</p><ul><li>try-catch 方式（通过 <code>SphU.entry(...)</code>），用户在 catch 块中执行异常处理 &#x2F; fallback</li><li>if-else 方式（通过 <code>SphO.entry(...)</code>），当返回 false 时执行异常处理 &#x2F; fallback</li></ul><p>​        Sentinel 还支持基于注解的资源定义方式，可以通过 <code>@SentinelResource</code> 注解参数指定异常处理函数和 fallback 函数。</p><h2 id="隔离设计上的对比"><a href="#隔离设计上的对比" class="headerlink" title="隔离设计上的对比"></a>隔离设计上的对比</h2><p>​        隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。</p><p>​        但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的线程池会非常影响性能。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。</p><p>​        Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。</p><h2 id="熔断降级对比"><a href="#熔断降级对比" class="headerlink" title="熔断降级对比"></a>熔断降级对比</h2><p>​        Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。</p><h2 id="实时指标统计实现对比"><a href="#实时指标统计实现对比" class="headerlink" title="实时指标统计实现对比"></a>实时指标统计实现对比</h2><p>​        Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功&#x2F;失败&#x2F;超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。</p><p>​        Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 <code>LeapArray</code> 的高性能滑动窗口，后续根据需要可能会引入 reactive stream 等实现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th></th><th>Sentinel</th><th>Hystrix</th></tr></thead><tbody><tr><td>隔离策略</td><td>信号量隔离</td><td>线程池隔离&#x2F;信号量隔离</td></tr><tr><td>熔断降级策略</td><td>基于慢调用比例或异常比例</td><td>基于失败比率</td></tr><tr><td>实时指标实现</td><td>滑动窗口</td><td>滑动窗口（基于 RxJava）</td></tr><tr><td>规则配置</td><td>支持多种数据源</td><td>支持多种数据源</td></tr><tr><td>扩展性</td><td>多个扩展点</td><td>插件的形式</td></tr><tr><td>基于注解的支持</td><td>支持</td><td>支持</td></tr><tr><td>限流</td><td>基于 QPS，支持基于调用关系的限流</td><td>有限的支持</td></tr><tr><td>流量整形</td><td>支持慢启动、匀速排队模式</td><td>不支持</td></tr><tr><td>系统自适应保护</td><td>支持</td><td>不支持</td></tr><tr><td>控制台</td><td>开箱即用，可配置规则、查看秒级监控、机器发现等</td><td>不完善</td></tr><tr><td>常见框架的适配</td><td>Servlet、Spring Cloud、Dubbo、gRPC 等</td><td>Servlet、Spring Cloud Netflix</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hystrix简介</title>
      <link href="/2023/06/03/blog9/"/>
      <url>/2023/06/03/blog9/</url>
      
        <content type="html"><![CDATA[<h1 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h1><p>​Hystrix是一个用于构建弹性和容错系统的Java库，由Netflix开发和维护。它旨在帮助开发者构建具有容错能力的分布式系统，特别是在处理复杂的网络通信时。</p><p>​Hystrix主要解决的问题是在分布式系统中的服务之间进行通信时可能出现的故障和延迟。这些问题可能导致级联故障，即一个服务的故障传递到其他服务，最终导致整个系统不可用。Hystrix通过引入隔离、断路器和回退机制来解决这些问题。</p><p>​隔离是Hystrix的核心概念之一。它通过将每个服务调用封装在独立的线程池中运行，实现了请求的隔离。这样，当某个服务调用失败或延迟较高时，不会对其他服务产生负面影响。</p><p>​断路器是Hystrix的另一个重要概念。它监控服务调用的错误率和延迟情况。当错误率或延迟超过预设的阈值时，断路器会打开，停止对该服务的调用，并快速失败。这样可以防止级联故障，并且当服务恢复正常后，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>此外，Hystrix还提供了回退机制，用于在服务调用失败时提供备选方案。开发者可以定义回退逻辑，当服务调用失败时，Hystrix会自动调用回退逻辑来返回预先定义的备选结果，保证系统的稳定性和可用性。</p><p>​Hystrix还提供了丰富的监控和度量功能，开发者可以实时监控服务调用的成功率、失败率、延迟等指标，并通过配置仪表盘和报警机制来及时发现和处理故障。</p><p>​总而言之，Hystrix是一个弹性和容错库，可以帮助开发者构建可靠的分布式系统。它通过隔离、断路器和回退机制来处理故障和延迟，并提供监控和度量功能来帮助开发者实时了解系统的健康状态。</p><h1 id="Hystrix服务降级"><a href="#Hystrix服务降级" class="headerlink" title="Hystrix服务降级"></a>Hystrix服务降级</h1><p>​Hystrix中的服务降级是指在系统出现故障或异常情况时，为了保证系统的可用性和稳定性，临时替代原本的服务调用，返回一个备选的响应结果。</p><p>​服务降级是通过定义回退逻辑来实现的。在使用Hystrix时，开发者可以为每个服务调用定义一个回退方法（Fallback Method），该方法在服务调用失败或超时时被触发，返回一个备选结果。</p><p>​回退方法的实现应尽量快速且轻量级，避免引入新的故障点。它可以返回一个默认值、预先计算的结果、缓存的数据或静态错误页面等，具体根据业务需求而定。通过合理定义回退逻辑，可以提供用户友好的响应或保证系统的基本功能仍能正常运行。</p><p>​Hystrix提供了多种方式来实现服务降级：</p><ol><li>注解方式：通过在服务调用的方法上添加@HystrixCommand注解，指定回退方法。当服务调用发生异常、超时或熔断时，会触发回退方法。</li><li>编程方式：通过Hystrix提供的命令模式（HystrixCommand）或可观察者模式（HystrixObservableCommand）进行服务调用，并在调用链中指定回退方法。</li><li>信号量隔离：除了使用线程池隔离外，Hystrix还支持信号量隔离，可以在同一线程中执行服务调用和回退方法，减少线程切换和上下文切换的开销。</li></ol><p>通过服务降级，Hystrix可以在服务故障或不可用时，提供一种临时替代方案，保证系统的可用性和稳定性。开发者可以根据具体情况定义合适的回退逻辑，提供良好的用户体验或保持基本功能的正常运行。</p><h1 id="Hystrix服务熔断"><a href="#Hystrix服务熔断" class="headerlink" title="Hystrix服务熔断"></a>Hystrix服务熔断</h1><p>​Hystrix中的服务熔断是一种用于防止故障扩散和快速恢复的机制。当服务调用失败率超过一定阈值时，Hystrix会打开断路器，停止对该服务的调用，并且在一段时间内直接返回预先设定的备选结果，而不去执行实际的服务调用。</p><p>​服务熔断的目的是防止级联故障，当一个服务出现问题时，避免对依赖它的其他服务造成更大的影响。通过断路器的打开，可以快速失败并迅速恢复正常。当断路器处于打开状态时，Hystrix会定期允许一部分流量通过，以便检测服务是否恢复正常。如果服务调用成功率达到一定阈值，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>​Hystrix中的服务熔断通过以下方式实现：</p><ol><li>错误百分比阈值：开发者可以配置一个错误百分比阈值，当在一个统计窗口内的请求错误率超过该阈值时，断路器将打开。</li><li>请求阈值：开发者可以配置一个请求阈值，当在一个统计窗口内的请求数量低于该阈值时，不会触发断路器。这是为了避免在服务启动初期的误判。</li><li>熔断器状态：断路器有三种状态：关闭、打开和半开。初始状态为关闭。当错误百分比超过阈值时，断路器打开；在打开状态下，所有请求都会直接返回备选结果；在一段时间后，断路器进入半开状态，允许一部分流量通过以检测服务的健康状态；如果半开状态下的请求成功，则断路器闭合；否则，重新打开断路器。</li></ol><p>通过服务熔断，Hystrix可以及时停止对不可用的服务的调用，防止故障的扩散，并通过快速失败和自动恢复的机制来提高系统的稳定性和可用性。开发者可以根据具体需求，配置合适的错误百分比阈值和请求阈值，以及定义适当的备选结果，从而保护系统免受不可用服务的影响。</p><h1 id="Hystrix服务限流"><a href="#Hystrix服务限流" class="headerlink" title="Hystrix服务限流"></a>Hystrix服务限流</h1><p>​Hystrix中的服务限流是一种控制系统资源使用的机制，用于保护系统免受过多请求的影响。通过限制对某个服务的并发请求量，可以防止系统资源被过度消耗，确保系统的稳定性和可用性。</p><p>​在Hystrix中，可以通过以下方式来实现服务限流：</p><ol><li>线程池隔离：Hystrix将每个服务调用封装在独立的线程池中运行，通过配置线程池的大小和队列容量，可以限制同时执行的并发请求数量。当线程池满了，新的请求将被拒绝或排队等待。</li><li>信号量隔离：除了线程池隔离外，Hystrix还支持使用信号量来限制并发请求的数量。开发者可以在服务调用的方法上添加@HystrixCommand注解，并指定一个信号量的数量作为参数，从而限制对该服务的并发访问。</li><li>请求队列：线程池隔离模式下，可以设置一个请求队列，用于缓冲未能立即执行的请求。请求队列的大小也可以作为限制并发请求的一种手段。当队列已满时，新的请求将被拒绝。</li></ol><p>​通过配置线程池大小、队列容量和信号量数量，开发者可以根据系统的资源情况和负载情况，灵活地控制并发请求的数量。适当的限流策略可以保护系统免受过载的影响，避免资源耗尽和性能下降。</p><p>​需要注意的是，服务限流只是一种保护机制，不能替代系统的容量规划和性能优化。合理的限流策略应结合实际情况进行调整，以达到最佳的系统性能和用户体验。</p><h1 id="Hystrix工作流程"><a href="#Hystrix工作流程" class="headerlink" title="Hystrix工作流程"></a>Hystrix工作流程</h1><p>​Hystrix的工作流程可以概括为以下几个步骤：</p><ol><li>发起服务调用：应用程序通过调用封装了服务调用的Hystrix命令（HystrixCommand）或可观察者（HystrixObservableCommand）来发起服务调用。这些命令包含了要执行的服务逻辑以及相关的配置信息。</li><li>降级检查：在服务调用之前，Hystrix会检查是否配置了回退逻辑（Fallback），以应对服务调用失败或超时的情况。如果配置了回退逻辑，Hystrix会将其与原始服务调用绑定。</li><li>断路器判断：在发起服务调用之前，Hystrix会检查断路器的状态。如果断路器处于打开状态（Open），Hystrix会立即触发回退逻辑，不会实际发起服务调用。</li><li>服务调用：如果降级检查和断路器判断通过，Hystrix会尝试发起实际的服务调用。根据配置，服务调用可能会在一个独立的线程池中执行，以实现请求隔离。Hystrix还可以通过信号量来控制并发请求数量。</li><li>容错处理：在服务调用过程中，Hystrix会监控请求的结果。如果请求发生故障、超时或异常，Hystrix会根据配置的容错策略执行相应的操作，例如打开断路器、触发回退逻辑等。</li><li>回退逻辑执行：当服务调用失败或超时时，Hystrix会执行与之绑定的回退逻辑。回退逻辑可以是预先定义的备选结果、缓存数据、静态错误页面等，以提供系统的基本功能或友好的用户体验。</li><li>断路器状态更新：根据服务调用的结果，Hystrix会更新断路器的状态。如果服务调用成功，断路器会逐渐闭合；如果服务调用失败或发生故障，断路器会打开，停止对该服务的调用。断路器在一段时间后会尝试半开状态，允许一部分流量通过以检测服务的健康状态。</li></ol><p>​通过以上的工作流程，Hystrix能够提供服务的容错和弹性处理，防止故障的扩散和级联故障的发生。它通过断路器、降级逻辑和线程隔离等机制来保护系统的可用性和稳定性，并提供监控和度量功能来实时了解系统的健康状况。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ribbon、Gateway、Nginx</title>
      <link href="/2023/06/03/blog8/"/>
      <url>/2023/06/03/blog8/</url>
      
        <content type="html"><![CDATA[<h1 id="Ribbon、Gateway、Nginx区别"><a href="#Ribbon、Gateway、Nginx区别" class="headerlink" title="Ribbon、Gateway、Nginx区别"></a>Ribbon、Gateway、Nginx区别</h1><h2 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h2><p>​Ribbon 是一个用于客户端负载均衡的开源项目，最初由 Netflix 开发并开源。它主要用于在分布式系统中选择合适的服务实例并进行负载均衡。</p><p>​在微服务架构中，服务通常以多个实例运行，这些实例可能分布在不同的主机或容器中。Ribbon 可以与服务注册中心（如 Eureka、Consul 等）集成，通过查询注册中心获取可用的服务实例列表。</p><p>​Ribbon 在客户端应用内部工作，作为一个负载均衡组件，它会根据一定的负载均衡策略选择一个合适的服务实例来发送请求。这些负载均衡策略包括轮询、随机、加权随机、最少连接等。选择的服务实例将接收客户端的请求，并将响应返回给客户端。</p><p>​Ribbon 还提供了一些其他功能，如超时设置、重试机制、服务实例健康检查等。它可以根据服务实例的健康状态和负载情况动态地选择合适的实例，以实现负载均衡和故障恢复。</p><p>​Ribbon 的优点是简单轻量、易于集成和扩展。它与多种服务注册中心和开发框架兼容，适用于各种微服务架构中的负载均衡需求。</p><h2 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h2><p>​Gateway是一种在分布式系统中充当入口点的中间层组件。它位于客户端和后端服务之间，负责接收来自客户端的请求，并将请求转发到适当的后端服务进行处理。</p><p>​网关的主要功能包括：</p><ol><li><p>请求路由：网关根据预定义的路由规则将请求路由到相应的后端服务。路由规则可以基于请求的路径、请求方法、请求头等进行匹配和转发。</p></li><li><p>协议转换：网关可以根据需要将请求和响应从一种协议转换为另一种协议。例如，可以将传入的请求从 HTTP 转换为 gRPC，或将响应从 gRPC 转换为 JSON。</p></li><li><p>负载均衡：网关可以实现负载均衡策略，将请求均匀地分发到多个后端服务实例。这可以通过集成服务发现组件（如 Eureka、Consul 等）来实现，并根据服务实例的健康状态和负载情况进行动态选择。</p></li><li><p>安全认证与授权：网关可以提供身份验证和授权功能，保护后端服务免受未经授权的访问。它可以验证请求的身份信息（如令牌、证书等），并根据配置的权限规则控制访问权限。</p></li><li><p>监控与日志记录：网关可以记录请求和响应的日志，并提供监控指标和统计信息，用于系统性能分析、故障排查和流量监控。</p></li><li><p>缓存：网关可以缓存经常请求的响应，以提高系统的响应速度和吞吐量。这可以减少后端服务的负载，并提供更快的响应时间。</p></li></ol><p>​网关在微服务架构中扮演着重要的角色，它提供了一种集中管理和处理请求的方式，简化了客户端和后端服务之间的通信和协调。常见的网关实现包括 Spring Cloud Gateway、Netflix Zuul、Kong 等。这些网关可以与其他微服务组件集成，并提供丰富的功能来支持复杂的系统架构和需求。</p><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><p>​Nginx是一个高性能的开源反向代理服务器、负载均衡器和Web服务器。它具有轻量级、高效率和可扩展性的特点，被广泛应用于构建高性能的Web应用和服务。</p><ol><li><p>反向代理：<br>Nginx作为反向代理服务器，接收客户端请求，并将请求转发到后端服务器。它可以隐藏后端服务器的细节，并提供负载均衡功能，将请求分发到多个后端服务器上，从而提高系统的可用性和性能。</p></li><li><p>负载均衡：<br>Nginx支持多种负载均衡算法，如轮询、IP哈希、最少连接等。它可以根据配置的负载均衡策略将请求均匀地分发到多个后端服务器，以实现负载均衡和故障恢复。</p></li><li><p>静态文件服务：<br>Nginx可以快速高效地提供静态文件的服务，如HTML、CSS、JavaScript、图像文件等。它通过使用异步非阻塞的方式处理请求，以及内置的缓存机制，提供了出色的性能和可扩展性。</p></li><li><p>SSL&#x2F;TLS加密：<br>Nginx支持SSL&#x2F;TLS协议，可以用于配置安全的HTTPS连接，为网站和应用程序提供加密和安全传输的功能。它可以作为SSL终端点，处理与客户端之间的加密通信。</p></li><li><p>动态请求转发：<br>Nginx还可以根据请求的内容或规则将请求转发到不同的后端服务。它支持配置灵活的反向代理规则，根据URL路径、请求头、参数等条件进行请求转发和路由。</p></li><li><p>高性能和可扩展性：<br>Nginx采用事件驱动、非阻塞的架构设计，可以处理大量并发连接和高流量的请求，具有出色的性能表现。它还支持多进程、多线程的部署模式，可以根据需求进行水平扩展。</p></li><li><p>日志记录和监控：<br>Nginx提供详细的访问日志记录，记录请求和响应的信息，便于故障排查和性能优化。它还支持实时监控和统计指标的收集，可以与其他监控工具集成，实现对系统的监控和管理。</p></li></ol><p>​Nginx是一个强大而灵活的服务器软件，广泛应用于Web应用、反向代理、负载均衡、缓存、媒体流服务等多个领域。</p><h2 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a>三者区别</h2><ol><li>功能定位：<ul><li>Gateway: 网关是一个完整的请求路由和代理解决方案，通常用于构建微服务架构中的入口点，负责请求的接收、路由、转发、安全性、监控等。</li><li>Ribbon: Ribbon是一个客户端负载均衡组件，用于在客户端应用内部选择合适的服务实例，主要负责服务实例的选择和负载均衡算法的应用。</li><li>Nginx: Nginx是一个高性能的反向代理服务器，可以作为负载均衡器，接收客户端请求并将其转发到后端服务器，主要负责请求转发和负载均衡算法的实现。</li></ul></li><li>部署位置：<ul><li>Gateway: 网关通常位于整个架构的边界，作为对外的入口点，接收外部请求并路由到内部的服务实例。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，嵌入在客户端应用中，与应用共存于同一个进程内。</li><li>Nginx: Nginx作为反向代理服务器，通常部署在服务器端，位于客户端与后端服务之间，接收客户端请求并将其转发到后端服务器。</li></ul></li><li>负载均衡算法：<ul><li>Gateway: 网关可以结合多种负载均衡算法，如轮询、权重、哈希等，根据不同的路由规则和服务实例情况进行选择。</li><li>Ribbon: Ribbon提供了丰富的负载均衡算法选择，如轮询、随机、加权随机、最少连接等，可以根据需要选择合适的算法。</li><li>Nginx: Nginx也支持多种负载均衡算法，如轮询、IP哈希、最少连接等，可以根据需求进行配置。</li></ul></li><li>扩展性和灵活性：<ul><li>Gateway: 网关通常提供了更多的功能，如认证、授权、监控等，以及自定义路由规则的灵活性，可以根据具体需求进行定制开发。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，对于客户端应用来说，具有更高的扩展性和灵活性，可以根据业务需求进行自定义的负载均衡逻辑实现。</li><li>Nginx: Nginx作为反向代理服务器，可以灵活配置代理规则和负载均衡算法，同时也支持自定义的扩展模块。</li></ul></li></ol><p>​</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​在项目中同时使用到这三者的情况时候，可以这么理解，用户请求进来是先过Nginx网关，这里的Nginx就相当于一个流量网关，是属于用户访问的一个入口。 然后在进入到gateway网关中，这里的getway网关属于一个业务网关，通过对应的属性配置将请求传递到每一个业务微服务中去。而Ribbon负责微服务之间调用时的负载均衡。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>统计范围内的元音字符串数</title>
      <link href="/2023/06/02/blog7/"/>
      <url>/2023/06/02/blog7/</url>
      
        <content type="html"><![CDATA[<h2 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h2><p><a href="https://leetcode.cn/problems/count-vowel-strings-in-ranges/description/">2559. 统计范围内的元音字符串数 - 力扣（Leetcode）</a></p><p>给你一个下标从 <strong>0</strong> 开始的字符串数组 <code>words</code> 以及一个二维整数数组 <code>queries</code> 。</p><p>每个查询 <code>queries[i] = [li, ri]</code> 会要求我们统计在 <code>words</code> 中下标在 <code>li</code> 到 <code>ri</code> 范围内（<strong>包含</strong> 这两个值）并且以元音开头和结尾的字符串的数目。</p><p>返回一个整数数组，其中数组的第 <code>i</code> 个元素对应第 <code>i</code> 个查询的答案。</p><p><strong>注意：</strong>元音字母是 <code>&#39;a&#39;</code>、<code>&#39;e&#39;</code>、<code>&#39;i&#39;</code>、<code>&#39;o&#39;</code> 和 <code>&#39;u&#39;</code> 。</p><p><strong>示例 1：</strong></p><pre><code>输入：words = [&quot;aba&quot;,&quot;bcb&quot;,&quot;ece&quot;,&quot;aa&quot;,&quot;e&quot;], queries = [[0,2],[1,4],[1,1]]输出：[2,3,0]解释：以元音开头和结尾的字符串是 &quot;aba&quot;、&quot;ece&quot;、&quot;aa&quot; 和 &quot;e&quot; 。查询 [0,2] 结果为 2（字符串 &quot;aba&quot; 和 &quot;ece&quot;）。查询 [1,4] 结果为 3（字符串 &quot;ece&quot;、&quot;aa&quot;、&quot;e&quot;）。查询 [1,1] 结果为 0 。返回结果 [2,3,0] 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：words = [&quot;a&quot;,&quot;e&quot;,&quot;i&quot;], queries = [[0,2],[0,1],[2,2]]输出：[3,2,1]解释：每个字符串都满足这一条件，所以返回 [3,2,1] 。</code></pre><h2 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h2><p>​简单啊，直接暴力求解就完了</p><p>​写代码，测试，提交，，，，然后就超时了，，，，emmmmmmmmmm</p><p>​前缀和优化下，通过</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre><code class="java">class Solution &#123;    public int[] vowelStrings(String[] words, int[][] queries) &#123;        Set&lt;Character&gt; vowels = Set.of(&#39;a&#39;, &#39;e&#39;, &#39;i&#39;, &#39;o&#39;, &#39;u&#39;);        int n = words.length;        int[] prefixSums = new int[n + 1];        for (int i = 0; i &lt; n; ++i) &#123;            char a = words[i].charAt(0), b = words[i].charAt(words[i].length() - 1);            if (vowels.contains(a) &amp;&amp; vowels.contains(b)) &#123;                prefixSums[i+1] = prefixSums[i] + 1;            &#125;else&#123;                prefixSums[i+1] = prefixSums[i];            &#125;        &#125;        int q = queries.length;        int[] ans = new int[q];        for (int i = 0; i &lt; q; i++) &#123;            int start = queries[i][0], end = queries[i][1];            ans[i] = prefixSums[end + 1] - prefixSums[start];        &#125;        return ans;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis主从同步</title>
      <link href="/2023/06/02/blog6/"/>
      <url>/2023/06/02/blog6/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis主从同步"><a href="#Redis主从同步" class="headerlink" title="Redis主从同步"></a>Redis主从同步</h1><h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p><p><img src="/../imgs/blog6/image-20210725152222497.png" alt="image-20210725152222497"></p><p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p><p>有几个概念，可以作为判断依据：</p><ul><li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</li><li><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</li></ul><p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p><p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p><p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p><p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p><p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p><p>如图：</p><p><img src="/../imgs/blog6/image-20210725152700914.png" alt="image-20210725152700914"></p><p>完整流程描述：</p><ul><li>slave节点请求增量同步</li><li>master节点判断replid，发现不一致，拒绝增量同步</li><li>master将完整内存数据生成RDB，发送RDB到slave</li><li>slave清空本地数据，加载master的RDB</li><li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li><li>slave执行接收到的命令，保持与master之间的同步</li></ul><h3 id="2-2-2-增量同步"><a href="#2-2-2-增量同步" class="headerlink" title="2.2.2.增量同步"></a>2.2.2.增量同步</h3><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p><p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p><p><img src="/../imgs/blog6/image-20210725153201086.png" alt="image-20210725153201086"></p><p>那么master怎么知道slave与自己的数据差异在哪里呢?</p><h3 id="repl-backlog原理"><a href="#repl-backlog原理" class="headerlink" title="repl_backlog原理"></a>repl_backlog原理</h3><p>master怎么知道slave与自己的数据差异在哪里呢?</p><p>这就要说到全量同步时的repl_baklog文件了。</p><p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p><p>repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p><p><img src="/../imgs/blog6/image-20210725153359022.png" alt="image-20210725153359022"> </p><p>slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。</p><p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p><p><img src="/../imgs/blog6/image-20210725153524190.png" alt="image-20210725153524190"> </p><p>直到数组被填满：</p><p><img src="/../imgs/blog6/image-20210725153715910.png" alt="image-20210725153715910"> </p><p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p><p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset： </p><p><img src="/../imgs/blog6/image-20210725153937031.png" alt="image-20210725153937031"> </p><p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p><p><img src="/../imgs/blog6/image-20210725154155984.png" alt="image-20210725154155984"> </p><p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p><p><img src="/../imgs/blog6/image-20210725154216392.png" alt="image-20210725154216392"></p><h3 id="主从同步优化"><a href="#主从同步优化" class="headerlink" title="主从同步优化"></a>主从同步优化</h3><p>主从同步可以保证主从数据的一致性，非常重要。</p><p>可以从以下几个方面来优化Redis主从就集群：</p><ul><li>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。</li><li>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</li><li>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</li><li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</li></ul><p>主从从架构图：</p><p><img src="/../imgs/blog6/image-20210725154405899.png" alt="image-20210725154405899"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>简述全量同步和增量同步区别？</p><ul><li>全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。</li><li>增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave</li></ul><p>什么时候执行全量同步？</p><ul><li>slave节点第一次连接master节点时</li><li>slave节点断开时间太久，repl_baklog中的offset已经被覆盖时</li></ul><p>什么时候执行增量同步？</p><ul><li>slave节点断开又恢复，并且在repl_baklog中能找到offset时</li></ul><p>转载自：黑马程序员Redis教程（【黑马程序员Redis入门到实战教程，深度透析redis底层原理+redis分布式锁+企业解决方案+黑马点评实战项目】 <a href="https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web%EF%BC%89">https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web）</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>礼盒的最大甜蜜度</title>
      <link href="/2023/06/01/blog5/"/>
      <url>/2023/06/01/blog5/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/"><a href="https://leetcode.cn/problems/maximum-tastiness-of-candy-basket/description/">2517. 礼盒的最大甜蜜度 - 力扣（Leetcode）</a></a></p><p>​给你一个正整数数组 <code>price</code> ，其中 <code>price[i]</code> 表示第 <code>i</code> 类糖果的价格，另给你一个正整数 <code>k</code> 。</p><p>商店组合 <code>k</code> 类 <strong>不同</strong> 糖果打包成礼盒出售。礼盒的 <strong>甜蜜度</strong> 是礼盒中任意两种糖果 <strong>价格</strong> 绝对差的最小值。</p><p>返回礼盒的 <strong>最大</strong> 甜蜜度<em>。</em></p><p><strong>示例 1：</strong></p><pre><code>输入：price = [13,5,1,8,21,2], k = 3输出：8解释：选出价格分别为 [13,5,21] 的三类糖果。礼盒的甜蜜度为 min(|13 - 5|, |13 - 21|, |5 - 21|) = min(8, 8, 16) = 8 。可以证明能够取得的最大甜蜜度就是 8 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：price = [1,3,1], k = 2输出：2解释：选出价格分别为 [1,3] 的两类糖果。 礼盒的甜蜜度为 min(|1 - 3|) = min(2) = 2 。可以证明能够取得的最大甜蜜度就是 2 。</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：price = [7,7,7,7], k = 2输出：0解释：从现有的糖果中任选两类糖果，甜蜜度都会是 0 。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​最小最大，基本要想到二分了，直接二分甜蜜值，因为选择的差值跟顺序无关，我们可以排序后贪心，当前选择大于之前选择加甜蜜值就统计答案一次，如果最终次数大于等于tastiness，说明甜蜜值还可以更大，收缩左边界，否则收缩右边界。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int maximumTastiness(int[] price, int k) &#123;​    Arrays.sort(price);​    int left = 0, right = price[price.length - 1];​    while (left +1 != right) &#123;​      int mid = (left + right) / 2;​      if (check(price, k, mid)) &#123;​        left = mid;​      &#125; else &#123;​        right = mid;​      &#125;​    &#125;​    return left;  &#125;  public boolean check(int[] price, int k, int tastiness) &#123;​    int prev = Integer.MIN_VALUE / 2;​    int cnt = 0;​    for (int p : price) &#123;​      if (p - prev &gt;= tastiness) &#123;​        cnt++;​        prev = p;​      &#125;​    &#125;​    return cnt &gt;= k;  &#125;&#125;</code></pre><p>甜蜜的祝自己节日快乐</p>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么Redis集群分片最大槽数是16384个</title>
      <link href="/2023/06/01/blog4/"/>
      <url>/2023/06/01/blog4/</url>
      
        <content type="html"><![CDATA[<h4 id="为什么Redis集群分片最大槽数是16384个？"><a href="#为什么Redis集群分片最大槽数是16384个？" class="headerlink" title="为什么Redis集群分片最大槽数是16384个？"></a>为什么Redis集群分片最大槽数是16384个？</h4><p>​GitHub上已有关于这个问题的解答，<a href="https://github.com/redis/redis/issues/2576">why redis-cluster use 16384 slots? · Issue #2576 · redis&#x2F;redis (github.com)</a>，这里只做大概解释</p><p>​Redis集群通过CRC16算法对key进行哈希并对16384取模来决定该key具体放在哪个槽位，而该算法的hash结果有16位，也就是65536个值，那为啥不分配65536个槽而是16384（2^14）个？</p><p>​首先翻译一下作者的解答：</p><p>​正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间(使用65K的插槽)。同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot &#x2F; N位占设置位的很大百分比。</p><p>​翻译了又好像没翻译，还是没看懂，，，</p><p>​其实总结起来就是以下三个因素的考虑。</p><p>（1）如果槽位个数为65536，发送的心跳信息头达到8k，发送的心跳包过大。</p><p><img src="/imgs/blog4/image-20230601095147944.png"></p><p>上图即为Redis节点发送的信息头结构，其中占据最大空间的就是myslots[CLUSTER_SLOTS&#x2F;8]。如果槽位为65536个，大小为65536 &#x2F; 8 &#x2F; 1024 &#x3D; 8 kb。如果槽位为16384个，大小为16384 &#x2F; 8 &#x2F; 1024 &#x3D; 2 kb。在Redis集群中，Redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536个，发送的消息头太大，浪费带宽。</p><p>（2）Redis的集群主节点数量基本不可能超过1000个，16384个槽位已经够用<br>集群节点越多，心跳包的消息体内携带的数据越多。如果节点超过1000个，也会导致网络拥堵。因此Redis作者不建议Redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。</p><p>（3）节点一定的情况下，槽位越少，压缩比越高，容易传输<br>Redis主节点的配置信息中它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中会对bitmap进行压缩，但是如果bitmap的填充率slots &#x2F;N很高的话(N表示节点数)，bitmap的压缩率就很低。也就是说当节点数一定时，哈希槽数量很多的话，bitmap的压缩率就很低，不易传输。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无重复字符的最长子串</title>
      <link href="/2023/05/31/blog3/"/>
      <url>/2023/05/31/blog3/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/">3. 无重复字符的最长子串 - 力扣（Leetcode）</a></p><p>​给定一个字符串 <code>s</code> ，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。</p><p><strong>示例 1:</strong></p><pre><code>输入: s = &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: s = &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。</code></pre><p><strong>示例 3:</strong></p><pre><code>输入: s = &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。     请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​没啥好说的，一眼滑动窗口。。。</p><p>​以示例1为例，对于“abcabcbb”，定义两个指针（ left 和 right ），初始都指向字符串0位置，两个指针之间的字符串即为当前找到的子串，right指针向右遍历，使用hashmap记录出现过的字符和字符最后一次出现的位置，当前字串出现重复字符时（即hashmap中存在当前right指向的字符），将left指针移动到重复字符的下一个位置即可（map.get(s.charAt(i)) + 1），遍历过程中记录字串长度最大值。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int lengthOfLongestSubstring(String s) &#123;​    if (s.length() &lt;=  1)&#123;​      return s.length();​    &#125;​    HashMap&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;();​    int ans = 0;​    int left = 0;​    for(int i = 0; i &lt; s.length(); i++)&#123;​      if(map.containsKey(s.charAt(i)))&#123;​        left = Math.max(left, map.get(s.charAt(i)) + 1);​      &#125;​      map.put(s.charAt(i), i);​      ans = Math.max(ans, i-left+1);​    &#125;​    return ans;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引失效情况</title>
      <link href="/2023/05/31/blog2/"/>
      <url>/2023/05/31/blog2/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL索引失效"><a href="#MySQL索引失效" class="headerlink" title="MySQL索引失效"></a>MySQL索引失效</h1><p>​简单介绍下几种MySQL索引失效的常见情况。</p><h3 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1.数据准备"></a>1.数据准备</h3><p>​首先准备一张数据表user_info并建立索引</p><pre><code class="mysql">`CREATE TABLE `user_info` ( `id` int(8) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;, `number` varchar(12) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;编号&#39;, `username` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;用户名&#39;, `age` int(11) DEFAULT NULL COMMENT &#39;年龄&#39;, `birthday` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &#39;生日&#39;, PRIMARY KEY (`id`), KEY `union_idx` (`number`,`username`,`age`), KEY `create_time_idx` (`birthday`) );`</code></pre><p>该表包含3个索引：</p><p>主键：id</p><p>联合索引：number、username、age</p><p>普通索引：birthday</p><p>然后插入一些数据</p><pre><code class="mysql">INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1244&#39;, &#39;Mercury&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3546&#39;, &#39;Diana&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1124&#39;, &#39;Mars&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6426&#39;, &#39;Saturn&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3525&#39;, &#39;Eureka&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;5245&#39;, &#39;Mercury1&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3235246&#39;, &#39;Diana1&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6346&#39;, &#39;Mars1&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;623461&#39;, &#39;Saturn1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;235&#39;, &#39;Eureka1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;11244&#39;, &#39;Mercury3&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;13546&#39;, &#39;Diana3&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;112244&#39;, &#39;Mars3&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;643126&#39;, &#39;Saturn3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;35215&#39;, &#39;Eureka3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;52145&#39;, &#39;Mercury4&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;32235246&#39;, &#39;Diana4&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6332446&#39;, &#39;Mars4&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6231461&#39;, &#39;Saturn4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;231115&#39;, &#39;Eureka4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);</code></pre><p>注：测试MySQL版本为8.0.28</p><h3 id="2-案例测试"><a href="#2-案例测试" class="headerlink" title="2.案例测试"></a>2.案例测试</h3><h4 id="2-1-联合索引不满足最左匹配原则"><a href="#2-1-联合索引不满足最左匹配原则" class="headerlink" title="2.1 联合索引不满足最左匹配原则"></a>2.1 联合索引不满足最左匹配原则</h4><p>​最左前缀匹配原则：在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左列开始匹配。如本例中联合索引（number，username，age），若想查询走该索引，查询条件中应出现最左边的列，即number。</p><p>测试1：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39;;</code></pre><p>运行结果：</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%951.png"></p><p>key为“union_idx”说明查询走了联合索引。</p><p>测试2：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39; and age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%952.png"></p><p>测试2结果中‘key_len’与测试1相同，说明该查询虽然走了联合索引，但因未满足最左匹配原则（查询条件中未出现username），导致username之后的联合索引失效。若number使用范围查询如number&gt;‘1244’，后面的查询条件即使有username也不会生效，这里不做测试。</p><p>但是where后面查询列出现顺序不会影响索引，如</p><p>测试3：</p><pre><code class="mysql">explain select * from user_info where username = &#39;Mercury&#39; and number = &#39;1244&#39;;explain select * from user_info where number = &#39;1244&#39; and username = &#39;Mercury&#39;;</code></pre><p>上面两条语句‘ken_len’相同</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%953.png" alt="image-20230531203957562"></p><h4 id="2-2-索引列使用数学运算"><a href="#2-2-索引列使用数学运算" class="headerlink" title="2.2 索引列使用数学运算"></a>2.2 索引列使用数学运算</h4><p>测试4：</p><pre><code class="mysql">explain select * from user_info where id + 1 = 2;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%954.png"></p><p>查询类型为全表扫面，并未使用索引</p><h4 id="2-3-隐式类型转换"><a href="#2-3-隐式类型转换" class="headerlink" title="2.3 隐式类型转换"></a>2.3 隐式类型转换</h4><p>测试5：</p><pre><code class="mysql">explain select * from user_info where number = 1244;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%955.png" alt="测试5"></p><p>number字段为varchar类型，而查询条件为int，类型不匹配导致索引失效。</p><h4 id="2-4模糊查询以-开头"><a href="#2-4模糊查询以-开头" class="headerlink" title="2.4模糊查询以%开头"></a>2.4模糊查询以%开头</h4><p>测试6：</p><pre><code class="mysql">explain select * from user_info where number like &#39;%2&#39;;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%956.png" alt="测试6"></p><h4 id="2-5-使用or"><a href="#2-5-使用or" class="headerlink" title="2.5 使用or"></a>2.5 使用or</h4><p>测试7：</p><pre><code class="mysql">explain select * from user_info where id = 1 or age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%957.png" alt="测试7"></p><p>age列无索引，导致前面id列索引失效。使用or时切记两边查询条件都要有索引。</p><h4 id="2-6索引列使用函数"><a href="#2-6索引列使用函数" class="headerlink" title="2.6索引列使用函数"></a>2.6索引列使用函数</h4><p>测试8：</p><p>explain select * from user_info where SUBSTR(number, 2,3) &#x3D; ‘12’;</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%958.png" alt="测试8"></p><h4 id="2-7两列作比较或者运算"><a href="#2-7两列作比较或者运算" class="headerlink" title="2.7两列作比较或者运算"></a>2.7两列作比较或者运算</h4><p>测试9：</p><pre><code class="mysql">explain select * from user_info where id &lt; age;explain select * from user_info where id + age = 25;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%959.png" alt="测试9"></p><h4 id="2-8其他"><a href="#2-8其他" class="headerlink" title="2.8其他"></a>2.8其他</h4><p>​使用不等于&lt;&gt;，not in， not exists， is not null 以及MySQL优化器认为走全表扫描效率更高的查询。好累啊不想做测试了，开摆。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化</title>
      <link href="/2023/05/31/blog1/"/>
      <url>/2023/05/31/blog1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Redis持久化"><a href="#1-Redis持久化" class="headerlink" title="1.Redis持久化"></a>1.Redis持久化</h1><p>Redis有两种持久化方案：</p><ul><li>RDB持久化</li><li>AOF持久化</li></ul><h2 id="1-1-RDB"><a href="#1-1-RDB" class="headerlink" title="1.1.RDB"></a>1.1.RDB</h2><p>RDB全称Redis Database Backup file（Redis数据备份文件），RDB其实就是把数据以快照的形式保存在磁盘上。什么是快照呢，你可以理解成把当前时刻的数据拍成一张照片保存下来。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。</p><h3 id="1-1-1-RDB执行"><a href="#1-1-1-RDB执行" class="headerlink" title="1.1.1.RDB执行"></a>1.1.1.RDB执行</h3><p>RDB持久化在四种情况下会执行：</p><ul><li>执行save命令</li><li>执行bgsave命令</li><li>Redis停机时</li><li>触发RDB条件时</li></ul><p><strong>1）save命令</strong></p><p>save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。</p><p><strong>2）bgsave命令</strong></p><p>bgsave命令执行后Redis执行fork操作创建子进程完成RDB，主进程可以继续处理用户请求，不会阻塞。</p><p><strong>3）停机时</strong></p><p>Redis停机时会执行一次save命令，实现RDB持久化。</p><p><strong>4）触发RDB条件</strong></p><p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p><pre><code class="properties"># 下面的配置代表600秒内如果至少有10个key被修改，则执行bgsavesave 600 10  </code></pre><p>RDB的其它配置也可以在redis.conf文件中设置：</p><pre><code class="properties"># 是否进行压缩（会耗费cpu资源）rdbcompression yes# RDB文件保存名称（默认为dump.rdb）dbfilename dump.rdb  </code></pre><h3 id="1-1-2-RDB原理"><a href="#1-1-2-RDB原理" class="headerlink" title="1.1.2.RDB原理"></a>1.1.2.RDB原理</h3><p>bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。</p><p>fork采用的是copy-on-write技术：</p><ul><li>当主进程执行读操作时，访问共享内存；</li><li>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</li></ul><p><img src="/imgs/blog1/image-20210725151319695-16855170885551.png"></p><h2 id="1-2-AOF"><a href="#1-2-AOF" class="headerlink" title="1.2.AOF"></a>1.2.AOF</h2><h3 id="1-2-1-AOF原理"><a href="#1-2-1-AOF原理" class="headerlink" title="1.2.1.AOF原理"></a>1.2.1.AOF原理</h3><p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。</p><h3 id="1-2-2-AOF配置"><a href="#1-2-2-AOF配置" class="headerlink" title="1.2.2.AOF配置"></a>1.2.2.AOF配置</h3><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p><pre><code class="properties"># 是否开启AOF功能，默认是noappendonly yes</code></pre><p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p><pre><code class="properties"># 每执行一次写命令，立即记录appendfsync always # 每隔1秒将缓冲区数据写到AOF文件（默认）appendfsync everysec # 由操作系统决定何时将缓冲区内容写回磁盘appendfsync no</code></pre><p>三种策略对比：</p><p><img src="/imgs/blog1/image-20210725151654046-16855171063852.png"></p><h3 id="1-2-3-AOF文件重写"><a href="#1-2-3-AOF文件重写" class="headerlink" title="1.2.3.AOF文件重写"></a>1.2.3.AOF文件重写</h3><p>AOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。</p><p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p><pre><code class="properties"># AOF文件相比上次增长超过多少百分比则触发bgrewriteaofauto-aof-rewrite-percentage 100# AOF文件达到一定大小触发bgrewriteaofauto-aof-rewrite-min-size 64mb </code></pre><p>重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。</p><h2 id="1-3-RDB与AOF对比"><a href="#1-3-RDB与AOF对比" class="headerlink" title="1.3.RDB与AOF对比"></a>1.3.RDB与AOF对比</h2><p>RDB和AOF各有优缺点，在实际开发中一般会<strong>结合</strong>两者来使用。</p><p><img src="/imgs/blog1/image-20210725151940515-16855171206073.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
