<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GoF五种创建型模式</title>
      <link href="/2023/06/26/blog26/"/>
      <url>/2023/06/26/blog26/</url>
      
        <content type="html"><![CDATA[<p>创建型模式的主要关注点是“怎样创建对象？”，它的主要特点是“将对象的创建与使用分离”。</p><p>这样可以降低系统的耦合度，使用者不需要关注对象的创建细节。</p><p>创建型模式分为：</p><ul><li>单例模式</li><li>工厂方法模式</li><li>抽象工程模式</li><li>原型模式</li><li>建造者模式</li></ul><h2 id="4-1-单例设计模式"><a href="#4-1-单例设计模式" class="headerlink" title="4.1 单例设计模式"></a>4.1 单例设计模式</h2><p>单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p><p>这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。</p><h3 id="4-1-1-单例模式的结构"><a href="#4-1-1-单例模式的结构" class="headerlink" title="4.1.1 单例模式的结构"></a>4.1.1 单例模式的结构</h3><p>单例模式的主要有以下角色：</p><ul><li>单例类。只能创建一个实例的类</li><li>访问类。使用单例类</li></ul><h3 id="4-1-2-单例模式的实现"><a href="#4-1-2-单例模式的实现" class="headerlink" title="4.1.2 单例模式的实现"></a>4.1.2 单例模式的实现</h3><blockquote><p>单例设计模式分类两种：</p><p>​饿汉式：类加载就会导致该单实例对象被创建</p><p>​懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建</p></blockquote><ol><li><p>饿汉式-方式1（静态变量方式）</p><pre><code class="java">/** * 饿汉式 *      静态变量创建类的对象 */public class Singleton &#123;    //私有构造方法    private Singleton() &#123;&#125;    //在成员位置创建该类的对象    private static Singleton instance = new Singleton();    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        return instance;    &#125;&#125;</code></pre><p><font color='red'>说明：</font></p><p>​该方式在成员位置声明Singleton类型的静态变量，并创建Singleton类的对象instance。instance对象是随着类的加载而创建的。如果该对象足够大的话，而一直没有使用就会造成内存的浪费。</p></li><li><p>饿汉式-方式2（静态代码块方式）</p><pre><code class="java">/** * 恶汉式 *      在静态代码块中创建该类对象 */public class Singleton &#123;    //私有构造方法    private Singleton() &#123;&#125;    //在成员位置创建该类的对象    private static Singleton instance;    static &#123;        instance = new Singleton();    &#125;    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        return instance;    &#125;&#125;</code></pre><p><font color='red'>说明：</font></p><p>​该方式在成员位置声明Singleton类型的静态变量，而对象的创建是在静态代码块中，也是对着类的加载而创建。所以和饿汉式的方式1基本上一样，当然该方式也存在内存浪费问题。</p></li><li><p>懒汉式-方式1（线程不安全）</p><pre><code class="java">/** * 懒汉式 *  线程不安全 */public class Singleton &#123;    //私有构造方法    private Singleton() &#123;&#125;    //在成员位置创建该类的对象    private static Singleton instance;    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        if(instance == null) &#123;            instance = new Singleton();        &#125;        return instance;    &#125;&#125;</code></pre><p><font color='red'>说明：</font></p><p>​从上面代码我们可以看出该方式在成员位置声明Singleton类型的静态变量，并没有进行对象的赋值操作，那么什么时候赋值的呢？当调用getInstance()方法获取Singleton类的对象的时候才创建Singleton类的对象，这样就实现了懒加载的效果。但是，如果是多线程环境，会出现线程安全问题。</p></li><li><p>懒汉式-方式2（线程安全）</p><pre><code class="java">/** * 懒汉式 *  线程安全 */public class Singleton &#123;    //私有构造方法    private Singleton() &#123;&#125;    //在成员位置创建该类的对象    private static Singleton instance;    //对外提供静态方法获取该对象    public static synchronized Singleton getInstance() &#123;        if(instance == null) &#123;            instance = new Singleton();        &#125;        return instance;    &#125;&#125;</code></pre><p><font color='red'>说明：</font></p><p>​该方式也实现了懒加载效果，同时又解决了线程安全问题。但是在getInstance()方法上添加了synchronized关键字，导致该方法的执行效果特别低。从上面代码我们可以看出，其实就是在初始化instance的时候才会出现线程安全问题，一旦初始化完成就不存在了。</p></li><li><p>懒汉式-方式3（双重检查锁）</p><p>再来讨论一下懒汉模式中加锁的问题，对于 <code>getInstance()</code> 方法来说，绝大部分的操作都是读操作，读操作是线程安全的，所以我们没必让每个线程必须持有锁才能调用该方法，我们需要调整加锁的时机。由此也产生了一种新的实现模式：双重检查锁模式</p><pre><code class="java">/** * 双重检查方式 */public class Singleton &#123;     //私有构造方法    private Singleton() &#123;&#125;    private static Singleton instance;   //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        //第一次判断，如果instance不为null，不进入抢锁阶段，直接返回实例        if(instance == null) &#123;            synchronized (Singleton.class) &#123;                //抢到锁之后再次判断是否为null                if(instance == null) &#123;                    instance = new Singleton();                &#125;            &#125;        &#125;        return instance;    &#125;&#125;</code></pre><p>双重检查锁模式是一种非常好的单例实现模式，解决了单例、性能、线程安全问题，上面的双重检测锁模式看上去完美无缺，其实是存在问题，在多线程的情况下，可能会出现空指针问题，出现问题的原因是JVM在实例化对象的时候会进行优化和指令重排序操作。</p><p>要解决双重检查锁模式带来空指针异常的问题，只需要使用 <code>volatile</code> 关键字, <code>volatile</code> 关键字可以保证可见性和有序性。</p><pre><code class="java">/** * 双重检查方式 */public class Singleton &#123;    //私有构造方法    private Singleton() &#123;&#125;    private static volatile Singleton instance;   //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        //第一次判断，如果instance不为null，不进入抢锁阶段，直接返回实际        if(instance == null) &#123;            synchronized (Singleton.class) &#123;                //抢到锁之后再次判断是否为空                if(instance == null) &#123;                    instance = new Singleton();                &#125;            &#125;        &#125;        return instance;    &#125;&#125;</code></pre><p><font color="red">小结：</font></p><p>添加 <code>volatile</code> 关键字之后的双重检查锁模式是一种比较好的单例实现模式，能够保证在多线程的情况下线程安全也不会有性能问题。</p></li><li><p>懒汉式-方式4（静态内部类方式）</p><p>静态内部类单例模式中实例由内部类创建，由于 JVM 在加载外部类的过程中, 是不会加载静态内部类的, 只有内部类的属性&#x2F;方法被调用时才会被加载, 并初始化其静态属性。静态属性由于被 <code>static</code> 修饰，保证只被实例化一次，并且严格保证实例化顺序。</p><pre><code class="java">/** * 静态内部类方式 */public class Singleton &#123;    //私有构造方法    private Singleton() &#123;&#125;    private static class SingletonHolder &#123;        private static final Singleton INSTANCE = new Singleton();    &#125;    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        return SingletonHolder.INSTANCE;    &#125;&#125;</code></pre><p><font color='red'>说明：</font></p><p>​第一次加载Singleton类时不会去初始化INSTANCE，只有第一次调用getInstance，虚拟机加载SingletonHolder</p><p>并初始化INSTANCE，这样不仅能确保线程安全，也能保证 Singleton 类的唯一性。</p><p><font color="red">小结：</font></p><p>​静态内部类单例模式是一种优秀的单例模式，是开源项目中比较常用的一种单例模式。在没有加任何锁的情况下，保证了多线程下的安全，并且没有任何性能影响和空间的浪费。</p></li><li><p>枚举方式</p><p>枚举类实现单例模式是极力推荐的单例实现模式，因为枚举类型是线程安全的，并且只会装载一次，设计者充分的利用了枚举的这个特性来实现单例模式，枚举的写法非常简单，而且枚举类型是所用单例实现中唯一一种不会被破坏的单例实现模式。</p><pre><code class="java">/** * 枚举方式 */public enum Singleton &#123;    INSTANCE;&#125;</code></pre><p><font color='red'>说明：</font></p><p>​枚举方式属于恶汉式方式。</p></li></ol><h3 id="4-1-3-存在的问题"><a href="#4-1-3-存在的问题" class="headerlink" title="4.1.3 存在的问题"></a>4.1.3 存在的问题</h3><h4 id="4-1-3-1-问题演示"><a href="#4-1-3-1-问题演示" class="headerlink" title="4.1.3.1 问题演示"></a>4.1.3.1 问题演示</h4><p>破坏单例模式：</p><p>使上面定义的单例类（Singleton）可以创建多个对象，枚举方式除外。有两种方式，分别是序列化和反射。</p><ul><li><p>序列化反序列化</p><p><strong>Singleton类：</strong></p><pre><code class="java">public class Singleton implements Serializable &#123;    //私有构造方法    private Singleton() &#123;&#125;    private static class SingletonHolder &#123;        private static final Singleton INSTANCE = new Singleton();    &#125;    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        return SingletonHolder.INSTANCE;    &#125;&#125;</code></pre><p><strong>Test类：</strong></p><pre><code class="java">public class Test &#123;    public static void main(String[] args) throws Exception &#123;        //往文件中写对象        //writeObject2File();        //从文件中读取对象        Singleton s1 = readObjectFromFile();        Singleton s2 = readObjectFromFile();        //判断两个反序列化后的对象是否是同一个对象        System.out.println(s1 == s2);    &#125;    private static Singleton readObjectFromFile() throws Exception &#123;        //创建对象输入流对象        ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;C:\\Users\\Think\\Desktop\\a.txt&quot;));        //第一个读取Singleton对象        Singleton instance = (Singleton) ois.readObject();        return instance;    &#125;    public static void writeObject2File() throws Exception &#123;        //获取Singleton类的对象        Singleton instance = Singleton.getInstance();        //创建对象输出流        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;C:\\Users\\Think\\Desktop\\a.txt&quot;));        //将instance对象写出到文件中        oos.writeObject(instance);    &#125;&#125;</code></pre><blockquote><p>上面代码运行结果是<code>false</code>，表明序列化和反序列化已经破坏了单例设计模式。</p></blockquote></li><li><p>反射</p><p><strong>Singleton类：</strong></p><pre><code class="java">public class Singleton &#123;    //私有构造方法    private Singleton() &#123;&#125;        private static volatile Singleton instance;    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        if(instance != null) &#123;            return instance;        &#125;        synchronized (Singleton.class) &#123;            if(instance != null) &#123;                return instance;            &#125;            instance = new Singleton();            return instance;        &#125;    &#125;&#125;</code></pre><p><strong>Test类：</strong></p><pre><code class="java">public class Test &#123;    public static void main(String[] args) throws Exception &#123;        //获取Singleton类的字节码对象        Class clazz = Singleton.class;        //获取Singleton类的私有无参构造方法对象        Constructor constructor = clazz.getDeclaredConstructor();        //取消访问检查        constructor.setAccessible(true);        //创建Singleton类的对象s1        Singleton s1 = (Singleton) constructor.newInstance();        //创建Singleton类的对象s2        Singleton s2 = (Singleton) constructor.newInstance();        //判断通过反射创建的两个Singleton对象是否是同一个对象        System.out.println(s1 == s2);    &#125;&#125;</code></pre><blockquote><p>上面代码运行结果是<code>false</code>，表明序列化和反序列化已经破坏了单例设计模式</p></blockquote></li></ul><blockquote><p><font color="red">注意：</font>枚举方式不会出现这两个问题。</p></blockquote><h4 id="4-1-3-2-问题的解决"><a href="#4-1-3-2-问题的解决" class="headerlink" title="4.1.3.2 问题的解决"></a>4.1.3.2 问题的解决</h4><ul><li><p>序列化、反序列方式破坏单例模式的解决方法</p><p>在Singleton类中添加<code>readResolve()</code>方法，在反序列化时被反射调用，如果定义了这个方法，就返回这个方法的值，如果没有定义，则返回新new出来的对象。</p><p><strong>Singleton类：</strong></p><pre><code class="java">public class Singleton implements Serializable &#123;    //私有构造方法    private Singleton() &#123;&#125;    private static class SingletonHolder &#123;        private static final Singleton INSTANCE = new Singleton();    &#125;    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        return SingletonHolder.INSTANCE;    &#125;        /**     * 下面是为了解决序列化反序列化破解单例模式     */    private Object readResolve() &#123;        return SingletonHolder.INSTANCE;    &#125;&#125;</code></pre><p><strong>源码解析：</strong></p><p>ObjectInputStream类</p><pre><code class="java">public final Object readObject() throws IOException, ClassNotFoundException&#123;    ...    // if nested read, passHandle contains handle of enclosing object    int outerHandle = passHandle;    try &#123;        Object obj = readObject0(false);//重点查看readObject0方法    .....&#125;    private Object readObject0(boolean unshared) throws IOException &#123;    ...    try &#123;        switch (tc) &#123;            ...            case TC_OBJECT:                return checkResolve(readOrdinaryObject(unshared));//重点查看readOrdinaryObject方法            ...        &#125;    &#125; finally &#123;        depth--;        bin.setBlockDataMode(oldMode);    &#125;    &#125;    private Object readOrdinaryObject(boolean unshared) throws IOException &#123;    ...    //isInstantiable 返回true，执行 desc.newInstance()，通过反射创建新的单例类，    obj = desc.isInstantiable() ? desc.newInstance() : null;     ...    // 在Singleton类中添加 readResolve 方法后 desc.hasReadResolveMethod() 方法执行结果为true    if (obj != null &amp;&amp; handles.lookupException(passHandle) == null &amp;&amp; desc.hasReadResolveMethod()) &#123;        // 通过反射调用 Singleton 类中的 readResolve 方法，将返回值赋值给rep变量        // 这样多次调用ObjectInputStream类中的readObject方法，继而就会调用我们定义的readResolve方法，所以返回的是同一个对象。        Object rep = desc.invokeReadResolve(obj);         ...    &#125;    return obj;&#125;</code></pre></li><li><p>反射方式破解单例的解决方法</p><pre><code class="java">public class Singleton &#123;    //私有构造方法    private Singleton() &#123;        /*           反射破解单例模式需要添加的代码        */        if(instance != null) &#123;            throw new RuntimeException();        &#125;    &#125;        private static volatile Singleton instance;    //对外提供静态方法获取该对象    public static Singleton getInstance() &#123;        if(instance != null) &#123;            return instance;        &#125;        synchronized (Singleton.class) &#123;            if(instance != null) &#123;                return instance;            &#125;            instance = new Singleton();            return instance;        &#125;    &#125;&#125;</code></pre><p><font color="red">说明:</font></p><p>​这种方式比较好理解。当通过反射方式调用构造方法进行创建创建时，直接抛异常。不运行此中操作。</p></li></ul><h3 id="4-1-4-JDK源码解析-Runtime类"><a href="#4-1-4-JDK源码解析-Runtime类" class="headerlink" title="4.1.4 JDK源码解析-Runtime类"></a>4.1.4 JDK源码解析-Runtime类</h3><p>Runtime类就是使用的单例设计模式。</p><ol><li><p>通过源代码查看使用的是哪儿种单例模式</p><pre><code class="java">public class Runtime &#123;    private static Runtime currentRuntime = new Runtime();    /**     * Returns the runtime object associated with the current Java application.     * Most of the methods of class &lt;code&gt;Runtime&lt;/code&gt; are instance     * methods and must be invoked with respect to the current runtime object.     *     * @return  the &lt;code&gt;Runtime&lt;/code&gt; object associated with the current     *          Java application.     */    public static Runtime getRuntime() &#123;        return currentRuntime;    &#125;    /** Don&#39;t let anyone else instantiate this class */    private Runtime() &#123;&#125;    ...&#125;</code></pre><p>从上面源代码中可以看出Runtime类使用的是恶汉式（静态属性）方式来实现单例模式的。</p></li><li><p>使用Runtime类中的方法</p><pre><code class="java">public class RuntimeDemo &#123;    public static void main(String[] args) throws IOException &#123;        //获取Runtime类对象        Runtime runtime = Runtime.getRuntime();        //返回 Java 虚拟机中的内存总量。        System.out.println(runtime.totalMemory());        //返回 Java 虚拟机试图使用的最大内存量。        System.out.println(runtime.maxMemory());        //创建一个新的进程执行指定的字符串命令，返回进程对象        Process process = runtime.exec(&quot;ipconfig&quot;);        //获取命令执行后的结果，通过输入流获取        InputStream inputStream = process.getInputStream();        byte[] arr = new byte[1024 * 1024* 100];        int b = inputStream.read(arr);        System.out.println(new String(arr,0,b,&quot;gbk&quot;));    &#125;&#125;</code></pre></li></ol><h2 id="4-2-工厂模式（工厂方法-amp-抽象工厂）"><a href="#4-2-工厂模式（工厂方法-amp-抽象工厂）" class="headerlink" title="4.2 工厂模式（工厂方法&amp;抽象工厂）"></a>4.2 工厂模式（工厂方法&amp;抽象工厂）</h2><h3 id="4-2-1-概述"><a href="#4-2-1-概述" class="headerlink" title="4.2.1 概述"></a>4.2.1 概述</h3><p>需求：设计一个咖啡店点餐系统。  </p><p>设计一个咖啡类（Coffee），并定义其两个子类（美式咖啡【AmericanCoffee】和拿铁咖啡【LatteCoffee】）；再设计一个咖啡店类（CoffeeStore），咖啡店具有点咖啡的功能。</p><p>具体类的设计如下：</p><img src="../imgs/blog26/%E5%B7%A5%E5%8E%82%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%BC%95%E5%85%A5.png" style="zoom:80%;" /><p>在java中，万物皆对象，这些对象都需要创建，如果创建的时候直接new该对象，就会对该对象耦合严重，假如我们要更换对象，所有new对象的地方都需要修改一遍，这显然违背了软件设计的开闭原则。如果我们使用工厂来生产对象，我们就只和工厂打交道就可以了，彻底和对象解耦，如果要更换对象，直接在工厂里更换该对象即可，达到了与对象解耦的目的；所以说，工厂模式最大的优点就是：<strong>解耦</strong>。</p><p>在本教程中会介绍三种工厂的使用</p><ul><li>简单工厂模式（不属于GOF的23种经典设计模式）</li><li>工厂方法模式</li><li>抽象工厂模式</li></ul><h3 id="4-2-2-简单工厂模式"><a href="#4-2-2-简单工厂模式" class="headerlink" title="4.2.2 简单工厂模式"></a>4.2.2 简单工厂模式</h3><p>简单工厂不是一种设计模式，反而比较像是一种编程习惯。</p><h4 id="4-2-2-1-结构"><a href="#4-2-2-1-结构" class="headerlink" title="4.2.2.1 结构"></a>4.2.2.1 结构</h4><p>简单工厂包含如下角色：</p><ul><li>抽象产品 ：定义了产品的规范，描述了产品的主要特性和功能。</li><li>具体产品 ：实现或者继承抽象产品的子类</li><li>具体工厂 ：提供了创建产品的方法，调用者通过该方法来获取产品。</li></ul><h4 id="4-2-2-2-实现"><a href="#4-2-2-2-实现" class="headerlink" title="4.2.2.2 实现"></a>4.2.2.2 实现</h4><p>现在使用简单工厂对上面案例进行改进，类图如下：</p><img src="../imgs/blog26/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F.png" style="zoom:70%;" /><p>工厂类代码如下：</p><pre><code class="java">public class SimpleCoffeeFactory &#123;    public Coffee createCoffee(String type) &#123;        Coffee coffee = null;        if(&quot;americano&quot;.equals(type)) &#123;            coffee = new AmericanoCoffee();        &#125; else if(&quot;latte&quot;.equals(type)) &#123;            coffee = new LatteCoffee();        &#125;        return coffee;    &#125;&#125;</code></pre><p>工厂（factory）处理创建对象的细节，一旦有了SimpleCoffeeFactory，CoffeeStore类中的orderCoffee()就变成此对象的客户，后期如果需要Coffee对象直接从工厂中获取即可。这样也就解除了和Coffee实现类的耦合，同时又产生了新的耦合，CoffeeStore对象和SimpleCoffeeFactory工厂对象的耦合，工厂对象和商品对象的耦合。</p><p>后期如果再加新品种的咖啡，我们势必要需求修改SimpleCoffeeFactory的代码，违反了开闭原则。工厂类的客户端可能有很多，比如创建美团外卖等，这样只需要修改工厂类的代码，省去其他的修改操作。</p><h4 id="4-2-2-4-优缺点"><a href="#4-2-2-4-优缺点" class="headerlink" title="4.2.2.4 优缺点"></a>4.2.2.4 优缺点</h4><p><strong>优点：</strong></p><p>封装了创建对象的过程，可以通过参数直接获取对象。把对象的创建和业务逻辑层分开，这样以后就避免了修改客户代码，如果要实现新产品直接修改工厂类，而不需要在原代码中修改，这样就降低了客户代码修改的可能性，更加容易扩展。</p><p><strong>缺点：</strong></p><p>增加新产品时还是需要修改工厂类的代码，违背了“开闭原则”。</p><h4 id="4-2-2-3-扩展"><a href="#4-2-2-3-扩展" class="headerlink" title="4.2.2.3 扩展"></a>4.2.2.3 扩展</h4><p><strong>静态工厂</strong></p><p>在开发中也有一部分人将工厂类中的创建对象的功能定义为静态的，这个就是静态工厂模式，它也不是23种设计模式中的。代码如下：</p><pre><code class="java">public class SimpleCoffeeFactory &#123;    public static Coffee createCoffee(String type) &#123;        Coffee coffee = null;        if(&quot;americano&quot;.equals(type)) &#123;            coffee = new AmericanoCoffee();        &#125; else if(&quot;latte&quot;.equals(type)) &#123;            coffee = new LatteCoffee();        &#125;        return coffe;    &#125;&#125;</code></pre><h3 id="4-2-3-工厂方法模式"><a href="#4-2-3-工厂方法模式" class="headerlink" title="4.2.3 工厂方法模式"></a>4.2.3 工厂方法模式</h3><p>针对上例中的缺点，使用工厂方法模式就可以完美的解决，完全遵循开闭原则。</p><h4 id="4-2-3-1-概念"><a href="#4-2-3-1-概念" class="headerlink" title="4.2.3.1 概念"></a>4.2.3.1 概念</h4><p>定义一个用于创建对象的接口，让子类决定实例化哪个产品类对象。工厂方法使一个产品类的实例化延迟到其工厂的子类。</p><h4 id="4-2-3-2-结构"><a href="#4-2-3-2-结构" class="headerlink" title="4.2.3.2 结构"></a>4.2.3.2 结构</h4><p>工厂方法模式的主要角色：</p><ul><li>抽象工厂（Abstract Factory）：提供了创建产品的接口，调用者通过它访问具体工厂的工厂方法来创建产品。</li><li>具体工厂（ConcreteFactory）：主要是实现抽象工厂中的抽象方法，完成具体产品的创建。</li><li>抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能。</li><li>具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。</li></ul><h4 id="4-2-3-3-实现"><a href="#4-2-3-3-实现" class="headerlink" title="4.2.3.3 实现"></a>4.2.3.3 实现</h4><p>使用工厂方法模式对上例进行改进，类图如下：</p><img src="../imgs/blog26/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F.png" style="zoom:70%;" /><p>代码如下：</p><p>抽象工厂：</p><pre><code class="java">public interface CoffeeFactory &#123;    Coffee createCoffee();&#125;</code></pre><p>具体工厂：</p><pre><code class="java">public class LatteCoffeeFactory implements CoffeeFactory &#123;    public Coffee createCoffee() &#123;        return new LatteCoffee();    &#125;&#125;public class AmericanCoffeeFactory implements CoffeeFactory &#123;    public Coffee createCoffee() &#123;        return new AmericanCoffee();    &#125;&#125;</code></pre><p>咖啡店类：</p><pre><code class="java">public class CoffeeStore &#123;    private CoffeeFactory factory;    public CoffeeStore(CoffeeFactory factory) &#123;        this.factory = factory;    &#125;    public Coffee orderCoffee(String type) &#123;        Coffee coffee = factory.createCoffee();        coffee.addMilk();        coffee.addsugar();        return coffee;    &#125;&#125;</code></pre><p>从以上的编写的代码可以看到，要增加产品类时也要相应地增加工厂类，不需要修改工厂类的代码了，这样就解决了简单工厂模式的缺点。</p><p>工厂方法模式是简单工厂模式的进一步抽象。由于使用了多态性，工厂方法模式保持了简单工厂模式的优点，而且克服了它的缺点。</p><h4 id="4-2-3-4-优缺点"><a href="#4-2-3-4-优缺点" class="headerlink" title="4.2.3.4 优缺点"></a>4.2.3.4 优缺点</h4><p><strong>优点：</strong></p><ul><li>用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程；</li><li>在系统增加新的产品时只需要添加具体产品类和对应的具体工厂类，无须对原工厂进行任何修改，满足开闭原则；</li></ul><p><strong>缺点：</strong></p><ul><li>每增加一个产品就要增加一个具体产品类和一个对应的具体工厂类，这增加了系统的复杂度。</li></ul><h3 id="4-2-4-抽象工厂模式"><a href="#4-2-4-抽象工厂模式" class="headerlink" title="4.2.4 抽象工厂模式"></a>4.2.4 抽象工厂模式</h3><p>前面介绍的工厂方法模式中考虑的是一类产品的生产，如畜牧场只养动物、电视机厂只生产电视机、传智播客只培养计算机软件专业的学生等。</p><p>这些工厂只生产同种类产品，同种类产品称为同等级产品，也就是说：工厂方法模式只考虑生产同等级的产品，但是在现实生活中许多工厂是综合型的工厂，能生产多等级（种类） 的产品，如电器厂既生产电视机又生产洗衣机或空调，大学既有软件专业又有生物专业等。</p><p>本节要介绍的抽象工厂模式将考虑多等级产品的生产，将同一个具体工厂所生产的位于不同等级的一组产品称为一个产品族，下图所示横轴是产品等级，也就是同一类产品；纵轴是产品族，也就是同一品牌的产品，同一品牌的产品产自同一个工厂。</p><img src="../imgs/blog26/image-20200401214509176.png" style="zoom:67%;" /><img src="../imgs/blog26/image-20200401222951963.png" style="zoom:67%;" /><h4 id="4-2-4-1-概念"><a href="#4-2-4-1-概念" class="headerlink" title="4.2.4.1 概念"></a>4.2.4.1 概念</h4><p>是一种为访问类提供一个创建一组相关或相互依赖对象的接口，且访问类无须指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。</p><p>抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。</p><h4 id="4-2-4-2-结构"><a href="#4-2-4-2-结构" class="headerlink" title="4.2.4.2 结构"></a>4.2.4.2 结构</h4><p>抽象工厂模式的主要角色如下：</p><ul><li>抽象工厂（Abstract Factory）：提供了创建产品的接口，它包含多个创建产品的方法，可以创建多个不同等级的产品。</li><li>具体工厂（Concrete Factory）：主要是实现抽象工厂中的多个抽象方法，完成具体产品的创建。</li><li>抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能，抽象工厂模式有多个抽象产品。</li><li>具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它 同具体工厂之间是多对一的关系。</li></ul><h4 id="4-2-4-2-实现"><a href="#4-2-4-2-实现" class="headerlink" title="4.2.4.2 实现"></a>4.2.4.2 实现</h4><p>现咖啡店业务发生改变，不仅要生产咖啡还要生产甜点，如提拉米苏、抹茶慕斯等，要是按照工厂方法模式，需要定义提拉米苏类、抹茶慕斯类、提拉米苏工厂、抹茶慕斯工厂、甜点工厂类，很容易发生类爆炸情况。其中拿铁咖啡、美式咖啡是一个产品等级，都是咖啡；提拉米苏、抹茶慕斯也是一个产品等级；拿铁咖啡和提拉米苏是同一产品族（也就是都属于意大利风味），美式咖啡和抹茶慕斯是同一产品族（也就是都属于美式风味）。所以这个案例可以使用抽象工厂模式实现。类图如下：</p><img src="../imgs/blog26/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F.png" style="zoom:67%;" /><p>代码如下：</p><p>抽象工厂：</p><pre><code class="java">public interface DessertFactory &#123;    Coffee createCoffee();    Dessert createDessert();&#125;</code></pre><p>具体工厂：</p><pre><code class="java">//美式甜点工厂public class AmericanDessertFactory implements DessertFactory &#123;    public Coffee createCoffee() &#123;        return new AmericanCoffee();    &#125;    public Dessert createDessert() &#123;        return new MatchaMousse();    &#125;&#125;//意大利风味甜点工厂public class ItalyDessertFactory implements DessertFactory &#123;    public Coffee createCoffee() &#123;        return new LatteCoffee();    &#125;    public Dessert createDessert() &#123;        return new Tiramisu();    &#125;&#125;</code></pre><p>如果要加同一个产品族的话，只需要再加一个对应的工厂类即可，不需要修改其他的类。</p><h4 id="4-2-4-3-优缺点"><a href="#4-2-4-3-优缺点" class="headerlink" title="4.2.4.3 优缺点"></a>4.2.4.3 优缺点</h4><p><strong>优点：</strong></p><p>当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。</p><p><strong>缺点：</strong></p><p>当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。</p><h4 id="4-2-4-4-使用场景"><a href="#4-2-4-4-使用场景" class="headerlink" title="4.2.4.4 使用场景"></a>4.2.4.4 使用场景</h4><ul><li><p>当需要创建的对象是一系列相互关联或相互依赖的产品族时，如电器工厂中的电视机、洗衣机、空调等。</p></li><li><p>系统中有多个产品族，但每次只使用其中的某一族产品。如有人只喜欢穿某一个品牌的衣服和鞋。</p></li><li><p>系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。</p></li></ul><p>如：输入法换皮肤，一整套一起换。生成不同操作系统的程序。</p><h3 id="4-2-5-模式扩展"><a href="#4-2-5-模式扩展" class="headerlink" title="4.2.5 模式扩展"></a>4.2.5 模式扩展</h3><p><strong>简单工厂+配置文件解除耦合</strong></p><p>可以通过工厂模式+配置文件的方式解除工厂对象和产品对象的耦合。在工厂类中加载配置文件中的全类名，并创建对象进行存储，客户端如果需要对象，直接进行获取即可。</p><p>第一步：定义配置文件</p><p>为了演示方便，我们使用properties文件作为配置文件，名称为bean.properties</p><pre><code class="properties">american=com.itheima.pattern.factory.config_factory.AmericanCoffeelatte=com.itheima.pattern.factory.config_factory.LatteCoffee</code></pre><p>第二步：改进工厂类</p><pre><code class="java">public class CoffeeFactory &#123;    private static Map&lt;String,Coffee&gt; map = new HashMap();    static &#123;        Properties p = new Properties();        InputStream is = CoffeeFactory.class.getClassLoader().getResourceAsStream(&quot;bean.properties&quot;);        try &#123;            p.load(is);            //遍历Properties集合对象            Set&lt;Object&gt; keys = p.keySet();            for (Object key : keys) &#123;                //根据键获取值（全类名）                String className = p.getProperty((String) key);                //获取字节码对象                Class clazz = Class.forName(className);                Coffee obj = (Coffee) clazz.newInstance();                map.put((String)key,obj);            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    public static Coffee createCoffee(String name) &#123;        return map.get(name);    &#125;&#125;</code></pre><p>静态成员变量用来存储创建的对象（键存储的是名称，值存储的是对应的对象），而读取配置文件以及创建对象写在静态代码块中，目的就是只需要执行一次。</p><h3 id="4-2-6-JDK源码解析-Collection-iterator方法"><a href="#4-2-6-JDK源码解析-Collection-iterator方法" class="headerlink" title="4.2.6 JDK源码解析-Collection.iterator方法"></a>4.2.6 JDK源码解析-Collection.iterator方法</h3><pre><code class="java">public class Demo &#123;    public static void main(String[] args) &#123;        List&lt;String&gt; list = new ArrayList&lt;&gt;();        list.add(&quot;令狐冲&quot;);        list.add(&quot;风清扬&quot;);        list.add(&quot;任我行&quot;);        //获取迭代器对象        Iterator&lt;String&gt; it = list.iterator();        //使用迭代器遍历        while(it.hasNext()) &#123;            String ele = it.next();            System.out.println(ele);        &#125;    &#125;&#125;</code></pre><p>对上面的代码大家应该很熟，使用迭代器遍历集合，获取集合中的元素。而单列集合获取迭代器的方法就使用到了工厂方法模式。我们看通过类图看看结构：</p><img src="../imgs/blog26/JDK%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90.png" style="zoom:75%;" /><p>Collection接口是抽象工厂类，ArrayList是具体的工厂类；Iterator接口是抽象商品类，ArrayList类中的Iter内部类是具体的商品类。在具体的工厂类中iterator()方法创建具体的商品类的对象。</p><blockquote><p>另：</p><p>​1,DateForamt类中的getInstance()方法使用的是工厂模式；</p><p>​2,Calendar类中的getInstance()方法使用的是工厂模式；</p></blockquote><h2 id="4-3-原型模式"><a href="#4-3-原型模式" class="headerlink" title="4.3 原型模式"></a>4.3 原型模式</h2><h3 id="4-3-1-概述"><a href="#4-3-1-概述" class="headerlink" title="4.3.1 概述"></a>4.3.1 概述</h3><p>用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型对象相同的新对象。</p><h3 id="4-3-2-结构"><a href="#4-3-2-结构" class="headerlink" title="4.3.2 结构"></a>4.3.2 结构</h3><p>原型模式包含如下角色：</p><ul><li>抽象原型类：规定了具体原型对象必须实现的的 clone() 方法。</li><li>具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。</li><li>访问类：使用具体原型类中的 clone() 方法来复制新的对象。</li></ul><p>接口类图如下：</p><p><img src="/../imgs/blog26/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F.png"></p><h3 id="4-3-3-实现"><a href="#4-3-3-实现" class="headerlink" title="4.3.3 实现"></a>4.3.3 实现</h3><p>原型模式的克隆分为浅克隆和深克隆。</p><blockquote><p>浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。</p><p>深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。</p></blockquote><p>Java中的Object类中提供了 <code>clone()</code> 方法来实现浅克隆。 Cloneable 接口是上面的类图中的抽象原型类，而实现了Cloneable接口的子实现类就是具体的原型类。代码如下：</p><p><strong>Realizetype（具体的原型类）：</strong></p><pre><code class="java">public class Realizetype implements Cloneable &#123;    public Realizetype() &#123;        System.out.println(&quot;具体的原型对象创建完成！&quot;);    &#125;    @Override    protected Realizetype clone() throws CloneNotSupportedException &#123;        System.out.println(&quot;具体原型复制成功！&quot;);        return (Realizetype) super.clone();    &#125;&#125;</code></pre><p><strong>PrototypeTest（测试访问类）：</strong></p><pre><code class="java">public class PrototypeTest &#123;    public static void main(String[] args) throws CloneNotSupportedException &#123;        Realizetype r1 = new Realizetype();        Realizetype r2 = r1.clone();        System.out.println(&quot;对象r1和r2是同一个对象？&quot; + (r1 == r2));    &#125;&#125;</code></pre><h3 id="4-3-4-案例"><a href="#4-3-4-案例" class="headerlink" title="4.3.4 案例"></a>4.3.4 案例</h3><p><strong>用原型模式生成“三好学生”奖状</strong></p><p>同一学校的“三好学生”奖状除了获奖人姓名不同，其他都相同，可以使用原型模式复制多个“三好学生”奖状出来，然后在修改奖状上的名字即可。</p><p>类图如下：</p><img src="../imgs/blog26/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F1.png" style="zoom:80%;" /><p>代码如下：</p><pre><code class="java">//奖状类public class Citation implements Cloneable &#123;    private String name;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return (this.name);    &#125;    public void show() &#123;        System.out.println(name + &quot;同学：在2020学年第一学期中表现优秀，被评为三好学生。特发此状！&quot;);    &#125;    @Override    public Citation clone() throws CloneNotSupportedException &#123;        return (Citation) super.clone();    &#125;&#125;//测试访问类public class CitationTest &#123;    public static void main(String[] args) throws CloneNotSupportedException &#123;        Citation c1 = new Citation();        c1.setName(&quot;张三&quot;);        //复制奖状        Citation c2 = c1.clone();        //将奖状的名字修改李四        c2.setName(&quot;李四&quot;);        c1.show();        c2.show();    &#125;&#125;</code></pre><h3 id="4-3-5-使用场景"><a href="#4-3-5-使用场景" class="headerlink" title="4.3.5 使用场景"></a>4.3.5 使用场景</h3><ul><li>对象的创建非常复杂，可以使用原型模式快捷的创建对象。</li><li>性能和安全要求比较高。</li></ul><h3 id="4-3-6-扩展（深克隆）"><a href="#4-3-6-扩展（深克隆）" class="headerlink" title="4.3.6 扩展（深克隆）"></a>4.3.6 扩展（深克隆）</h3><p>将上面的“三好学生”奖状的案例中Citation类的name属性修改为Student类型的属性。代码如下：</p><pre><code class="java">//奖状类public class Citation implements Cloneable &#123;    private Student stu;    public Student getStu() &#123;        return stu;    &#125;    public void setStu(Student stu) &#123;        this.stu = stu;    &#125;    void show() &#123;        System.out.println(stu.getName() + &quot;同学：在2020学年第一学期中表现优秀，被评为三好学生。特发此状！&quot;);    &#125;    @Override    public Citation clone() throws CloneNotSupportedException &#123;        return (Citation) super.clone();    &#125;&#125;//学生类public class Student &#123;    private String name;    private String address;    public Student(String name, String address) &#123;        this.name = name;        this.address = address;    &#125;    public Student() &#123;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getAddress() &#123;        return address;    &#125;    public void setAddress(String address) &#123;        this.address = address;    &#125;&#125;//测试类public class CitationTest &#123;    public static void main(String[] args) throws CloneNotSupportedException &#123;        Citation c1 = new Citation();        Student stu = new Student(&quot;张三&quot;, &quot;西安&quot;);        c1.setStu(stu);        //复制奖状        Citation c2 = c1.clone();        //获取c2奖状所属学生对象        Student stu1 = c2.getStu();        stu1.setName(&quot;李四&quot;);        //判断stu对象和stu1对象是否是同一个对象        System.out.println(&quot;stu和stu1是同一个对象？&quot; + (stu == stu1));        c1.show();        c2.show();    &#125;&#125;</code></pre><p>运行结果为：</p><img src="../imgs/blog26/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F2.png" style="zoom:80%;" /><p><font color="red">说明：</font></p><p>​stu对象和stu1对象是同一个对象，就会产生将stu1对象中name属性值改为“李四”，两个Citation（奖状）对象中显示的都是李四。这就是浅克隆的效果，对具体原型类（Citation）中的引用类型的属性进行引用的复制。这种情况需要使用深克隆，而进行深克隆需要使用对象流。代码如下：</p><pre><code class="java">public class CitationTest1 &#123;    public static void main(String[] args) throws Exception &#123;        Citation c1 = new Citation();        Student stu = new Student(&quot;张三&quot;, &quot;西安&quot;);        c1.setStu(stu);        //创建对象输出流对象        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;C:\\Users\\Think\\Desktop\\b.txt&quot;));        //将c1对象写出到文件中        oos.writeObject(c1);        oos.close();        //创建对象出入流对象        ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;C:\\Users\\Think\\Desktop\\b.txt&quot;));        //读取对象        Citation c2 = (Citation) ois.readObject();        //获取c2奖状所属学生对象        Student stu1 = c2.getStu();        stu1.setName(&quot;李四&quot;);        //判断stu对象和stu1对象是否是同一个对象        System.out.println(&quot;stu和stu1是同一个对象？&quot; + (stu == stu1));        c1.show();        c2.show();    &#125;&#125;</code></pre><p>运行结果为：</p><img src="../imgs/blog26/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F3.png" style="zoom:80%;" /><blockquote><p>注意：Citation类和Student类必须实现Serializable接口，否则会抛NotSerializableException异常。</p></blockquote><h2 id="4-4-建造者模式"><a href="#4-4-建造者模式" class="headerlink" title="4.4 建造者模式"></a>4.4 建造者模式</h2><h3 id="4-4-1-概述"><a href="#4-4-1-概述" class="headerlink" title="4.4.1 概述"></a>4.4.1 概述</h3><p>将一个复杂对象的构建与表示分离，使得同样的构建过程可以创建不同的表示。</p><img src="../imgs/blog26/image-20200413225341516.png" style="zoom:60%;" /><ul><li>分离了部件的构造(由Builder来负责)和装配(由Director负责)。 从而可以构造出复杂的对象。这个模式适用于：某个对象的构建过程复杂的情况。</li><li>由于实现了构建和装配的解耦。不同的构建器，相同的装配，也可以做出不同的对象；相同的构建器，不同的装配顺序也可以做出不同的对象。也就是实现了构建算法、装配算法的解耦，实现了更好的复用。</li><li>建造者模式可以将部件和其组装过程分开，一步一步创建一个复杂的对象。用户只需要指定复杂对象的类型就可以得到该对象，而无须知道其内部的具体构造细节。</li></ul><h3 id="4-4-2-结构"><a href="#4-4-2-结构" class="headerlink" title="4.4.2 结构"></a>4.4.2 结构</h3><p>建造者（Builder）模式包含如下角色：</p><ul><li><p>抽象建造者类（Builder）：这个接口规定要实现复杂对象的那些部分的创建，并不涉及具体的部件对象的创建。 </p></li><li><p>具体建造者类（ConcreteBuilder）：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。在构造过程完成后，提供产品的实例。 </p></li><li><p>产品类（Product）：要创建的复杂对象。</p></li><li><p>指挥者类（Director）：调用具体建造者来创建复杂对象的各个部分，在指导者中不涉及具体产品的信息，只负责保证对象各部分完整创建或按某种顺序创建。</p></li></ul><p>类图如下：</p><img src="../imgs/blog26/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F.png" style="zoom:80%;" /><h3 id="4-4-3-实例"><a href="#4-4-3-实例" class="headerlink" title="4.4.3 实例"></a>4.4.3 实例</h3><p><strong>创建共享单车</strong></p><p>生产自行车是一个复杂的过程，它包含了车架，车座等组件的生产。而车架又有碳纤维，铝合金等材质的，车座有橡胶，真皮等材质。对于自行车的生产就可以使用建造者模式。</p><p>这里Bike是产品，包含车架，车座等组件；Builder是抽象建造者，MobikeBuilder和OfoBuilder是具体的建造者；Director是指挥者。类图如下：</p><img src="../imgs/blog26/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F1.png" style="zoom:80%;" /><p>具体的代码如下：</p><pre><code class="java">//自行车类public class Bike &#123;    private String frame;    private String seat;    public String getFrame() &#123;        return frame;    &#125;    public void setFrame(String frame) &#123;        this.frame = frame;    &#125;    public String getSeat() &#123;        return seat;    &#125;    public void setSeat(String seat) &#123;        this.seat = seat;    &#125;&#125;// 抽象 builder 类public abstract class Builder &#123;    protected Bike mBike = new Bike();    public abstract void buildFrame();    public abstract void buildSeat();    public abstract Bike createBike();&#125;//摩拜单车Builder类public class MobikeBuilder extends Builder &#123;    @Override    public void buildFrame() &#123;        mBike.setFrame(&quot;铝合金车架&quot;);    &#125;    @Override    public void buildSeat() &#123;        mBike.setSeat(&quot;真皮车座&quot;);    &#125;    @Override    public Bike createBike() &#123;        return mBike;    &#125;&#125;//ofo单车Builder类public class OfoBuilder extends Builder &#123;    @Override    public void buildFrame() &#123;        mBike.setFrame(&quot;碳纤维车架&quot;);    &#125;    @Override    public void buildSeat() &#123;        mBike.setSeat(&quot;橡胶车座&quot;);    &#125;    @Override    public Bike createBike() &#123;        return mBike;    &#125;&#125;//指挥者类public class Director &#123;    private Builder mBuilder;    public Director(Builder builder) &#123;        mBuilder = builder;    &#125;    public Bike construct() &#123;        mBuilder.buildFrame();        mBuilder.buildSeat();        return mBuilder.createBike();    &#125;&#125;//测试类public class Client &#123;    public static void main(String[] args) &#123;        showBike(new OfoBuilder());        showBike(new MobikeBuilder());    &#125;    private static void showBike(Builder builder) &#123;        Director director = new Director(builder);        Bike bike = director.construct();        System.out.println(bike.getFrame());        System.out.println(bike.getSeat());    &#125;&#125;</code></pre><p><strong>注意：</strong></p><p>上面示例是 Builder模式的常规用法，指挥者类 Director 在建造者模式中具有很重要的作用，它用于指导具体构建者如何构建产品，控制调用先后次序，并向调用者返回完整的产品类，但是有些情况下需要简化系统结构，可以把指挥者类和抽象建造者进行结合</p><pre><code class="java">// 抽象 builder 类public abstract class Builder &#123;    protected Bike mBike = new Bike();    public abstract void buildFrame();    public abstract void buildSeat();    public abstract Bike createBike();        public Bike construct() &#123;        this.buildFrame();        this.BuildSeat();        return this.createBike();    &#125;&#125;</code></pre><p><strong>说明：</strong></p><p>这样做确实简化了系统结构，但同时也加重了抽象建造者类的职责，也不是太符合单一职责原则，如果construct() 过于复杂，建议还是封装到 Director 中。</p><h3 id="4-4-4-优缺点"><a href="#4-4-4-优缺点" class="headerlink" title="4.4.4 优缺点"></a>4.4.4 优缺点</h3><p><strong>优点：</strong></p><ul><li>建造者模式的封装性很好。使用建造者模式可以有效的封装变化，在使用建造者模式的场景中，一般产品类和建造者类是比较稳定的，因此，将主要的业务逻辑封装在指挥者类中对整体而言可以取得比较好的稳定性。</li><li>在建造者模式中，客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。</li><li>可以更加精细地控制产品的创建过程 。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。</li><li>建造者模式很容易进行扩展。如果有新的需求，通过实现一个新的建造者类就可以完成，基本上不用修改之前已经测试通过的代码，因此也就不会对原有功能引入风险。符合开闭原则。</li></ul><p><strong>缺点：</strong></p><p>造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，则不适合使用建造者模式，因此其使用范围受到一定的限制。</p><h3 id="4-4-5-使用场景"><a href="#4-4-5-使用场景" class="headerlink" title="4.4.5 使用场景"></a>4.4.5 使用场景</h3><p>建造者（Builder）模式创建的是复杂对象，其产品的各个部分经常面临着剧烈的变化，但将它们组合在一起的算法却相对稳定，所以它通常在以下场合使用。</p><ul><li>创建的对象较复杂，由多个部件构成，各部件面临着复杂的变化，但构件间的建造顺序是稳定的。</li><li>创建复杂对象的算法独立于该对象的组成部分以及它们的装配方式，即产品的构建过程和最终的表示是独立的。</li></ul><h3 id="4-4-6-模式扩展"><a href="#4-4-6-模式扩展" class="headerlink" title="4.4.6 模式扩展"></a>4.4.6 模式扩展</h3><p>建造者模式除了上面的用途外，在开发中还有一个常用的使用方式，就是当一个类构造器需要传入很多参数时，如果创建这个类的实例，代码可读性会非常差，而且很容易引入错误，此时就可以利用建造者模式进行重构。</p><p>重构前代码如下：</p><pre><code class="java">public class Phone &#123;    private String cpu;    private String screen;    private String memory;    private String mainboard;    public Phone(String cpu, String screen, String memory, String mainboard) &#123;        this.cpu = cpu;        this.screen = screen;        this.memory = memory;        this.mainboard = mainboard;    &#125;    public String getCpu() &#123;        return cpu;    &#125;    public void setCpu(String cpu) &#123;        this.cpu = cpu;    &#125;    public String getScreen() &#123;        return screen;    &#125;    public void setScreen(String screen) &#123;        this.screen = screen;    &#125;    public String getMemory() &#123;        return memory;    &#125;    public void setMemory(String memory) &#123;        this.memory = memory;    &#125;    public String getMainboard() &#123;        return mainboard;    &#125;    public void setMainboard(String mainboard) &#123;        this.mainboard = mainboard;    &#125;    @Override    public String toString() &#123;        return &quot;Phone&#123;&quot; +                &quot;cpu=&#39;&quot; + cpu + &#39;\&#39;&#39; +                &quot;, screen=&#39;&quot; + screen + &#39;\&#39;&#39; +                &quot;, memory=&#39;&quot; + memory + &#39;\&#39;&#39; +                &quot;, mainboard=&#39;&quot; + mainboard + &#39;\&#39;&#39; +                &#39;&#125;&#39;;    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        //构建Phone对象        Phone phone = new Phone(&quot;intel&quot;,&quot;三星屏幕&quot;,&quot;金士顿&quot;,&quot;华硕&quot;);        System.out.println(phone);    &#125;&#125;</code></pre><p>上面在客户端代码中构建Phone对象，传递了四个参数，如果参数更多呢？代码的可读性及使用的成本就是比较高。</p><p>重构后代码：</p><pre><code class="java">public class Phone &#123;    private String cpu;    private String screen;    private String memory;    private String mainboard;    private Phone(Builder builder) &#123;        cpu = builder.cpu;        screen = builder.screen;        memory = builder.memory;        mainboard = builder.mainboard;    &#125;    public static final class Builder &#123;        private String cpu;        private String screen;        private String memory;        private String mainboard;        public Builder() &#123;&#125;        public Builder cpu(String val) &#123;            cpu = val;            return this;        &#125;        public Builder screen(String val) &#123;            screen = val;            return this;        &#125;        public Builder memory(String val) &#123;            memory = val;            return this;        &#125;        public Builder mainboard(String val) &#123;            mainboard = val;            return this;        &#125;        public Phone build() &#123;            return new Phone(this);&#125;    &#125;    @Override    public String toString() &#123;        return &quot;Phone&#123;&quot; +                &quot;cpu=&#39;&quot; + cpu + &#39;\&#39;&#39; +                &quot;, screen=&#39;&quot; + screen + &#39;\&#39;&#39; +                &quot;, memory=&#39;&quot; + memory + &#39;\&#39;&#39; +                &quot;, mainboard=&#39;&quot; + mainboard + &#39;\&#39;&#39; +                &#39;&#125;&#39;;    &#125;&#125;public class Client &#123;    public static void main(String[] args) &#123;        Phone phone = new Phone.Builder()                .cpu(&quot;intel&quot;)                .mainboard(&quot;华硕&quot;)                .memory(&quot;金士顿&quot;)                .screen(&quot;三星&quot;)                .build();        System.out.println(phone);    &#125;&#125;</code></pre><p>重构后的代码在使用起来更方便，某种程度上也可以提高开发效率。从软件设计上，对程序员的要求比较高。</p><h2 id="4-5-创建者模式对比"><a href="#4-5-创建者模式对比" class="headerlink" title="4.5 创建者模式对比"></a>4.5 创建者模式对比</h2><h3 id="4-5-1-工厂方法模式VS建造者模式"><a href="#4-5-1-工厂方法模式VS建造者模式" class="headerlink" title="4.5.1 工厂方法模式VS建造者模式"></a>4.5.1 工厂方法模式VS建造者模式</h3><p>工厂方法模式注重的是整体对象的创建方式；而建造者模式注重的是部件构建的过程，意在通过一步一步地精确构造创建出一个复杂的对象。</p><p>我们举个简单例子来说明两者的差异，如要制造一个超人，如果使用工厂方法模式，直接产生出来的就是一个力大无穷、能够飞翔、内裤外穿的超人；而如果使用建造者模式，则需要组装手、头、脚、躯干等部分，然后再把内裤外穿，于是一个超人就诞生了。</p><h3 id="4-5-2-抽象工厂模式VS建造者模式"><a href="#4-5-2-抽象工厂模式VS建造者模式" class="headerlink" title="4.5.2 抽象工厂模式VS建造者模式"></a>4.5.2 抽象工厂模式VS建造者模式</h3><p>抽象工厂模式实现对产品家族的创建，一个产品家族是这样的一系列产品：具有不同分类维度的产品组合，采用抽象工厂模式则是不需要关心构建过程，只关心什么产品由什么工厂生产即可。</p><p>建造者模式则是要求按照指定的蓝图建造产品，它的主要目的是通过组装零配件而产生一个新产品。</p><p>如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件设计原则</title>
      <link href="/2023/06/25/blog25/"/>
      <url>/2023/06/25/blog25/</url>
      
        <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>在软件开发中，为了提高软件系统的可维护性和可复用性，增加软件的可扩展性和灵活性，程序员要尽量根据6条原则来开发程序，从而提高软件开发效率、节约软件开发成本和维护成本。</p><h2 id="开闭原则"><a href="#开闭原则" class="headerlink" title="开闭原则"></a>开闭原则</h2><p><strong>对扩展开放，对修改关闭</strong>。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。</p><p>想要达到这样的效果，我们需要使用接口和抽象类。</p><p>因为抽象灵活性好，适应性广，只要抽象的合理，可以基本保持软件架构的稳定。而软件中易变的细节可以从抽象派生来的实现类来进行扩展，当软件需要发生变化时，只需要根据需求重新派生一个实现类来扩展就可以了。</p><p>下面以 <code>搜狗输入法</code> 的皮肤为例介绍开闭原则的应用。</p><p>【例】<code>搜狗输入法</code> 的皮肤设计。</p><p>分析：<code>搜狗输入法</code> 的皮肤是输入法背景图片、窗口颜色和声音等元素的组合。用户可以根据自己的喜爱更换自己的输入法的皮肤，也可以从网上下载新的皮肤。这些皮肤有共同的特点，可以为其定义一个抽象类（AbstractSkin），而每个具体的皮肤（DefaultSpecificSkin和HeimaSpecificSkin）是其子类。用户窗体可以根据需要选择或者增加新的主题，而不需要修改原代码，所以它是满足开闭原则的。</p><p><img src="/../imgs/blog25/open-close.png"></p><h2 id="里氏代换原则"><a href="#里氏代换原则" class="headerlink" title="里氏代换原则"></a>里氏代换原则</h2><p>里氏代换原则是面向对象设计的基本原则之一。</p><p>里氏代换原则：任何基类可以出现的地方，子类一定可以出现。通俗理解：子类可以扩展父类的功能，但不能改变父类原有的功能。换句话说，子类继承父类时，除添加新的方法完成新增功能外，尽量不要重写父类的方法。</p><p>如果通过重写父类的方法来完成新的功能，这样写起来虽然简单，但是整个继承体系的可复用性会比较差，特别是运用多态比较频繁时，程序运行出错的概率会非常大。</p><p>下面看一个里氏替换原则中经典的一个例子</p><p>【例】正方形不是长方形。</p><p>在数学领域里，正方形毫无疑问是长方形，它是一个长宽相等的长方形。所以，我们开发的一个与几何图形相关的软件系统，就可以顺理成章的让正方形继承自长方形。</p><p><img src="/../imgs/blog25/%E6%AD%A3%E6%96%B9%E5%BD%A2%E4%B8%8D%E6%98%AF%E9%95%BF%E6%96%B9%E5%BD%A2.png"></p><p>代码如下：</p><p><strong>长方形类（Rectangle）：</strong></p><pre><code class="java">public class Rectangle &#123;    private double length;    private double width;    public double getLength() &#123;        return length;    &#125;    public void setLength(double length) &#123;        this.length = length;    &#125;    public double getWidth() &#123;        return width;    &#125;    public void setWidth(double width) &#123;        this.width = width;    &#125;&#125;</code></pre><p><strong>正方形（Square）：</strong></p><p>由于正方形的长和宽相同，所以在方法setLength和setWidth中，对长度和宽度都需要赋相同值。</p><pre><code class="java">public class Square extends Rectangle &#123;        public void setWidth(double width) &#123;        super.setLength(width);        super.setWidth(width);    &#125;    public void setLength(double length) &#123;        super.setLength(length);        super.setWidth(length);    &#125;&#125;</code></pre><p>类RectangleDemo是我们的软件系统中的一个组件，它有一个resize方法依赖基类Rectangle，resize方法是RectandleDemo类中的一个方法，用来实现宽度逐渐增长的效果。</p><pre><code class="java">public class RectangleDemo &#123;        public static void resize(Rectangle rectangle) &#123;        while (rectangle.getWidth() &lt;= rectangle.getLength()) &#123;            rectangle.setWidth(rectangle.getWidth() + 1);        &#125;    &#125;    //打印长方形的长和宽    public static void printLengthAndWidth(Rectangle rectangle) &#123;        System.out.println(rectangle.getLength());        System.out.println(rectangle.getWidth());    &#125;    public static void main(String[] args) &#123;        Rectangle rectangle = new Rectangle();        rectangle.setLength(20);        rectangle.setWidth(10);        resize(rectangle);        printLengthAndWidth(rectangle);        System.out.println(&quot;============&quot;);        Rectangle rectangle1 = new Square();        rectangle1.setLength(10);        resize(rectangle1);        printLengthAndWidth(rectangle1);    &#125;&#125;</code></pre><p>我们运行一下这段代码就会发现，假如我们把一个普通长方形作为参数传入resize方法，就会看到长方形宽度逐渐增长的效果，当宽度大于长度,代码就会停止，这种行为的结果符合我们的预期；假如我们再把一个正方形作为参数传入resize方法后，就会看到正方形的宽度和长度都在不断增长，代码会一直运行下去，直至系统产生溢出错误。所以，普通的长方形是适合这段代码的，正方形不适合。<br>我们得出结论：在resize方法中，Rectangle类型的参数是不能被Square类型的参数所代替，如果进行了替换就得不到预期结果。因此，Square类和Rectangle类之间的继承关系违反了里氏代换原则，它们之间的继承关系不成立，正方形不是长方形。</p><p>如何改进呢？此时我们需要重新设计他们之间的关系。抽象出来一个四边形接口(Quadrilateral)，让Rectangle类和Square类实现Quadrilateral接口</p><img src="../imgs/blog25/%E6%AD%A3%E6%96%B9%E5%BD%A2%E4%B8%8D%E6%98%AF%E9%95%BF%E6%96%B9%E5%BD%A2%E6%94%B9%E8%BF%9B.png" style="zoom:80%;" /><h2 id="依赖倒转原则"><a href="#依赖倒转原则" class="headerlink" title="依赖倒转原则"></a>依赖倒转原则</h2><p>高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。简单的说就是要求对抽象进行编程，不要对实现进行编程，这样就降低了客户与实现模块间的耦合。</p><p>下面看一个例子来理解依赖倒转原则</p><p>【例】组装电脑</p><p>现要组装一台电脑，需要配件cpu，硬盘，内存条。只有这些配置都有了，计算机才能正常的运行。选择cpu有很多选择，如Intel，AMD等，硬盘可以选择希捷，西数等，内存条可以选择金士顿，海盗船等。</p><p><strong>类图如下：</strong></p><img src="../imgs/blog25/%E4%BE%9D%E8%B5%96%E5%80%92%E8%BD%AC%E5%8E%9F%E5%88%99.png" style="zoom:80%;" /><p>代码如下：</p><p><strong>希捷硬盘类（XiJieHardDisk）:</strong></p><pre><code class="java">public class XiJieHardDisk implements HardDisk &#123;    public void save(String data) &#123;        System.out.println(&quot;使用希捷硬盘存储数据&quot; + data);    &#125;    public String get() &#123;        System.out.println(&quot;使用希捷希捷硬盘取数据&quot;);        return &quot;数据&quot;;    &#125;&#125;</code></pre><p><strong>Intel处理器（IntelCpu）：</strong></p><pre><code class="java">public class IntelCpu implements Cpu &#123;    public void run() &#123;        System.out.println(&quot;使用Intel处理器&quot;);    &#125;&#125;</code></pre><p><strong>金士顿内存条（KingstonMemory）：</strong></p><pre><code class="java">public class KingstonMemory implements Memory &#123;    public void save() &#123;        System.out.println(&quot;使用金士顿作为内存条&quot;);    &#125;&#125;</code></pre><p><strong>电脑（Computer）：</strong></p><pre><code class="java">public class Computer &#123;    private XiJieHardDisk hardDisk;    private IntelCpu cpu;    private KingstonMemory memory;    public IntelCpu getCpu() &#123;        return cpu;    &#125;    public void setCpu(IntelCpu cpu) &#123;        this.cpu = cpu;    &#125;    public KingstonMemory getMemory() &#123;        return memory;    &#125;    public void setMemory(KingstonMemory memory) &#123;        this.memory = memory;    &#125;    public XiJieHardDisk getHardDisk() &#123;        return hardDisk;    &#125;    public void setHardDisk(XiJieHardDisk hardDisk) &#123;        this.hardDisk = hardDisk;    &#125;    public void run() &#123;        System.out.println(&quot;计算机工作&quot;);        cpu.run();        memory.save();        String data = hardDisk.get();        System.out.println(&quot;从硬盘中获取的数据为：&quot; + data);    &#125;&#125;</code></pre><p><strong>测试类（TestComputer）：</strong></p><p>测试类用来组装电脑。</p><pre><code class="java">public class TestComputer &#123;    public static void main(String[] args) &#123;        Computer computer = new Computer();        computer.setHardDisk(new XiJieHardDisk());        computer.setCpu(new IntelCpu());        computer.setMemory(new KingstonMemory());        computer.run();    &#125;&#125;</code></pre><p>上面代码可以看到已经组装了一台电脑，但是似乎组装的电脑的cpu只能是Intel的，内存条只能是金士顿的，硬盘只能是希捷的，这对用户肯定是不友好的，用户有了机箱肯定是想按照自己的喜好，选择自己喜欢的配件。</p><p>根据依赖倒转原则进行改进：</p><p>代码我们只需要修改Computer类，让Computer类依赖抽象（各个配件的接口），而不是依赖于各个组件具体的实现类。</p><p><strong>类图如下：</strong></p><img src="../imgs/blog25/%E4%BE%9D%E8%B5%96%E5%80%92%E8%BD%AC%E5%8E%9F%E5%88%99%E6%94%B9%E8%BF%9B.png" alt="image-20191229173554296" style="zoom:70%;" /><p><strong>电脑（Computer）：</strong></p><pre><code class="java">public class Computer &#123;    private HardDisk hardDisk;    private Cpu cpu;    private Memory memory;    public HardDisk getHardDisk() &#123;        return hardDisk;    &#125;    public void setHardDisk(HardDisk hardDisk) &#123;        this.hardDisk = hardDisk;    &#125;    public Cpu getCpu() &#123;        return cpu;    &#125;    public void setCpu(Cpu cpu) &#123;        this.cpu = cpu;    &#125;    public Memory getMemory() &#123;        return memory;    &#125;    public void setMemory(Memory memory) &#123;        this.memory = memory;    &#125;    public void run() &#123;        System.out.println(&quot;计算机工作&quot;);    &#125;&#125;</code></pre><p>面向对象的开发很好的解决了这个问题，一般情况下抽象的变化概率很小，让用户程序依赖于抽象，实现的细节也依赖于抽象。即使实现细节不断变动，只要抽象不变，客户程序就不需要变化。这大大降低了客户程序与实现细节的耦合度。</p><h2 id="接口隔离原则"><a href="#接口隔离原则" class="headerlink" title="接口隔离原则"></a>接口隔离原则</h2><p>客户端不应该被迫依赖于它不使用的方法；一个类对另一个类的依赖应该建立在最小的接口上。</p><p>下面看一个例子来理解接口隔离原则</p><p>【例】安全门案例</p><p>我们需要创建一个<code>黑马</code>品牌的安全门，该安全门具有防火、防水、防盗的功能。可以将防火，防水，防盗功能提取成一个接口，形成一套规范。类图如下：</p><p><img src="/../imgs/blog25/%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99.png"></p><p>上面的设计我们发现了它存在的问题，黑马品牌的安全门具有防盗，防水，防火的功能。现在如果我们还需要再创建一个传智品牌的安全门，而该安全门只具有防盗、防水功能呢？很显然如果实现SafetyDoor接口就违背了接口隔离原则，那么我们如何进行修改呢？看如下类图：</p><p><img src="/../imgs/blog25/%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%991.png"></p><p>代码如下：</p><p><strong>AntiTheft（接口）：</strong></p><pre><code class="java">public interface AntiTheft &#123;    void antiTheft();&#125;</code></pre><p><strong>Fireproof（接口）：</strong></p><pre><code class="java">public interface Fireproof &#123;    void fireproof();&#125;</code></pre><p><strong>Waterproof（接口）：</strong></p><pre><code class="java">public interface Waterproof &#123;    void waterproof();&#125;</code></pre><p><strong>HeiMaSafetyDoor（类）：</strong></p><pre><code class="java">public class HeiMaSafetyDoor implements AntiTheft,Fireproof,Waterproof &#123;    public void antiTheft() &#123;        System.out.println(&quot;防盗&quot;);    &#125;    public void fireproof() &#123;        System.out.println(&quot;防火&quot;);    &#125;    public void waterproof() &#123;        System.out.println(&quot;防水&quot;);    &#125;&#125;</code></pre><p><strong>ItcastSafetyDoor（类）：</strong></p><pre><code class="java">public class ItcastSafetyDoor implements AntiTheft,Fireproof &#123;    public void antiTheft() &#123;        System.out.println(&quot;防盗&quot;);    &#125;    public void fireproof() &#123;        System.out.println(&quot;防火&quot;);    &#125;&#125;</code></pre><h2 id="迪米特法则"><a href="#迪米特法则" class="headerlink" title="迪米特法则"></a>迪米特法则</h2><p>迪米特法则又叫最少知识原则。</p><p>只和你的直接朋友交谈，不跟“陌生人”说话（Talk only to your immediate friends and not to strangers）。</p><p>其含义是：如果两个软件实体无须直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。</p><p>迪米特法则中的“朋友”是指：当前对象本身、当前对象的成员对象、当前对象所创建的对象、当前对象的方法参数等，这些对象同当前对象存在关联、聚合或组合关系，可以直接访问这些对象的方法。</p><p>下面看一个例子来理解迪米特法则</p><p>【例】明星与经纪人的关系实例</p><p>明星由于全身心投入艺术，所以许多日常事务由经纪人负责处理，如和粉丝的见面会，和媒体公司的业务洽淡等。这里的经纪人是明星的朋友，而粉丝和媒体公司是陌生人，所以适合使用迪米特法则。</p><p>类图如下：</p><img src="../imgs/blog25/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99.png" alt="image-20191229173554296" style="zoom:80%;" /><p>代码如下：</p><p><strong>明星类（Star）</strong></p><pre><code class="java">public class Star &#123;    private String name;    public Star(String name) &#123;        this.name=name;    &#125;    public String getName() &#123;        return name;    &#125;&#125;</code></pre><p><strong>粉丝类（Fans）</strong></p><pre><code class="java">public class Fans &#123;    private String name;    public Fans(String name) &#123;        this.name=name;    &#125;    public String getName() &#123;        return name;    &#125;&#125;</code></pre><p><strong>媒体公司类（Company）</strong></p><pre><code class="java">public class Company &#123;    private String name;    public Company(String name) &#123;        this.name=name;    &#125;    public String getName() &#123;        return name;    &#125;&#125;</code></pre><p><strong>经纪人类（Agent）</strong></p><pre><code class="java">public class Agent &#123;    private Star star;    private Fans fans;    private Company company;    public void setStar(Star star) &#123;        this.star = star;    &#125;    public void setFans(Fans fans) &#123;        this.fans = fans;    &#125;    public void setCompany(Company company) &#123;        this.company = company;    &#125;    public void meeting() &#123;        System.out.println(fans.getName() + &quot;与明星&quot; + star.getName() + &quot;见面了。&quot;);    &#125;    public void business() &#123;        System.out.println(company.getName() + &quot;与明星&quot; + star.getName() + &quot;洽淡业务。&quot;);    &#125;&#125;</code></pre><h2 id="合成复用原则"><a href="#合成复用原则" class="headerlink" title="合成复用原则"></a>合成复用原则</h2><p>合成复用原则是指：尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。</p><p>通常类的复用分为继承复用和合成复用两种。</p><p>继承复用虽然有简单和易实现的优点，但它也存在以下缺点：</p><ol><li>继承复用破坏了类的封装性。因为继承会将父类的实现细节暴露给子类，父类对子类是透明的，所以这种复用又称为“白箱”复用。</li><li>子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这不利于类的扩展与维护。</li><li>它限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，所以在运行时不可能发生变化。</li></ol><p>采用组合或聚合复用时，可以将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能，它有以下优点：</p><ol><li>它维持了类的封装性。因为成分对象的内部细节是新对象看不见的，所以这种复用又称为“黑箱”复用。</li><li>对象间的耦合度低。可以在类的成员位置声明抽象。</li><li>复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成分对象类型相同的对象。</li></ol><p>下面看一个例子来理解合成复用原则</p><p>【例】汽车分类管理程序</p><p>汽车按“动力源”划分可分为汽油汽车、电动汽车等；按“颜色”划分可分为白色汽车、黑色汽车和红色汽车等。如果同时考虑这两种分类，其组合就很多。类图如下： </p><img src="../imgs/blog25/%E5%90%88%E6%88%90%E5%A4%8D%E7%94%A8%E5%8E%9F%E5%88%99.png" alt="image-20191229173554296" style="zoom:80%;" /><p>从上面类图我们可以看到使用继承复用产生了很多子类，如果现在又有新的动力源或者新的颜色的话，就需要再定义新的类。我们试着将继承复用改为聚合复用看一下。</p><img src="../imgs/blog25/%E5%90%88%E6%88%90%E5%A4%8D%E7%94%A8%E5%8E%9F%E5%88%991.png" alt="image-20191229173554296" style="zoom:80%;" />]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>类及类关系的表示方法</title>
      <link href="/2023/06/25/blog24/"/>
      <url>/2023/06/25/blog24/</url>
      
        <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>统一建模语言（Unified Modeling Language，UML）是用来设计软件的可视化建模语言。它的特点是简单、统一、图形化、能表达软件设计中的动态与静态信息。</p><p>UML 从目标系统的不同角度出发，定义了用例图、类图、对象图、状态图、活动图、时序图、协作图、构件图、部署图等 9 种图。</p><h2 id="类图概述"><a href="#类图概述" class="headerlink" title="类图概述"></a>类图概述</h2><p>类图(Class diagram)是显示了模型的静态结构，特别是模型中存在的类、类的内部结构以及它们与其他类的关系等。类图不显示暂时性的信息。类图是面向对象建模的主要组成部分。</p><h2 id="类图的作用"><a href="#类图的作用" class="headerlink" title="类图的作用"></a>类图的作用</h2><ul><li>在软件工程中，类图是一种静态的结构图，描述了系统的类的集合，类的属性和类之间的关系，可以简化了人们对系统的理解；</li><li>类图是系统分析和设计阶段的重要产物，是系统编码和测试的重要模型。</li></ul><h2 id="类图表示法"><a href="#类图表示法" class="headerlink" title="类图表示法"></a>类图表示法</h2><h3 id="类的表示方式"><a href="#类的表示方式" class="headerlink" title="类的表示方式"></a>类的表示方式</h3><p>在UML类图中，类使用包含类名、属性(field) 和方法(method) 且带有分割线的矩形来表示，比如下图表示一个Employee类，它包含name,age和address这3个属性，以及work()方法。 </p><p><img src="/../imgs/blog24/Employee.jpg"></p><p>属性&#x2F;方法名称前加的加号和减号表示了这个属性&#x2F;方法的可见性，UML类图中表示可见性的符号有三种：</p><ul><li><p>+：表示public</p></li><li><p>-：表示private</p></li><li><p>#：表示protected</p></li></ul><p>属性的完整表示方式是： <strong>可见性  名称 ：类型 [ &#x3D; 缺省值]</strong>  </p><p>方法的完整表示方式是： <strong>可见性  名称(参数列表) [ ： 返回类型]</strong></p><blockquote><p>注意：</p><p>​1，中括号中的内容表示是可选的</p><p>​2，也有将类型放在变量名前面，返回值类型放在方法名前面</p></blockquote><p><strong>举个栗子：</strong></p><p><img src="/../imgs/blog24/demo.png"></p><p>上图Demo类定义了三个方法：</p><ul><li>method()方法：修饰符为public，没有参数，没有返回值。</li><li>method1()方法：修饰符为private，没有参数，返回值类型为String。</li><li>method2()方法：修饰符为protected，接收两个参数，第一个参数类型为int，第二个参数类型为String，返回值类型是int。</li></ul><h3 id="类与类之间关系的表示方式"><a href="#类与类之间关系的表示方式" class="headerlink" title="类与类之间关系的表示方式"></a>类与类之间关系的表示方式</h3><h4 id="关联关系"><a href="#关联关系" class="headerlink" title="关联关系"></a>关联关系</h4><p>关联关系是对象之间的一种引用关系，用于表示一类对象与另一类对象之间的联系，如老师和学生、师傅和徒弟、丈夫和妻子等。关联关系是类与类之间最常用的一种关系，分为一般关联关系、聚合关系和组合关系。我们先介绍一般关联。</p><p>关联又可以分为单向关联，双向关联，自关联。</p><p><strong>1，单向关联</strong></p><p><img src="/../imgs/blog24/customer_address.png"></p><p>在UML类图中单向关联用一个带箭头的实线表示。上图表示每个顾客都有一个地址，这通过让Customer类持有一个类型为Address的成员变量类实现。</p><p><strong>2，双向关联</strong></p><p><img src="/../imgs/blog24/customer_product.png"></p><p>从上图中我们很容易看出，所谓的双向关联就是双方各自持有对方类型的成员变量。</p><p>在UML类图中，双向关联用一个不带箭头的直线表示。上图中在Customer类中维护一个List&lt;Product&gt;，表示一个顾客可以购买多个商品；在Product类中维护一个Customer类型的成员变量表示这个产品被哪个顾客所购买。</p><p><strong>3，自关联</strong></p><p><img src="/../imgs/blog24/node.png"></p><p>自关联在UML类图中用一个带有箭头且指向自身的线表示。上图的意思就是Node类包含类型为Node的成员变量，也就是“自己包含自己”。</p><h4 id="聚合关系"><a href="#聚合关系" class="headerlink" title="聚合关系"></a>聚合关系</h4><p>聚合关系是关联关系的一种，是强关联关系，是整体和部分之间的关系。</p><p>聚合关系也是通过成员对象来实现的，其中成员对象是整体对象的一部分，但是成员对象可以脱离整体对象而独立存在。例如，学校与老师的关系，学校包含老师，但如果学校停办了，老师依然存在。</p><p>在 UML 类图中，聚合关系可以用带空心菱形的实线来表示，菱形指向整体。下图所示是大学和教师的关系图：</p><p><img src="/../imgs/blog24/image-20191229173422328.png"></p><h4 id="组合关系"><a href="#组合关系" class="headerlink" title="组合关系"></a>组合关系</h4><p>组合表示类之间的整体与部分的关系，但它是一种更强烈的聚合关系。</p><p>在组合关系中，整体对象可以控制部分对象的生命周期，一旦整体对象不存在，部分对象也将不存在，部分对象不能脱离整体对象而存在。例如，头和嘴的关系，没有了头，嘴也就不存在了。</p><p>在 UML 类图中，组合关系用带实心菱形的实线来表示，菱形指向整体。下图所示是头和嘴的关系图：</p><p><img src="/../imgs/blog24/image-20191229173455149.png"></p><h4 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h4><p>依赖关系是一种使用关系，它是对象之间耦合度最弱的一种关联方式，是临时性的关联。在代码中，某个类的方法通过局部变量、方法的参数或者对静态方法的调用来访问另一个类（被依赖类）中的某些方法来完成一些职责。</p><p>在 UML 类图中，依赖关系使用带箭头的虚线来表示，箭头从使用类指向被依赖的类。下图所示是司机和汽车的关系图，司机驾驶汽车：</p><p><img src="/../imgs/blog24/image-20191229173518926.png"></p><h4 id="继承关系"><a href="#继承关系" class="headerlink" title="继承关系"></a>继承关系</h4><p>继承关系是对象之间耦合度最大的一种关系，表示一般与特殊的关系，是父类与子类之间的关系，是一种继承关系。</p><p>在 UML 类图中，泛化关系用带空心三角箭头的实线来表示，箭头从子类指向父类。在代码实现时，使用面向对象的继承机制来实现泛化关系。例如，Student 类和 Teacher 类都是 Person 类的子类，其类图如下图所示：</p><p><img src="/../imgs/blog24/image-20191229173539838.png"></p><h4 id="实现关系"><a href="#实现关系" class="headerlink" title="实现关系"></a>实现关系</h4><p>实现关系是接口与实现类之间的关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的所有的抽象操作。</p><p>在 UML 类图中，实现关系使用带空心三角箭头的虚线来表示，箭头从实现类指向接口。例如，汽车和船实现了交通工具，其类图如图 9 所示。</p><p><img src="/../imgs/blog24/image-20191229173554296.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Paxos协议和Raft协议</title>
      <link href="/2023/06/24/blog23/"/>
      <url>/2023/06/24/blog23/</url>
      
        <content type="html"><![CDATA[<h1 id="Paxos协议"><a href="#Paxos协议" class="headerlink" title="Paxos协议"></a>Paxos协议</h1><p>Paxos协议是一种用于分布式系统中实现一致性的共识算法。它由Leslie Lamport于1990年提出，是目前广泛应用于分布式计算领域的重要算法之一。</p><p>Paxos协议解决了分布式系统中的一致性问题，即在面对节点故障、网络延迟和消息丢失等情况下，如何确保节点达成一致的共识。</p><p>Paxos协议的核心思想是基于一个提议（proposal）的方式进行节点之间的通信和协商。协议中的参与者分为提议者（proposer）和接受者（acceptor）。节点通过提议者向接受者发出提案，并经过多轮的消息交互来达成一致。</p><p>Paxos协议的主要过程可以简要概括如下：</p><ol><li><p>提案阶段（Prepare Phase）：提议者向接受者发送一个编号为N的提案请求，要求接受者不再接受编号小于N的提案。</p></li><li><p>接受阶段（Accept Phase）：如果接受者接收到了编号为N的提案请求，并且当前没有接受过更大编号的提案，那么它会接受该提案。</p></li><li><p>学习阶段（Learn Phase）：一旦一个提案被大多数节点接受，它就被确定下来，并可以在系统中进行执行。</p></li></ol><p>Paxos协议通过多轮的消息交互来保证节点之间达成共识，即使在网络不可靠或存在故障的情况下，也能够保证系统的一致性。它具有较强的容错性和扩展性，可以应对分布式系统中各种复杂的情况。</p><p>需要注意的是，Paxos协议的设计相对复杂，其原始的描述较为晦涩难懂。为了降低使用难度，实际应用中通常会基于Paxos协议进行一些改进和优化，如Multi-Paxos和Fast Paxos等变种协议。</p><p>总的来说，Paxos协议是一种用于分布式一致性的共识算法，通过提案的方式进行节点间的协商和通信，以达成共识。它在分布式计算领域具有广泛的应用，并为构建高可用性和容错性的分布式系统提供了基础。</p><h1 id="Raft协议"><a href="#Raft协议" class="headerlink" title="Raft协议"></a>Raft协议</h1><p>Raft协议是一种用于实现分布式一致性的共识算法。它是由Diego Ongaro和John Ousterhout于2013年提出的，旨在解决分布式系统中的一致性问题。</p><p>在分布式系统中，多台计算机节点通过互联网络进行通信和协作，但由于网络延迟、节点故障等原因，节点之间的数据一致性可能会受到影响。共识算法的目标是确保在面对这些问题时，系统仍然能够保持一致性。</p><p>Raft协议将分布式系统中的节点分为领导者（leader）、跟随者（follower）和候选人（candidate）。节点之间通过选举产生一个领导者，领导者负责接收客户端的请求并复制日志到其他节点，以确保数据的一致性。跟随者和候选人则遵循领导者的指令执行操作。</p><p>Raft协议的核心思想是使用领导者来统一管理日志的复制和提交。当一个节点成为领导者后，它会定期向其他节点发送心跳信号以维持其领导地位。如果其他节点在一段时间内没有接收到领导者的心跳信号，它们将开始进行选举，尝试成为新的领导者。</p><p>Raft协议通过引入选举超时（election timeout）和随机化来解决分区（网络延迟导致节点无法通信）和脑裂（多个节点同时认为自己是领导者）等问题。它提供了一种相对简单且易于理解的机制，用于实现分布式系统中的一致性和高可用性。</p><p>总的来说，Raft协议是一种用于分布式一致性的共识算法，通过选举领导者和复制日志的方式确保分布式系统的一致性。它被广泛应用于各种分布式系统，如分布式数据库、分布式存储系统和分布式共享日志系统等。</p><h1 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h1><p>Raft协议和Paxos协议都是用于实现分布式一致性的共识算法，但它们在设计和实现上存在一些区别。以下是Raft和Paxos的一些对比：</p><ol><li><p>可理解性和可读性：</p><ul><li>Raft协议相对于Paxos协议来说更容易理解和阅读。Raft采用了领导者-跟随者模型，将系统的状态分为三个角色，即领导者、跟随者和候选人，从而使整个协议的行为更加直观可见。</li><li>Paxos协议相对复杂，原始的描述较为晦涩难懂，需要更多的阅读和解读。</li></ul></li><li><p>选主过程：</p><ul><li>Raft协议的选主过程相对简单明确。当领导者出现故障或者网络分区时，Raft通过选举超时和随机化的机制来实现新的领导者选举。选举过程在Raft中更加可控和容易理解。</li><li>Paxos协议的选主过程相对复杂，需要多轮的消息交互和协商。Paxos的选举过程更加隐式和间接。</li></ul></li><li><p>一致性层次：</p><ul><li>Raft协议将一致性问题划分为多个层次，并对每个层次提供了明确的解决方案。例如，Raft中的日志复制和提交是通过领导者进行的，而跟随者和候选人则遵循领导者的指令执行操作。</li><li>Paxos协议将一致性问题整体看待，没有像Raft那样进行明确的层次划分。Paxos更专注于提案和接受阶段，需要更多的消息交互来达成共识。</li></ul></li><li><p>可扩展性：</p><ul><li>Raft协议相对容易实现可扩展性。由于领导者负责接收客户端请求和复制日志，可以通过增加更多的领导者来提高系统的吞吐量。</li><li>Paxos协议在原始形式下的可扩展性较差。由于需要多轮消息交互和复杂的协商过程，扩展性的实现比较困难。但是，有一些基于Paxos的变种协议（如Multi-Paxos）对可扩展性进行了改进。</li></ul></li></ol><p>总体而言，Raft和Paxos是两种广泛应用的共识算法，它们都在分布式系统中起到了确保一致性的重要作用。Raft协议更容易理解和实现，适合于初学者和构建可维护</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务</title>
      <link href="/2023/06/21/blog22/"/>
      <url>/2023/06/21/blog22/</url>
      
        <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="1-基础概念"><a href="#1-基础概念" class="headerlink" title="1 基础概念"></a>1 基础概念</h1><h2 id="1-1-什么是事务"><a href="#1-1-什么是事务" class="headerlink" title="1.1 什么是事务"></a>1.1 什么是事务</h2><blockquote><p>什么是事务？举个生活中的例子：你去小卖铺买东西，“一手交钱，一手交货”就是一个事务的例子，交钱和交货必 须全部成功，事务才算成功，任一个活动失败，事务将撤销所有已成功的活动。 明白上述例子，再来看事务的定义：</p></blockquote><blockquote><p><strong>事务可以看做是一次大的活动，它由不同的小活动组成，这些活动要么全部成功，要么全部失败。</strong></p></blockquote><h2 id="1-2-本地事务"><a href="#1-2-本地事务" class="headerlink" title="1.2 本地事务"></a>1.2 本地事务</h2><blockquote><p>在计算机系统中，更多的是通过关系型数据库来控制事务，这是利用数据库本身的事务特性来实现的，因此叫数据 库事务，由于应用主要靠关系数据库来控制事务，而数据库通常和应用在同一个服务器，所以基于关系型数据库的 事务又被称为本地事务。</p></blockquote><blockquote><p>回顾一下数据库事务的四大特性 ACID：</p></blockquote><blockquote><ul><li>A（Atomic）：原子性，构成事务的所有操作，要么都执行完成，要么全部不执行，不可能出现部分成功部分失 败的情况。</li><li>C（Consistency）：一致性，在事务执行前后，数据库的一致性约束没有被破坏。比如：张三向李四转100元， 转账前和转账后的数据是正确状态这叫一致性，如果出现张三转出100元，李四账户没有增加100元这就出现了数 据错误，就没有达到一致性。</li><li>I（Isolation）：隔离性，数据库中的事务一般都是并发的，隔离性是指并发的两个事务的执行互不干扰，一个事 务不能看到其他事务运行过程的中间状态。通过配置事务隔离级别可以避脏读、重复读等问题。</li><li>D（Durability）：持久性，事务完成之后，该事务对数据的更改会被持久化到数据库，且不会被回滚。 <strong>数据库事务在实现时会将一次事务涉及的所有操作全部纳入到一个不可分割的执行单元，该执行单元中的所有操作 要么都成功，要么都失败，只要其中任一操作执行失败，都将导致整个事务的回滚</strong></li></ul></blockquote><h2 id="1-3-分布式事务"><a href="#1-3-分布式事务" class="headerlink" title="1.3 分布式事务"></a>1.3 分布式事务</h2><blockquote><p>随着互联网的快速发展，软件系统由原来的单体应用转变为分布式应用，下图描述了单体应 +用向微服务的演变：分布式系统会把一个应用系统拆分为可独立部署的多个服务，因此需要服务与服务之间远程协作才能完成事务操 作，这种分布式系统环境下由不同的服务之间通过网络远程协作完成事务称之为<strong>分布式事务</strong>，例如用户注册送积分 事务、创建订单减库存事务，银行转账事务等都是分布式事务。 <img src="/../imgs/blog22/16ea737e92d684adtplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p></blockquote><blockquote><p>我们知道本地事务依赖数据库本身提供的事务特性来实现，因此以下逻辑可以控制本地事务：</p></blockquote><pre><code class="arduino">arduino复制代码begin transaction； //1.本地数据库操作：张三减少金额 //2.本地数据库操作：李四增加金额 commit transation;</code></pre><blockquote><p>但是在分布式环境下，会变成下边这样：</p></blockquote><pre><code class="arduino">arduino复制代码begin transaction； //1.本地数据库操作：张三减少金额  //2.远程调用：让李四增加金额   commit transation;</code></pre><blockquote><p>可以设想，当远程调用让李四增加金额成功了，由于网络问题远程调用并没有返回，此时本地事务提交失败就回滚 了张三减少金额的操作，此时张三和李四的数据就不一致了。 因此在分布式架构的基础上，传统数据库事务就无法使用了，张三和李四的账户不在一个数据库中甚至不在一个应 用系统里，实现转账事务需要通过远程调用，由于网络问题就会导致分布式事务问题。</p></blockquote><h2 id="1-4-分布式事务的产生场景"><a href="#1-4-分布式事务的产生场景" class="headerlink" title="1.4 分布式事务的产生场景"></a>1.4 分布式事务的产生场景</h2><blockquote><ol><li>典型的场景就是微服务架构 微服务之间通过远程调用完成事务操作。 比如：订单微服务和库存微服务，下单的 同时订单微服务请求库存微服务减库存。 简言之：跨JVM进程产生分布式事务。 <img src="/../imgs/blog22/16ea737fe14e1525tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></li></ol></blockquote><blockquote><p>2.单体系统访问多个数据库实例 当单体系统需要访问多个数据库（实例）时就会产生分布式事务。 比如：用户信 息和订单信息分别在两个MySQL实例存储，用户管理系统删除用户信息，需要分别删除用户信息及用户的订单信 息，由于数据分布在不同的数据实例，需要通过不同的数据库链接去操作数据，此时产生分布式事务。 简言之：跨 数据库实例产生分布式事务。 <img src="/../imgs/blog22/16ea7381f6620be7tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p></blockquote><blockquote><p>3.多服务访问同一个数据库实例 比如：订单微服务和库存微服务即使访问同一个数据库也会产生分布式事务，原 因就是跨JVM进程，两个微服务持有了不同的数据库链接进行数据库操作，此时产生分布式事务。 <img src="/../imgs/blog22/16ea73838a825a3dtplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p></blockquote><h1 id="2-分布式事务的基本理论"><a href="#2-分布式事务的基本理论" class="headerlink" title="2 分布式事务的基本理论"></a>2 分布式事务的基本理论</h1><blockquote><p>我们了解到了分布式事务的基础概念。与本地事务不同的是，分布式系统之所以叫分布式，是因 为提供服务的各个节点分布在不同机器上，相互之间通过网络交互。不能因为有一点网络问题就导致整个系统无法 提供服务，网络因素成为了分布式事务的考量标准之一。因此，分布式事务需要更进一步的理论支持，接下来，我 们先来学习一下分布式事务的CAP理论。</p></blockquote><h2 id="2-1-CAP理论"><a href="#2-1-CAP理论" class="headerlink" title="2.1 CAP理论"></a>2.1 CAP理论</h2><blockquote><p>CAP是 <strong>Consistency</strong>、<strong>Availability</strong>、<strong>Partition tolerance</strong>三个词语的缩写，分别表示一致性、可用性、分区容忍 性。 下边我们分别来解释：</p></blockquote><blockquote><p>为了方便对CAP理论的理解，我们结合电商系统中的一些业务场景来理解CAP。</p></blockquote><blockquote><p>如下图，是商品信息管理的执行流程： <img src="/../imgs/blog22/16ea7384f6bcce72tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p></blockquote><blockquote><p>整体执行流程如下：</p></blockquote><pre><code>复制代码1、商品服务请求主数据库写入商品信息（添加商品、修改商品、删除商品）2、主数据库向商品服务响应写入成功。3、商品服务请求从数据库读取商品信息。</code></pre><blockquote><p><strong>C - Consistency：</strong></p></blockquote><blockquote><p>一致性是指写操作后的读操作可以读取到最新的数据状态，当数据分布在多个节点上，从任意结点读取到的数据都 是最新的状态</p></blockquote><blockquote><p>上图中，商品信息的读写要满足一致性就是要实现如下目标：</p></blockquote><pre><code>复制代码1、商品服务写入主数据库成功，则向从数据库查询新数据也成功。 2、商品服务写入主数据库失败，则向从数据库查询新数据也失败。 </code></pre><blockquote><p>如何实现一致性？</p></blockquote><pre><code>复制代码1、写入主数据库后要将数据同步到从数据库。 2、写入主数据库后，在向从数据库同步期间要将从数据库锁定，待同步完成后再释放锁，以免在新数据写入成功 后，向从数据库查询到旧的数据。</code></pre><blockquote><p>分布式系统一致性的特点：</p></blockquote><pre><code>复制代码1、由于存在数据同步的过程，写操作的响应会有一定的延迟。 2、为了保证数据一致性会对资源暂时锁定，待数据同步完成释放锁定资源。 3、如果请求数据同步失败的结点则会返回错误信息，一定不会返回旧数据。</code></pre><blockquote><p><strong>A - Availability ：</strong></p></blockquote><blockquote><p>可用性是指任何事务操作都可以得到响应结果，且不会出现响应超时或响应错误。 上图中，商品信息读取满足可用性就是要实现如下目标</p></blockquote><pre><code>复制代码1、从数据库接收到数据查询的请求则立即能够响应数据查询结果。 2、从数据库不允许出现响应超时或响应错误。</code></pre><blockquote><p>如何实现可用性？</p></blockquote><pre><code>复制代码1、写入主数据库后要将数据同步到从数据库。2、由于要保证从数据库的可用性，不可将从数据库中的资源进行锁定。3、即时数据还没有同步过来，从数据库也要返回要查询的数据，哪怕是旧数据，如果连旧数据也没有则可以按照 约定返回一个默认信息，但不能返回错误或响应超时。</code></pre><blockquote><p>分布式系统可用性的特点：</p></blockquote><pre><code>复制代码1、 所有请求都有响应，且不会出现响应超时或响应错误。</code></pre><blockquote><p><strong>P - Partition tolerance ：</strong></p></blockquote><blockquote><p>通常分布式系统的各各结点部署在不同的子网，这就是网络分区，不可避免的会出现由于网络问题而导致结点之间 通信失败，此时仍可对外提供服务，这叫分区容忍性。</p></blockquote><blockquote><p>上图中，商品信息读写满足分区容忍性就是要实现如下目标：</p></blockquote><pre><code>复制代码1、主数据库向从数据库同步数据失败不影响读写操作。 2、其一个结点挂掉不影响另一个结点对外提供服务。</code></pre><blockquote><p>如何实现分区容忍性？</p></blockquote><pre><code>复制代码1、尽量使用异步取代同步操作，例如使用异步方式将数据从主数据库同步到从数据，这样结点之间能有效的实现 松耦合。 2、添加从数据库结点，其中一个从结点挂掉其它从结点提供服务。</code></pre><blockquote><p>分布式分区容忍性的特点：</p></blockquote><pre><code>复制代码1、分区容忍性分是布式系统具备的基本能力。</code></pre><h3 id="2-1-2-CAP组合方式"><a href="#2-1-2-CAP组合方式" class="headerlink" title="2.1.2 CAP组合方式"></a>2.1.2 CAP组合方式</h3><blockquote><p>1、上边商品管理的例子是否同时具备 CAP呢？</p></blockquote><blockquote><p><strong>在所有分布式事务场景中不会同时具备CAP三个特性，因为在具备了P的前提下C和A是不能共存的</strong></p></blockquote><blockquote><p>比如： 下图满足了P即表示实现分区容忍： <img src="/../imgs/blog22/16ea7385d827d99ftplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p></blockquote><blockquote><p>本图分区容忍的含义是：</p></blockquote><pre><code>复制代码1）主数据库通过网络向从数据同步数据，可以认为主从数据库部署在不同的分区，通过网络进行交互。 2）当主数据库和从数据库之间的网络出现问题不影响主数据库和从数据库对外提供服务。 3）其一个结点挂掉不影响另一个结点对外提供服务。</code></pre><blockquote><p>如果要实现C则必须保证数据一致性，在数据同步的时候为防止向从数据库查询不一致的数据则需要将从数据库数 据锁定，待同步完成后解锁，如果同步失败从数据库要返回错误信息或超时信息。</p></blockquote><blockquote><p>如果要实现A则必须保证数据可用性，不管任何时候都可以向从数据查询数据，则不会响应超时或返回错误信息。</p></blockquote><blockquote><p>通过分析发现在满足P的前提下C和A存在矛盾性。</p></blockquote><blockquote><p>2、CAP有哪些组合方式呢？</p></blockquote><blockquote><p>所以在生产中对分布式事务处理时要根据需求来确定满足CAP的哪两个方面。</p></blockquote><blockquote><p>1）AP：放弃一致性，追求分区容忍性和可用性。这是很多分布式系统设计时的选择</p></blockquote><blockquote><p>例如： 上边的商品管理，完全可以实现AP，前提是只要用户可以接受所查询的到数据在一定时间内不是最新的即可。 通常实现AP都会保证最终一致性，后面讲的BASE理论就是根据AP来扩展的，一些业务场景 比如：订单退款，今 日退款成功，明日账户到账，只要用户可以接受在一定时间内到账即可。</p></blockquote><blockquote><p>2）CP：</p></blockquote><blockquote><p>放弃可用性，追求一致性和分区容错性，我们的zookeeper其实就是追求的强一致，又比如跨行转账，一次转账请 求要等待双方银行系统都完成整个事务才算完成。</p></blockquote><blockquote><p>3）CA：</p></blockquote><blockquote><p>放弃分区容忍性，即不进行分区，不考虑由于网络不通或结点挂掉的问题，则可以实现一致性和可用性。那么系统 将不是一个标准的分布式系统，我们最常用的关系型数据就满足了CA。</p></blockquote><blockquote><p>上边的商品管理，如果要实现CA则架构如下：</p></blockquote><p><img src="/../imgs/blog22/16f63c929af065b7tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>主数据库和从数据库中间不再进行数据同步，数据库可以响应每次的查询请求，通过事务隔离级别实现每个查询请 求都可以返回最新的数据。</p></blockquote><h3 id="2-1-3-总结"><a href="#2-1-3-总结" class="headerlink" title="2.1.3 总结"></a>2.1.3 总结</h3><blockquote><p>通过上面我们已经学习了CAP理论的相关知识，CAP是一个已经被证实的理论：一个分布式系统最多只能同时满足 一致性（Consistency）、可用性（Availability）和分区容忍性（Partition tolerance）这三项中的两项。它可以作 为我们进行架构设计、技术选型的考量标准。对于多数大型互联网应用的场景，结点众多、部署分散，而且现在的 集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9（99.99..%），并要达到良 好的响应性能来提高用户体验，因此一般都会做出如下选择：保证P和A，舍弃C强一致，保证最终一致性。</p></blockquote><h2 id="2-2-BASE理论"><a href="#2-2-BASE理论" class="headerlink" title="2.2 BASE理论"></a>2.2 BASE理论</h2><blockquote><p>1、理解强一致性和最终一致性</p></blockquote><blockquote><p>CAP理论告诉我们一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容忍 性（Partition tolerance）这三项中的两项，其中AP在实际应用中较多，AP即舍弃一致性，保证可用性和分区容忍 性，但是在实际生产中很多场景都要实现一致性，比如前边我们举的例子主数据库向从数据库同步数据，即使不要 一致性，但是最终也要将数据同步成功来保证数据一致，这种一致性和CAP中的一致性不同，CAP中的一致性要求 在任何时间查询每个结点数据都必须一致，它强调的是强一致性，但是最终一致性是允许可以在一段时间内每个结 点的数据不一致，但是经过一段时间每个结点的数据必须一致，它强调的是最终数据的一致性。</p></blockquote><blockquote><p>2、Base理论介绍</p></blockquote><blockquote><p>BASE 是 Basically Available(基本可用)、Soft state(软状态)和 Eventually consistent (最终一致性)三个短语的缩 写。BASE理论是对CAP中AP的一个扩展，通过牺牲强一致性来获得可用性，当出现故障允许部分不可用但要保证 核心功能可用，允许数据在一段时间内是不一致的，但最终达到一致状态。满足BASE理论的事务，我们称之为 <strong>“柔性事务”</strong>。</p></blockquote><ul><li>基本可用:分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。如，电商网站交易付款出 现问题了，商品依然可以正常浏览。</li><li>软状态:由于不要求强一致性，所以BASE允许系统中存在中间状态（也叫软状态），这个状态不影响系统可用 性，如订单的”支付中”、“数据同步中”等状态，待数据最终一致后状态改为“成功”状态。</li><li>最终一致:最终一致是指经过一段时间后，所有节点数据都将会达到一致。如订单的”支付中”状态，最终会变 为“支付成功”或者”支付失败”，使订单状态与实际交易结果达成一致，但需要一定时间的延迟、等待。</li></ul><h1 id="3-分布式事务解决方案之2PC-两阶段提交"><a href="#3-分布式事务解决方案之2PC-两阶段提交" class="headerlink" title="3 分布式事务解决方案之2PC(两阶段提交)"></a>3 分布式事务解决方案之2PC(两阶段提交)</h1><h2 id="3-1-什么是2PC"><a href="#3-1-什么是2PC" class="headerlink" title="3.1 什么是2PC"></a>3.1 什么是2PC</h2><blockquote><p>2PC即两阶段提交协议，是将整个事务流程分为两个阶段，准备阶段（Prepare phase）、提交阶段（commit phase），2是指两个阶段，P是指准备阶段，C是指提交阶段。</p></blockquote><blockquote><p>举例：张三和李四好久不见，老友约起聚餐，饭店老板要求先买单，才能出票。这时张三和李四分别抱怨近况不如 意，囊中羞涩，都不愿意请客，这时只能AA。只有张三和李四都付款，老板才能出票安排就餐。但由于张三和李四 都是铁公鸡，形成了尴尬的一幕：</p></blockquote><blockquote><p>准备阶段：老板要求张三付款，张三付款。老板要求李四付款，李四付款。</p></blockquote><blockquote><p>提交阶段：老板出票，两人拿票纷纷落座就餐。</p></blockquote><blockquote><p>例子中形成了一个事务，若张三或李四其中一人拒绝付款，或钱不够，店老板都不会给出票，并且会把已收款退 回。</p></blockquote><blockquote><p>整个事务过程由事务管理器和参与者组成，店老板就是事务管理器，张三、李四就是事务参与者，事务管理器负责 决策整个分布式事务的提交和回滚，事务参与者负责自己本地事务的提交和回滚</p></blockquote><h2 id="3-2-解决方案"><a href="#3-2-解决方案" class="headerlink" title="3.2 解决方案"></a>3.2 解决方案</h2><h3 id="3-2-1-XA方案"><a href="#3-2-1-XA方案" class="headerlink" title="3.2.1 XA方案"></a>3.2.1 XA方案</h3><blockquote><p>2PC的传统方案是在数据库层面实现的，如Oracle、MySQL都支持2PC协议，为了统一标准减少行业内不必要的对 接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织Open Group定义了分布式事务处理模型 DTP（Distributed Transaction Processing Reference Model）。</p></blockquote><blockquote><p>为了让大家更明确XA方案的内容程，下面新用户注册送积分为例来说明：</p></blockquote><p><img src="/../imgs/blog22/16ea73ccd0e96780tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>执行流程如下：</p></blockquote><pre><code>复制代码  1、应用程序（AP）持有用户库和积分库两个数据源。   2、应用程序（AP）通过TM通知用户库RM新增用户，同时通知积分库RM为该用户新增积分，RM此时并未提交事 务，此时用户和积分资源锁定。   3、TM收到执行回复，只要有一方失败则分别向其他RM发起回滚事务，回滚完毕，资源锁释放。   4、TM收到执行回复，全部成功，此时向所有RM发起提交事务，提交完毕，资源锁释放。  </code></pre><blockquote><p>DTP模型定义如下角色：</p></blockquote><ul><li>AP(Application Program)：即应用程序，可以理解为使用DTP分布式事务的程序。</li><li>RM(Resource Manager)：即资源管理器，可以理解为事务的参与者，一般情况下是指一个数据库实例，通过 资源管理器对该数据库进行控制，资源管理器控制着分支事务</li><li>TM(Transaction Manager)：事务管理器，负责协调和管理事务，事务管理器控制着全局事务，管理事务生命 周期，并协调各个RM。全局事务是指分布式事务处理环境中，需要操作多个数据库共同完成一个工作，这个 工作即是一个全局事务。</li><li>DTP模型定义TM和RM之间通讯的接口规范叫XA，简单理解为数据库提供的2PC接口协议，基于数据库的XA 协议来实现2PC又称为XA方案。</li><li>以上三个角色之间的交互方式如下：<ul><li>TM向AP提供 应用程序编程接口，AP通过TM提交及回滚事务。</li><li>TM交易中间件通过XA接口来通知RM数据库事务的开始、结束以及提交、回滚等</li><li>总结：</li><li>整个2PC的事务流程涉及到三个角色AP、RM、TM。AP指的是使用2PC分布式事务的应用程序；RM指的是资 源管理器，它控制着分支事务；TM指的是事务管理器，它控制着整个全局事务。</li></ul></li></ul><blockquote><p>1）在准备阶段RM执行实际的业务操作，但不提交事务，资源锁定；</p></blockquote><blockquote><p>2）在提交阶段TM会接受RM在准备阶段的执行回复，只要有任一个RM执行失败，TM会通知所有RM执行回滚操 作，否则，TM将会通知所有RM提交该事务。提交阶段结束资源锁释放。</p></blockquote><blockquote><p>XA方案的问题：</p></blockquote><pre><code>复制代码1、需要本地数据库支持XA协议。 2、资源锁需要等到两个阶段结束才释放，性能较差。</code></pre><h3 id="3-2-2-Seata方案"><a href="#3-2-2-Seata方案" class="headerlink" title="3.2.2 Seata方案"></a>3.2.2 Seata方案</h3><blockquote><p>Seata是由阿里中间件团队发起的开源项目 Fescar，后更名为Seata，它是一个是开源的分布式事务框架</p></blockquote><blockquote><p>传统2PC的问题在Seata中得到了解决，它通过对本地关系数据库的分支事务的协调来驱动完成全局事务，是工作 在应用层的中间件。主要优点是性能较好，且不长时间占用连接资源，它以高效并且对业务0侵入的方式解决微服 务场景下面临的分布式事务问题，它目前提供AT模式(即2PC)及TCC模式的分布式事务解决方案。</p></blockquote><blockquote><p><strong>Seata的设计思想如下</strong></p></blockquote><blockquote><p>Seata的设计目标其一是对业务无侵入，因此从业务无侵入的2PC方案着手，在传统2PC的基础上演进，并解决 2PC方案面临的问题。</p></blockquote><blockquote><p>Seata把一个分布式事务理解成一个包含了若干分支事务的全局事务。全局事务的职责是协调其下管辖的分支事务 达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个关系数据库的本地事务，下 图是全局事务与分支事务的关系图：</p></blockquote><p><img src="/../imgs/blog22/16ea73d5a91433a5tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>与 传统2PC 的模型类似，Seata定义了3个组件来协议分布式事务的处理过程：</p></blockquote><p><img src="/../imgs/blog22/16ea73d8f1415353tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><ol><li>Transaction Coordinator (TC)： 事务协调器，它是独立的中间件，需要独立部署运行，它维护全局事务的运 行状态，接收TM指令发起全局事务的提交与回滚，负责与RM通信协调各各分支事务的提交或回滚。</li><li>Transaction Manager (TM)： 事务管理器，TM需要嵌入应用程序中工作，它负责开启一个全局事务，并最终 向TC发起全局提交或全局回滚的指令。</li><li>Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器TC的指令，驱动分 支（本地）事务的提交和回滚。</li></ol><blockquote><p>还拿新用户注册送积分举例Seata的分布式事务过程</p></blockquote><p><img src="/../imgs/blog22/16ea73de3e956a0atplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>具体的执行流程如下：</p></blockquote><pre><code class="markdown">markdown复制代码1. 用户服务的 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的XID。 2. 用户服务的 RM 向 TC 注册 分支事务，该分支事务在用户服务执行新增用户逻辑，并将其纳入 XID 对应全局 事务的管辖。 3. 用户服务执行分支事务，向用户表插入一条记录。 4. 逻辑执行到远程调用积分服务时(XID 在微服务调用链路的上下文中传播)。积分服务的RM 向 TC 注册分支事 务，该分支事务执行增加积分的逻辑，并将其纳入 XID 对应全局事务的管辖。 5. 积分服务执行分支事务，向积分记录表插入一条记录，执行完毕后，返回用户服务。 6. 用户服务分支事务执行完毕。 7. TM 向 TC 发起针对 XID 的全局提交或回滚决议。 8. TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。</code></pre><blockquote><p>Seata实现2PC与传统2PC的差别：</p></blockquote><blockquote><p>架构层次方面，传统2PC方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身，通过 XA 协议实现，而 Seata的 RM 是以jar包的形式作为中间件层部署在应用程序这一侧的。</p></blockquote><blockquote><p>两阶段提交方面，传统2PC无论第二阶段的决议是commit还是rollback，事务性资源的锁都要保持到Phase2完成 才释放。而Seata的做法是在Phase1 就将本地事务提交，这样就可以省去Phase2持锁的时间，整体提高效率。</p></blockquote><h2 id="3-3-小结"><a href="#3-3-小结" class="headerlink" title="3.3 小结"></a>3.3 小结</h2><blockquote><p>本节讲解了传统2PC（基于数据库XA协议）和Seata实现2PC的两种2PC方案，由于Seata的0侵入性并且解决了传 统2PC长期锁资源的问题，所以推荐采用Seata实现2PC。</p></blockquote><blockquote><p>Seata实现2PC要点：</p></blockquote><pre><code class="java">java复制代码1、全局事务开始使用 @GlobalTransactional标识 。 2、每个本地事务方案仍然使用@Transactional标识。 3、每个数据都需要创建undo_log表，此表是seata保证本地事务一致性的关键</code></pre><h1 id="4-分布式事务解决方案之TCC"><a href="#4-分布式事务解决方案之TCC" class="headerlink" title="4 分布式事务解决方案之TCC"></a>4 分布式事务解决方案之TCC</h1><h2 id="4-1-什么是TCC事务"><a href="#4-1-什么是TCC事务" class="headerlink" title="4.1.什么是TCC事务"></a>4.1.什么是TCC事务</h2><blockquote><p>TCC是Try、Confirm、Cancel三个词语的缩写，TCC要求每个分支事务实现三个操作：预处理Try、确认 Confirm、撤销Cancel。Try操作做业务检查及资源预留，Confirm做业务确认操作，Cancel实现一个与Try相反的 操作即回滚操作。TM首先发起所有的分支事务的try操作，任何一个分支事务的try操作执行失败，TM将会发起所 有分支事务的Cancel操作，若try操作全部成功，TM将会发起所有分支事务的Confirm操作，其中Confirm&#x2F;Cancel 操作若执行失败，TM会进行重试。</p></blockquote><p><img src="/../imgs/blog22/16ea73e9692901b5tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><p><img src="/../imgs/blog22/16ea73eb5fde056ctplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>TCC分为三个阶段：</p></blockquote><ol><li>Try 阶段是做业务检查(一致性)及资源预留(隔离)，此阶段仅是一个初步操作，它和后续的Confirm 一起才能 真正构成一个完整的业务逻辑。</li><li>Confirm 阶段是做确认提交，Try阶段所有分支事务执行成功后开始执行 Confirm。通常情况下，采用TCC则 认为 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。若Confirm阶段真的出错了，需引 入重试机制或人工处理。</li><li>Cancel 阶段是在业务执行错误需要回滚的状态下执行分支事务的业务取消，预留资源释放。通常情况下，采 用TCC则认为Cancel阶段也是一定成功的。若Cancel阶段真的出错了，需引入重试机制或人工处理。</li><li>TM事务管理器 TM事务管理器可以实现为独立的服务，也可以让全局事务发起方充当TM的角色，TM独立出来是为了成为公 用组件，是为了考虑系统结构和软件复用</li></ol><blockquote><p>TM在发起全局事务时生成全局事务记录，全局事务ID贯穿整个分布式事务调用链条，用来记录事务上下文， 追踪和记录状态，由于Confirm 和cancel失败需进行重试，因此需要实现为幂等，幂等性是指同一个操作无论请求 多少次，其结果都相同</p></blockquote><h2 id="4-2-TCC-解决方案"><a href="#4-2-TCC-解决方案" class="headerlink" title="4.2 TCC 解决方案"></a>4.2 TCC 解决方案</h2><blockquote><p>目前市面上的TCC框架众多比如下面这几种： （以下数据采集日为2019年11月23日）</p></blockquote><table><thead><tr><th>框架名称</th><th>Gitbub地址</th><th>star数量</th></tr></thead><tbody><tr><td>tcc-transaction</td><td><a href="https://link.juejin.cn/?target=https://github.com/changmingxie/tcc-transaction">github.com&#x2F;changmingxi…</a></td><td>3850</td></tr><tr><td>Hmily</td><td><a href="https://link.juejin.cn/?target=https://github.com/yu199195/hmily">github.com&#x2F;yu199195&#x2F;hm…</a></td><td>2407</td></tr><tr><td>ByteTCC</td><td><a href="https://link.juejin.cn/?target=https://github.com/liuyangming/ByteTCC">github.com&#x2F;liuyangming…</a></td><td>1947</td></tr><tr><td>EasyTransaction</td><td><a href="https://link.juejin.cn/?target=https://github.com/QNJR-GROUP/EasyTransaction">github.com&#x2F;QNJR-GROUP&#x2F;…</a></td><td>1690</td></tr></tbody></table><blockquote><p>上面讲的Seata也支持TCC，但Seata的TCC模式对Spring Cloud并没有提供支持。我们的目标是理解TCC的原 理以及事务协调运作的过程，因此更请倾向于轻量级易于理解的框架，因此最终确定了Hmily。</p></blockquote><blockquote><p>Hmily是一个高性能分布式事务TCC开源框架。基于Java语言来开发（JDK1.8），支持Dubbo，Spring Cloud等 RPC框架进行分布式事务。它目前支持以下特性：</p></blockquote><pre><code class="diff">diff复制代码- 支持嵌套事务(Nested transaction support).- 采用disruptor框架进行事务日志的异步读写，与RPC框架的性能毫无差别- 支持SpringBoot-starter 项目启动，使用简单- RPC框架支持 : dubbo,motan,springcloud。- 本地事务存储支持 : redis,mongodb,zookeeper,file,mysql。- 事务日志序列化支持 ：java，hessian，kryo，protostuff- 采用Aspect AOP 切面思想与Spring无缝集成，天然支持集群。- RPC事务恢复，超时异常恢复等</code></pre><blockquote><p>Hmily利用AOP对参与分布式事务的本地方法与远程方法进行拦截处理，通过多方拦截，事务参与者能透明的 调用到另一方的Try、Confirm、Cancel方法；传递事务上下文；并记录事务日志，酌情进行补偿，重试等。</p></blockquote><blockquote><p>Hmily不需要事务协调服务，但需要提供一个数据库(mysql&#x2F;mongodb&#x2F;zookeeper&#x2F;redis&#x2F;file)来进行日志存 储。</p></blockquote><blockquote><p>Hmily实现的TCC服务与普通的服务一样，只需要暴露一个接口，也就是它的Try业务。Confirm&#x2F;Cancel业务 逻辑，只是因为全局事务提交&#x2F;回滚的需要才提供的，因此Confirm&#x2F;Cancel业务只需要被Hmily TCC事务框架 发现即可，不需要被调用它的其他业务服务所感知。</p></blockquote><blockquote><p>官网介绍：<a href="https://link.juejin.cn/?target=https://dromara.org/website/zh-cn/docs/hmily/index.html">dromara.org&#x2F;website&#x2F;zh-…</a></p></blockquote><blockquote><p>TCC需要注意三种异常处理分别是空回滚、幂等、悬挂</p></blockquote><blockquote><p><strong>空回滚：</strong></p></blockquote><blockquote><p>在没有调用 TCC 资源 Try 方法的情况下，调用了二阶段的 Cancel 方法，Cancel 方法需要识别出这是一个空回 滚，然后直接返回成功。</p></blockquote><blockquote><p>出现原因是当一个分支事务所在服务宕机或网络异常，分支事务调用记录为失败，这个时候其实是没有执行Try阶 段，当故障恢复后，分布式事务进行回滚则会调用二阶段的Cancel方法，从而形成空回滚。</p></blockquote><blockquote><p>解决思路是关键就是要识别出这个空回滚。思路很简单就是需要知道一阶段是否执行，如果执行了，那就是正常回 滚；如果没执行，那就是空回滚。前面已经说过TM在发起全局事务时生成全局事务记录，全局事务ID贯穿整个分 布式事务调用链条。再额外增加一张分支事务记录表，其中有全局事务 ID 和分支事务 ID，第一阶段 Try 方法里会 插入一条记录，表示一阶段执行了。Cancel 接口里读取该记录，如果该记录存在，则正常回滚；如果该记录不存 在，则是空回滚。</p></blockquote><blockquote><p><strong>幂等：</strong></p></blockquote><blockquote><p>通过前面介绍已经了解到，为了保证TCC二阶段提交重试机制不会引发数据不一致，要求 TCC 的二阶段 Try、 Confirm 和 Cancel 接口保证幂等，这样不会重复使用或者释放资源。如果幂等控制没有做好，很有可能导致数据 不一致等严重问题。</p></blockquote><blockquote><p>解决思路在上述“分支事务记录”中增加执行状态，每次执行前都查询该状态</p></blockquote><blockquote><p><strong>悬挂：</strong></p></blockquote><blockquote><p>悬挂就是对于一个分布式事务，其二阶段 Cancel 接口比 Try 接口先执行</p></blockquote><blockquote><p>出现原因是在 RPC 调用分支事务try时，先注册分支事务，再执行RPC调用，如果此时 RPC 调用的网络发生拥堵， 通常 RPC 调用是有超时时间的，RPC 超时以后，TM就会通知RM回滚该分布式事务，可能回滚完成后，RPC 请求 才到达参与者真正执行，而一个 Try 方法预留的业务资源，只有该分布式事务才能使用，该分布式事务第一阶段预 留的业务资源就再也没有人能够处理了，对于这种情况，我们就称为悬挂，即业务资源预留后没法继续处理。</p></blockquote><blockquote><p>解决思路是如果二阶段执行完成，那一阶段就不能再继续执行。在执行一阶段事务时判断在该全局事务下，“分支 事务记录”表中是否已经有二阶段事务记录，如果有则不执行Try。</p></blockquote><blockquote><p><strong>举例，场景为 A 转账 30 元给 B，A和B账户在不同的服务</strong></p></blockquote><blockquote><p>方案1：</p></blockquote><blockquote><p>账户A</p></blockquote><pre><code class="go">go复制代码    ```    try：        检查余额是否够30元         扣减30元     confirm：         空     cancel：        增加30元    ```</code></pre><blockquote><p>账户B</p></blockquote><pre><code class="go">go复制代码 ``` try：    增加30元  confirm：     空  cancel：    减少30元 ```</code></pre><blockquote><p>方案1说明：</p></blockquote><blockquote><p>1）账户A，这里的余额就是所谓的业务资源，按照前面提到的原则，在第一阶段需要检查并预留业务资源，因此， 我们在扣钱 TCC 资源的 Try 接口里先检查 A 账户余额是否足够，如果足够则扣除 30 元。 Confirm 接口表示正式 提交，由于业务资源已经在 Try 接口里扣除掉了，那么在第二阶段的 Confirm 接口里可以什么都不用做。Cancel 接口的执行表示整个事务回滚，账户A回滚则需要把 Try 接口里扣除掉的 30 元还给账户。</p></blockquote><blockquote><p>2）账号B，在第一阶段 Try 接口里实现给账户B加钱，Cancel 接口的执行表示整个事务回滚，账户B回滚则需要把 Try 接口里加的 30 元再减去。</p></blockquote><blockquote><p>方案1的问题分析：</p></blockquote><pre><code class="arduino">arduino复制代码1）如果账户A的try没有执行在cancel则就多加了30元。 2）由于try，cancel、confirm都是由单独的线程去调用，且会出现重复调用，所以都需要实现幂等。 3）账号B在try中增加30元，当try执行完成后可能会其它线程给消费了。 4）如果账户B的try没有执行在cancel则就多减了30元。</code></pre><blockquote><p>问题解决：</p></blockquote><pre><code class="arduino">arduino复制代码1）账户A的cancel方法需要判断try方法是否执行，正常执行try后方可执行cancel。 2）try，cancel、confirm方法实现幂等。 3）账号B在try方法中不允许更新账户金额，在confirm中更新账户金额。 4）账户B的cancel方法需要判断try方法是否执行，正常执行try后方可执行cancel。</code></pre><blockquote><p>优化方案：</p></blockquote><blockquote><p>账户A</p></blockquote><pre><code class="arduino">arduino复制代码    ```    try：        try幂等校验         try悬挂处理         检查余额是否够30元         扣减30元     confirm：         空     cancel：        cancel幂等校验         cancel空回滚处理         增加可用余额30元    ````</code></pre><blockquote><p>账户B</p></blockquote><pre><code class="go">go复制代码 ``` try：    空  confirm：     confirm幂等校验     正式增加30元  cancel：    空 ```</code></pre><h2 id="4-3-小结"><a href="#4-3-小结" class="headerlink" title="4.3 小结"></a>4.3 小结</h2><blockquote><p>如果拿TCC事务的处理流程与2PC两阶段提交做比较，2PC通常都是在跨库的DB层面，而TCC则在应用层面的处 理，需要通过业务逻辑来实现。这种分布式事务的实现方式的优势在于，<strong>可以让应用自己定义数据操作的粒度，使 得降低锁冲突、提高吞吐量成为可能。</strong></p></blockquote><blockquote><p>而不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现try、confirm、cancel三个操作。此 外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。</p></blockquote><h1 id="5-分布式事务解决方案之可靠消息最终一致性"><a href="#5-分布式事务解决方案之可靠消息最终一致性" class="headerlink" title="5 分布式事务解决方案之可靠消息最终一致性"></a>5 分布式事务解决方案之可靠消息最终一致性</h1><p>###5.1 什么是可靠消息最终一致性事务</p><blockquote><p>可靠消息最终一致性方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方(消息消费者)一定能 够接收消息并处理事务成功，此方案强调的是只要消息发给事务参与方最终事务要达到一致</p></blockquote><blockquote><p>此方案是利用消息中间件完成，如下图：</p></blockquote><blockquote><p>事务发起方（消息生产方）将消息发给消息中间件，事务参与方从消息中间件接收消息，事务发起方和消息中间件 之间，事务参与方（消息消费方）和消息中间件之间都是通过网络通信，由于网络通信的不确定性会导致分布式事 务问题。</p></blockquote><p><img src="/../imgs/blog22/16ea73f05cbb47dbtplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>因此可靠消息最终一致性方案要解决以下几个问题：</p></blockquote><blockquote><p>1.本地事务与消息发送的原子性问题 本地事务与消息发送的原子性问题即：事务发起方在本地事务执行成功后消息必须发出去，否则就丢弃消息。即实 现本地事务和消息发送的原子性，要么都成功，要么都失败。本地事务与消息发送的原子性问题是实现可靠消息最 终一致性方案的关键问题。</p></blockquote><blockquote><p>先来尝试下这种操作，先发送消息，再操作数据库：</p></blockquote><pre><code class="arduino">arduino复制代码begin transaction；     //1.发送MQ     //2.数据库操作 commit transation;</code></pre><blockquote><p>这种情况下无法保证数据库操作与发送消息的一致性，因为可能发送消息成功，数据库操作失败。</p></blockquote><blockquote><p>你立马想到第二种方案，先进行数据库操作，再发送消息：</p></blockquote><pre><code class="arduino">arduino复制代码begin transaction；    //1.数据库操作     //2.发送MQ commit transation;</code></pre><blockquote><p>这种情况下貌似没有问题，如果发送MQ消息失败，就会抛出异常，导致数据库事务回滚。但如果是超时异常，数 据库回滚，但MQ其实已经正常发送了，同样会导致不一致。</p></blockquote><blockquote><p>2 事务参与方接收消息的可靠性</p></blockquote><blockquote><p>事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息。</p></blockquote><blockquote><p>3 消息重复消费的问题</p></blockquote><blockquote><p>由于网络2的存在，若某一个消费节点超时但是消费成功，此时消息中间件会重复投递此消息，就导致了消息的重 复消费。</p></blockquote><blockquote><p>要解决消息重复消费的问题就要实现事务参与方的方法幂等性。</p></blockquote><h2 id="5-2-解决方案"><a href="#5-2-解决方案" class="headerlink" title="5.2 解决方案"></a>5.2 解决方案</h2><h3 id="5-2-1-本地消息表方案"><a href="#5-2-1-本地消息表方案" class="headerlink" title="5.2.1 本地消息表方案"></a>5.2.1 本地消息表方案</h3><blockquote><p>本地消息表这个方案最初是eBay提出的，此方案的核心是通过本地事务保证数据业务操作和消息的一致性，然后 通过定时任务将消息发送至消息中间件，待确认消息发送给消费方成功再将消息删除。</p></blockquote><blockquote><p>下面以注册送积分为例来说明：</p></blockquote><blockquote><p>下面以注册送积分为例来说明：</p></blockquote><blockquote><p>下例共有两个微服务交互，用户服务和积分服务，用户服务负责添加用户，积分服务负责增加积分。</p></blockquote><p><img src="/../imgs/blog22/16ea73f268c6f51ctplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>交互流程如下： <strong>1、用户注册</strong> 用户服务在本地事务新增用户和增加 ”积分消息日志“。（用户表和消息表通过本地事务保证一致） 下边是伪代码</p></blockquote><pre><code class="arduino">arduino复制代码begin transaction；     //1.新增用户     //2.存储积分消息日志 commit transation;</code></pre><blockquote><p>这种情况下，本地数据库操作与存储积分消息日志处于同一个事务中，本地数据库操作与记录消息日志操作具备原子性</p></blockquote><blockquote><p><strong>2、定时任务扫描日志</strong></p></blockquote><blockquote><p>如何保证将消息发送给消息队列呢？</p></blockquote><blockquote><p>经过第一步消息已经写到消息日志表中，可以启动独立的线程，定时对消息日志表中的消息进行扫描并发送至消息 中间件，在消息中间件反馈发送成功后删除该消息日志，否则等待定时任务下一周期重试。</p></blockquote><blockquote><p><strong>3、消费消息</strong></p></blockquote><blockquote><p>如何保证消费者一定能消费到消息呢？</p></blockquote><blockquote><p>这里可以使用MQ的ack（即消息确认）机制，消费者监听MQ，如果消费者接收到消息并且业务处理完成后向MQ 发送ack（即消息确认），此时说明消费者正常消费消息完成，MQ将不再向消费者推送消息，否则消费者会不断重 试向消费者来发送消息。</p></blockquote><blockquote><p>积分服务接收到”增加积分“消息，开始增加积分，积分增加成功后向消息中间件回应ack，否则消息中间件将重复 投递此消息。</p></blockquote><blockquote><p>由于消息会重复投递，积分服务的”增加积分“功能需要实现幂等性</p></blockquote><h3 id="5-2-2-RocketMQ事务消息方案"><a href="#5-2-2-RocketMQ事务消息方案" class="headerlink" title="5.2.2 RocketMQ事务消息方案"></a>5.2.2 RocketMQ事务消息方案</h3><blockquote><p>RocketMQ 是一个来自阿里巴巴的分布式消息中间件，于 2012 年开源，并在 2017 年正式成为 Apache 顶级项 目。据了解，包括阿里云上的消息产品以及收购的子公司在内，阿里集团的消息产品全线都运行在 RocketMQ 之 上，并且最近几年的双十一大促中，RocketMQ 都有抢眼表现。Apache RocketMQ 4.3之后的版本正式支持事务消 息，为分布式事务实现提供了便利性支持。</p></blockquote><blockquote><p>RocketMQ 事务消息设计则主要是为了解决 Producer 端的消息发送与本地事务执行的原子性问题，RocketMQ 的 设计中 broker 与 producer 端的双向通信能力，使得 broker 天生可以作为一个事务协调者存在；而 RocketMQ 本身提供的存储机制为事务消息提供了持久化能力；RocketMQ 的高可用机制以及可靠消息设计则为事务消息在系 统发生异常时依然能够保证达成事务的最终一致性。</p></blockquote><blockquote><p>在RocketMQ 4.3后实现了完整的事务消息，实际上其实是对本地消息表的一个封装，将本地消息表移动到了MQ 内部，解决 Producer 端的消息发送与本地事务执行的原子性问题。</p></blockquote><p><img src="/../imgs/blog22/16ea73f47e1296fdtplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>执行流程如下： 为方便理解我们还以注册送积分的例子来描述 整个流程。</p></blockquote><blockquote><p>Producer 即MQ发送方，本例中是用户服务，负责新增用户。MQ订阅方即消息消费方，本例中是积分服务，负责 新增积分。</p></blockquote><blockquote><p>1、Producer 发送事务消息</p></blockquote><blockquote><p>Producer （MQ发送方）发送事务消息至MQ Server，MQ Server将消息状态标记为Prepared（预备状态），注 意此时这条消息消费者（MQ订阅方）是无法消费到的。 本例中，Producer 发送 ”增加积分消息“ 到MQ Server。</p></blockquote><blockquote><p>2、MQ Server回应消息发送成功 MQ Server接收到Producer 发送给的消息则回应发送成功表示MQ已接收到消息。</p></blockquote><blockquote><p>3、Producer 执行本地事务 Producer 端执行业务代码逻辑，通过本地数据库事务控制 本例中，Producer 执行添加用户操作。</p></blockquote><blockquote><p>4、消息投递 若Producer 本地事务执行成功则自动向MQServer发送commit消息，MQ Server接收到commit消息后将”增加积 分消息“ 状态标记为可消费，此时MQ订阅方（积分服务）即正常消费消息； 若Producer 本地事务执行失败则自动向MQServer发送rollback消息，MQ Server接收到rollback消息后 将删 除”增加积分消息“ 。</p></blockquote><blockquote><p>MQ订阅方（积分服务）消费消息，消费成功则向MQ回应ack，否则将重复接收消息。这里ack默认自动回应，即 程序执行正常则自动回应ack。</p></blockquote><blockquote><p>5、事务回查 如果执行Producer端本地事务过程中，执行端挂掉，或者超时，MQ Server将会不停的询问同组的其他 Producer 来获取事务执行状态，这个过程叫事务回查。MQ Server会根据事务回查结果来决定是否投递消息。</p></blockquote><blockquote><p>以上主干流程已由RocketMQ实现，对用户侧来说，用户需要分别实现本地事务执行以及本地事务回查方法，因此 只需关注本地事务的执行状态即可。</p></blockquote><blockquote><p>RoacketMQ提供RocketMQLocalTransactionListener接口：</p></blockquote><pre><code class="java">java复制代码public interface RocketMQLocalTransactionListener &#123; /**  ‐ 发送prepare消息成功此方法被回调，该方法用于执行本地事务  ‐ @param msg 回传的消息，利用transactionId即可获取到该消息的唯一Id  ‐ @param arg 调用send方法时传递的参数，当send时候若有额外的参数可以传递到send方法中，这里能获取到  ‐ @return 返回事务状态，COMMIT：提交 ROLLBACK：回滚 UNKNOW：回调  */ RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg);  /**  ‐ @param msg 通过获取transactionId来判断这条消息的本地事务执行状态  ‐ @return 返回事务状态，COMMIT：提交 ROLLBACK：回滚 UNKNOW：回调  */ RocketMQLocalTransactionState checkLocalTransaction(Message msg); &#125;</code></pre><blockquote><p>发送事务消息：</p></blockquote><blockquote><p>以下是RocketMQ提供用于发送事务消息的API：</p></blockquote><pre><code class="ini">ini复制代码    TransactionMQProducer producer = new TransactionMQProducer(&quot;ProducerGroup&quot;);     producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);     producer.start();   //设置TransactionListener实现    producer.setTransactionListener(transactionListener）；    //发送事务消息     SendResult sendResult = producer.sendMessageInTransaction(msg, null);</code></pre><h2 id="5-3-小结"><a href="#5-3-小结" class="headerlink" title="5.3  小结"></a>5.3  小结</h2><blockquote><p>可靠消息最终一致性就是保证消息从生产方经过消息中间件传递到消费方的一致性， RocketMQ作为 消息中间件，</p></blockquote><blockquote><p>RocketMQ主要解决了两个功能：</p></blockquote><pre><code>复制代码1、本地事务与消息发送的原子性问题。 2、事务参与方接收消息的可靠性。 可靠消息最终一致性事务适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消 息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。</code></pre><h1 id="6-分布式事务解决方案之最大努力通知"><a href="#6-分布式事务解决方案之最大努力通知" class="headerlink" title="6 分布式事务解决方案之最大努力通知"></a>6 分布式事务解决方案之最大努力通知</h1><h2 id="6-1-什么是最大努力通知"><a href="#6-1-什么是最大努力通知" class="headerlink" title="6.1 什么是最大努力通知"></a>6.1 什么是最大努力通知</h2><blockquote><p>最大努力通知也是一种解决分布式事务的方案，下边是一个是充值的例子：</p></blockquote><p><img src="/../imgs/blog22/16ea73fdf5b8c8d5tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>交互流程:</p></blockquote><pre><code>复制代码1、账户系统调用充值系统接口2、充值系统完成支付处理向账户系统发起充值结果通知 若通知失败，则充值系统按策略进行重复通知3、账户系统接收到充值结果通知修改充值状态。4、账户系统未接收到通知会主动调用充值系统的接口查询充值结果</code></pre><blockquote><p>通过上边的例子我们总结最大努力通知方案的目标：</p></blockquote><blockquote><p>目标：发起通知方通过一定的机制最大努力将业务处理结果通知到接收方。</p></blockquote><blockquote><p>具体包括：</p></blockquote><pre><code>复制代码1、有一定的消息重复通知机制。 因为接收通知方可能没有接收到通知，此时要有一定的机制对消息重复通知。2、消息校对机制。 如果尽最大努力也没有通知到接收方，或者接收方消费消息后要再次消费，此时可由接收方主动向通知方查询消息 信息来满足需求。</code></pre><blockquote><p>最大努力通知与可靠消息一致性有什么不同</p></blockquote><blockquote><p>1、解决方案思想不同</p></blockquote><blockquote><p>可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发到接收通知方，消息的可靠性关键由发起通知 方来保证。</p></blockquote><blockquote><p>最大努力通知，发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是可能消息接收不到，此时需要接 收通知方主动调用发起通知方的接口查询业务处理结果，通知的可靠性关键在接收通知方</p></blockquote><blockquote><p>两者的业务应用场景不同</p></blockquote><blockquote><p>可靠消息一致性关注的是交易过程的事务一致，以异步的方式完成交易。</p></blockquote><blockquote><p>最大努力通知关注的是交易后的通知事务，即将交易结果可靠的通知出去。</p></blockquote><blockquote><p>3、技术解决方向不同 可靠消息一致性要解决消息从发出到接收的一致性，即消息发出并且被接收到。</p></blockquote><blockquote><p>最大努力通知无法保证消息从发出到接收的一致性，只提供消息接收的可靠性机制。可靠机制是，最大努力的将消 息通知给接收方，当消息无法被接收方接收时，由接收方主动查询消息（业务处理结果）。</p></blockquote><h2 id="6-2-解决方案"><a href="#6-2-解决方案" class="headerlink" title="6.2 解决方案"></a>6.2 解决方案</h2><blockquote><p>通过对最大努力通知的理解，采用MQ的ack机制就可以实现最大努力通知</p></blockquote><blockquote><p>方案1：</p></blockquote><p><img src="/../imgs/blog22/16ea74000fa1534dtplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>本方案是利用MQ的ack机制由MQ向接收通知方发送通知，流程如下：</p></blockquote><pre><code>复制代码1、发起通知方将通知发给MQ。使用普通消息机制将通知发给MQ。 注意：如果消息没有发出去可由接收通知方主动请求发起通知方查询业务执行结果。（后边会讲）2、接收通知方监听 MQ3、接收通知方接收消息，业务处理完成回应ack4、接收通知方若没有回应ack则MQ会重复通知。5、接收通知方可通过消息校对接口来校对消息的一致性。</code></pre><blockquote><p>方案2：</p></blockquote><blockquote><p>本方案也是利用MQ的ack机制，与方案1不同的是应用程序向接收通知方发送通知，如下图：</p></blockquote><p><img src="/../imgs/blog22/16ea74021054bc47tplv-t2oaga2asx-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>交互流程如下：</p></blockquote><pre><code>复制代码1、发起通知方将通知发给MQ。 使用可靠消息一致方案中的事务消息保证本地事务与消息的原子性，最终将通知先发给MQ。2、通知程序监听 MQ，接收MQ的消息。 方案1中接收通知方直接监听MQ，方案2中由通知程序监听MQ。通知程序若没有回应ack则MQ会重复通知。3、通知程序通过互联网接口协议（如http、webservice）调用接收通知方案接口，完成通知。 通知程序调用接收通知方案接口成功就表示通知成功，即消费MQ消息成功，MQ将不再向通知程序投递通知消 息。4、接收通知方可通过消息校对接口来校对消息的一致性。</code></pre><blockquote><p>方案1和方案2的不同点：</p></blockquote><blockquote><p>1、方案1中接收通知方与MQ接口，即接收通知方案监听 MQ，此方案主要应用与内部应用之间的通知。</p></blockquote><blockquote><p>2、方案2中由通知程序与MQ接口，通知程序监听MQ，收到MQ的消息后由通知程序通过互联网接口协议调用接收 通知方。此方案主要应用于外部应用之间的通知，例如支付宝、微信的支付结果通知。</p></blockquote><h1 id="7-分布式事务对比分析"><a href="#7-分布式事务对比分析" class="headerlink" title="7 分布式事务对比分析:"></a>7 分布式事务对比分析:</h1><blockquote><p>在了解各种分布式事务的解决方案后，我们了解到各种方案的优缺点：</p></blockquote><blockquote><p>2PC 最大的诟病是一个阻塞协议。RM在执行分支事务后需要等待TM的决定，此时服务会阻塞并锁定资源。由于其 阻塞机制和最差时间复杂度高， 因此，这种设计不能适应随着事务涉及的服务数量增加而扩展的需要，很难用于并 发较高以及子事务生命周期较长 (long-running transactions) 的分布式服务中。</p></blockquote><blockquote><p>如果拿TCC事务的处理流程与2PC两阶段提交做比较，2PC通常都是在跨库的DB层面，而TCC则在应用层面的处 理，需要通过业务逻辑来实现。这种分布式事务的实现方式的优势在于，可以让应用自己定义数据操作的粒度，使 得降低锁冲突、提高吞吐量成为可能。而不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现 try、confirm、cancel三个操作。此外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实 现不同的回滚策略。典型的使用场景：满，登录送优惠券等。</p></blockquote><blockquote><p>可靠消息最终一致性事务适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消 息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。典型的使用场景：注 册送积分，登录送优惠券等。</p></blockquote><blockquote><p>最大努力通知是分布式事务中要求最低的一种,适用于一些最终一致性时间敏感度低的业务；允许发起通知方处理业 务失败，在接收通知方收到通知后积极进行失败处理，无论发起通知方如何处理结果都会不影响到接收通知方的后 续处理；发起通知方需提供查询执行情况接口，用于接收通知方校对结果。典型的使用场景：银行通知、支付结果 通知等。</p></blockquote><blockquote><p>最大努力通知是分布式事务中要求最低的一种,适用于一些最终一致性时间敏感度低的业务；允许发起通知方处理业 务失败，在接收通知方收到通知后积极进行失败处理，无论发起通知方如何处理结果都会不影响到接收通知方的后 续处理；发起通知方需提供查询执行情况接口，用于接收通知方校对结果。典型的使用场景：银行通知、支付结果 通知等。</p></blockquote><table><thead><tr><th></th><th>2PC</th><th>TCC</th><th>可靠消息</th><th>最大努力通知</th></tr></thead><tbody><tr><td>一致性</td><td>强一致性</td><td>最终一致</td><td>最终一致</td><td>最终一致</td></tr><tr><td>吞吐量</td><td>低</td><td>中</td><td>高</td><td>高</td></tr><tr><td>实现复杂度</td><td>易</td><td>难</td><td>中</td><td>易</td></tr></tbody></table><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在条件允许的情况下，我们尽可能选择本地事务单数据源，因为它减少了网络交互带来的性能损耗，且避免了数据 弱一致性带来的种种问题。若某系统频繁且不合理的使用分布式事务，应首先从整体设计角度观察服务的拆分是否 合理，是否高内聚低耦合？是否粒度太小？分布式事务一直是业界难题，因为网络的不确定性，而且我们习惯于拿 分布式事务与单机事务ACID做对比。无论是数据库层的XA、还是应用层TCC、可靠消息、最大努力通知等方案，都没有完美解决分布式事务问题，它们 不过是各自在性能、一致性、可用性等方面做取舍，寻求某些场景偏好下的权衡。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式ID</title>
      <link href="/2023/06/21/blog21/"/>
      <url>/2023/06/21/blog21/</url>
      
        <content type="html"><![CDATA[<h1 id="一、为什么要用分布式ID？"><a href="#一、为什么要用分布式ID？" class="headerlink" title="一、为什么要用分布式ID？"></a>一、为什么要用分布式ID？</h1><p>在说分布式ID的具体实现之前，我们来简单分析一下为什么用分布式ID？分布式ID应该满足哪些特征？</p><h2 id="1、什么是分布式ID？"><a href="#1、什么是分布式ID？" class="headerlink" title="1、什么是分布式ID？"></a>1、什么是分布式ID？</h2><p>拿MySQL数据库举个栗子：</p><p>在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。</p><p>但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有唯一ID做标识。此时一个能够生成全局唯一ID的系统是非常必要的。那么这个全局唯一ID就叫分布式ID。</p><h2 id="2、那么分布式ID需要满足哪些条件？"><a href="#2、那么分布式ID需要满足哪些条件？" class="headerlink" title="2、那么分布式ID需要满足哪些条件？"></a>2、那么分布式ID需要满足哪些条件？</h2><ul><li>全局唯一：必须保证ID是全局性唯一的，基本要求</li><li>高性能：高可用低延时，ID生成响应要快，否则反倒会成为业务瓶颈</li><li>高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性</li><li>好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单</li><li>趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求</li></ul><h1 id="二、-分布式ID都有哪些生成方式？"><a href="#二、-分布式ID都有哪些生成方式？" class="headerlink" title="二、 分布式ID都有哪些生成方式？"></a>二、 分布式ID都有哪些生成方式？</h1><p>今天主要分析一下以下9种，分布式ID生成器方式以及优缺点：</p><ul><li>UUID</li><li>数据库自增ID</li><li>数据库多主模式</li><li>号段模式</li><li>Redis</li><li>雪花算法（SnowFlake）</li><li>滴滴出品（TinyID）</li><li>百度 （Uidgenerator）</li><li>美团（Leaf）</li></ul><p>那么它们都是如何实现？以及各自有什么优缺点？我们往下看</p><p><img src="/../imgs/blog21/8bbae35f514a48a69a1c87ac636598b8tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>以上图片源自网络，如有侵权联系删除</p></blockquote><h2 id="1、基于UUID"><a href="#1、基于UUID" class="headerlink" title="1、基于UUID"></a>1、基于UUID</h2><p>在Java的世界里，想要得到一个具有唯一性的ID，首先被想到可能就是UUID，毕竟它有着全球唯一的特性。那么UUID可以做分布式ID吗？<strong>答案是可以的，但是并不推荐！</strong></p><pre><code class="typescript">typescript复制代码public static void main(String[] args) &#123;        String uuid = UUID.randomUUID().toString().replaceAll(&quot;-&quot;,&quot;&quot;);       System.out.println(uuid); &#125;</code></pre><p>UUID的生成简单到只有一行代码，输出结果<br> c2b8c2b9e46c47e3b30dca3b0d447718，但UUID却并不适用于实际的业务需求。像用作订单号UUID这样的字符串没有丝毫的意义，看不出和订单相关的有用信息；而对于数据库来说用作业务主键ID，它不仅是太长还是字符串，存储性能差查询也很耗时，所以不推荐用作分布式ID。</p><p><strong>优点：</strong></p><ul><li>生成足够简单，本地生成无网络消耗，具有唯一性</li></ul><p><strong>缺点：</strong></p><ul><li>无序的字符串，不具备趋势自增特性</li><li>没有具体的业务含义</li><li>长度过长16 字节128位，36位长度的字符串，存储以及查询对MySQL的性能消耗较大，MySQL官方明确建议主键要尽量越短越好，作为数据库主键 UUID 的无序性会导致数据位置频繁变动，严重影响性能。</li></ul><h2 id="2、基于数据库自增ID"><a href="#2、基于数据库自增ID" class="headerlink" title="2、基于数据库自增ID"></a>2、基于数据库自增ID</h2><p>基于数据库的auto_increment自增ID完全可以充当分布式ID，具体实现：需要一个单独的MySQL实例用来生成ID，建表结构如下：</p><pre><code class="sql">sql复制代码CREATE DATABASE `SEQ_ID`;CREATE TABLE SEQID.SEQUENCE_ID (    id bigint(20) unsigned NOT NULL auto_increment,     value char(10) NOT NULL default &#39;&#39;,    PRIMARY KEY (id),) ENGINE=MyISAM;sql复制代码insert into SEQUENCE_ID(value) VALUES (&#39;values&#39;);</code></pre><p>当我们需要一个ID的时候，向表中插入一条记录返回主键ID，但这种方式有一个比较致命的缺点，访问量激增时MySQL本身就是系统的瓶颈，用它来实现分布式服务风险比较大，不推荐！</p><p><strong>优点：</strong></p><ul><li>实现简单，ID单调自增，数值类型查询速度快</li></ul><p><strong>缺点：</strong></p><ul><li>DB单点存在宕机风险，无法扛住高并发场景</li></ul><h2 id="3、基于数据库集群模式"><a href="#3、基于数据库集群模式" class="headerlink" title="3、基于数据库集群模式"></a>3、基于数据库集群模式</h2><p>前边说了单点数据库方式不可取，那对上边的方式做一些高可用优化，换成主从模式集群。害怕一个主节点挂掉没法用，那就做双主模式集群，也就是两个Mysql实例都能单独的生产自增ID。</p><p>那这样还会有个问题，两个MySQL实例的自增ID都从1开始，<strong>会生成重复的ID怎么办？</strong></p><p><strong>解决方案</strong>：设置起始值和自增步长</p><p>MySQL_1 配置：</p><pre><code class="ini">ini复制代码set @@auto_increment_offset = 1;     -- 起始值set @@auto_increment_increment = 2;  -- 步长</code></pre><p>MySQL_2 配置：</p><pre><code class="ini">ini复制代码set @@auto_increment_offset = 2;     -- 起始值set @@auto_increment_increment = 2;  -- 步长</code></pre><p>这样两个MySQL实例的自增ID分别就是：</p><blockquote><p>1、3、5、7、9<br> 2、4、6、8、10</p></blockquote><p>那如果集群后的性能还是扛不住高并发咋办？就要进行MySQL扩容增加节点，这是一个比较麻烦的事。</p><p><img src="/../imgs/blog21/0c489de746c14dffa990829522470c35tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="img"></p><p>从上图可以看出，水平扩展的数据库集群，有利于解决数据库单点压力的问题，同时为了ID生成特性，将自增步长按照机器数量来设置。</p><p>增加第三台MySQL实例需要人工修改一、二两台MySQL实例的起始值和步长，把第三台机器的ID起始生成位置设定在比现有最大自增ID的位置远一些，但必须在一、二两台MySQL实例ID还没有增长到第三台MySQL实例的起始ID值的时候，否则自增ID就要出现重复了，<strong>必要时可能还需要停机修改</strong>。</p><p><strong>优点：</strong></p><ul><li>解决DB单点问题</li></ul><p><strong>缺点：</strong></p><ul><li>不利于后续扩容，而且实际上单个数据库自身压力还是大，依旧无法满足高并发场景。</li></ul><h2 id="4、基于数据库的号段模式"><a href="#4、基于数据库的号段模式" class="headerlink" title="4、基于数据库的号段模式"></a>4、基于数据库的号段模式</h2><p>号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下：</p><pre><code class="sql">sql复制代码CREATE TABLE id_generator (  id int(10) NOT NULL,  max_id bigint(20) NOT NULL COMMENT &#39;当前最大id&#39;,  step int(20) NOT NULL COMMENT &#39;号段的布长&#39;,  biz_type    int(20) NOT NULL COMMENT &#39;业务类型&#39;,  version int(20) NOT NULL COMMENT &#39;版本号&#39;,  PRIMARY KEY (`id`)) </code></pre><p>biz_type ：代表不同业务类型</p><p>max_id ：当前最大的可用id</p><p>step ：代表号段的长度</p><p>version ：是一个乐观锁，每次都更新version，保证并发时数据的正确性</p><p><img src="/../imgs/blog21/b09bc5c2db1e43668b8aa535ca98f5b6tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="img"></p><p>等这批号段ID用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id&#x3D; max_id + step，update成功则说明新号段获取成功，新的号段范围是(max_id ,max_id +step]。</p><pre><code class="java">java复制代码update id_generator set max_id = #&#123;max_id+step&#125;, version = version + 1 where version = # &#123;version&#125; and biz_type = XXX</code></pre><p>由于多业务端可能同时操作，所以采用版本号version乐观锁方式更新，这种分布式ID生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。</p><h2 id="5、基于Redis模式"><a href="#5、基于Redis模式" class="headerlink" title="5、基于Redis模式"></a>5、基于Redis模式</h2><p>Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。</p><pre><code class="arduino">arduino复制代码127.0.0.1:6379&gt; set seq_id 1     // 初始化自增ID为1OK127.0.0.1:6379&gt; incr seq_id      // 增加1，并返回递增后的数值(integer) 2</code></pre><p>用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF</p><ul><li>RDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。</li></ul><h2 id="6、基于雪花算法（Snowflake）模式"><a href="#6、基于雪花算法（Snowflake）模式" class="headerlink" title="6、基于雪花算法（Snowflake）模式"></a>6、基于雪花算法（Snowflake）模式</h2><p>雪花算法（Snowflake）是twitter公司内部分布式项目采用的ID生成算法，开源后广受国内大厂的好评，在该算法影响下各大公司相继开发出各具特色的分布式生成器。</p><p><img src="/../imgs/blog21/a73d8d4acb5d4745b35df2696f0d6cf4tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="img"></p><blockquote><p>以上图片源自网络，如有侵权联系删除</p></blockquote><p>Snowflake生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。</p><p>Snowflake ID组成结构：正数位（占1比特）+ 时间戳（占41比特）+ 机器ID（占5比特）+ 数据中心（占5比特）+ 自增值（占12比特），总共64比特组成的一个Long类型。</p><ul><li>第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。</li><li>时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) &#x2F; (1000L 60 60 24 365) &#x3D; 69年</li><li>工作机器id（10bit）：也被叫做workId，这个可以灵活配置，机房或者机器号组合都可以。</li><li>序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID</li></ul><p>根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。</p><p><strong>Java版本的Snowflake算法实现：</strong></p><pre><code class="java">java复制代码/** * Twitter的SnowFlake算法,使用SnowFlake算法生成一个整数，然后转化为62进制变成一个短地址URL * * https://github.com/beyondfengyu/SnowFlake */public class SnowFlakeShortUrl &#123;    /**     * 起始的时间戳     */    private final static long START_TIMESTAMP = 1480166465631L;    /**     * 每一部分占用的位数     */    private final static long SEQUENCE_BIT = 12;   //序列号占用的位数    private final static long MACHINE_BIT = 5;     //机器标识占用的位数    private final static long DATA_CENTER_BIT = 5; //数据中心占用的位数    /**     * 每一部分的最大值     */    private final static long MAX_SEQUENCE = -1L ^ (-1L &lt;&lt; SEQUENCE_BIT);    private final static long MAX_MACHINE_NUM = -1L ^ (-1L &lt;&lt; MACHINE_BIT);    private final static long MAX_DATA_CENTER_NUM = -1L ^ (-1L &lt;&lt; DATA_CENTER_BIT);    /**     * 每一部分向左的位移     */    private final static long MACHINE_LEFT = SEQUENCE_BIT;    private final static long DATA_CENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT;    private final static long TIMESTAMP_LEFT = DATA_CENTER_LEFT + DATA_CENTER_BIT;    private long dataCenterId;  //数据中心    private long machineId;     //机器标识    private long sequence = 0L; //序列号    private long lastTimeStamp = -1L;  //上一次时间戳    private long getNextMill() &#123;        long mill = getNewTimeStamp();        while (mill &lt;= lastTimeStamp) &#123;            mill = getNewTimeStamp();        &#125;        return mill;    &#125;    private long getNewTimeStamp() &#123;        return System.currentTimeMillis();    &#125;    /**     * 根据指定的数据中心ID和机器标志ID生成指定的序列号     *     * @param dataCenterId 数据中心ID     * @param machineId    机器标志ID     */    public SnowFlakeShortUrl(long dataCenterId, long machineId) &#123;        if (dataCenterId &gt; MAX_DATA_CENTER_NUM || dataCenterId &lt; 0) &#123;            throw new IllegalArgumentException(&quot;DtaCenterId can&#39;t be greater than MAX_DATA_CENTER_NUM or less than 0！&quot;);        &#125;        if (machineId &gt; MAX_MACHINE_NUM || machineId &lt; 0) &#123;            throw new IllegalArgumentException(&quot;MachineId can&#39;t be greater than MAX_MACHINE_NUM or less than 0！&quot;);        &#125;        this.dataCenterId = dataCenterId;        this.machineId = machineId;    &#125;    /**     * 产生下一个ID     *     * @return     */    public synchronized long nextId() &#123;        long currTimeStamp = getNewTimeStamp();        if (currTimeStamp &lt; lastTimeStamp) &#123;            throw new RuntimeException(&quot;Clock moved backwards.  Refusing to generate id&quot;);        &#125;        if (currTimeStamp == lastTimeStamp) &#123;            //相同毫秒内，序列号自增            sequence = (sequence + 1) &amp; MAX_SEQUENCE;            //同一毫秒的序列数已经达到最大            if (sequence == 0L) &#123;                currTimeStamp = getNextMill();            &#125;        &#125; else &#123;            //不同毫秒内，序列号置为0            sequence = 0L;        &#125;        lastTimeStamp = currTimeStamp;        return (currTimeStamp - START_TIMESTAMP) &lt;&lt; TIMESTAMP_LEFT //时间戳部分                | dataCenterId &lt;&lt; DATA_CENTER_LEFT       //数据中心部分                | machineId &lt;&lt; MACHINE_LEFT             //机器标识部分                | sequence;                             //序列号部分    &#125;        public static void main(String[] args) &#123;        SnowFlakeShortUrl snowFlake = new SnowFlakeShortUrl(2, 3);        for (int i = 0; i &lt; (1 &lt;&lt; 4); i++) &#123;            //10进制            System.out.println(snowFlake.nextId());        &#125;    &#125;&#125;</code></pre><h2 id="7、百度（uid-generator）"><a href="#7、百度（uid-generator）" class="headerlink" title="7、百度（uid-generator）"></a>7、百度（uid-generator）</h2><p>uid-generator是由百度技术部开发，项目GitHub地址<br> <a href="https://link.juejin.cn/?target=https://github.com/baidu/uid-">github.com&#x2F;baidu&#x2F;uid-</a>…</p><p>uid-generator是基于Snowflake算法实现的，与原始的snowflake算法不同在于，uid-generator支持自定义时间戳、工作机器ID和 序列号 等各部分的位数，而且uid-generator中采用用户自定义workId的生成策略。</p><p>uid-generator需要与数据库配合使用，需要新增一个WORKER_NODE表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增ID就是该机器的workId数据由host，port组成。</p><p><strong>对于uid-generator ID组成结构</strong>：</p><p>workId，占用了22个bit位，时间占用了28个bit位，序列化占用了13个bit位，需要注意的是，和原始的snowflake不太一样，时间的单位是秒，而不是毫秒，workId也不一样，而且同一应用每次重启就会消费一个workId。</p><blockquote><p>参考文献</p><p><a href="https://link.juejin.cn/?target=https://github.com/baidu/uid-">github.com&#x2F;baidu&#x2F;uid-</a>…</p></blockquote><h2 id="8、美团（Leaf）"><a href="#8、美团（Leaf）" class="headerlink" title="8、美团（Leaf）"></a>8、美团（Leaf）</h2><p>Leaf由美团开发，github地址：<br> <a href="https://link.juejin.cn/?target=https://github.com/Meituan-Di">github.com&#x2F;Meituan-Di</a>…</p><p>Leaf同时支持号段模式和snowflake算法模式，可以切换使用。</p><h3 id="号段模式"><a href="#号段模式" class="headerlink" title="号段模式"></a>号段模式</h3><p>先导入源码<br> <a href="https://link.juejin.cn/?target=https://github.com/Meituan-Di">github.com&#x2F;Meituan-Di</a>… ，在建一张表leaf_alloc</p><pre><code class="sql">sql复制代码DROP TABLE IF EXISTS `leaf_alloc`;CREATE TABLE `leaf_alloc` (  `biz_tag` varchar(128)  NOT NULL DEFAULT &#39;&#39; COMMENT &#39;业务key&#39;,  `max_id` bigint(20) NOT NULL DEFAULT &#39;1&#39; COMMENT &#39;当前已经分配了的最大id&#39;,  `step` int(11) NOT NULL COMMENT &#39;初始步长，也是动态调整的最小步长&#39;,  `description` varchar(256)  DEFAULT NULL COMMENT &#39;业务key的描述&#39;,  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;数据库维护的更新时间&#39;,  PRIMARY KEY (`biz_tag`)) ENGINE=InnoDB;</code></pre><p>然后在项目中开启号段模式，配置对应的数据库信息，并关闭snowflake模式</p><pre><code class="ini">ini复制代码leaf.name=com.sankuai.leaf.opensource.testleaf.segment.enable=trueleaf.jdbc.url=jdbc:mysql://localhost:3306/leaf_test?useUnicode=true&amp;characterEncoding=utf8&amp;characterSetResults=utf8leaf.jdbc.username=rootleaf.jdbc.password=rootleaf.snowflake.enable=false#leaf.snowflake.zk.address=#leaf.snowflake.port=</code></pre><p>启动leaf-server 模块的 LeafServerApplication项目就跑起来了</p><p>号段模式获取分布式自增ID的测试url ：http：&#x2F;&#x2F;localhost：<br> 8080&#x2F;api&#x2F;segment&#x2F;get&#x2F;leaf-segment-test</p><p>监控号段模式：<br> <a href="https://link.juejin.cn/?target=http://localhost:8080/cache">http://localhost:8080/cache</a></p><h3 id="snowflake模式"><a href="#snowflake模式" class="headerlink" title="snowflake模式"></a>snowflake模式</h3><p>Leaf的snowflake模式依赖于ZooKeeper，不同于原始snowflake算法也主要是在workId的生成上，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。</p><pre><code class="ini">ini复制代码leaf.snowflake.enable=trueleaf.snowflake.zk.address=127.0.0.1leaf.snowflake.port=2181</code></pre><p>snowflake模式获取分布式自增ID的测试url：<br> <a href="https://link.juejin.cn/?target=http://localhost:8080/api/snowflake/get/test">http://localhost:8080/api/snowflake/get/test</a></p><h2 id="9、滴滴（Tinyid）"><a href="#9、滴滴（Tinyid）" class="headerlink" title="9、滴滴（Tinyid）"></a>9、滴滴（Tinyid）</h2><p>Tinyid由滴滴开发，Github地址：<br> <a href="https://link.juejin.cn/?target=https://github.com/didi/tinyid%E3%80%82">github.com&#x2F;didi&#x2F;tinyid…</a></p><p>Tinyid是基于号段模式原理实现的与Leaf如出一辙，每个服务获取一个号段（1000,2000]、（2000,3000]、（3000,4000]</p><p><img src="/../imgs/blog21/8bb13d4b66f5454f978f58e1ccb12b21tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="img"></p><p>Tinyid提供http和tinyid-client两种方式接入</p><h3 id="Http方式接入"><a href="#Http方式接入" class="headerlink" title="Http方式接入"></a>Http方式接入</h3><p>（1）导入Tinyid源码：</p><p>git clone <a href="https://link.juejin.cn/?target=https://github.com/didi/tinyi">github.com&#x2F;didi&#x2F;tinyi</a>…</p><p>（2）创建数据表：</p><pre><code class="less">less复制代码CREATE TABLE `tiny_id_info` (  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增主键&#39;,  `biz_type` varchar(63) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;业务类型，唯一&#39;,  `begin_id` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;开始id，仅记录初始值，无其他含义。初始化时begin_id和max_id应相同&#39;,  `max_id` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;当前最大id&#39;,  `step` int(11) DEFAULT &#39;0&#39; COMMENT &#39;步长&#39;,  `delta` int(11) NOT NULL DEFAULT &#39;1&#39; COMMENT &#39;每次id增量&#39;,  `remainder` int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;余数&#39;,  `create_time` timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;创建时间&#39;,  `update_time` timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;更新时间&#39;,  `version` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;版本号&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `uniq_biz_type` (`biz_type`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT &#39;id信息表&#39;;CREATE TABLE `tiny_id_token` (  `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增id&#39;,  `token` varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;token&#39;,  `biz_type` varchar(63) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;此token可访问的业务类型标识&#39;,  `remark` varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;备注&#39;,  `create_time` timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;创建时间&#39;,  `update_time` timestamp NOT NULL DEFAULT &#39;2010-01-01 00:00:00&#39; COMMENT &#39;更新时间&#39;,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT &#39;token信息表&#39;;INSERT INTO `tiny_id_info` (`id`, `biz_type`, `begin_id`, `max_id`, `step`, `delta`, `remainder`, `create_time`, `update_time`, `version`)VALUES    (1, &#39;test&#39;, 1, 1, 100000, 1, 0, &#39;2018-07-21 23:52:58&#39;, &#39;2018-07-22 23:19:27&#39;, 1);INSERT INTO `tiny_id_info` (`id`, `biz_type`, `begin_id`, `max_id`, `step`, `delta`, `remainder`, `create_time`, `update_time`, `version`)VALUES    (2, &#39;test_odd&#39;, 1, 1, 100000, 2, 1, &#39;2018-07-21 23:52:58&#39;, &#39;2018-07-23 00:39:24&#39;, 3);INSERT INTO `tiny_id_token` (`id`, `token`, `biz_type`, `remark`, `create_time`, `update_time`)VALUES    (1, &#39;0f673adf80504e2eaa552f5d791b644c&#39;, &#39;test&#39;, &#39;1&#39;, &#39;2017-12-14 16:36:46&#39;, &#39;2017-12-14 16:36:48&#39;);INSERT INTO `tiny_id_token` (`id`, `token`, `biz_type`, `remark`, `create_time`, `update_time`)VALUES    (2, &#39;0f673adf80504e2eaa552f5d791b644c&#39;, &#39;test_odd&#39;, &#39;1&#39;, &#39;2017-12-14 16:36:46&#39;, &#39;2017-12-14 16:36:48&#39;);</code></pre><p>（3）配置数据库：</p><pre><code class="ini">ini复制代码datasource.tinyid.names=primarydatasource.tinyid.primary.driver-class-name=com.mysql.jdbc.Driverdatasource.tinyid.primary.url=jdbc:mysql://ip:port/databaseName?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=UTF-8datasource.tinyid.primary.username=rootdatasource.tinyid.primary.password=123456</code></pre><p>（4）启动tinyid-server后测试</p><pre><code class="makefile">makefile复制代码获取分布式自增ID: http://localhost:9999/tinyid/id/nextIdSimple?bizType=test&amp;token=0f673adf80504e2eaa552f5d791b644c&#39;返回结果: 3批量获取分布式自增ID:http://localhost:9999/tinyid/id/nextIdSimple?bizType=test&amp;token=0f673adf80504e2eaa552f5d791b644c&amp;batchSize=10&#39;返回结果:  4,5,6,7,8,9,10,11,12,13</code></pre><h3 id="Java客户端方式接入"><a href="#Java客户端方式接入" class="headerlink" title="Java客户端方式接入"></a>Java客户端方式接入</h3><p>重复Http方式的（2）（3）操作</p><p>引入依赖</p><pre><code class="xml">xml复制代码       &lt;dependency&gt;            &lt;groupId&gt;com.xiaoju.uemc.tinyid&lt;/groupId&gt;            &lt;artifactId&gt;tinyid-client&lt;/artifactId&gt;            &lt;version&gt;$&#123;tinyid.version&#125;&lt;/version&gt;        &lt;/dependency&gt;</code></pre><p>配置文件</p><pre><code class="ini">ini复制代码tinyid.server =localhost:9999tinyid.token =0f673adf80504e2eaa552f5d791b644c</code></pre><p>test 、tinyid.token是在数据库表中预先插入的数据，test 是具体业务类型，tinyid.token表示可访问的业务类型</p><pre><code class="ini">ini复制代码// 获取单个分布式自增IDLong id =  TinyId . nextId( &quot; test &quot; );// 按需批量分布式自增IDList&lt; Long &gt; ids =  TinyId . nextId( &quot; test &quot; , 10 );</code></pre><hr><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文只是简单介绍一下每种分布式ID生成器，旨在给大家一个详细学习的方向，每种生成方式都有它自己的优缺点，具体如何使用还要看具体的业务需求。</p><p>作者：java不会秃头<br>链接：<a href="https://juejin.cn/post/7202454684656418877">https://juejin.cn/post/7202454684656418877</a><br>来源：稀土掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ高级功能+源码分析</title>
      <link href="/2023/06/20/blog20/"/>
      <url>/2023/06/20/blog20/</url>
      
        <content type="html"><![CDATA[<h1 id="1-高级功能"><a href="#1-高级功能" class="headerlink" title="1. 高级功能"></a>1. 高级功能</h1><h2 id="1-1-消息存储"><a href="#1-1-消息存储" class="headerlink" title="1.1 消息存储"></a>1.1 消息存储</h2><p>分布式队列因为有高可靠性的要求，所以数据要进行持久化存储。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F.png"></p><ol><li>消息生成者发送消息</li><li>MQ收到消息，将消息进行持久化，在存储中新增一条记录</li><li>返回ACK给生产者</li><li>MQ push 消息给对应的消费者，然后等待消费者返回ACK</li><li>如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤</li><li>MQ删除消息</li></ol><h3 id="1-1-1-存储介质"><a href="#1-1-1-存储介质" class="headerlink" title="1.1.1 存储介质"></a>1.1.1 存储介质</h3><ul><li>关系型数据库DB</li></ul><p>Apache下开源的另外一款MQ—ActiveMQ（默认采用的KahaDB做消息存储）可选用JDBC的方式来做消息持久化，通过简单的xml配置信息即可实现JDBC消息存储。由于，普通关系型数据库（如Mysql）在单表数据量达到千万级别的情况下，其IO读写性能往往会出现瓶颈。在可靠性方面，该种方案非常依赖DB，如果一旦DB出现故障，则MQ的消息就无法落盘存储会导致线上故障</p><p><img src="/../imgs/blog20/MySQL.png"></p><ul><li><p>文件系统</p><p>目前业界较为常用的几款产品（RocketMQ&#x2F;Kafka&#x2F;RabbitMQ）均采用的是消息刷盘至所部署虚拟机&#x2F;物理机的文件系统来做持久化（刷盘一般可以分为异步刷盘和同步刷盘两种模式）。消息刷盘为消息存储提供了一种高效率、高可靠性和高性能的数据持久化方式。除非部署MQ机器本身或是本地磁盘挂了，否则一般是不会出现无法持久化的故障问题。</p><p><img src="/../imgs/blog20/%E7%A3%81%E7%9B%98.png"></p></li></ul><p>###1.1.2 性能对比</p><p>文件系统&gt;关系型数据库DB</p><h3 id="1-1-3-消息的存储和发送"><a href="#1-1-3-消息的存储和发送" class="headerlink" title="1.1.3 消息的存储和发送"></a>1.1.3 消息的存储和发送</h3><h4 id="1）消息存储"><a href="#1）消息存储" class="headerlink" title="1）消息存储"></a>1）消息存储</h4><p>磁盘如果使用得当，磁盘的速度完全可以匹配上网络 的数据传输速度。目前的高性能磁盘，顺序写速度可以达到600MB&#x2F;s， 超过了一般网卡的传输速度。但是磁盘随机写的速度只有大概100KB&#x2F;s，和顺序写的性能相差6000倍！因为有如此巨大的速度差别，好的消息队列系统会比普通的消息队列系统速度快多个数量级。RocketMQ的消息用顺序写,保证了消息存储的速度。</p><p>####2）消息发送</p><p>Linux操作系统分为【用户态】和【内核态】，文件操作、网络操作需要涉及这两种形态的切换，免不了进行数据复制。</p><p>一台服务器 把本机磁盘文件的内容发送到客户端，一般分为两个步骤：</p><p>1）read；读取本地文件内容； </p><p>2）write；将读取的内容通过网络发送出去。</p><p>这两个看似简单的操作，实际进行了4 次数据复制，分别是：</p><ol><li>从磁盘复制数据到内核态内存；</li><li>从内核态内存复 制到用户态内存；</li><li>然后从用户态 内存复制到网络驱动的内核态内存；</li><li>最后是从网络驱动的内核态内存复 制到网卡中进行传输。</li></ol><p><img src="/../imgs/blog20/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%E5%92%8C%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C.png">通过使用mmap的方式，可以省去向用户态的内存复制，提高速度。这种机制在Java中是通过MappedByteBuffer实现的</p><p>RocketMQ充分利用了上述特性，也就是所谓的“零拷贝”技术，提高消息存盘和网络发送的速度。</p><blockquote><p>这里需要注意的是，采用MappedByteBuffer这种内存映射的方式有几个限制，其中之一是一次只能映射1.5~2G 的文件至用户态的虚拟内存，这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因了</p></blockquote><h3 id="1-1-4-消息存储结构"><a href="#1-1-4-消息存储结构" class="headerlink" title="1.1.4 消息存储结构"></a>1.1.4 消息存储结构</h3><p>RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成 的，消息真正的物理存储文件是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。每 个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png"></p><ul><li>CommitLog：存储消息的元数据</li><li>ConsumerQueue：存储消息在CommitLog的索引</li><li>IndexFile：为了消息查询提供了一种通过key或时间区间来查询消息的方法，这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程</li></ul><h3 id="1-1-5-刷盘机制"><a href="#1-1-5-刷盘机制" class="headerlink" title="1.1.5 刷盘机制"></a>1.1.5 刷盘机制</h3><p>RocketMQ的消息是存储到磁盘上的，这样既能保证断电后恢复， 又可以让存储的消息量超出内存的限制。RocketMQ为了提高性能，会尽可能地保证磁盘的顺序写。消息在通过Producer写入RocketMQ的时 候，有两种写磁盘方式，分布式同步刷盘和异步刷盘。</p><p><img src="/../imgs/blog20/%E5%90%8C%E6%AD%A5%E5%88%B7%E7%9B%98%E5%92%8C%E5%BC%82%E6%AD%A5%E5%88%B7%E7%9B%98.png"></p><h4 id="1）同步刷盘"><a href="#1）同步刷盘" class="headerlink" title="1）同步刷盘"></a>1）同步刷盘</h4><p>在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写 成功的状态。</p><h4 id="2）异步刷盘"><a href="#2）异步刷盘" class="headerlink" title="2）异步刷盘"></a>2）异步刷盘</h4><p>在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。</p><p>####3）配置</p><p><strong>同步刷盘还是异步刷盘，都是通过Broker配置文件里的flushDiskType 参数设置的，这个参数被配置成SYNC_FLUSH、ASYNC_FLUSH中的 一个。</strong></p><h2 id="1-2-高可用性机制"><a href="#1-2-高可用性机制" class="headerlink" title="1.2 高可用性机制"></a>1.2 高可用性机制</h2><p><img src="/../imgs/blog20/RocketMQ%E8%A7%92%E8%89%B2.jpg"></p><p>RocketMQ分布式集群是通过Master和Slave的配合达到高可用性的。</p><p>Master和Slave的区别：在Broker的配置文件中，参数 brokerId的值为0表明这个Broker是Master，大于0表明这个Broker是 Slave，同时brokerRole参数也会说明这个Broker是Master还是Slave。</p><p>Master角色的Broker支持读和写，Slave角色的Broker仅支持读，也就是 Producer只能和Master角色的Broker连接写入消息；Consumer可以连接 Master角色的Broker，也可以连接Slave角色的Broker来读取消息。</p><h3 id="1-2-1-消息消费高可用"><a href="#1-2-1-消息消费高可用" class="headerlink" title="1.2.1 消息消费高可用"></a>1.2.1 消息消费高可用</h3><p>在Consumer的配置文件中，并不需要设置是从Master读还是从Slave 读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave 读。有了自动切换Consumer这种机制，当一个Master角色的机器出现故障后，Consumer仍然可以从Slave读取消息，不影响Consumer程序。这就达到了消费端的高可用性。</p><h3 id="1-2-2-消息发送高可用"><a href="#1-2-2-消息发送高可用" class="headerlink" title="1.2.2 消息发送高可用"></a>1.2.2 消息发送高可用</h3><p>在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上（相同Broker名称，不同 brokerId的机器组成一个Broker组），这样当一个Broker组的Master不可 用后，其他组的Master仍然可用，Producer仍然可以发送消息。 RocketMQ目前还不支持把Slave自动转成Master，如果机器资源不足， 需要把Slave转成Master，则要手动停止Slave角色的Broker，更改配置文 件，用新的配置文件启动Broker。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%BE%E8%AE%A1.jpg"></p><h3 id="1-2-3-消息主从复制"><a href="#1-2-3-消息主从复制" class="headerlink" title="1.2.3 消息主从复制"></a>1.2.3 消息主从复制</h3><p>如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式。</p><p>####1）同步复制</p><p>同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态；</p><p>在同步复制方式下，如果Master出故障， Slave上有全部的备份数据，容易恢复，但是同步复制会增大数据写入 延迟，降低系统吞吐量。</p><p>####2）异步复制 </p><p>异步复制方式是只要Master写成功 即可反馈给客户端写成功状态。</p><p>在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因为没有被写 入Slave，有可能会丢失；</p><p>####3）配置</p><p>同步复制和异步复制是通过Broker配置文件里的brokerRole参数进行设置的，这个参数可以被设置成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。</p><p>####4）总结</p><p><img src="/../imgs/blog20/%E5%A4%8D%E5%88%B6%E5%88%B7%E7%9B%98.png"></p><p>实际应用中要结合业务场景，合理设置刷盘方式和主从复制方式， 尤其是SYNC_FLUSH方式，由于频繁地触发磁盘写动作，会明显降低 性能。通常情况下，应该把Master和Save配置成ASYNC_FLUSH的刷盘 方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台 机器出故障，仍然能保证数据不丢，是个不错的选择。</p><h2 id="1-3-负载均衡"><a href="#1-3-负载均衡" class="headerlink" title="1.3 负载均衡"></a>1.3 负载均衡</h2><h3 id="1-3-1-Producer负载均衡"><a href="#1-3-1-Producer负载均衡" class="headerlink" title="1.3.1 Producer负载均衡"></a>1.3.1 Producer负载均衡</h3><p>Producer端，每个实例在发消息的时候，默认会轮询所有的message queue发送，以达到让消息平均落在不同的queue上。而由于queue可以散落在不同的broker，所以消息就发送到不同的broker下，如下图：</p><p><img src="/../imgs/blog20/producer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png"></p><p>图中箭头线条上的标号代表顺序，发布方会把第一条消息发送至 Queue 0，然后第二条消息发送至 Queue 1，以此类推。</p><h3 id="1-3-2-Consumer负载均衡"><a href="#1-3-2-Consumer负载均衡" class="headerlink" title="1.3.2 Consumer负载均衡"></a>1.3.2 Consumer负载均衡</h3><h4 id="1）集群模式"><a href="#1）集群模式" class="headerlink" title="1）集群模式"></a>1）集群模式</h4><p>在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。RocketMQ采用主动拉取的方式拉取并消费消息，在拉取的时候需要明确指定拉取哪一条message queue。</p><p>而每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时候会按照queue的数量和实例的数量平均分配queue给每个实例。</p><p>默认的分配算法是AllocateMessageQueueAveragely，如下图：</p><p><img src="/../imgs/blog20/consumer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png"></p><p>还有另外一种平均的算法是AllocateMessageQueueAveragelyByCircle，也是平均分摊每一条queue，只是以环状轮流分queue的形式，如下图：</p><p><img src="/../imgs/blog20/consumer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A12.png"></p><p>需要注意的是，集群模式下，queue都是只允许分配只一个实例，这是由于如果多个实例同时消费一个queue的消息，由于拉取哪些消息是consumer主动控制的，那样会导致同一个消息在不同的实例下被消费多次，所以算法上都是一个queue只分给一个consumer实例，一个consumer实例可以允许同时分到不同的queue。</p><p>通过增加consumer实例去分摊queue的消费，可以起到水平扩展的消费能力的作用。而有实例下线的时候，会重新触发负载均衡，这时候原来分配到的queue将分配到其他实例上继续消费。</p><p>但是如果consumer实例的数量比message queue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。</p><p>####2）广播模式</p><p>由于广播模式下要求一条消息需要投递到一个消费组下面所有的消费者实例，所以也就没有消息被分摊消费的说法。</p><p>在实现上，其中一个不同就是在consumer分配queue的时候，所有consumer都分到所有的queue。</p><p><img src="/../imgs/blog20/consumer%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A13.png"></p><h2 id="1-4-消息重试"><a href="#1-4-消息重试" class="headerlink" title="1.4 消息重试"></a>1.4 消息重试</h2><h3 id="1-4-1-顺序消息的重试"><a href="#1-4-1-顺序消息的重试" class="headerlink" title="1.4.1 顺序消息的重试"></a>1.4.1 顺序消息的重试</h3><p>对于顺序消息，当消费者消费消息失败后，消息队列 RocketMQ 会自动不断进行消息重试（每次间隔时间为 1 秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。</p><h3 id="1-4-2-无序消息的重试"><a href="#1-4-2-无序消息的重试" class="headerlink" title="1.4.2 无序消息的重试"></a>1.4.2 无序消息的重试</h3><p>对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回状态达到消息重试的结果。</p><p>无序消息的重试只针对集群消费方式生效；广播方式不提供失败重试特性，即消费失败后，失败消息不再重试，继续消费新的消息。</p><h4 id="1）重试次数"><a href="#1）重试次数" class="headerlink" title="1）重试次数"></a>1）重试次数</h4><p>消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：</p><table><thead><tr><th align="center">第几次重试</th><th align="center">与上次重试的间隔时间</th><th align="center">第几次重试</th><th align="center">与上次重试的间隔时间</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">10 秒</td><td align="center">9</td><td align="center">7 分钟</td></tr><tr><td align="center">2</td><td align="center">30 秒</td><td align="center">10</td><td align="center">8 分钟</td></tr><tr><td align="center">3</td><td align="center">1 分钟</td><td align="center">11</td><td align="center">9 分钟</td></tr><tr><td align="center">4</td><td align="center">2 分钟</td><td align="center">12</td><td align="center">10 分钟</td></tr><tr><td align="center">5</td><td align="center">3 分钟</td><td align="center">13</td><td align="center">20 分钟</td></tr><tr><td align="center">6</td><td align="center">4 分钟</td><td align="center">14</td><td align="center">30 分钟</td></tr><tr><td align="center">7</td><td align="center">5 分钟</td><td align="center">15</td><td align="center">1 小时</td></tr><tr><td align="center">8</td><td align="center">6 分钟</td><td align="center">16</td><td align="center">2 小时</td></tr></tbody></table><p>如果消息重试 16 次后仍然失败，消息将不再投递。如果严格按照上述重试时间间隔计算，某条消息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围消息将不再重试投递。</p><p><strong>注意：</strong> 一条消息无论重试多少次，这些重试消息的 Message ID 不会改变。</p><h4 id="2）配置方式"><a href="#2）配置方式" class="headerlink" title="2）配置方式"></a>2）配置方式</h4><p><strong>消费失败后，重试配置方式</strong></p><p>集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置（三种方式任选一种）：</p><ul><li>返回 Action.ReconsumeLater （推荐）</li><li>返回 Null</li><li>抛出异常</li></ul><pre><code class="java">public class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        //处理消息        doConsumeMessage(message);        //方式1：返回 Action.ReconsumeLater，消息将重试        return Action.ReconsumeLater;        //方式2：返回 null，消息将重试        return null;        //方式3：直接抛出异常， 消息将重试        throw new RuntimeException(&quot;Consumer Message exceotion&quot;);    &#125;&#125;</code></pre><p><strong>消费失败后，不重试配置方式</strong></p><p>集群消费方式下，消息失败后期望消息不重试，需要捕获消费逻辑中可能抛出的异常，最终返回 Action.CommitMessage，此后这条消息将不会再重试。</p><pre><code class="java">public class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        try &#123;            doConsumeMessage(message);        &#125; catch (Throwable e) &#123;            //捕获消费逻辑中的所有异常，并返回 Action.CommitMessage;            return Action.CommitMessage;        &#125;        //消息处理正常，直接返回 Action.CommitMessage;        return Action.CommitMessage;    &#125;&#125;</code></pre><p><strong>自定义消息最大重试次数</strong></p><p>消息队列 RocketMQ 允许 Consumer 启动的时候设置最大重试次数，重试时间间隔将按照如下策略：</p><ul><li>最大重试次数小于等于 16 次，则重试时间间隔同上表描述。</li><li>最大重试次数大于 16 次，超过 16 次的重试时间间隔均为每次 2 小时。</li></ul><pre><code class="java">Properties properties = new Properties();//配置对应 Group ID 的最大消息重试次数为 20 次properties.put(PropertyKeyConst.MaxReconsumeTimes,&quot;20&quot;);Consumer consumer =ONSFactory.createConsumer(properties);</code></pre><blockquote><p>注意：</p></blockquote><ul><li>消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。</li><li>如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了 MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。</li><li>配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置</li></ul><p><strong>获取消息重试次数</strong></p><p>消费者收到消息后，可按照如下方式获取消息的重试次数：</p><pre><code class="java">public class MessageListenerImpl implements MessageListener &#123;    @Override    public Action consume(Message message, ConsumeContext context) &#123;        //获取消息的重试次数        System.out.println(message.getReconsumeTimes());        return Action.CommitMessage;    &#125;&#125;</code></pre><h2 id="1-5-死信队列"><a href="#1-5-死信队列" class="headerlink" title="1.5 死信队列"></a>1.5 死信队列</h2><p>当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。</p><p>在消息队列 RocketMQ 中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。</p><h3 id="1-5-1-死信特性"><a href="#1-5-1-死信特性" class="headerlink" title="1.5.1 死信特性"></a>1.5.1 死信特性</h3><p>死信消息具有以下特性</p><ul><li>不会再被消费者正常消费。</li><li>有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。</li></ul><p>死信队列具有以下特性：</p><ul><li>一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。</li><li>如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。</li><li>一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。</li></ul><h3 id="1-5-2-查看死信信息"><a href="#1-5-2-查看死信信息" class="headerlink" title="1.5.2 查看死信信息"></a>1.5.2 查看死信信息</h3><ol><li>在控制台查询出现死信队列的主题信息</li></ol><p><img src="/../imgs/blog20/%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%E4%B8%BB%E9%A2%98.png"></p><ol start="2"><li>在消息界面根据主题查询死信消息</li></ol><p><img src="/../imgs/blog20/%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%E4%B8%BB%E9%A2%982.png"></p><ol start="3"><li>选择重新发送消息</li></ol><p>一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，通常需要您对其进行特殊处理。排查可疑因素并解决问题后，可以在消息队列 RocketMQ 控制台重新发送该消息，让消费者重新消费一次。</p><h2 id="1-6-消费幂等"><a href="#1-6-消费幂等" class="headerlink" title="1.6 消费幂等"></a>1.6 消费幂等</h2><p>消息队列 RocketMQ 消费者在接收到消息以后，有必要根据业务上的唯一 Key 对消息做幂等处理的必要性。</p><h3 id="1-6-1-消费幂等的必要性"><a href="#1-6-1-消费幂等的必要性" class="headerlink" title="1.6.1 消费幂等的必要性"></a>1.6.1 消费幂等的必要性</h3><p>在互联网应用中，尤其在网络不稳定的情况下，消息队列 RocketMQ 的消息有可能会出现重复，这个重复简单可以概括为以下情况：</p><ul><li><p>发送时消息重复</p><p>当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。</p></li><li><p>投递时消息重复</p><p>消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。 为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。</p></li><li><p>负载均衡时消息重复（包括但不限于网络抖动、Broker 重启以及订阅方应用重启）</p><p>当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。</p></li></ul><h3 id="1-6-2-处理方式"><a href="#1-6-2-处理方式" class="headerlink" title="1.6.2 处理方式"></a>1.6.2 处理方式</h3><p>因为 Message ID 有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以 Message ID 作为处理依据。 最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息 Key 进行设置：</p><pre><code class="java">Message message = new Message();message.setKey(&quot;ORDERID_100&quot;);SendResult sendResult = producer.send(message);</code></pre><p>订阅方收到消息时可以根据消息的 Key 进行幂等处理：</p><pre><code class="java">consumer.subscribe(&quot;ons_test&quot;, &quot;*&quot;, new MessageListener() &#123;    public Action consume(Message message, ConsumeContext context) &#123;        String key = message.getKey()        // 根据业务唯一标识的 key 做幂等处理    &#125;&#125;);</code></pre><h1 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2. 源码分析"></a>2. 源码分析</h1><h2 id="2-1-环境搭建"><a href="#2-1-环境搭建" class="headerlink" title="2.1 环境搭建"></a>2.1 环境搭建</h2><p>依赖工具</p><ul><li>JDK ：1.8+</li><li>Maven</li><li>IntelliJ IDEA</li></ul><h3 id="2-1-1-源码拉取"><a href="#2-1-1-源码拉取" class="headerlink" title="2.1.1 源码拉取"></a>2.1.1 源码拉取</h3><p>从官方仓库 <a href="https://github.com/apache/rocketmq">https://github.com/apache/rocketmq</a> <code>clone</code>或者<code>download</code>源码。</p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%811.png"></p><p><strong>源码目录结构：</strong></p><ul><li><p>broker: broker 模块（broke 启动进程） </p></li><li><p>client ：消息客户端，包含消息生产者、消息消费者相关类 </p></li><li><p>common ：公共包 </p></li><li><p>dev ：开发者信息（非源代码） </p></li><li><p>distribution ：部署实例文件夹（非源代码） </p></li><li><p>example: RocketMQ 例代码 </p></li><li><p>filter ：消息过滤相关基础类</p></li><li><p>filtersrv：消息过滤服务器实现相关类（Filter启动进程）</p></li><li><p>logappender：日志实现相关类</p></li><li><p>namesrv：NameServer实现相关类（NameServer启动进程）</p></li><li><p>openmessageing：消息开放标准</p></li><li><p>remoting：远程通信模块，给予Netty</p></li><li><p>srcutil：服务工具类</p></li><li><p>store：消息存储实现相关类</p></li><li><p>style：checkstyle相关实现</p></li><li><p>test：测试相关类</p></li><li><p>tools：工具类，监控命令相关实现类</p></li></ul><p>###2.1.2 导入IDEA</p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%812.png"></p><p><strong>执行安装</strong></p><pre><code class="sh">clean install -Dmaven.test.skip=true</code></pre><h3 id="2-1-3-调试"><a href="#2-1-3-调试" class="headerlink" title="2.1.3 调试"></a>2.1.3 调试</h3><p>创建<code>conf</code>配置文件夹,从<code>distribution</code>拷贝<code>broker.conf</code>和<code>logback_broker.xml</code>和<code>logback_namesrv.xml</code></p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%816.png"></p><h4 id="1）启动NameServer"><a href="#1）启动NameServer" class="headerlink" title="1）启动NameServer"></a>1）启动NameServer</h4><ul><li>展开namesrv模块，右键NamesrvStartup.java</li></ul><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%813.png"></p><ul><li>配置<strong>ROCKETMQ_HOME</strong></li></ul><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%814.png"></p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%815.png"></p><ul><li><p>重新启动</p><p>控制台打印结果</p></li></ul><pre><code class="sh">The Name Server boot success. serializeType=JSON</code></pre><h4 id="2）启动Broker"><a href="#2）启动Broker" class="headerlink" title="2）启动Broker"></a>2）启动Broker</h4><ul><li><code>broker.conf</code>配置文件内容</li></ul><pre><code class="properties">brokerClusterName = DefaultClusterbrokerName = broker-abrokerId = 0# namesrvAddr地址namesrvAddr=127.0.0.1:9876deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSHautoCreateTopicEnable=true# 存储路径storePathRootDir=E:\\RocketMQ\\data\\rocketmq\\dataDir# commitLog路径storePathCommitLog=E:\\RocketMQ\\data\\rocketmq\\dataDir\\commitlog# 消息队列存储路径storePathConsumeQueue=E:\\RocketMQ\\data\\rocketmq\\dataDir\\consumequeue# 消息索引存储路径storePathIndex=E:\\RocketMQ\\data\\rocketmq\\dataDir\\index# checkpoint文件路径storeCheckpoint=E:\\RocketMQ\\data\\rocketmq\\dataDir\\checkpoint# abort文件存储路径abortFile=E:\\RocketMQ\\data\\rocketmq\\dataDir\\abort</code></pre><ul><li>创建数据文件夹<code>dataDir</code></li><li>启动<code>BrokerStartup</code>,配置<code>broker.conf</code>和<code>ROCKETMQ_HOME</code></li></ul><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%817.png"></p><p><img src="/../imgs/blog20/%E6%BA%90%E7%A0%818.png"></p><p>####3）发送消息</p><ul><li>进入example模块的<code>org.apache.rocketmq.example.quickstart</code></li><li>指定Namesrv地址</li></ul><pre><code class="java">DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</code></pre><ul><li>运行<code>main</code>方法，发送消息</li></ul><h4 id="4）消费消息"><a href="#4）消费消息" class="headerlink" title="4）消费消息"></a>4）消费消息</h4><ul><li>进入example模块的<code>org.apache.rocketmq.example.quickstart</code></li><li>指定Namesrv地址</li></ul><pre><code class="java">DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_4&quot;);consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</code></pre><ul><li>运行<code>main</code>方法，消费消息</li></ul><h2 id="2-2-NameServer"><a href="#2-2-NameServer" class="headerlink" title="2.2 NameServer"></a>2.2 NameServer</h2><h3 id="2-2-1-架构设计"><a href="#2-2-1-架构设计" class="headerlink" title="2.2.1 架构设计"></a>2.2.1 架构设计</h3><p>消息中间件的设计思路一般是基于主题订阅发布的机制，消息生产者（Producer）发送某一个主题到消息服务器，消息服务器负责将消息持久化存储，消息消费者（Consumer）订阅该兴趣的主题，消息服务器根据订阅信息（路由信息）将消息推送到消费者（Push模式）或者消费者主动向消息服务器拉去（Pull模式），从而实现消息生产者与消息消费者解耦。为了避免消息服务器的单点故障导致的整个系统瘫痪，通常会部署多台消息服务器共同承担消息的存储。那消息生产者如何知道消息要发送到哪台消息服务器呢？如果某一台消息服务器宕机了，那么消息生产者如何在不重启服务情况下感知呢？</p><p>NameServer就是为了解决以上问题设计的。</p><p><img src="/../imgs/blog20/RocketMQ%E8%A7%92%E8%89%B2.jpg"></p><p>Broker消息服务器在启动的时向所有NameServer注册，消息生产者（Producer）在发送消息时之前先从NameServer获取Broker服务器地址列表，然后根据负载均衡算法从列表中选择一台服务器进行发送。NameServer与每台Broker保持长连接，并间隔30S检测Broker是否存活，如果检测到Broker宕机，则从路由注册表中删除。但是路由变化不会马上通知消息生产者。这样设计的目的是为了降低NameServer实现的复杂度，在消息发送端提供容错机制保证消息发送的可用性。</p><p>NameServer本身的高可用是通过部署多台NameServer来实现，但彼此之间不通讯，也就是NameServer服务器之间在某一个时刻的数据并不完全相同，但这对消息发送并不会造成任何影响，这也是NameServer设计的一个亮点，总之，RocketMQ设计追求简单高效。</p><h3 id="2-2-2-启动流程"><a href="#2-2-2-启动流程" class="headerlink" title="2.2.2 启动流程"></a>2.2.2 启动流程</h3><p><img src="/../imgs/blog20/NameServer%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.png"></p><p>启动类：<code>org.apache.rocketmq.namesrv.NamesrvStartup</code></p><p>####步骤一</p><p>解析配置文件，填充NameServerConfig、NettyServerConfig属性值，并创建NamesrvController</p><p><em><strong>代码：NamesrvController#createNamesrvController</strong></em></p><pre><code class="java">//创建NamesrvConfigfinal NamesrvConfig namesrvConfig = new NamesrvConfig();//创建NettyServerConfigfinal NettyServerConfig nettyServerConfig = new NettyServerConfig();//设置启动端口号nettyServerConfig.setListenPort(9876);//解析启动-c参数if (commandLine.hasOption(&#39;c&#39;)) &#123;    String file = commandLine.getOptionValue(&#39;c&#39;);    if (file != null) &#123;        InputStream in = new BufferedInputStream(new FileInputStream(file));        properties = new Properties();        properties.load(in);        MixAll.properties2Object(properties, namesrvConfig);        MixAll.properties2Object(properties, nettyServerConfig);        namesrvConfig.setConfigStorePath(file);        System.out.printf(&quot;load config properties file OK, %s%n&quot;, file);        in.close();    &#125;&#125;//解析启动-p参数if (commandLine.hasOption(&#39;p&#39;)) &#123;    InternalLogger console = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_CONSOLE_NAME);    MixAll.printObjectProperties(console, namesrvConfig);    MixAll.printObjectProperties(console, nettyServerConfig);    System.exit(0);&#125;//将启动参数填充到namesrvConfig,nettyServerConfigMixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig);//创建NameServerControllerfinal NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig);</code></pre><p><u><strong>NamesrvConfig属性</strong></u></p><pre><code class="java">private String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV));private String kvConfigPath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;kvConfig.json&quot;;private String configStorePath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;namesrv.properties&quot;;private String productEnvName = &quot;center&quot;;private boolean clusterTest = false;private boolean orderMessageEnable = false;</code></pre><p><strong>rocketmqHome：</strong>rocketmq主目录</p><p><strong>kvConfig：</strong>NameServer存储KV配置属性的持久化路径</p><p><strong>configStorePath：</strong>nameServer默认配置文件路径</p><p><strong>orderMessageEnable：</strong>是否支持顺序消息</p><p><u><strong>NettyServerConfig属性</strong></u></p><pre><code class="java">private int listenPort = 8888;private int serverWorkerThreads = 8;private int serverCallbackExecutorThreads = 0;private int serverSelectorThreads = 3;private int serverOnewaySemaphoreValue = 256;private int serverAsyncSemaphoreValue = 64;private int serverChannelMaxIdleTimeSeconds = 120;private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize;private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize;private boolean serverPooledByteBufAllocatorEnable = true;private boolean useEpollNativeSelector = false;</code></pre><p><strong>listenPort：</strong>NameServer监听端口，该值默认会被初始化为9876<br><strong>serverWorkerThreads：</strong>Netty业务线程池线程个数<br><strong>serverCallbackExecutorThreads：</strong>Netty public任务线程池线程个数，Netty网络设计，根据业务类型会创建不同的线程池，比如处理消息发送、消息消费、心跳检测等。如果该业务类型未注册线程池，则由public线程池执行。<br><strong>serverSelectorThreads：</strong>IO线程池个数，主要是NameServer、Broker端解析请求、返回相应的线程个数，这类线程主要是处理网路请求的，解析请求包，然后转发到各个业务线程池完成具体的操作，然后将结果返回给调用方;<br><strong>serverOnewaySemaphoreValue：</strong>send oneway消息请求并发读（Broker端参数）;<br><strong>serverAsyncSemaphoreValue：</strong>异步消息发送最大并发度;<br><strong>serverChannelMaxIdleTimeSeconds ：</strong>网络连接最大的空闲时间，默认120s。<br><strong>serverSocketSndBufSize：</strong>网络socket发送缓冲区大小。<br><strong>serverSocketRcvBufSize：</strong> 网络接收端缓存区大小。<br><strong>serverPooledByteBufAllocatorEnable：</strong>ByteBuffer是否开启缓存;<br><strong>useEpollNativeSelector：</strong>是否启用Epoll IO模型。</p><h4 id="步骤二"><a href="#步骤二" class="headerlink" title="步骤二"></a>步骤二</h4><p>根据启动属性创建NamesrvController实例，并初始化该实例。NameServerController实例为NameServer核心控制器</p><p><em><strong>代码：NamesrvController#initialize</strong></em></p><pre><code class="java">public boolean initialize() &#123;    //加载KV配置    this.kvConfigManager.load();    //创建NettyServer网络处理对象    this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService);    //开启定时任务:每隔10s扫描一次Broker,移除不活跃的Broker    this.remotingExecutor =        Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(&quot;RemotingExecutorThread_&quot;));    this.registerProcessor();    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            NamesrvController.this.routeInfoManager.scanNotActiveBroker();        &#125;    &#125;, 5, 10, TimeUnit.SECONDS);    //开启定时任务:每隔10min打印一次KV配置    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            NamesrvController.this.kvConfigManager.printAllPeriodically();        &#125;    &#125;, 1, 10, TimeUnit.MINUTES);    return true;&#125;</code></pre><h4 id="步骤三"><a href="#步骤三" class="headerlink" title="步骤三"></a>步骤三</h4><p>在JVM进程关闭之前，先将线程池关闭，及时释放资源</p><p><em><strong>代码：NamesrvStartup#start</strong></em></p><pre><code class="java">//注册JVM钩子函数代码Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() &#123;    @Override    public Void call() throws Exception &#123;        //释放资源        controller.shutdown();        return null;    &#125;&#125;));</code></pre><h3 id="2-2-3-路由管理"><a href="#2-2-3-路由管理" class="headerlink" title="2.2.3 路由管理"></a>2.2.3 路由管理</h3><p>NameServer的主要作用是为消息的生产者和消息消费者提供关于主题Topic的路由信息，那么NameServer需要存储路由的基础信息，还要管理Broker节点，包括路由注册、路由删除等。</p><h4 id="2-2-3-1-路由元信息"><a href="#2-2-3-1-路由元信息" class="headerlink" title="2.2.3.1 路由元信息"></a>2.2.3.1 路由元信息</h4><p><em><strong>代码：RouteInfoManager</strong></em></p><pre><code class="java">private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;</code></pre><p><img src="/../imgs/blog20/%E8%B7%AF%E7%94%B1%E5%AE%9E%E4%BD%93%E5%9B%BE.png"></p><p><strong>topicQueueTable：</strong>Topic消息队列路由信息，消息发送时根据路由表进行负载均衡</p><p><strong>brokerAddrTable：</strong>Broker基础信息，包括brokerName、所属集群名称、主备Broker地址</p><p><strong>clusterAddrTable：</strong>Broker集群信息，存储集群中所有Broker名称</p><p><strong>brokerLiveTable：</strong>Broker状态信息，NameServer每次收到心跳包是会替换该信息</p><p><strong>filterServerTable：</strong>Broker上的FilterServer列表，用于类模式消息过滤。</p><blockquote><p>RocketMQ基于定于发布机制，一个Topic拥有多个消息队列，一个Broker为每一个主题创建4个读队列和4个写队列。多个Broker组成一个集群，集群由相同的多台Broker组成Master-Slave架构，brokerId为0代表Master，大于0为Slave。BrokerLiveInfo中的lastUpdateTimestamp存储上次收到Broker心跳包的时间。</p></blockquote><p><img src="/../imgs/blog20/%E5%AE%9E%E4%BD%93%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%BE%8B.png"></p><p><img src="/../imgs/blog20/%E5%AE%9E%E4%BD%93%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%BE%8B2.png"></p><h4 id="2-2-3-2-路由注册"><a href="#2-2-3-2-路由注册" class="headerlink" title="2.2.3.2 路由注册"></a>2.2.3.2 路由注册</h4><p>#####1）发送心跳包</p><p><img src="/../imgs/blog20/%E8%B7%AF%E7%94%B1%E6%B3%A8%E5%86%8C.png"></p><p>RocketMQ路由注册是通过Broker与NameServer的心跳功能实现的。Broker启动时向集群中所有的NameServer发送心跳信息，每隔30s向集群中所有NameServer发送心跳包，NameServer收到心跳包时会更新brokerLiveTable缓存中BrokerLiveInfo的lastUpdataTimeStamp信息，然后NameServer每隔10s扫描brokerLiveTable，如果连续120S没有收到心跳包，NameServer将移除Broker的路由信息同时关闭Socket连接。</p><p><em><strong>代码：BrokerController#start</strong></em></p><pre><code class="java">//注册Broker信息this.registerBrokerAll(true, false, true);//每隔30s上报Broker信息到NameServerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;    @Override    public void run() &#123;        try &#123;            BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister());        &#125; catch (Throwable e) &#123;            log.error(&quot;registerBrokerAll Exception&quot;, e);        &#125;    &#125;&#125;, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)),                                                   TimeUnit.MILLISECONDS);</code></pre><p><em><strong>代码：BrokerOuterAPI#registerBrokerAll</strong></em></p><pre><code class="java">//获得nameServer地址信息List&lt;String&gt; nameServerAddressList = this.remotingClient.getNameServerAddressList();//遍历所有nameserver列表if (nameServerAddressList != null &amp;&amp; nameServerAddressList.size() &gt; 0) &#123;    //封装请求头    final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader();    requestHeader.setBrokerAddr(brokerAddr);    requestHeader.setBrokerId(brokerId);    requestHeader.setBrokerName(brokerName);    requestHeader.setClusterName(clusterName);    requestHeader.setHaServerAddr(haServerAddr);    requestHeader.setCompressed(compressed);    //封装请求体    RegisterBrokerBody requestBody = new RegisterBrokerBody();    requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper);    requestBody.setFilterServerList(filterServerList);    final byte[] body = requestBody.encode(compressed);    final int bodyCrc32 = UtilAll.crc32(body);    requestHeader.setBodyCrc32(bodyCrc32);    final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size());    for (final String namesrvAddr : nameServerAddressList) &#123;        brokerOuterExecutor.execute(new Runnable() &#123;            @Override            public void run() &#123;                try &#123;                    //分别向NameServer注册                    RegisterBrokerResult result = registerBroker(namesrvAddr,oneway, timeoutMills,requestHeader,body);                    if (result != null) &#123;                        registerBrokerResultList.add(result);                    &#125;                    log.info(&quot;register broker[&#123;&#125;]to name server &#123;&#125; OK&quot;, brokerId, namesrvAddr);                &#125; catch (Exception e) &#123;                    log.warn(&quot;registerBroker Exception, &#123;&#125;&quot;, namesrvAddr, e);                &#125; finally &#123;                    countDownLatch.countDown();                &#125;            &#125;        &#125;);    &#125;    try &#123;        countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS);    &#125; catch (InterruptedException e) &#123;    &#125;&#125;</code></pre><p><em><strong>代码：BrokerOutAPI#registerBroker</strong></em></p><pre><code class="java">if (oneway) &#123;    try &#123;        this.remotingClient.invokeOneway(namesrvAddr, request, timeoutMills);    &#125; catch (RemotingTooMuchRequestException e) &#123;        // Ignore    &#125;    return null;&#125;RemotingCommand response = this.remotingClient.invokeSync(namesrvAddr, request, timeoutMills);</code></pre><h5 id="2）处理心跳包"><a href="#2）处理心跳包" class="headerlink" title="2）处理心跳包"></a>2）处理心跳包</h5><p><img src="/../imgs/blog20/NameServer%E5%A4%84%E7%90%86%E8%B7%AF%E7%94%B1%E6%B3%A8%E5%86%8C.png"></p><p><code>org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor</code>网路处理类解析请求类型，如果请求类型是为<em><strong>REGISTER_BROKER</strong></em>，则将请求转发到<code>RouteInfoManager#regiesterBroker</code></p><p><em><strong>代码：DefaultRequestProcessor#processRequest</strong></em></p><pre><code class="java">//判断是注册Broker信息case RequestCode.REGISTER_BROKER:    Version brokerVersion = MQVersion.value2Version(request.getVersion());    if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) &#123;        return this.registerBrokerWithFilterServer(ctx, request);    &#125; else &#123;        //注册Broker信息        return this.registerBroker(ctx, request);    &#125;</code></pre><p><em><strong>代码：DefaultRequestProcessor#registerBroker</strong></em></p><pre><code class="java">RegisterBrokerResult result = this.namesrvController.getRouteInfoManager().registerBroker(    requestHeader.getClusterName(),    requestHeader.getBrokerAddr(),    requestHeader.getBrokerName(),    requestHeader.getBrokerId(),    requestHeader.getHaServerAddr(),    topicConfigWrapper,    null,    ctx.channel());</code></pre><p><em><strong>代码：RouteInfoManager#registerBroker</strong></em></p><p>维护路由信息</p><pre><code class="java">//加锁this.lock.writeLock().lockInterruptibly();//维护clusterAddrTableSet&lt;String&gt; brokerNames = this.clusterAddrTable.get(clusterName);if (null == brokerNames) &#123;    brokerNames = new HashSet&lt;String&gt;();    this.clusterAddrTable.put(clusterName, brokerNames);&#125;brokerNames.add(brokerName);</code></pre><pre><code class="java">//维护brokerAddrTableBrokerData brokerData = this.brokerAddrTable.get(brokerName);//第一次注册,则创建brokerDataif (null == brokerData) &#123;    registerFirst = true;    brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;());    this.brokerAddrTable.put(brokerName, brokerData);&#125;//非第一次注册,更新BrokerMap&lt;Long, String&gt; brokerAddrsMap = brokerData.getBrokerAddrs();Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerAddrsMap.entrySet().iterator();while (it.hasNext()) &#123;    Entry&lt;Long, String&gt; item = it.next();    if (null != brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId != item.getKey()) &#123;        it.remove();    &#125;&#125;String oldAddr = brokerData.getBrokerAddrs().put(brokerId, brokerAddr);registerFirst = registerFirst || (null == oldAddr);</code></pre><pre><code class="java">//维护topicQueueTableif (null != topicConfigWrapper &amp;&amp; MixAll.MASTER_ID == brokerId) &#123;    if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion()) ||         registerFirst) &#123;        ConcurrentMap&lt;String, TopicConfig&gt; tcTable = topicConfigWrapper.getTopicConfigTable();        if (tcTable != null) &#123;            for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) &#123;                this.createAndUpdateQueueData(brokerName, entry.getValue());            &#125;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：RouteInfoManager#createAndUpdateQueueData</strong></em></p><pre><code class="java">private void createAndUpdateQueueData(final String brokerName, final TopicConfig topicConfig) &#123;    //创建QueueData    QueueData queueData = new QueueData();    queueData.setBrokerName(brokerName);    queueData.setWriteQueueNums(topicConfig.getWriteQueueNums());    queueData.setReadQueueNums(topicConfig.getReadQueueNums());    queueData.setPerm(topicConfig.getPerm());    queueData.setTopicSynFlag(topicConfig.getTopicSysFlag());    //获得topicQueueTable中队列集合    List&lt;QueueData&gt; queueDataList = this.topicQueueTable.get(topicConfig.getTopicName());    //topicQueueTable为空,则直接添加queueData到队列集合    if (null == queueDataList) &#123;        queueDataList = new LinkedList&lt;QueueData&gt;();        queueDataList.add(queueData);        this.topicQueueTable.put(topicConfig.getTopicName(), queueDataList);        log.info(&quot;new topic registered, &#123;&#125; &#123;&#125;&quot;, topicConfig.getTopicName(), queueData);    &#125; else &#123;        //判断是否是新的队列        boolean addNewOne = true;        Iterator&lt;QueueData&gt; it = queueDataList.iterator();        while (it.hasNext()) &#123;            QueueData qd = it.next();            //如果brokerName相同,代表不是新的队列            if (qd.getBrokerName().equals(brokerName)) &#123;                if (qd.equals(queueData)) &#123;                    addNewOne = false;            &#125; else &#123;                        log.info(&quot;topic changed, &#123;&#125; OLD: &#123;&#125; NEW: &#123;&#125;&quot;, topicConfig.getTopicName(), qd,                            queueData);                        it.remove();                    &#125;                &#125;            &#125;        //如果是新的队列,则添加队列到queueDataList        if (addNewOne) &#123;            queueDataList.add(queueData);        &#125;    &#125;&#125;</code></pre><pre><code class="java">//维护brokerLiveTableBrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddr,new BrokerLiveInfo(    System.currentTimeMillis(),    topicConfigWrapper.getDataVersion(),    channel,    haServerAddr));</code></pre><pre><code class="java">//维护filterServerListif (filterServerList != null) &#123;    if (filterServerList.isEmpty()) &#123;        this.filterServerTable.remove(brokerAddr);    &#125; else &#123;        this.filterServerTable.put(brokerAddr, filterServerList);    &#125;&#125;if (MixAll.MASTER_ID != brokerId) &#123;    String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID);    if (masterAddr != null) &#123;        BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.get(masterAddr);        if (brokerLiveInfo != null) &#123;            result.setHaServerAddr(brokerLiveInfo.getHaServerAddr());            result.setMasterAddr(masterAddr);        &#125;    &#125;&#125;</code></pre><h4 id="2-2-3-3-路由删除"><a href="#2-2-3-3-路由删除" class="headerlink" title="2.2.3.3 路由删除"></a>2.2.3.3 路由删除</h4><p><code>Broker</code>每隔30s向<code>NameServer</code>发送一个心跳包，心跳包包含<code>BrokerId</code>，<code>Broker</code>地址，<code>Broker</code>名称，<code>Broker</code>所属集群名称、<code>Broker</code>关联的<code>FilterServer</code>列表。但是如果<code>Broker</code>宕机，<code>NameServer</code>无法收到心跳包，此时<code>NameServer</code>如何来剔除这些失效的<code>Broker</code>呢？<code>NameServer</code>会每隔10s扫描<code>brokerLiveTable</code>状态表，如果<code>BrokerLive</code>的<strong>lastUpdateTimestamp</strong>的时间戳距当前时间超过120s，则认为<code>Broker</code>失效，移除该<code>Broker</code>，关闭与<code>Broker</code>连接，同时更新<code>topicQueueTable</code>、<code>brokerAddrTable</code>、<code>brokerLiveTable</code>、<code>filterServerTable</code>。</p><p><strong>RocketMQ有两个触发点来删除路由信息</strong>：</p><ul><li>NameServer定期扫描brokerLiveTable检测上次心跳包与当前系统的时间差，如果时间超过120s，则需要移除broker。</li><li>Broker在正常关闭的情况下，会执行unregisterBroker指令</li></ul><p>这两种方式路由删除的方法都是一样的，就是从相关路由表中删除与该broker相关的信息。</p><p><img src="/../imgs/blog20/%E8%B7%AF%E7%94%B1%E5%88%A0%E9%99%A4.png"></p><p><em><strong>代码：NamesrvController#initialize</strong></em></p><pre><code class="java">//每隔10s扫描一次为活跃Brokerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;    @Override    public void run() &#123;        NamesrvController.this.routeInfoManager.scanNotActiveBroker();    &#125;&#125;, 5, 10, TimeUnit.SECONDS);</code></pre><p><em><strong>代码：RouteInfoManager#scanNotActiveBroker</strong></em></p><pre><code class="java">public void scanNotActiveBroker() &#123;    //获得brokerLiveTable    Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; it = this.brokerLiveTable.entrySet().iterator();    //遍历brokerLiveTable    while (it.hasNext()) &#123;        Entry&lt;String, BrokerLiveInfo&gt; next = it.next();        long last = next.getValue().getLastUpdateTimestamp();        //如果收到心跳包的时间距当时时间是否超过120s        if ((last + BROKER_CHANNEL_EXPIRED_TIME) &lt; System.currentTimeMillis()) &#123;            //关闭连接            RemotingUtil.closeChannel(next.getValue().getChannel());            //移除broker            it.remove();            //维护路由表            this.onChannelDestroy(next.getKey(), next.getValue().getChannel());        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：RouteInfoManager#onChannelDestroy</strong></em></p><pre><code class="java">//申请写锁,根据brokerAddress从brokerLiveTable和filterServerTable移除this.lock.writeLock().lockInterruptibly();this.brokerLiveTable.remove(brokerAddrFound);this.filterServerTable.remove(brokerAddrFound);</code></pre><pre><code class="java">//维护brokerAddrTableString brokerNameFound = null;boolean removeBrokerName = false;Iterator&lt;Entry&lt;String, BrokerData&gt;&gt; itBrokerAddrTable =this.brokerAddrTable.entrySet().iterator();//遍历brokerAddrTablewhile (itBrokerAddrTable.hasNext() &amp;&amp; (null == brokerNameFound)) &#123;    BrokerData brokerData = itBrokerAddrTable.next().getValue();    //遍历broker地址    Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerData.getBrokerAddrs().entrySet().iterator();    while (it.hasNext()) &#123;        Entry&lt;Long, String&gt; entry = it.next();        Long brokerId = entry.getKey();        String brokerAddr = entry.getValue();        //根据broker地址移除brokerAddr        if (brokerAddr.equals(brokerAddrFound)) &#123;            brokerNameFound = brokerData.getBrokerName();            it.remove();            log.info(&quot;remove brokerAddr[&#123;&#125;, &#123;&#125;] from brokerAddrTable, because channel destroyed&quot;,                brokerId, brokerAddr);            break;        &#125;    &#125;    //如果当前主题只包含待移除的broker,则移除该topic    if (brokerData.getBrokerAddrs().isEmpty()) &#123;        removeBrokerName = true;        itBrokerAddrTable.remove();        log.info(&quot;remove brokerName[&#123;&#125;] from brokerAddrTable, because channel destroyed&quot;,            brokerData.getBrokerName());    &#125;&#125;</code></pre><pre><code class="java">//维护clusterAddrTableif (brokerNameFound != null &amp;&amp; removeBrokerName) &#123;    Iterator&lt;Entry&lt;String, Set&lt;String&gt;&gt;&gt; it = this.clusterAddrTable.entrySet().iterator();    //遍历clusterAddrTable    while (it.hasNext()) &#123;        Entry&lt;String, Set&lt;String&gt;&gt; entry = it.next();        //获得集群名称        String clusterName = entry.getKey();        //获得集群中brokerName集合        Set&lt;String&gt; brokerNames = entry.getValue();        //从brokerNames中移除brokerNameFound        boolean removed = brokerNames.remove(brokerNameFound);        if (removed) &#123;            log.info(&quot;remove brokerName[&#123;&#125;], clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed&quot;,                brokerNameFound, clusterName);            if (brokerNames.isEmpty()) &#123;                log.info(&quot;remove the clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed and no broker in this cluster&quot;,                    clusterName);                //如果集群中不包含任何broker,则移除该集群                it.remove();            &#125;            break;        &#125;    &#125;&#125;</code></pre><pre><code class="java">//维护topicQueueTable队列if (removeBrokerName) &#123;    //遍历topicQueueTable    Iterator&lt;Entry&lt;String, List&lt;QueueData&gt;&gt;&gt; itTopicQueueTable =        this.topicQueueTable.entrySet().iterator();    while (itTopicQueueTable.hasNext()) &#123;        Entry&lt;String, List&lt;QueueData&gt;&gt; entry = itTopicQueueTable.next();        //主题名称        String topic = entry.getKey();        //队列集合        List&lt;QueueData&gt; queueDataList = entry.getValue();        //遍历该主题队列        Iterator&lt;QueueData&gt; itQueueData = queueDataList.iterator();        while (itQueueData.hasNext()) &#123;            //从队列中移除为活跃broker信息            QueueData queueData = itQueueData.next();            if (queueData.getBrokerName().equals(brokerNameFound)) &#123;                itQueueData.remove();                log.info(&quot;remove topic[&#123;&#125; &#123;&#125;], from topicQueueTable, because channel destroyed&quot;,                    topic, queueData);            &#125;        &#125;        //如果该topic的队列为空,则移除该topic        if (queueDataList.isEmpty()) &#123;            itTopicQueueTable.remove();            log.info(&quot;remove topic[&#123;&#125;] all queue, from topicQueueTable, because channel destroyed&quot;,                topic);        &#125;    &#125;&#125;</code></pre><pre><code class="java">//释放写锁finally &#123;    this.lock.writeLock().unlock();&#125;</code></pre><h4 id="2-2-3-4-路由发现"><a href="#2-2-3-4-路由发现" class="headerlink" title="2.2.3.4 路由发现"></a>2.2.3.4 路由发现</h4><p>RocketMQ路由发现是非实时的，当Topic路由出现变化后，NameServer不会主动推送给客户端，而是由客户端定时拉取主题最新的路由。</p><p><em><strong>代码：DefaultRequestProcessor#getRouteInfoByTopic</strong></em></p><pre><code class="java">public RemotingCommand getRouteInfoByTopic(ChannelHandlerContext ctx,    RemotingCommand request) throws RemotingCommandException &#123;    final RemotingCommand response = RemotingCommand.createResponseCommand(null);    final GetRouteInfoRequestHeader requestHeader =        (GetRouteInfoRequestHeader) request.decodeCommandCustomHeader(GetRouteInfoRequestHeader.class);    //调用RouteInfoManager的方法,从路由表topicQueueTable、brokerAddrTable、filterServerTable中分别填充TopicRouteData的List&lt;QueueData&gt;、List&lt;BrokerData&gt;、filterServer    TopicRouteData topicRouteData = this.namesrvController.getRouteInfoManager().pickupTopicRouteData(requestHeader.getTopic());    //如果找到主题对应你的路由信息并且该主题为顺序消息，则从NameServer KVConfig中获取关于顺序消息相关的配置填充路由信息    if (topicRouteData != null) &#123;        if (this.namesrvController.getNamesrvConfig().isOrderMessageEnable()) &#123;            String orderTopicConf =                this.namesrvController.getKvConfigManager().getKVConfig(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG,                    requestHeader.getTopic());            topicRouteData.setOrderTopicConf(orderTopicConf);        &#125;        byte[] content = topicRouteData.encode();        response.setBody(content);        response.setCode(ResponseCode.SUCCESS);        response.setRemark(null);        return response;    &#125;    response.setCode(ResponseCode.TOPIC_NOT_EXIST);    response.setRemark(&quot;No topic route info in name server for the topic: &quot; + requestHeader.getTopic()        + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));    return response;&#125;</code></pre><h3 id="2-2-4-小结"><a href="#2-2-4-小结" class="headerlink" title="2.2.4 小结"></a>2.2.4 小结</h3><p><img src="/../imgs/blog20/NameServer%E5%B0%8F%E7%BB%93.png"></p><h2 id="2-3-Producer"><a href="#2-3-Producer" class="headerlink" title="2.3 Producer"></a>2.3 Producer</h2><p>消息生产者的代码都在client模块中，相对于RocketMQ来讲，消息生产者就是客户端，也是消息的提供者。</p><p><img src="/../imgs/blog20/DefaultMQProducer%E7%B1%BB%E5%9B%BE.png"></p><p>###2.3.1 方法和属性</p><p>####1）主要方法介绍</p><p><img src="/../imgs/blog20/MQAdmin.png"></p><ul><li><pre><code class="java">//创建主题void createTopic(final String key, final String newTopic, final int queueNum) throws MQClientException;</code></pre></li><li><pre><code class="java">//根据时间戳从队列中查找消息偏移量long searchOffset(final MessageQueue mq, final long timestamp)</code></pre></li><li><pre><code class="java">//查找消息队列中最大的偏移量long maxOffset(final MessageQueue mq) throws MQClientException;</code></pre></li><li><pre><code class="java">//查找消息队列中最小的偏移量long minOffset(final MessageQueue mq) </code></pre></li><li><pre><code class="java">//根据偏移量查找消息MessageExt viewMessage(final String offsetMsgId) throws RemotingException, MQBrokerException,        InterruptedException, MQClientException;</code></pre></li><li><pre><code class="java">//根据条件查找消息QueryResult queryMessage(final String topic, final String key, final int maxNum, final long begin,        final long end) throws MQClientException, InterruptedException;</code></pre></li><li><pre><code class="java">//根据消息ID和主题查找消息MessageExt viewMessage(String topic,String msgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException;</code></pre></li></ul><p><img src="/../imgs/blog20/MQProducer.png"></p><ul><li><pre><code class="java">//启动void start() throws MQClientException;</code></pre></li><li><pre><code class="java">//关闭void shutdown();</code></pre></li><li><pre><code class="java">//查找该主题下所有消息List&lt;MessageQueue&gt; fetchPublishMessageQueues(final String topic) throws MQClientException;</code></pre></li><li><pre><code class="java">//同步发送消息SendResult send(final Message msg) throws MQClientException, RemotingException, MQBrokerException,        InterruptedException;</code></pre></li><li><pre><code class="java">//同步超时发送消息SendResult send(final Message msg, final long timeout) throws MQClientException,        RemotingException, MQBrokerException, InterruptedException;</code></pre></li><li><pre><code class="java">//异步发送消息void send(final Message msg, final SendCallback sendCallback) throws MQClientException,        RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//异步超时发送消息void send(final Message msg, final SendCallback sendCallback, final long timeout)    throws MQClientException, RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//发送单向消息void sendOneway(final Message msg) throws MQClientException, RemotingException,    InterruptedException;</code></pre></li><li><pre><code class="java">//选择指定队列同步发送消息SendResult send(final Message msg, final MessageQueue mq) throws MQClientException,    RemotingException, MQBrokerException, InterruptedException;</code></pre></li><li><pre><code class="java">//选择指定队列异步发送消息void send(final Message msg, final MessageQueue mq, final SendCallback sendCallback)    throws MQClientException, RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//选择指定队列单项发送消息void sendOneway(final Message msg, final MessageQueue mq) throws MQClientException,    RemotingException, InterruptedException;</code></pre></li><li><pre><code class="java">//批量发送消息SendResult send(final Collection&lt;Message&gt; msgs) throws MQClientException, RemotingException, MQBrokerException,InterruptedException;</code></pre></li></ul><p>####2）属性介绍</p><p><img src="/../imgs/blog20/DefaultMQProducer%E5%B1%9E%E6%80%A7.png"></p><pre><code class="java">producerGroup：生产者所属组createTopicKey：默认TopicdefaultTopicQueueNums：默认主题在每一个Broker队列数量sendMsgTimeout：发送消息默认超时时间，默认3scompressMsgBodyOverHowmuch：消息体超过该值则启用压缩，默认4kretryTimesWhenSendFailed：同步方式发送消息重试次数，默认为2，总共执行3次retryTimesWhenSendAsyncFailed：异步方法发送消息重试次数，默认为2retryAnotherBrokerWhenNotStoreOK：消息重试时选择另外一个Broker时，是否不等待存储结果就返回，默认为falsemaxMessageSize：允许发送的最大消息长度，默认为4M</code></pre><h3 id="2-3-2-启动流程"><a href="#2-3-2-启动流程" class="headerlink" title="2.3.2 启动流程"></a>2.3.2 启动流程</h3><p><img src="/../imgs/blog20/%E7%94%9F%E4%BA%A7%E8%80%85%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：DefaultMQProducerImpl#start</strong></em></p><pre><code class="java">//检查生产者组是否满足要求this.checkConfig();//更改当前instanceName为进程IDif (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) &#123;    this.defaultMQProducer.changeInstanceNameToPID();&#125;//获得MQ客户端实例this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQProducer, rpcHook);</code></pre><blockquote><p>整个JVM中只存在一个MQClientManager实例，维护一个MQClientInstance缓存表</p><p>ConcurrentMap&lt;String&#x2F;* clientId *&#x2F;, MQClientInstance&gt; factoryTable &#x3D; new ConcurrentHashMap&lt;String,MQClientInstance&gt;();</p><p>同一个clientId只会创建一个MQClientInstance。</p><p>MQClientInstance封装了RocketMQ网络处理API，是消息生产者和消息消费者与NameServer、Broker打交道的网络通道</p></blockquote><p><em><strong>代码：MQClientManager#getAndCreateMQClientInstance</strong></em></p><pre><code class="java">public MQClientInstance getAndCreateMQClientInstance(final ClientConfig clientConfig,                                                      RPCHook rpcHook) &#123;    //构建客户端ID    String clientId = clientConfig.buildMQClientId();    //根据客户端ID或者客户端实例    MQClientInstance instance = this.factoryTable.get(clientId);    //实例如果为空就创建新的实例,并添加到实例表中    if (null == instance) &#123;        instance =            new MQClientInstance(clientConfig.cloneClientConfig(),                this.factoryIndexGenerator.getAndIncrement(), clientId, rpcHook);        MQClientInstance prev = this.factoryTable.putIfAbsent(clientId, instance);        if (prev != null) &#123;            instance = prev;            log.warn(&quot;Returned Previous MQClientInstance for clientId:[&#123;&#125;]&quot;, clientId);        &#125; else &#123;            log.info(&quot;Created new MQClientInstance for clientId:[&#123;&#125;]&quot;, clientId);        &#125;    &#125;    return instance;&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#start</strong></em></p><pre><code class="java">//注册当前生产者到到MQClientInstance管理中,方便后续调用网路请求boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this);if (!registerOK) &#123;    this.serviceState = ServiceState.CREATE_JUST;    throw new MQClientException(&quot;The producer group[&quot; + this.defaultMQProducer.getProducerGroup()        + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),        null);&#125;//启动生产者if (startFactory) &#123;    mQClientFactory.start();&#125;</code></pre><h3 id="2-3-3-消息发送"><a href="#2-3-3-消息发送" class="headerlink" title="2.3.3 消息发送"></a>2.3.3 消息发送</h3><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81.png"></p><p><em><strong>代码：DefaultMQProducerImpl#send(Message msg)</strong></em></p><pre><code class="java">//发送消息public SendResult send(Message msg) &#123;    return send(msg, this.defaultMQProducer.getSendMsgTimeout());&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#send(Message msg,long timeout)</strong></em></p><pre><code class="java">//发送消息,默认超时时间为3spublic SendResult send(Message msg,long timeout)&#123;    return this.sendDefaultImpl(msg, CommunicationMode.SYNC, null, timeout);&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#sendDefaultImpl</strong></em></p><pre><code class="java">//校验消息Validators.checkMessage(msg, this.defaultMQProducer);</code></pre><p>####1）验证消息</p><p><em><strong>代码：Validators#checkMessage</strong></em></p><pre><code class="java">public static void checkMessage(Message msg, DefaultMQProducer defaultMQProducer)    throws MQClientException &#123;    //判断是否为空    if (null == msg) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message is null&quot;);    &#125;    // 校验主题    Validators.checkTopic(msg.getTopic());            // 校验消息体    if (null == msg.getBody()) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body is null&quot;);    &#125;    if (0 == msg.getBody().length) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body length is zero&quot;);    &#125;    if (msg.getBody().length &gt; defaultMQProducer.getMaxMessageSize()) &#123;        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL,            &quot;the message body size over max value, MAX: &quot; + defaultMQProducer.getMaxMessageSize());    &#125;&#125;</code></pre><p>####2）查找路由</p><p><em><strong>代码：DefaultMQProducerImpl#tryToFindTopicPublishInfo</strong></em></p><pre><code class="java">private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123;    //从缓存中获得主题的路由信息    TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic);    //路由信息为空,则从NameServer获取路由    if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123;        this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo());        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic);        topicPublishInfo = this.topicPublishInfoTable.get(topic);    &#125;    if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123;        return topicPublishInfo;    &#125; else &#123;        //如果未找到当前主题的路由信息,则用默认主题继续查找        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer);        topicPublishInfo = this.topicPublishInfoTable.get(topic);        return topicPublishInfo;    &#125;&#125;</code></pre><p><img src="/../imgs/blog20/Topic%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF.png"></p><p><em><strong>代码：TopicPublishInfo</strong></em></p><pre><code class="java">public class TopicPublishInfo &#123;    private boolean orderTopic = false;//是否是顺序消息    private boolean haveTopicRouterInfo = false;     private List&lt;MessageQueue&gt; messageQueueList = new ArrayList&lt;MessageQueue&gt;();//该主题消息队列    private volatile ThreadLocalIndex sendWhichQueue = new ThreadLocalIndex();//每选择一次消息队列,该值+1    private TopicRouteData topicRouteData;//关联Topic路由元信息&#125;</code></pre><p><em><strong>代码：MQClientInstance#updateTopicRouteInfoFromNameServer</strong></em></p><pre><code class="java">TopicRouteData topicRouteData;//使用默认主题从NameServer获取路由信息if (isDefault &amp;&amp; defaultMQProducer != null) &#123;    topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(),        1000 * 3);    if (topicRouteData != null) &#123;        for (QueueData data : topicRouteData.getQueueDatas()) &#123;            int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums());            data.setReadQueueNums(queueNums);            data.setWriteQueueNums(queueNums);        &#125;    &#125;&#125; else &#123;    //使用指定主题从NameServer获取路由信息    topicRouteData = this.mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, 1000 * 3);&#125;</code></pre><p><em><strong>代码：MQClientInstance#updateTopicRouteInfoFromNameServer</strong></em></p><pre><code class="java">//判断路由是否需要更改TopicRouteData old = this.topicRouteTable.get(topic);boolean changed = topicRouteDataIsChange(old, topicRouteData);if (!changed) &#123;    changed = this.isNeedUpdateTopicRouteInfo(topic);&#125; else &#123;    log.info(&quot;the topic[&#123;&#125;] route info changed, old[&#123;&#125;] ,new[&#123;&#125;]&quot;, topic, old, topicRouteData);&#125;</code></pre><p><em><strong>代码：MQClientInstance#updateTopicRouteInfoFromNameServer</strong></em></p><pre><code class="java">if (changed) &#123;    //将topicRouteData转换为发布队列    TopicPublishInfo publishInfo = topicRouteData2TopicPublishInfo(topic, topicRouteData);    publishInfo.setHaveTopicRouterInfo(true);    //遍历生产    Iterator&lt;Entry&lt;String, MQProducerInner&gt;&gt; it = this.producerTable.entrySet().iterator();    while (it.hasNext()) &#123;        Entry&lt;String, MQProducerInner&gt; entry = it.next();        MQProducerInner impl = entry.getValue();        if (impl != null) &#123;            //生产者不为空时,更新publishInfo信息            impl.updateTopicPublishInfo(topic, publishInfo);        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：MQClientInstance#topicRouteData2TopicPublishInfo</strong></em></p><pre><code class="java">public static TopicPublishInfo topicRouteData2TopicPublishInfo(final String topic, final TopicRouteData route) &#123;        //创建TopicPublishInfo对象        TopicPublishInfo info = new TopicPublishInfo();        //关联topicRoute        info.setTopicRouteData(route);        //顺序消息,更新TopicPublishInfo        if (route.getOrderTopicConf() != null &amp;&amp; route.getOrderTopicConf().length() &gt; 0) &#123;            String[] brokers = route.getOrderTopicConf().split(&quot;;&quot;);            for (String broker : brokers) &#123;                String[] item = broker.split(&quot;:&quot;);                int nums = Integer.parseInt(item[1]);                for (int i = 0; i &lt; nums; i++) &#123;                    MessageQueue mq = new MessageQueue(topic, item[0], i);                    info.getMessageQueueList().add(mq);                &#125;            &#125;            info.setOrderTopic(true);        &#125; else &#123;            //非顺序消息更新TopicPublishInfo            List&lt;QueueData&gt; qds = route.getQueueDatas();            Collections.sort(qds);            //遍历topic队列信息            for (QueueData qd : qds) &#123;                //是否是写队列                if (PermName.isWriteable(qd.getPerm())) &#123;                    BrokerData brokerData = null;                    //遍历写队列Broker                    for (BrokerData bd : route.getBrokerDatas()) &#123;                        //根据名称获得读队列对应的Broker                        if (bd.getBrokerName().equals(qd.getBrokerName())) &#123;                        brokerData = bd;                        break;                    &#125;                &#125;                if (null == brokerData) &#123;                    continue;                &#125;                if (!brokerData.getBrokerAddrs().containsKey(MixAll.MASTER_ID)) &#123;                    continue;                &#125;                //封装TopicPublishInfo写队列                for (int i = 0; i &lt; qd.getWriteQueueNums(); i++) &#123;                    MessageQueue mq = new MessageQueue(topic, qd.getBrokerName(), i);                    info.getMessageQueueList().add(mq);                &#125;            &#125;        &#125;        info.setOrderTopic(false);    &#125;    //返回TopicPublishInfo对象    return info;&#125;</code></pre><h4 id="3）选择队列"><a href="#3）选择队列" class="headerlink" title="3）选择队列"></a>3）选择队列</h4><ul><li>默认不启用Broker故障延迟机制</li></ul><p><em><strong>代码：TopicPublishInfo#selectOneMessageQueue(lastBrokerName)</strong></em></p><pre><code class="java">public MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123;    //第一次选择队列    if (lastBrokerName == null) &#123;        return selectOneMessageQueue();    &#125; else &#123;        //sendWhichQueue        int index = this.sendWhichQueue.getAndIncrement();        //遍历消息队列集合        for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123;            //sendWhichQueue自增后取模            int pos = Math.abs(index++) % this.messageQueueList.size();            if (pos &lt; 0)                pos = 0;            //规避上次Broker队列            MessageQueue mq = this.messageQueueList.get(pos);            if (!mq.getBrokerName().equals(lastBrokerName)) &#123;                return mq;            &#125;        &#125;        //如果以上情况都不满足,返回sendWhichQueue取模后的队列        return selectOneMessageQueue();    &#125;&#125;</code></pre><p><em><strong>代码：TopicPublishInfo#selectOneMessageQueue()</strong></em></p><pre><code class="java">//第一次选择队列public MessageQueue selectOneMessageQueue() &#123;    //sendWhichQueue自增    int index = this.sendWhichQueue.getAndIncrement();    //对队列大小取模    int pos = Math.abs(index) % this.messageQueueList.size();    if (pos &lt; 0)        pos = 0;    //返回对应的队列    return this.messageQueueList.get(pos);&#125;</code></pre><ul><li>启用Broker故障延迟机制</li></ul><pre><code class="java">public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123;    //Broker故障延迟机制    if (this.sendLatencyFaultEnable) &#123;        try &#123;            //对sendWhichQueue自增            int index = tpInfo.getSendWhichQueue().getAndIncrement();            //对消息队列轮询获取一个队列            for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123;                int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size();                if (pos &lt; 0)                    pos = 0;                MessageQueue mq = tpInfo.getMessageQueueList().get(pos);                //验证该队列是否可用                if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123;                    //可用                    if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName))                        return mq;                &#125;            &#125;            //从规避的Broker中选择一个可用的Broker            final String notBestBroker = latencyFaultTolerance.pickOneAtLeast();            //获得Broker的写队列集合            int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker);            if (writeQueueNums &gt; 0) &#123;                //获得一个队列,指定broker和队列ID并返回                final MessageQueue mq = tpInfo.selectOneMessageQueue();                if (notBestBroker != null) &#123;                    mq.setBrokerName(notBestBroker);                    mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums);                &#125;                return mq;            &#125; else &#123;                latencyFaultTolerance.remove(notBestBroker);            &#125;        &#125; catch (Exception e) &#123;            log.error(&quot;Error occurred when selecting message queue&quot;, e);        &#125;        return tpInfo.selectOneMessageQueue();    &#125;    return tpInfo.selectOneMessageQueue(lastBrokerName);&#125;</code></pre><p><img src="/../imgs/blog20/Broker%E6%95%85%E9%9A%9C%E5%BB%B6%E8%BF%9F%E6%9C%BA%E5%88%B6%E6%A0%B8%E5%BF%83%E7%B1%BB.png"></p><ul><li>延迟机制接口规范</li></ul><pre><code class="java">public interface LatencyFaultTolerance&lt;T&gt; &#123;    //更新失败条目    void updateFaultItem(final T name, final long currentLatency, final long notAvailableDuration);    //判断Broker是否可用    boolean isAvailable(final T name);    //移除Fault条目    void remove(final T name);    //尝试从规避的Broker中选择一个可用的Broker    T pickOneAtLeast();&#125;</code></pre><ul><li>FaultItem：失败条目</li></ul><pre><code class="java">class FaultItem implements Comparable&lt;FaultItem&gt; &#123;    //条目唯一键,这里为brokerName    private final String name;    //本次消息发送延迟    private volatile long currentLatency;    //故障规避开始时间    private volatile long startTimestamp;&#125;</code></pre><ul><li>消息失败策略</li></ul><pre><code class="java">public class MQFaultStrategy &#123;   //根据currentLatency本地消息发送延迟,从latencyMax尾部向前找到第一个比currentLatency小的索引,如果没有找到,返回0    private long[] latencyMax = &#123;50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L&#125;;    //根据这个索引从notAvailableDuration取出对应的时间,在该时长内,Broker设置为不可用    private long[] notAvailableDuration = &#123;0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L&#125;;&#125;</code></pre><p><u><em><strong>原理分析</strong></em></u></p><p><em><strong>代码：DefaultMQProducerImpl#sendDefaultImpl</strong></em></p><pre><code class="java">sendResult = this.sendKernelImpl(msg,                                  mq,                                  communicationMode,                                  sendCallback,                                  topicPublishInfo,                                  timeout - costTime);endTimestamp = System.currentTimeMillis();this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false);</code></pre><p>如果上述发送过程出现异常，则调用<code>DefaultMQProducerImpl#updateFaultItem</code></p><pre><code class="java">public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123;    //参数一：broker名称    //参数二:本次消息发送延迟时间    //参数三:是否隔离    this.mqFaultStrategy.updateFaultItem(brokerName, currentLatency, isolation);&#125;</code></pre><p><em><strong>代码：MQFaultStrategy#updateFaultItem</strong></em></p><pre><code class="java">public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123;    if (this.sendLatencyFaultEnable) &#123;        //计算broker规避的时长        long duration = computeNotAvailableDuration(isolation ? 30000 : currentLatency);        //更新该FaultItem规避时长        this.latencyFaultTolerance.updateFaultItem(brokerName, currentLatency, duration);    &#125;&#125;</code></pre><p><em><strong>代码：MQFaultStrategy#computeNotAvailableDuration</strong></em></p><pre><code class="java">private long computeNotAvailableDuration(final long currentLatency) &#123;    //遍历latencyMax    for (int i = latencyMax.length - 1; i &gt;= 0; i--) &#123;        //找到第一个比currentLatency的latencyMax值        if (currentLatency &gt;= latencyMax[i])            return this.notAvailableDuration[i];    &#125;    //没有找到则返回0    return 0;&#125;</code></pre><p><em><strong>代码：LatencyFaultToleranceImpl#updateFaultItem</strong></em></p><pre><code class="java">public void updateFaultItem(final String name, final long currentLatency, final long notAvailableDuration) &#123;    //获得原FaultItem    FaultItem old = this.faultItemTable.get(name);    //为空新建faultItem对象,设置规避时长和开始时间    if (null == old) &#123;        final FaultItem faultItem = new FaultItem(name);        faultItem.setCurrentLatency(currentLatency);        faultItem.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);        old = this.faultItemTable.putIfAbsent(name, faultItem);        if (old != null) &#123;            old.setCurrentLatency(currentLatency);            old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);        &#125;    &#125; else &#123;        //更新规避时长和开始时间        old.setCurrentLatency(currentLatency);        old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);    &#125;&#125;</code></pre><p>####4）发送消息</p><p>消息发送API核心入口<em><strong>DefaultMQProducerImpl#sendKernelImpl</strong></em></p><pre><code class="java">private SendResult sendKernelImpl(    final Message msg,//待发送消息    final MessageQueue mq,//消息发送队列    final CommunicationMode communicationMode,//消息发送内模式    final SendCallback sendCallback,pp//异步消息回调函数    final TopicPublishInfo topicPublishInfo,//主题路由信息    final long timeout//超时时间    )</code></pre><p><em><strong>代码：DefaultMQProducerImpl#sendKernelImpl</strong></em></p><pre><code class="java">//获得broker网络地址信息String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());if (null == brokerAddr) &#123;    //没有找到从NameServer更新broker网络地址信息    tryToFindTopicPublishInfo(mq.getTopic());    brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());&#125;</code></pre><pre><code class="java">//为消息分类唯一IDif (!(msg instanceof MessageBatch)) &#123;    MessageClientIDSetter.setUniqID(msg);&#125;boolean topicWithNamespace = false;if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123;    msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace());    topicWithNamespace = true;&#125;//消息大小超过4K,启用消息压缩int sysFlag = 0;boolean msgBodyCompressed = false;if (this.tryToCompressMessage(msg)) &#123;    sysFlag |= MessageSysFlag.COMPRESSED_FLAG;    msgBodyCompressed = true;&#125;//如果是事务消息,设置消息标记MessageSysFlag.TRANSACTION_PREPARED_TYPEfinal String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123;    sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;&#125;</code></pre><pre><code class="java">//如果注册了消息发送钩子函数,在执行消息发送前的增强逻辑if (this.hasSendMessageHook()) &#123;    context = new SendMessageContext();    context.setProducer(this);    context.setProducerGroup(this.defaultMQProducer.getProducerGroup());    context.setCommunicationMode(communicationMode);    context.setBornHost(this.defaultMQProducer.getClientIP());    context.setBrokerAddr(brokerAddr);    context.setMessage(msg);    context.setMq(mq);    context.setNamespace(this.defaultMQProducer.getNamespace());    String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);    if (isTrans != null &amp;&amp; isTrans.equals(&quot;true&quot;)) &#123;        context.setMsgType(MessageType.Trans_Msg_Half);    &#125;    if (msg.getProperty(&quot;__STARTDELIVERTIME&quot;) != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) &#123;        context.setMsgType(MessageType.Delay_Msg);    &#125;    this.executeSendMessageHookBefore(context);&#125;</code></pre><p><em><strong>代码：SendMessageHook</strong></em></p><pre><code class="java">public interface SendMessageHook &#123;    String hookName();    void sendMessageBefore(final SendMessageContext context);    void sendMessageAfter(final SendMessageContext context);&#125;</code></pre><p><em><strong>代码：DefaultMQProducerImpl#sendKernelImpl</strong></em></p><pre><code class="java">//构建消息发送请求包SendMessageRequestHeader requestHeader = new SendMessageRequestHeader();//生产者组requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());//主题requestHeader.setTopic(msg.getTopic());//默认创建主题KeyrequestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey());//该主题在单个Broker默认队列树requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums());//队列IDrequestHeader.setQueueId(mq.getQueueId());//消息系统标记requestHeader.setSysFlag(sysFlag);//消息发送时间requestHeader.setBornTimestamp(System.currentTimeMillis());//消息标记requestHeader.setFlag(msg.getFlag());//消息扩展信息requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties()));//消息重试次数requestHeader.setReconsumeTimes(0);requestHeader.setUnitMode(this.isUnitMode());//是否是批量消息等requestHeader.setBatch(msg instanceof MessageBatch);if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;    String reconsumeTimes = MessageAccessor.getReconsumeTime(msg);    if (reconsumeTimes != null) &#123;        requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes));        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME);    &#125;    String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg);    if (maxReconsumeTimes != null) &#123;        requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes));        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES);    &#125;&#125;</code></pre><pre><code class="java">case ASYNC://异步发送    Message tmpMessage = msg;    boolean messageCloned = false;    if (msgBodyCompressed) &#123;        //If msg body was compressed, msgbody should be reset using prevBody.        //Clone new message using commpressed message body and recover origin massage.        //Fix bug:https://github.com/apache/rocketmq-externals/issues/66        tmpMessage = MessageAccessor.cloneMessage(msg);        messageCloned = true;        msg.setBody(prevBody);    &#125;    if (topicWithNamespace) &#123;        if (!messageCloned) &#123;            tmpMessage = MessageAccessor.cloneMessage(msg);            messageCloned = true;        &#125;        msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(),                                                     this.defaultMQProducer.getNamespace()));    &#125;        long costTimeAsync = System.currentTimeMillis() - beginStartTime;        if (timeout &lt; costTimeAsync) &#123;            throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);        &#125;        sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(                    brokerAddr,                    mq.getBrokerName(),                    tmpMessage,                    requestHeader,                    timeout - costTimeAsync,                    communicationMode,                    sendCallback,                    topicPublishInfo,                    this.mQClientFactory,                    this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(),                    context,                    this);        break;case ONEWAY:case SYNC://同步发送    long costTimeSync = System.currentTimeMillis() - beginStartTime;        if (timeout &lt; costTimeSync) &#123;            throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);        &#125;        sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(            brokerAddr,            mq.getBrokerName(),            msg,            requestHeader,            timeout - costTimeSync,            communicationMode,            context,            this);        break;    default:        assert false;        break;&#125;</code></pre><pre><code class="java">//如果注册了钩子函数,则发送完毕后执行钩子函数if (this.hasSendMessageHook()) &#123;    context.setSendResult(sendResult);    this.executeSendMessageHookAfter(context);&#125;</code></pre><h3 id="2-3-4-批量消息发送"><a href="#2-3-4-批量消息发送" class="headerlink" title="2.3.4 批量消息发送"></a>2.3.4 批量消息发送</h3><p><img src="/../imgs/blog20/%E5%8F%91%E9%80%81%E6%89%B9%E9%87%8F%E6%B6%88%E6%81%AF.png"></p><p>批量消息发送是将同一个主题的多条消息一起打包发送到消息服务端，减少网络调用次数，提高网络传输效率。当然，并不是在同一批次中发送的消息数量越多越好，其判断依据是单条消息的长度，如果单条消息内容比较长，则打包多条消息发送会影响其他线程发送消息的响应时间，并且单批次消息总长度不能超过DefaultMQProducer#maxMessageSize。</p><p>批量消息发送要解决的问题是如何将这些消息编码以便服务端能够正确解码出每条消息的消息内容。</p><p><em><strong>代码：DefaultMQProducer#send</strong></em></p><pre><code class="java">public SendResult send(Collection&lt;Message&gt; msgs)     throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123;    //压缩消息集合成一条消息,然后发送出去    return this.defaultMQProducerImpl.send(batch(msgs));&#125;</code></pre><p><em><strong>代码：DefaultMQProducer#batch</strong></em></p><pre><code class="java">private MessageBatch batch(Collection&lt;Message&gt; msgs) throws MQClientException &#123;    MessageBatch msgBatch;    try &#123;        //将集合消息封装到MessageBatch        msgBatch = MessageBatch.generateFromList(msgs);        //遍历消息集合,检查消息合法性,设置消息ID,设置Topic        for (Message message : msgBatch) &#123;            Validators.checkMessage(message, this);            MessageClientIDSetter.setUniqID(message);            message.setTopic(withNamespace(message.getTopic()));        &#125;        //压缩消息,设置消息body        msgBatch.setBody(msgBatch.encode());    &#125; catch (Exception e) &#123;        throw new MQClientException(&quot;Failed to initiate the MessageBatch&quot;, e);    &#125;    //设置msgBatch的topic    msgBatch.setTopic(withNamespace(msgBatch.getTopic()));    return msgBatch;&#125;</code></pre><h2 id="2-4-消息存储"><a href="#2-4-消息存储" class="headerlink" title="2.4 消息存储"></a>2.4 消息存储</h2><p>###2.4.1 消息存储核心类</p><p><img src="/../imgs/blog20/DefaultMessageStore.png"></p><pre><code class="java">private final MessageStoreConfig messageStoreConfig;//消息配置属性private final CommitLog commitLog;//CommitLog文件存储的实现类private final ConcurrentMap&lt;String/* topic */, ConcurrentMap&lt;Integer/* queueId */, ConsumeQueue&gt;&gt; consumeQueueTable;//消息队列存储缓存表,按照消息主题分组private final FlushConsumeQueueService flushConsumeQueueService;//消息队列文件刷盘线程private final CleanCommitLogService cleanCommitLogService;//清除CommitLog文件服务private final CleanConsumeQueueService cleanConsumeQueueService;//清除ConsumerQueue队列文件服务private final IndexService indexService;//索引实现类private final AllocateMappedFileService allocateMappedFileService;//MappedFile分配服务private final ReputMessageService reputMessageService;//CommitLog消息分发,根据CommitLog文件构建ConsumerQueue、IndexFile文件private final HAService haService;//存储HA机制private final ScheduleMessageService scheduleMessageService;//消息服务调度线程private final StoreStatsService storeStatsService;//消息存储服务private final TransientStorePool transientStorePool;//消息堆外内存缓存private final BrokerStatsManager brokerStatsManager;//Broker状态管理器private final MessageArrivingListener messageArrivingListener;//消息拉取长轮询模式消息达到监听器private final BrokerConfig brokerConfig;//Broker配置类private StoreCheckpoint storeCheckpoint;//文件刷盘监测点private final LinkedList&lt;CommitLogDispatcher&gt; dispatcherList;//CommitLog文件转发请求</code></pre><h3 id="2-4-2-消息存储流程"><a href="#2-4-2-消息存储流程" class="headerlink" title="2.4.2 消息存储流程"></a>2.4.2 消息存储流程</h3><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>消息存储入口：DefaultMessageStore#putMessage</strong></em></p><pre><code class="java">//判断Broker角色如果是从节点,则无需写入if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) &#123;        long value = this.printTimes.getAndIncrement();        if ((value % 50000) == 0) &#123;            log.warn(&quot;message store is slave mode, so putMessage is forbidden &quot;);        &#125;    return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125;//判断当前写入状态如果是正在写入,则不能继续if (!this.runningFlags.isWriteable()) &#123;        long value = this.printTimes.getAndIncrement();        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125; else &#123;    this.printTimes.set(0);&#125;//判断消息主题长度是否超过最大限制if (msg.getTopic().length() &gt; Byte.MAX_VALUE) &#123;    log.warn(&quot;putMessage message topic length too long &quot; + msg.getTopic().length());    return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);&#125;//判断消息属性长度是否超过限制if (msg.getPropertiesString() != null &amp;&amp; msg.getPropertiesString().length() &gt; Short.MAX_VALUE) &#123;    log.warn(&quot;putMessage message properties length too long &quot; + msg.getPropertiesString().length());    return new PutMessageResult(PutMessageStatus.PROPERTIES_SIZE_EXCEEDED, null);&#125;//判断系统PageCache缓存去是否占用if (this.isOSPageCacheBusy()) &#123;    return new PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, null);&#125;//将消息写入CommitLog文件PutMessageResult result = this.commitLog.putMessage(msg);</code></pre><p><em><strong>代码：CommitLog#putMessage</strong></em></p><pre><code class="java">//记录消息存储时间msg.setStoreTimestamp(beginLockTimestamp);//判断如果mappedFile如果为空或者已满,创建新的mappedFile文件if (null == mappedFile || mappedFile.isFull()) &#123;    mappedFile = this.mappedFileQueue.getLastMappedFile(0); &#125;//如果创建失败,直接返回if (null == mappedFile) &#123;    log.error(&quot;create mapped file1 error, topic: &quot; + msg.getTopic() + &quot; clientAddr: &quot; + msg.getBornHostString());    beginTimeInLock = 0;    return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);&#125;//写入消息到mappedFile中result = mappedFile.appendMessage(msg, this.appendMessageCallback);</code></pre><p><em><strong>代码：MappedFile#appendMessagesInner</strong></em></p><pre><code class="java">//获得文件的写入指针int currentPos = this.wrotePosition.get();//如果指针大于文件大小则直接返回if (currentPos &lt; this.fileSize) &#123;    //通过writeBuffer.slice()创建一个与MappedFile共享的内存区,并设置position为当前指针    ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice();    byteBuffer.position(currentPos);    AppendMessageResult result = null;    if (messageExt instanceof MessageExtBrokerInner) &#123;           //通过回调方法写入        result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt);    &#125; else if (messageExt instanceof MessageExtBatch) &#123;        result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt);    &#125; else &#123;        return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);    &#125;    this.wrotePosition.addAndGet(result.getWroteBytes());    this.storeTimestamp = result.getStoreTimestamp();    return result;&#125;</code></pre><p><em><strong>代码：CommitLog#doAppend</strong></em></p><pre><code class="java">//文件写入位置long wroteOffset = fileFromOffset + byteBuffer.position();//设置消息IDthis.resetByteBuffer(hostHolder, 8);String msgId = MessageDecoder.createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset);//获得该消息在消息队列中的偏移量keyBuilder.setLength(0);keyBuilder.append(msgInner.getTopic());keyBuilder.append(&#39;-&#39;);keyBuilder.append(msgInner.getQueueId());String key = keyBuilder.toString();Long queueOffset = CommitLog.this.topicQueueTable.get(key);if (null == queueOffset) &#123;    queueOffset = 0L;    CommitLog.this.topicQueueTable.put(key, queueOffset);&#125;//获得消息属性长度final byte[] propertiesData =msgInner.getPropertiesString() == null ? null : msgInner.getPropertiesString().getBytes(MessageDecoder.CHARSET_UTF8);final int propertiesLength = propertiesData == null ? 0 : propertiesData.length;if (propertiesLength &gt; Short.MAX_VALUE) &#123;    log.warn(&quot;putMessage message properties length too long. length=&#123;&#125;&quot;, propertiesData.length);    return new AppendMessageResult(AppendMessageStatus.PROPERTIES_SIZE_EXCEEDED);&#125;//获得消息主题大小final byte[] topicData = msgInner.getTopic().getBytes(MessageDecoder.CHARSET_UTF8);final int topicLength = topicData.length;//获得消息体大小final int bodyLength = msgInner.getBody() == null ? 0 : msgInner.getBody().length;//计算消息总长度final int msgLen = calMsgLength(bodyLength, topicLength, propertiesLength);</code></pre><p><em><strong>代码：CommitLog#calMsgLength</strong></em></p><pre><code class="java">protected static int calMsgLength(int bodyLength, int topicLength, int propertiesLength) &#123;    final int msgLen = 4 //TOTALSIZE        + 4 //MAGICCODE          + 4 //BODYCRC        + 4 //QUEUEID        + 4 //FLAG        + 8 //QUEUEOFFSET        + 8 //PHYSICALOFFSET        + 4 //SYSFLAG        + 8 //BORNTIMESTAMP        + 8 //BORNHOST        + 8 //STORETIMESTAMP        + 8 //STOREHOSTADDRESS        + 4 //RECONSUMETIMES        + 8 //Prepared Transaction Offset        + 4 + (bodyLength &gt; 0 ? bodyLength : 0) //BODY        + 1 + topicLength //TOPIC        + 2 + (propertiesLength &gt; 0 ? propertiesLength : 0) //propertiesLength        + 0;    return msgLen;&#125;</code></pre><p><em><strong>代码：CommitLog#doAppend</strong></em></p><pre><code class="java">//消息长度不能超过4Mif (msgLen &gt; this.maxMessageSize) &#123;    CommitLog.log.warn(&quot;message size exceeded, msg total size: &quot; + msgLen + &quot;, msg body size: &quot; + bodyLength        + &quot;, maxMessageSize: &quot; + this.maxMessageSize);    return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED);&#125;//消息是如果没有足够的存储空间则新创建CommitLog文件if ((msgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) &#123;    this.resetByteBuffer(this.msgStoreItemMemory, maxBlank);    // 1 TOTALSIZE    this.msgStoreItemMemory.putInt(maxBlank);    // 2 MAGICCODE    this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);    // 3 The remaining space may be any value    // Here the length of the specially set maxBlank    final long beginTimeMills = CommitLog.this.defaultMessageStore.now();    byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank);    return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgId, msgInner.getStoreTimestamp(),        queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);&#125;//将消息存储到ByteBuffer中,返回AppendMessageResultfinal long beginTimeMills = CommitLog.this.defaultMessageStore.now();// Write messages to the queue bufferbyteBuffer.put(this.msgStoreItemMemory.array(), 0, msgLen);AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset,                                                      msgLen, msgId,msgInner.getStoreTimestamp(),                                                      queueOffset,                                                      CommitLog.this.defaultMessageStore.now()                                                      -beginTimeMills);switch (tranType) &#123;    case MessageSysFlag.TRANSACTION_PREPARED_TYPE:    case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:        break;    case MessageSysFlag.TRANSACTION_NOT_TYPE:    case MessageSysFlag.TRANSACTION_COMMIT_TYPE:        //更新消息队列偏移量        CommitLog.this.topicQueueTable.put(key, ++queueOffset);        break;    default:        break;&#125;</code></pre><p><em><strong>代码：CommitLog#putMessage</strong></em></p><pre><code class="java">//释放锁putMessageLock.unlock();//刷盘handleDiskFlush(result, putMessageResult, msg);//执行HA主从同步handleHA(result, putMessageResult, msg);</code></pre><h3 id="2-4-3-存储文件"><a href="#2-4-3-存储文件" class="headerlink" title="2.4.3 存储文件"></a>2.4.3 存储文件</h3><p><img src="/../imgs/blog20/%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6.png"></p><ul><li>commitLog：消息存储目录</li><li>config：运行期间一些配置信息</li><li>consumerqueue：消息消费队列存储目录</li><li>index：消息索引文件存储目录</li><li>abort：如果存在改文件寿命Broker非正常关闭</li><li>checkpoint：文件检查点，存储CommitLog文件最后一次刷盘时间戳、consumerquueue最后一次刷盘时间，index索引文件最后一次刷盘时间戳。</li></ul><h3 id="2-4-4-存储文件内存映射"><a href="#2-4-4-存储文件内存映射" class="headerlink" title="2.4.4 存储文件内存映射"></a>2.4.4 存储文件内存映射</h3><p>RocketMQ通过使用内存映射文件提高IO访问性能，无论是CommitLog、ConsumerQueue还是IndexFile，单个文件都被设计为固定长度，如果一个文件写满以后再创建一个新文件，文件名就为该文件第一条消息对应的全局物理偏移量。</p><p>####1）MappedFileQueue</p><p><img src="/../imgs/blog20/MappedFileQueue.png"></p><pre><code class="java">String storePath;//存储目录int mappedFileSize;// 单个文件大小CopyOnWriteArrayList&lt;MappedFile&gt; mappedFiles;//MappedFile文件集合AllocateMappedFileService allocateMappedFileService;//创建MapFile服务类long flushedWhere = 0;//当前刷盘指针long committedWhere = 0;//当前数据提交指针,内存中ByteBuffer当前的写指针,该值大于等于flushWhere</code></pre><ul><li>根据存储时间查询MappedFile</li></ul><pre><code class="java">public MappedFile getMappedFileByTime(final long timestamp) &#123;    Object[] mfs = this.copyMappedFiles(0);        if (null == mfs)        return null;    //遍历MappedFile文件数组    for (int i = 0; i &lt; mfs.length; i++) &#123;        MappedFile mappedFile = (MappedFile) mfs[i];        //MappedFile文件的最后修改时间大于指定时间戳则返回该文件        if (mappedFile.getLastModifiedTimestamp() &gt;= timestamp) &#123;            return mappedFile;        &#125;    &#125;    return (MappedFile) mfs[mfs.length - 1];&#125;</code></pre><ul><li>根据消息偏移量offset查找MappedFile</li></ul><pre><code class="java">public MappedFile findMappedFileByOffset(final long offset, final boolean returnFirstOnNotFound) &#123;    try &#123;        //获得第一个MappedFile文件        MappedFile firstMappedFile = this.getFirstMappedFile();        //获得最后一个MappedFile文件        MappedFile lastMappedFile = this.getLastMappedFile();        //第一个文件和最后一个文件均不为空,则进行处理        if (firstMappedFile != null &amp;&amp; lastMappedFile != null) &#123;            if (offset &lt; firstMappedFile.getFileFromOffset() ||                 offset &gt;= lastMappedFile.getFileFromOffset() + this.mappedFileSize) &#123;            &#125; else &#123;                //获得文件索引                int index = (int) ((offset / this.mappedFileSize)                                    - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));                MappedFile targetFile = null;                try &#123;                    //根据索引返回目标文件                    targetFile = this.mappedFiles.get(index);                &#125; catch (Exception ignored) &#123;                &#125;                if (targetFile != null &amp;&amp; offset &gt;= targetFile.getFileFromOffset()                    &amp;&amp; offset &lt; targetFile.getFileFromOffset() + this.mappedFileSize) &#123;                    return targetFile;                &#125;                for (MappedFile tmpMappedFile : this.mappedFiles) &#123;                    if (offset &gt;= tmpMappedFile.getFileFromOffset()                        &amp;&amp; offset &lt; tmpMappedFile.getFileFromOffset() + this.mappedFileSize) &#123;                        return tmpMappedFile;                    &#125;                &#125;            &#125;            if (returnFirstOnNotFound) &#123;                return firstMappedFile;            &#125;        &#125;    &#125; catch (Exception e) &#123;        log.error(&quot;findMappedFileByOffset Exception&quot;, e);    &#125;    return null;&#125;</code></pre><ul><li>获取存储文件最小偏移量</li></ul><pre><code class="java">public long getMinOffset() &#123;    if (!this.mappedFiles.isEmpty()) &#123;        try &#123;            return this.mappedFiles.get(0).getFileFromOffset();        &#125; catch (IndexOutOfBoundsException e) &#123;            //continue;        &#125; catch (Exception e) &#123;            log.error(&quot;getMinOffset has exception.&quot;, e);        &#125;    &#125;    return -1;&#125;</code></pre><ul><li>获取存储文件最大偏移量</li></ul><pre><code class="java">public long getMaxOffset() &#123;    MappedFile mappedFile = getLastMappedFile();    if (mappedFile != null) &#123;        return mappedFile.getFileFromOffset() + mappedFile.getReadPosition();    &#125;    return 0;&#125;</code></pre><ul><li>返回存储文件当前写指针</li></ul><pre><code class="java">public long getMaxWrotePosition() &#123;    MappedFile mappedFile = getLastMappedFile();    if (mappedFile != null) &#123;        return mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();    &#125;    return 0;&#125;</code></pre><p>####2）MappedFile</p><p><img src="/../imgs/blog20/MappedFile.png"></p><pre><code class="java">int OS_PAGE_SIZE = 1024 * 4;//操作系统每页大小,默认4KAtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0);//当前JVM实例中MappedFile虚拟内存AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0);//当前JVM实例中MappedFile对象个数AtomicInteger wrotePosition = new AtomicInteger(0);//当前文件的写指针AtomicInteger committedPosition = new AtomicInteger(0);//当前文件的提交指针AtomicInteger flushedPosition = new AtomicInteger(0);//刷写到磁盘指针int fileSize;//文件大小FileChannel fileChannel;//文件通道ByteBuffer writeBuffer = null;//堆外内存ByteBufferTransientStorePool transientStorePool = null;//堆外内存池String fileName;//文件名称long fileFromOffset;//该文件的处理偏移量File file;//物理文件MappedByteBuffer mappedByteBuffer;//物理文件对应的内存映射Buffervolatile long storeTimestamp = 0;//文件最后一次内容写入时间boolean firstCreateInQueue = false;//是否是MappedFileQueue队列中第一个文件</code></pre><p><em><strong>MappedFile初始化</strong></em></p><ul><li>未开启<code>transientStorePoolEnable</code>。<code>transientStorePoolEnable=true</code>为<code>true</code>表示数据先存储到堆外内存，然后通过<code>Commit</code>线程将数据提交到内存映射Buffer中，再通过<code>Flush</code>线程将内存映射<code>Buffer</code>中数据持久化磁盘。</li></ul><pre><code class="java">private void init(final String fileName, final int fileSize) throws IOException &#123;    this.fileName = fileName;    this.fileSize = fileSize;    this.file = new File(fileName);    this.fileFromOffset = Long.parseLong(this.file.getName());    boolean ok = false;        ensureDirOK(this.file.getParent());    try &#123;        this.fileChannel = new RandomAccessFile(this.file, &quot;rw&quot;).getChannel();        this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize);        TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(fileSize);        TOTAL_MAPPED_FILES.incrementAndGet();        ok = true;    &#125; catch (FileNotFoundException e) &#123;        log.error(&quot;create file channel &quot; + this.fileName + &quot; Failed. &quot;, e);        throw e;    &#125; catch (IOException e) &#123;        log.error(&quot;map file &quot; + this.fileName + &quot; Failed. &quot;, e);        throw e;    &#125; finally &#123;        if (!ok &amp;&amp; this.fileChannel != null) &#123;            this.fileChannel.close();        &#125;    &#125;&#125;</code></pre><p>开启<code>transientStorePoolEnable</code></p><pre><code class="java">public void init(final String fileName, final int fileSize,    final TransientStorePool transientStorePool) throws IOException &#123;    init(fileName, fileSize);    this.writeBuffer = transientStorePool.borrowBuffer();//初始化writeBuffer    this.transientStorePool = transientStorePool;&#125;</code></pre><p><em><strong>MappedFile提交</strong></em></p><p>提交数据到FileChannel，commitLeastPages为本次提交最小的页数，如果待提交数据不满commitLeastPages，则不执行本次提交操作。如果writeBuffer如果为空，直接返回writePosition指针，无需执行commit操作，表名commit操作主体是writeBuffer。</p><pre><code class="java">public int commit(final int commitLeastPages) &#123;    if (writeBuffer == null) &#123;        //no need to commit data to file channel, so just regard wrotePosition as committedPosition.        return this.wrotePosition.get();    &#125;    //判断是否满足提交条件    if (this.isAbleToCommit(commitLeastPages)) &#123;        if (this.hold()) &#123;            commit0(commitLeastPages);            this.release();        &#125; else &#123;            log.warn(&quot;in commit, hold failed, commit offset = &quot; + this.committedPosition.get());        &#125;    &#125;    // 所有数据提交后,清空缓冲区    if (writeBuffer != null &amp;&amp; this.transientStorePool != null &amp;&amp; this.fileSize == this.committedPosition.get()) &#123;        this.transientStorePool.returnBuffer(writeBuffer);        this.writeBuffer = null;    &#125;    return this.committedPosition.get();&#125;</code></pre><p><em><strong>MappedFile#isAbleToCommit</strong></em></p><p>判断是否执行commit操作，如果文件已满返回true；如果commitLeastpages大于0，则比较writePosition与上一次提交的指针commitPosition的差值，除以OS_PAGE_SIZE得到当前脏页的数量，如果大于commitLeastPages则返回true，如果commitLeastpages小于0表示只要存在脏页就提交。</p><pre><code class="java">protected boolean isAbleToCommit(final int commitLeastPages) &#123;    //已经刷盘指针    int flush = this.committedPosition.get();    //文件写指针    int write = this.wrotePosition.get();    //写满刷盘    if (this.isFull()) &#123;        return true;    &#125;    if (commitLeastPages &gt; 0) &#123;        //文件内容达到commitLeastPages页数,则刷盘        return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) &gt;= commitLeastPages;    &#125;    return write &gt; flush;&#125;</code></pre><p><em><strong>MappedFile#commit0</strong></em></p><p>具体提交的实现，首先创建WriteBuffer区共享缓存区，然后将新创建的position回退到上一次提交的位置（commitPosition），设置limit为wrotePosition（当前最大有效数据指针），然后把commitPosition到wrotePosition的数据写入到FileChannel中，然后更新committedPosition指针为wrotePosition。commit的作用就是将MappedFile的writeBuffer中数据提交到文件通道FileChannel中。</p><pre><code class="java">protected void commit0(final int commitLeastPages) &#123;    //写指针    int writePos = this.wrotePosition.get();    //上次提交指针    int lastCommittedPosition = this.committedPosition.get();    if (writePos - this.committedPosition.get() &gt; 0) &#123;        try &#123;            //复制共享内存区域            ByteBuffer byteBuffer = writeBuffer.slice();            //设置提交位置是上次提交位置            byteBuffer.position(lastCommittedPosition);            //最大提交数量            byteBuffer.limit(writePos);            //设置fileChannel位置为上次提交位置            this.fileChannel.position(lastCommittedPosition);            //将lastCommittedPosition到writePos的数据复制到FileChannel中            this.fileChannel.write(byteBuffer);            //重置提交位置            this.committedPosition.set(writePos);        &#125; catch (Throwable e) &#123;            log.error(&quot;Error occurred when commit data to FileChannel.&quot;, e);        &#125;    &#125;&#125;</code></pre><p><em><strong>MappedFile#flush</strong></em></p><p>刷写磁盘，直接调用MappedByteBuffer或fileChannel的force方法将内存中的数据持久化到磁盘，那么flushedPosition应该等于MappedByteBuffer中的写指针；如果writeBuffer不为空，则flushPosition应该等于上一次的commit指针；因为上一次提交的数据就是进入到MappedByteBuffer中的数据；如果writeBuffer为空，数据时直接进入到MappedByteBuffer，wrotePosition代表的是MappedByteBuffer中的指针，故设置flushPosition为wrotePosition。</p><p><img src="/../imgs/blog20/flush.jpg"></p><pre><code class="java">public int flush(final int flushLeastPages) &#123;    //数据达到刷盘条件    if (this.isAbleToFlush(flushLeastPages)) &#123;        //加锁，同步刷盘        if (this.hold()) &#123;            //获得读指针            int value = getReadPosition();            try &#123;                //数据从writeBuffer提交数据到fileChannel再刷新到磁盘                if (writeBuffer != null || this.fileChannel.position() != 0) &#123;                    this.fileChannel.force(false);                &#125; else &#123;                    //从mmap刷新数据到磁盘                    this.mappedByteBuffer.force();                &#125;            &#125; catch (Throwable e) &#123;                log.error(&quot;Error occurred when force data to disk.&quot;, e);            &#125;            //更新刷盘位置            this.flushedPosition.set(value);            this.release();        &#125; else &#123;            log.warn(&quot;in flush, hold failed, flush offset = &quot; + this.flushedPosition.get());            this.flushedPosition.set(getReadPosition());        &#125;    &#125;    return this.getFlushedPosition();&#125;</code></pre><p><em><strong>MappedFile#getReadPosition</strong></em></p><p>获取当前文件最大可读指针。如果writeBuffer为空，则直接返回当前的写指针；如果writeBuffer不为空，则返回上一次提交的指针。在MappedFile设置中,只有提交了的数据（写入到MappedByteBuffer或FileChannel中的数据）才是安全的数据</p><pre><code class="java">public int getReadPosition() &#123;    //如果writeBuffer为空,刷盘的位置就是应该等于上次commit的位置,如果为空则为mmap的写指针    return this.writeBuffer == null ? this.wrotePosition.get() : this.committedPosition.get();&#125;</code></pre><p><em><strong>MappedFile#selectMappedBuffer</strong></em></p><p>查找pos到当前最大可读之间的数据，由于在整个写入期间都未曾改MappedByteBuffer的指针，如果mappedByteBuffer.slice()方法返回的共享缓存区空间为整个MappedFile，然后通过设置ByteBuffer的position为待查找的值，读取字节长度当前可读最大长度，最终返回的ByteBuffer的limit为size。整个共享缓存区的容量为（MappedFile#fileSize-pos）。故在操作SelectMappedBufferResult不能对包含在里面的ByteBuffer调用filp方法。</p><pre><code class="java">public SelectMappedBufferResult selectMappedBuffer(int pos) &#123;    //获得最大可读指针    int readPosition = getReadPosition();    //pos小于最大可读指针,并且大于0    if (pos &lt; readPosition &amp;&amp; pos &gt;= 0) &#123;        if (this.hold()) &#123;            //复制mappedByteBuffer读共享区            ByteBuffer byteBuffer = this.mappedByteBuffer.slice();            //设置读指针位置            byteBuffer.position(pos);            //获得可读范围            int size = readPosition - pos;            //设置最大刻度范围            ByteBuffer byteBufferNew = byteBuffer.slice();            byteBufferNew.limit(size);            return new SelectMappedBufferResult(this.fileFromOffset + pos, byteBufferNew, size, this);        &#125;    &#125;    return null;&#125;</code></pre><p><em><strong>MappedFile#shutdown</strong></em></p><p>MappedFile文件销毁的实现方法为public boolean destory(long intervalForcibly)，intervalForcibly表示拒绝被销毁的最大存活时间。</p><pre><code class="java">public void shutdown(final long intervalForcibly) &#123;    if (this.available) &#123;        //关闭MapedFile        this.available = false;        //设置当前关闭时间戳        this.firstShutdownTimestamp = System.currentTimeMillis();        //释放资源        this.release();    &#125; else if (this.getRefCount() &gt; 0) &#123;        if ((System.currentTimeMillis() - this.firstShutdownTimestamp) &gt;= intervalForcibly) &#123;            this.refCount.set(-1000 - this.getRefCount());            this.release();        &#125;    &#125;&#125;</code></pre><h4 id="3）TransientStorePool"><a href="#3）TransientStorePool" class="headerlink" title="3）TransientStorePool"></a>3）TransientStorePool</h4><p>短暂的存储池。RocketMQ单独创建一个MappedByteBuffer内存缓存池，用来临时存储数据，数据先写入该内存映射中，然后由commit线程定时将数据从该内存复制到与目标物理文件对应的内存映射中。RocketMQ引入该机制主要的原因是提供一种内存锁定，将当前堆外内存一直锁定在内存中，避免被进程将内存交换到磁盘。</p><p><img src="/../imgs/blog20/TransientStorePool.png"></p><pre><code class="java">private final int poolSize;//availableBuffers个数private final int fileSize;//每隔ByteBuffer大小private final Deque&lt;ByteBuffer&gt; availableBuffers;//ByteBuffer容器。双端队列</code></pre><p><em><strong>初始化</strong></em></p><pre><code class="java">public void init() &#123;    //创建poolSize个堆外内存    for (int i = 0; i &lt; poolSize; i++) &#123;        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);        final long address = ((DirectBuffer) byteBuffer).address();        Pointer pointer = new Pointer(address);        //使用com.sun.jna.Library类库将该批内存锁定,避免被置换到交换区,提高存储性能        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));        availableBuffers.offer(byteBuffer);    &#125;&#125;</code></pre><h3 id="2-4-5-实时更新消息消费队列与索引文件"><a href="#2-4-5-实时更新消息消费队列与索引文件" class="headerlink" title="2.4.5 实时更新消息消费队列与索引文件"></a>2.4.5 实时更新消息消费队列与索引文件</h3><p>消息消费队文件、消息属性索引文件都是基于CommitLog文件构建的，当消息生产者提交的消息存储在CommitLog文件中，ConsumerQueue、IndexFile需要及时更新，否则消息无法及时被消费，根据消息属性查找消息也会出现较大延迟。RocketMQ通过开启一个线程ReputMessageService来准实时转发CommitLog文件更新事件，相应的任务处理器根据转发的消息及时更新ConsumerQueue、IndexFile文件。</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png"></p><p><img src="/../imgs/blog20/%E6%9E%84%E5%BB%BA%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E9%98%9F%E5%88%97%E5%92%8C%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6.png"></p><p><em><strong>代码：DefaultMessageStore：start</strong></em></p><pre><code class="java">//设置CommitLog内存中最大偏移量this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);//启动this.reputMessageService.start();</code></pre><p><em><strong>代码：DefaultMessageStore：run</strong></em></p><pre><code class="java">public void run() &#123;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service started&quot;);    //每隔1毫秒就继续尝试推送消息到消息消费队列和索引文件    while (!this.isStopped()) &#123;        try &#123;            Thread.sleep(1);            this.doReput();        &#125; catch (Exception e) &#123;            DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><em><strong>代码：DefaultMessageStore：deReput</strong></em></p><pre><code class="java">//从result中循环遍历消息,一次读一条,创建DispatherRequest对象。for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123;    DispatchRequest dispatchRequest =                               DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false);    int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize();    if (dispatchRequest.isSuccess()) &#123;        if (size &gt; 0) &#123;            DefaultMessageStore.this.doDispatch(dispatchRequest);        &#125;    &#125;&#125;</code></pre><p><em><strong>DispatchRequest</strong></em></p><p><img src="/../imgs/blog20/DispatchRequest.png"></p><pre><code class="java">String topic; //消息主题名称int queueId;  //消息队列IDlong commitLogOffset;//消息物理偏移量int msgSize;//消息长度long tagsCode;//消息过滤tag hashCodelong storeTimestamp;//消息存储时间戳long consumeQueueOffset;//消息队列偏移量String keys;//消息索引keyboolean success;//是否成功解析到完整的消息String uniqKey;//消息唯一键int sysFlag;//消息系统标记long preparedTransactionOffset;//消息预处理事务偏移量Map&lt;String, String&gt; propertiesMap;//消息属性byte[] bitMap;//位图</code></pre><h4 id="1）转发到ConsumerQueue"><a href="#1）转发到ConsumerQueue" class="headerlink" title="1）转发到ConsumerQueue"></a>1）转发到ConsumerQueue</h4><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91%E5%88%B0%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E9%98%9F%E5%88%97.png"></p><pre><code class="java">class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher &#123;    @Override    public void dispatch(DispatchRequest request) &#123;        final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());        switch (tranType) &#123;            case MessageSysFlag.TRANSACTION_NOT_TYPE:            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:                //消息分发                DefaultMessageStore.this.putMessagePositionInfo(request);                break;            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:                break;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#putMessagePositionInfo</strong></em></p><pre><code class="java">public void putMessagePositionInfo(DispatchRequest dispatchRequest) &#123;    //获得消费队列    ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId());    //消费队列分发消息    cq.putMessagePositionInfoWrapper(dispatchRequest);&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#putMessagePositionInfo</strong></em></p><pre><code class="java">//依次将消息偏移量、消息长度、tag写入到ByteBuffer中this.byteBufferIndex.flip();this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE);this.byteBufferIndex.putLong(offset);this.byteBufferIndex.putInt(size);this.byteBufferIndex.putLong(tagsCode);//获得内存映射文件MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset);if (mappedFile != null) &#123;    //将消息追加到内存映射文件,异步输盘    return mappedFile.appendMessage(this.byteBufferIndex.array());&#125;</code></pre><h4 id="2）转发到Index"><a href="#2）转发到Index" class="headerlink" title="2）转发到Index"></a>2）转发到Index</h4><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91%E5%88%B0%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6.png"></p><pre><code class="java">class CommitLogDispatcherBuildIndex implements CommitLogDispatcher &#123;    @Override    public void dispatch(DispatchRequest request) &#123;        if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) &#123;            DefaultMessageStore.this.indexService.buildIndex(request);        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#buildIndex</strong></em></p><pre><code class="java">public void buildIndex(DispatchRequest req) &#123;    //获得索引文件    IndexFile indexFile = retryGetAndCreateIndexFile();    if (indexFile != null) &#123;        //获得文件最大物理偏移量        long endPhyOffset = indexFile.getEndPhyOffset();        DispatchRequest msg = req;        String topic = msg.getTopic();        String keys = msg.getKeys();        //如果该消息的物理偏移量小于索引文件中的最大物理偏移量,则说明是重复数据,忽略本次索引构建        if (msg.getCommitLogOffset() &lt; endPhyOffset) &#123;            return;        &#125;        final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());        switch (tranType) &#123;            case MessageSysFlag.TRANSACTION_NOT_TYPE:            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:                break;            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:                return;        &#125;                //如果消息ID不为空,则添加到Hash索引中        if (req.getUniqKey() != null) &#123;            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));            if (indexFile == null) &#123;                return;            &#125;        &#125;        //构建索引key,RocketMQ支持为同一个消息建立多个索引,多个索引键空格隔开.        if (keys != null &amp;&amp; keys.length() &gt; 0) &#123;            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);            for (int i = 0; i &lt; keyset.length; i++) &#123;                String key = keyset[i];                if (key.length() &gt; 0) &#123;                    indexFile = putKey(indexFile, msg, buildKey(topic, key));                    if (indexFile == null) &#123;                        return;                    &#125;                &#125;            &#125;        &#125;    &#125; else &#123;        log.error(&quot;build index error, stop building index&quot;);    &#125;&#125;</code></pre><h3 id="2-4-6-消息队列和索引文件恢复"><a href="#2-4-6-消息队列和索引文件恢复" class="headerlink" title="2.4.6 消息队列和索引文件恢复"></a>2.4.6 消息队列和索引文件恢复</h3><p>由于RocketMQ存储首先将消息全量存储在CommitLog文件中，然后异步生成转发任务更新ConsumerQueue和Index文件。如果消息成功存储到CommitLog文件中，转发任务未成功执行，此时消息服务器Broker由于某个愿意宕机，导致CommitLog、ConsumerQueue、IndexFile文件数据不一致。如果不加以人工修复的话，会有一部分消息即便在CommitLog中文件中存在，但由于没有转发到ConsumerQueue，这部分消息将永远复发被消费者消费。</p><p><img src="/../imgs/blog20/%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B.png"></p><p>####1）存储文件加载</p><p><em><strong>代码：DefaultMessageStore#load</strong></em></p><p>判断上一次是否异常退出。实现机制是Broker在启动时创建abort文件，在退出时通过JVM钩子函数删除abort文件。如果下次启动时存在abort文件。说明Broker时异常退出的，CommitLog与ConsumerQueue数据有可能不一致，需要进行修复。</p><pre><code class="java">//判断临时文件是否存在boolean lastExitOK = !this.isTempFileExist();//根据临时文件判断当前Broker是否异常退出private boolean isTempFileExist() &#123;    String fileName = StorePathConfigHelper        .getAbortFile(this.messageStoreConfig.getStorePathRootDir());    File file = new File(fileName);    return file.exists();&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#load</strong></em></p><pre><code class="java">//加载延时队列if (null != scheduleMessageService) &#123;    result = result &amp;&amp; this.scheduleMessageService.load();&#125;// 加载CommitLog文件result = result &amp;&amp; this.commitLog.load();// 加载消费队列文件result = result &amp;&amp; this.loadConsumeQueue();if (result) &#123;    //加载存储监测点,监测点主要记录CommitLog文件、ConsumerQueue文件、Index索引文件的刷盘点    this.storeCheckpoint =new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir()));    //加载index文件    this.indexService.load(lastExitOK);    //根据Broker是否异常退出,执行不同的恢复策略    this.recover(lastExitOK);&#125;</code></pre><p><em><strong>代码：MappedFileQueue#load</strong></em></p><p>加载CommitLog到映射文件</p><pre><code class="java">//指向CommitLog文件目录File dir = new File(this.storePath);//获得文件数组File[] files = dir.listFiles();if (files != null) &#123;    // 文件排序    Arrays.sort(files);    //遍历文件    for (File file : files) &#123;        //如果文件大小和配置文件不一致,退出        if (file.length() != this.mappedFileSize) &#123;                        return false;        &#125;        try &#123;            //创建映射文件            MappedFile mappedFile = new MappedFile(file.getPath(), mappedFileSize);            mappedFile.setWrotePosition(this.mappedFileSize);            mappedFile.setFlushedPosition(this.mappedFileSize);            mappedFile.setCommittedPosition(this.mappedFileSize);            //将映射文件添加到队列            this.mappedFiles.add(mappedFile);            log.info(&quot;load &quot; + file.getPath() + &quot; OK&quot;);        &#125; catch (IOException e) &#123;            log.error(&quot;load file &quot; + file + &quot; error&quot;, e);            return false;        &#125;    &#125;&#125;return true;</code></pre><p><em><strong>代码：DefaultMessageStore#loadConsumeQueue</strong></em></p><p>加载消息消费队列</p><pre><code class="java">//执行消费队列目录File dirLogic = new File(StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()));//遍历消费队列目录File[] fileTopicList = dirLogic.listFiles();if (fileTopicList != null) &#123;    for (File fileTopic : fileTopicList) &#123;        //获得子目录名称,即topic名称        String topic = fileTopic.getName();        //遍历子目录下的消费队列文件        File[] fileQueueIdList = fileTopic.listFiles();        if (fileQueueIdList != null) &#123;            //遍历文件            for (File fileQueueId : fileQueueIdList) &#123;                //文件名称即队列ID                int queueId;                try &#123;                    queueId = Integer.parseInt(fileQueueId.getName());                &#125; catch (NumberFormatException e) &#123;                    continue;                &#125;                //创建消费队列并加载到内存                ConsumeQueue logic = new ConsumeQueue(                    topic,                    queueId,                    StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()),            this.getMessageStoreConfig().getMapedFileSizeConsumeQueue(),                    this);                this.putConsumeQueue(topic, queueId, logic);                if (!logic.load()) &#123;                    return false;                &#125;            &#125;        &#125;    &#125;&#125;log.info(&quot;load logics queue all over, OK&quot;);return true;</code></pre><p><em><strong>代码：IndexService#load</strong></em></p><p>加载索引文件</p><pre><code class="java">public boolean load(final boolean lastExitOK) &#123;    //索引文件目录    File dir = new File(this.storePath);    //遍历索引文件    File[] files = dir.listFiles();    if (files != null) &#123;        //文件排序        Arrays.sort(files);        //遍历文件        for (File file : files) &#123;            try &#123;                //加载索引文件                IndexFile f = new IndexFile(file.getPath(), this.hashSlotNum, this.indexNum, 0, 0);                f.load();                if (!lastExitOK) &#123;                    //索引文件上次的刷盘时间小于该索引文件的消息时间戳,该文件将立即删除                    if (f.getEndTimestamp() &gt; this.defaultMessageStore.getStoreCheckpoint()                        .getIndexMsgTimestamp()) &#123;                        f.destroy(0);                        continue;                    &#125;                &#125;                //将索引文件添加到队列                log.info(&quot;load index file OK, &quot; + f.getFileName());                this.indexFileList.add(f);            &#125; catch (IOException e) &#123;                log.error(&quot;load file &#123;&#125; error&quot;, file, e);                return false;            &#125; catch (NumberFormatException e) &#123;                log.error(&quot;load file &#123;&#125; error&quot;, file, e);            &#125;        &#125;    &#125;    return true;&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#recover</strong></em></p><p>文件恢复，根据Broker是否正常退出执行不同的恢复策略</p><pre><code class="java">private void recover(final boolean lastExitOK) &#123;    //获得最大的物理便宜消费队列    long maxPhyOffsetOfConsumeQueue = this.recoverConsumeQueue();    if (lastExitOK) &#123;        //正常恢复        this.commitLog.recoverNormally(maxPhyOffsetOfConsumeQueue);    &#125; else &#123;        //异常恢复        this.commitLog.recoverAbnormally(maxPhyOffsetOfConsumeQueue);    &#125;    //在CommitLog中保存每个消息消费队列当前的存储逻辑偏移量    this.recoverTopicQueueTable();&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#recoverTopicQueueTable</strong></em></p><p>恢复ConsumerQueue后，将在CommitLog实例中保存每隔消息队列当前的存储逻辑偏移量，这也是消息中不仅存储主题、消息队列ID、还存储了消息队列的关键所在。</p><pre><code class="java">public void recoverTopicQueueTable() &#123;    HashMap&lt;String/* topic-queueid */, Long/* offset */&gt; table = new HashMap&lt;String, Long&gt;(1024);    //CommitLog最小偏移量    long minPhyOffset = this.commitLog.getMinOffset();    //遍历消费队列,将消费队列保存在CommitLog中    for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) &#123;        for (ConsumeQueue logic : maps.values()) &#123;            String key = logic.getTopic() + &quot;-&quot; + logic.getQueueId();            table.put(key, logic.getMaxOffsetInQueue());            logic.correctMinOffset(minPhyOffset);        &#125;    &#125;    this.commitLog.setTopicQueueTable(table);&#125;</code></pre><p>####2）正常恢复</p><p><em><strong>代码：CommitLog#recoverNormally</strong></em></p><pre><code class="java">public void recoverNormally(long maxPhyOffsetOfConsumeQueue) &#123;        final List&lt;MappedFile&gt; mappedFiles = this.mappedFileQueue.getMappedFiles();    if (!mappedFiles.isEmpty()) &#123;         //Broker正常停止再重启时,从倒数第三个开始恢复,如果不足3个文件,则从第一个文件开始恢复。        int index = mappedFiles.size() - 3;        if (index &lt; 0)            index = 0;        MappedFile mappedFile = mappedFiles.get(index);        ByteBuffer byteBuffer = mappedFile.sliceByteBuffer();        long processOffset = mappedFile.getFileFromOffset();        //代表当前已校验通过的offset        long mappedFileOffset = 0;        while (true) &#123;            //查找消息            DispatchRequest dispatchRequest = this.checkMessageAndReturnSize(byteBuffer, checkCRCOnRecover);            //消息长度            int size = dispatchRequest.getMsgSize();               //查找结果为true,并且消息长度大于0,表示消息正确.mappedFileOffset向前移动本消息长度            if (dispatchRequest.isSuccess() &amp;&amp; size &gt; 0) &#123;                mappedFileOffset += size;            &#125;            //如果查找结果为true且消息长度等于0,表示已到该文件末尾,如果还有下一个文件,则重置processOffset和MappedFileOffset重复查找下一个文件,否则跳出循环。            else if (dispatchRequest.isSuccess() &amp;&amp; size == 0) &#123;              index++;              if (index &gt;= mappedFiles.size()) &#123;                  // Current branch can not happen                  break;              &#125; else &#123;                  //取出每个文件                  mappedFile = mappedFiles.get(index);                  byteBuffer = mappedFile.sliceByteBuffer();                  processOffset = mappedFile.getFileFromOffset();                  mappedFileOffset = 0;                                    &#125;            &#125;            // 查找结果为false，表明该文件未填满所有消息，跳出循环，结束循环            else if (!dispatchRequest.isSuccess()) &#123;                log.info(&quot;recover physics file end, &quot; + mappedFile.getFileName());                break;            &#125;        &#125;        //更新MappedFileQueue的flushedWhere和committedWhere指针        processOffset += mappedFileOffset;        this.mappedFileQueue.setFlushedWhere(processOffset);        this.mappedFileQueue.setCommittedWhere(processOffset);        //删除offset之后的所有文件        this.mappedFileQueue.truncateDirtyFiles(processOffset);                if (maxPhyOffsetOfConsumeQueue &gt;= processOffset) &#123;            this.defaultMessageStore.truncateDirtyLogicFiles(processOffset);        &#125;    &#125; else &#123;        this.mappedFileQueue.setFlushedWhere(0);        this.mappedFileQueue.setCommittedWhere(0);        this.defaultMessageStore.destroyLogics();    &#125;&#125;</code></pre><p><em><strong>代码：MappedFileQueue#truncateDirtyFiles</strong></em></p><pre><code class="java">public void truncateDirtyFiles(long offset) &#123;    List&lt;MappedFile&gt; willRemoveFiles = new ArrayList&lt;MappedFile&gt;();    //遍历目录下文件    for (MappedFile file : this.mappedFiles) &#123;        //文件尾部的偏移量        long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize;        //文件尾部的偏移量大于offset        if (fileTailOffset &gt; offset) &#123;            //offset大于文件的起始偏移量            if (offset &gt;= file.getFileFromOffset()) &#123;                //更新wrotePosition、committedPosition、flushedPosistion                file.setWrotePosition((int) (offset % this.mappedFileSize));                file.setCommittedPosition((int) (offset % this.mappedFileSize));                file.setFlushedPosition((int) (offset % this.mappedFileSize));            &#125; else &#123;                //offset小于文件的起始偏移量,说明该文件是有效文件后面创建的,释放mappedFile占用内存,删除文件                file.destroy(1000);                willRemoveFiles.add(file);            &#125;        &#125;    &#125;    this.deleteExpiredFile(willRemoveFiles);&#125;</code></pre><p>####3）异常恢复</p><p>Broker异常停止文件恢复的实现为CommitLog#recoverAbnormally。异常文件恢复步骤与正常停止文件恢复流程基本相同，其主要差别有两个。首先，正常停止默认从倒数第三个文件开始进行恢复，而异常停止则需要从最后一个文件往前走，找到第一个消息存储正常的文件。其次，如果CommitLog目录没有消息文件，如果消息消费队列目录下存在文件，则需要销毁。</p><p><em><strong>代码：CommitLog#recoverAbnormally</strong></em></p><pre><code class="java">if (!mappedFiles.isEmpty()) &#123;    // Looking beginning to recover from which file    int index = mappedFiles.size() - 1;    MappedFile mappedFile = null;    for (; index &gt;= 0; index--) &#123;        mappedFile = mappedFiles.get(index);        //判断消息文件是否是一个正确的文件        if (this.isMappedFileMatchedRecover(mappedFile)) &#123;            log.info(&quot;recover from this mapped file &quot; + mappedFile.getFileName());            break;        &#125;    &#125;    //根据索引取出mappedFile文件    if (index &lt; 0) &#123;        index = 0;        mappedFile = mappedFiles.get(index);    &#125;    //...验证消息的合法性,并将消息转发到消息消费队列和索引文件       &#125;else&#123;    //未找到mappedFile,重置flushWhere、committedWhere都为0，销毁消息队列文件    this.mappedFileQueue.setFlushedWhere(0);    this.mappedFileQueue.setCommittedWhere(0);    this.defaultMessageStore.destroyLogics();&#125;</code></pre><h3 id="2-4-7-刷盘机制"><a href="#2-4-7-刷盘机制" class="headerlink" title="2.4.7 刷盘机制"></a>2.4.7 刷盘机制</h3><p>RocketMQ的存储是基于JDK NIO的内存映射机制（MappedByteBuffer）的，消息存储首先将消息追加到内存，再根据配置的刷盘策略在不同时间进行刷写磁盘。</p><h4 id="同步刷盘"><a href="#同步刷盘" class="headerlink" title="同步刷盘"></a>同步刷盘</h4><p>消息追加到内存后，立即将数据刷写到磁盘文件</p><p><img src="/../imgs/blog20/%E5%90%8C%E6%AD%A5%E5%88%B7%E7%9B%98%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：CommitLog#handleDiskFlush</strong></em></p><pre><code class="java">//刷盘服务final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;if (messageExt.isWaitStoreMsgOK()) &#123;    //封装刷盘请求    GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes());    //提交刷盘请求    service.putRequest(request);    //线程阻塞5秒，等待刷盘结束    boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout());    if (!flushOK) &#123;        putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT);    &#125;</code></pre><p><em><strong>GroupCommitRequest</strong></em></p><p><img src="/../imgs/blog20/GroupCommitRequest.png"></p><pre><code class="java">long nextOffset;//刷盘点偏移量CountDownLatch countDownLatch = new CountDownLatch(1);//倒计树锁存器volatile boolean flushOK = false;//刷盘结果;默认为false</code></pre><p><em><strong>代码：GroupCommitService#run</strong></em></p><pre><code class="java">public void run() &#123;    CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);    while (!this.isStopped()) &#123;        try &#123;            //线程等待10ms            this.waitForRunning(10);            //执行提交            this.doCommit();        &#125; catch (Exception e) &#123;            CommitLog.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    ...&#125;</code></pre><p><em><strong>代码：GroupCommitService#doCommit</strong></em></p><pre><code class="java">private void doCommit() &#123;    //加锁    synchronized (this.requestsRead) &#123;        if (!this.requestsRead.isEmpty()) &#123;            //遍历requestsRead            for (GroupCommitRequest req : this.requestsRead) &#123;                // There may be a message in the next file, so a maximum of                // two times the flush                boolean flushOK = false;                for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) &#123;                    flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset();                    //刷盘                    if (!flushOK) &#123;                        CommitLog.this.mappedFileQueue.flush(0);                    &#125;                &#125;                //唤醒发送消息客户端                req.wakeupCustomer(flushOK);            &#125;                        //更新刷盘监测点            long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();            if (storeTimestamp &gt; 0) &#123;               CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);            &#125;                        this.requestsRead.clear();        &#125; else &#123;            // Because of individual messages is set to not sync flush, it            // will come to this process            CommitLog.this.mappedFileQueue.flush(0);        &#125;    &#125;&#125;</code></pre><h4 id="异步刷盘"><a href="#异步刷盘" class="headerlink" title="异步刷盘"></a>异步刷盘</h4><p>在消息追加到内存后，立即返回给消息发送端。如果开启transientStorePoolEnable，RocketMQ会单独申请一个与目标物理文件（commitLog）同样大小的堆外内存，该堆外内存将使用内存锁定，确保不会被置换到虚拟内存中去，消息首先追加到堆外内存，然后提交到物理文件的内存映射中，然后刷写到磁盘。如果未开启transientStorePoolEnable，消息直接追加到物理文件直接映射文件中，然后刷写到磁盘中。</p><p><img src="/../imgs/blog20/%E5%BC%82%E6%AD%A5%E5%88%B7%E7%9B%98%E6%B5%81%E7%A8%8B.png"></p><p>开启transientStorePoolEnable后异步刷盘步骤:</p><ol><li>将消息直接追加到ByteBuffer（堆外内存）</li><li>CommitRealTimeService线程每隔200ms将ByteBuffer新追加内容提交到MappedByteBuffer中</li><li>MappedByteBuffer在内存中追加提交的内容，wrotePosition指针向后移动</li><li>commit操作成功返回，将committedPosition位置恢复</li><li>FlushRealTimeService线程默认每500ms将MappedByteBuffer中新追加的内存刷写到磁盘</li></ol><p><em><strong>代码：CommitLog$CommitRealTimeService#run</strong></em></p><p>提交线程工作机制</p><pre><code class="java">//间隔时间,默认200msint interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();//一次提交的至少页数int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();//两次真实提交的最大间隔,默认200msint commitDataThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();//上次提交间隔超过commitDataThoroughInterval,则忽略提交commitDataThoroughInterval参数,直接提交long begin = System.currentTimeMillis();if (begin &gt;= (this.lastCommitTimestamp + commitDataThoroughInterval)) &#123;    this.lastCommitTimestamp = begin;    commitDataLeastPages = 0;&#125;//执行提交操作,将待提交数据提交到物理文件的内存映射区boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);long end = System.currentTimeMillis();if (!result) &#123;    this.lastCommitTimestamp = end; // result = false means some data committed.    //now wake up flush thread.    //唤醒刷盘线程    flushCommitLogService.wakeup();&#125;if (end - begin &gt; 500) &#123;    log.info(&quot;Commit data to file costs &#123;&#125; ms&quot;, end - begin);&#125;this.waitForRunning(interval);</code></pre><p><em><strong>代码：CommitLog$FlushRealTimeService#run</strong></em></p><p>刷盘线程工作机制</p><pre><code class="java">//表示await方法等待,默认falseboolean flushCommitLogTimed = CommitLog.this.defaultMessageStore.getMessageStoreConfig().isFlushCommitLogTimed();//线程执行时间间隔int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushIntervalCommitLog();//一次刷写任务至少包含页数int flushPhysicQueueLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogLeastPages();//两次真实刷写任务最大间隔int flushPhysicQueueThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogThoroughInterval();...//距离上次提交间隔超过flushPhysicQueueThoroughInterval,则本次刷盘任务将忽略flushPhysicQueueLeastPages,直接提交long currentTimeMillis = System.currentTimeMillis();if (currentTimeMillis &gt;= (this.lastFlushTimestamp + flushPhysicQueueThoroughInterval)) &#123;    this.lastFlushTimestamp = currentTimeMillis;    flushPhysicQueueLeastPages = 0;    printFlushProgress = (printTimes++ % 10) == 0;&#125;...//执行一次刷盘前,先等待指定时间间隔if (flushCommitLogTimed) &#123;    Thread.sleep(interval);&#125; else &#123;    this.waitForRunning(interval);&#125;...long begin = System.currentTimeMillis();//刷写磁盘CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages);long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();if (storeTimestamp &gt; 0) &#123;//更新存储监测点文件的时间戳CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);</code></pre><h3 id="2-4-8-过期文件删除机制"><a href="#2-4-8-过期文件删除机制" class="headerlink" title="2.4.8 过期文件删除机制"></a>2.4.8 过期文件删除机制</h3><p>由于RocketMQ操作CommitLog、ConsumerQueue文件是基于内存映射机制并在启动的时候回加载CommitLog、ConsumerQueue目录下的所有文件，为了避免内存与磁盘的浪费，不可能将消息永久存储在消息服务器上，所以要引入一种机制来删除已过期的文件。RocketMQ顺序写CommitLog、ConsumerQueue文件，所有写操作全部落在最后一个CommitLog或者ConsumerQueue文件上，之前的文件在下一个文件创建后将不会再被更新。RocketMQ清除过期文件的方法时：如果当前文件在在一定时间间隔内没有再次被消费，则认为是过期文件，可以被删除，RocketMQ不会关注这个文件上的消息是否全部被消费。默认每个文件的过期时间为72小时，通过在Broker配置文件中设置fileReservedTime来改变过期时间，单位为小时。</p><p><em><strong>代码：DefaultMessageStore#addScheduleTask</strong></em></p><pre><code class="java">private void addScheduleTask() &#123;    //每隔10s调度一次清除文件    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;        @Override        public void run() &#123;            DefaultMessageStore.this.cleanFilesPeriodically();        &#125;    &#125;, 1000 * 60, this.messageStoreConfig.getCleanResourceInterval(), TimeUnit.MILLISECONDS);    ...&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#cleanFilesPeriodically</strong></em></p><pre><code class="java">private void cleanFilesPeriodically() &#123;    //清除存储文件    this.cleanCommitLogService.run();    //清除消息消费队列文件    this.cleanConsumeQueueService.run();&#125;</code></pre><p><em><strong>代码：DefaultMessageStore#deleteExpiredFiles</strong></em></p><pre><code class="java">private void deleteExpiredFiles() &#123;    //删除的数量    int deleteCount = 0;    //文件保留的时间    long fileReservedTime = DefaultMessageStore.this.getMessageStoreConfig().getFileReservedTime();    //删除物理文件的间隔    int deletePhysicFilesInterval = DefaultMessageStore.this.getMessageStoreConfig().getDeleteCommitLogFilesInterval();    //线程被占用,第一次拒绝删除后能保留的最大时间,超过该时间,文件将被强制删除    int destroyMapedFileIntervalForcibly = DefaultMessageStore.this.getMessageStoreConfig().getDestroyMapedFileIntervalForcibly();boolean timeup = this.isTimeToDelete();boolean spacefull = this.isSpaceToDelete();boolean manualDelete = this.manualDeleteFileSeveralTimes &gt; 0;if (timeup || spacefull || manualDelete) &#123;    ...执行删除逻辑&#125;else&#123;    ...无作为&#125;</code></pre><p>删除文件操作的条件</p><ol><li>指定删除文件的时间点，RocketMQ通过deleteWhen设置一天的固定时间执行一次删除过期文件操作，默认4点</li><li>磁盘空间如果不充足，删除过期文件</li><li>预留，手工触发。</li></ol><p><em><strong>代码：CleanCommitLogService#isSpaceToDelete</strong></em></p><p>当磁盘空间不足时执行删除过期文件</p><pre><code class="java">private boolean isSpaceToDelete() &#123;    //磁盘分区的最大使用量    double ratio = DefaultMessageStore.this.getMessageStoreConfig().getDiskMaxUsedSpaceRatio() / 100.0;    //是否需要立即执行删除过期文件操作    cleanImmediately = false;    &#123;        String storePathPhysic = DefaultMessageStore.this.getMessageStoreConfig().getStorePathCommitLog();        //当前CommitLog目录所在的磁盘分区的磁盘使用率        double physicRatio = UtilAll.getDiskPartitionSpaceUsedPercent(storePathPhysic);        //diskSpaceWarningLevelRatio:磁盘使用率警告阈值,默认0.90        if (physicRatio &gt; diskSpaceWarningLevelRatio) &#123;            boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskFull();            if (diskok) &#123;                DefaultMessageStore.log.error(&quot;physic disk maybe full soon &quot; + physicRatio + &quot;, so mark disk full&quot;);            &#125;            //diskSpaceCleanForciblyRatio:强制清除阈值,默认0.85            cleanImmediately = true;        &#125; else if (physicRatio &gt; diskSpaceCleanForciblyRatio) &#123;            cleanImmediately = true;        &#125; else &#123;            boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskOK();            if (!diskok) &#123;            DefaultMessageStore.log.info(&quot;physic disk space OK &quot; + physicRatio + &quot;, so mark disk ok&quot;);        &#125;    &#125;    if (physicRatio &lt; 0 || physicRatio &gt; ratio) &#123;        DefaultMessageStore.log.info(&quot;physic disk maybe full soon, so reclaim space, &quot; + physicRatio);        return true;    &#125;&#125;</code></pre><p><em><strong>代码：MappedFileQueue#deleteExpiredFileByTime</strong></em></p><p>执行文件销毁和删除</p><pre><code class="java">for (int i = 0; i &lt; mfsLength; i++) &#123;    //遍历每隔文件    MappedFile mappedFile = (MappedFile) mfs[i];    //计算文件存活时间    long liveMaxTimestamp = mappedFile.getLastModifiedTimestamp() + expiredTime;    //如果超过72小时,执行文件删除    if (System.currentTimeMillis() &gt;= liveMaxTimestamp || cleanImmediately) &#123;        if (mappedFile.destroy(intervalForcibly)) &#123;            files.add(mappedFile);            deleteCount++;            if (files.size() &gt;= DELETE_FILES_BATCH_MAX) &#123;                break;            &#125;            if (deleteFilesInterval &gt; 0 &amp;&amp; (i + 1) &lt; mfsLength) &#123;                try &#123;                    Thread.sleep(deleteFilesInterval);                &#125; catch (InterruptedException e) &#123;                &#125;            &#125;        &#125; else &#123;            break;        &#125;    &#125; else &#123;        //avoid deleting files in the middle        break;    &#125;&#125;</code></pre><h3 id="2-4-9-小结"><a href="#2-4-9-小结" class="headerlink" title="2.4.9 小结"></a>2.4.9 小结</h3><p>RocketMQ的存储文件包括消息文件（Commitlog）、消息消费队列文件（ConsumerQueue）、Hash索引文件（IndexFile）、监测点文件（checkPoint）、abort（关闭异常文件）。单个消息存储文件、消息消费队列文件、Hash索引文件长度固定以便使用内存映射机制进行文件的读写操作。RocketMQ组织文件以文件的起始偏移量来命令文件，这样根据偏移量能快速定位到真实的物理文件。RocketMQ基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制，异步刷盘是指在消息存储时先追加到内存映射文件，然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘。</p><p>CommitLog，消息存储文件，RocketMQ为了保证消息发送的高吞吐量，采用单一文件存储所有主题消息，保证消息存储是完全的顺序写，但这样给文件读取带来了不便，为此RocketMQ为了方便消息消费构建了消息消费队列文件，基于主题与队列进行组织，同时RocketMQ为消息实现了Hash索引，可以为消息设置索引键，根据所以能够快速从CommitLog文件中检索消息。</p><p>当消息达到CommitLog后，会通过ReputMessageService线程接近实时地将消息转发给消息消费队列文件与索引文件。为了安全起见，RocketMQ引入abort文件，记录Broker的停机是否是正常关闭还是异常关闭，在重启Broker时为了保证CommitLog文件，消息消费队列文件与Hash索引文件的正确性，分别采用不同策略来恢复文件。</p><p>RocketMQ不会永久存储消息文件、消息消费队列文件，而是启动文件过期机制并在磁盘空间不足或者默认凌晨4点删除过期文件，文件保存72小时并且在删除文件时并不会判断该消息文件上的消息是否被消费。</p><h2 id="2-5-Consumer"><a href="#2-5-Consumer" class="headerlink" title="2.5 Consumer"></a>2.5 Consumer</h2><h3 id="2-5-1-消息消费概述"><a href="#2-5-1-消息消费概述" class="headerlink" title="2.5.1 消息消费概述"></a>2.5.1 消息消费概述</h3><p>消息消费以组的模式开展，一个消费组内可以包含多个消费者，每一个消费者组可订阅多个主题，消费组之间有ff式和广播模式两种消费模式。集群模式，主题下的同一条消息只允许被其中一个消费者消费。广播模式，主题下的同一条消息，将被集群内的所有消费者消费一次。消息服务器与消费者之间的消息传递也有两种模式：推模式、拉模式。所谓的拉模式，是消费端主动拉起拉消息请求，而推模式是消息达到消息服务器后，推送给消息消费者。RocketMQ消息推模式的实现基于拉模式，在拉模式上包装一层，一个拉取任务完成后开始下一个拉取任务。</p><p>集群模式下，多个消费者如何对消息队列进行负载呢？消息队列负载机制遵循一个通用思想：一个消息队列同一个时间只允许被一个消费者消费，一个消费者可以消费多个消息队列。</p><p>RocketMQ支持局部顺序消息消费，也就是保证同一个消息队列上的消息顺序消费。不支持消息全局顺序消费，如果要实现某一个主题的全局顺序消费，可以将该主题的队列数设置为1，牺牲高可用性。</p><p>###2.5.2 消息消费初探</p><p><strong><u>消息推送模式</u></strong></p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81.png"></p><p><strong><u>消息消费重要方法</u></strong></p><pre><code class="java">void sendMessageBack(final MessageExt msg, final int delayLevel, final String brokerName)：发送消息确认Set&lt;MessageQueue&gt; fetchSubscribeMessageQueues(final String topic) :获取消费者对主题分配了那些消息队列void registerMessageListener(final MessageListenerConcurrently messageListener)：注册并发事件监听器void registerMessageListener(final MessageListenerOrderly messageListener)：注册顺序消息事件监听器void subscribe(final String topic, final String subExpression)：基于主题订阅消息，消息过滤使用表达式void subscribe(final String topic, final String fullClassName,final String filterClassSource)：基于主题订阅消息，消息过滤使用类模式void subscribe(final String topic, final MessageSelector selector) ：订阅消息，并指定队列选择器void unsubscribe(final String topic)：取消消息订阅</code></pre><p><strong><u>DefaultMQPushConsumer</u></strong></p><p><img src="/../imgs/blog20/DefaultMQPushConsumer.png"></p><pre><code class="java">//消费者组private String consumerGroup;//消息消费模式private MessageModel messageModel = MessageModel.CLUSTERING;//指定消费开始偏移量（最大偏移量、最小偏移量、启动时间戳）开始消费private ConsumeFromWhere consumeFromWhere = ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET;//集群模式下的消息队列负载策略private AllocateMessageQueueStrategy allocateMessageQueueStrategy;//订阅信息private Map&lt;String /* topic */, String /* sub expression */&gt; subscription = new HashMap&lt;String, String&gt;();//消息业务监听器private MessageListener messageListener;//消息消费进度存储器private OffsetStore offsetStore;//消费者最小线程数量private int consumeThreadMin = 20;//消费者最大线程数量private int consumeThreadMax = 20;//并发消息消费时处理队列最大跨度private int consumeConcurrentlyMaxSpan = 2000;//每1000次流控后打印流控日志private int pullThresholdForQueue = 1000;//推模式下任务间隔时间private long pullInterval = 0;//推模式下任务拉取的条数,默认32条private int pullBatchSize = 32;//每次传入MessageListener#consumerMessage中消息的数量private int consumeMessageBatchMaxSize = 1;//是否每次拉取消息都订阅消息private boolean postSubscriptionWhenPull = false;//消息重试次数,-1代表16次private int maxReconsumeTimes = -1;//消息消费超时时间private long consumeTimeout = 15;</code></pre><h3 id="2-5-3-消费者启动流程"><a href="#2-5-3-消费者启动流程" class="headerlink" title="2.5.3 消费者启动流程"></a>2.5.3 消费者启动流程</h3><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：DefaultMQPushConsumerImpl#start</strong></em></p><pre><code class="java">public synchronized void start() throws MQClientException &#123;    switch (this.serviceState) &#123;        case CREATE_JUST:                            this.defaultMQPushConsumer.getMessageModel(), this.defaultMQPushConsumer.isUnitMode());            this.serviceState = ServiceState.START_FAILED;            //检查消息者是否合法            this.checkConfig();            //构建主题订阅信息            this.copySubscription();            //设置消费者客户端实例名称为进程ID            if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123;                this.defaultMQPushConsumer.changeInstanceNameToPID();            &#125;            //创建MQClient实例            this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook);            //构建rebalanceImpl            this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup());            this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel());            this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy());            this.rebalanceImpl.setmQClientFactory(this.mQClientFactor            this.pullAPIWrapper = new PullAPIWrapper(                mQClientFactory,                this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode());            this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookLis            if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123;                this.offsetStore = this.defaultMQPushConsumer.getOffsetStore();            &#125; else &#123;                   switch (this.defaultMQPushConsumer.getMessageModel()) &#123;                                  case BROADCASTING: //消息消费广播模式,将消费进度保存在本地                       this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());                           break;                       case CLUSTERING://消息消费集群模式,将消费进度保存在远端Broker                           this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());                           break;                       default:                           break;                   &#125;                   this.defaultMQPushConsumer.setOffsetStore(this.offsetStore);               &#125;            this.offsetStore.load            //创建顺序消息消费服务            if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123;                this.consumeOrderly = true;                this.consumeMessageService =                    new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner());                //创建并发消息消费服务            &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123;                this.consumeOrderly = false;                this.consumeMessageService =                    new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner());            &#125;            //消息消费服务启动            this.consumeMessageService.start();            //注册消费者实例            boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this);                        if (!registerOK) &#123;                this.serviceState = ServiceState.CREATE_JUST;                this.consumeMessageService.shutdown();                throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup()                    + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),                    null);            //启动消费者客户端            mQClientFactory.start();            log.info(&quot;the consumer [&#123;&#125;] start OK.&quot;, this.defaultMQPushConsumer.getConsumerGroup());            this.serviceState = ServiceState.RUNNING;            break;            case RUNNING:            case START_FAILED:        case SHUTDOWN_ALREADY:            throw new MQClientException(&quot;The PushConsumer service state not OK, maybe started once, &quot;                + this.serviceState                + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),                null);        default:            break;    &#125;    this.updateTopicSubscribeInfoWhenSubscriptionChanged();    this.mQClientFactory.checkClientInBroker();    this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();    this.mQClientFactory.rebalanceImmediately();&#125;</code></pre><h3 id="2-5-4-消息拉取"><a href="#2-5-4-消息拉取" class="headerlink" title="2.5.4 消息拉取"></a>2.5.4 消息拉取</h3><p>消息消费模式有两种模式：广播模式与集群模式。广播模式比较简单，每一个消费者需要拉取订阅主题下所有队列的消息。本文重点讲解集群模式。在集群模式下，同一个消费者组内有多个消息消费者，同一个主题存在多个消费队列，消费者通过负载均衡的方式消费消息。</p><p>消息队列负载均衡，通常的作法是一个消息队列在同一个时间只允许被一个消费消费者消费，一个消息消费者可以同时消费多个消息队列。</p><h4 id="1）PullMessageService实现机制"><a href="#1）PullMessageService实现机制" class="headerlink" title="1）PullMessageService实现机制"></a>1）PullMessageService实现机制</h4><p>从MQClientInstance的启动流程中可以看出，RocketMQ使用一个单独的线程PullMessageService来负责消息的拉取。</p><p><img src="/../imgs/blog20/pullMessageService%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6.png"></p><p><em><strong>代码：PullMessageService#run</strong></em></p><pre><code class="java">public void run() &#123;    log.info(this.getServiceName() + &quot; service started&quot;);    //循环拉取消息    while (!this.isStopped()) &#123;        try &#123;            //从请求队列中获取拉取消息请求            PullRequest pullRequest = this.pullRequestQueue.take();            //拉取消息            this.pullMessage(pullRequest);        &#125; catch (InterruptedException ignored) &#123;        &#125; catch (Exception e) &#123;            log.error(&quot;Pull Message Service Run Method exception&quot;, e);        &#125;    &#125;    log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><u><strong>PullRequest</strong></u></p><p><img src="/../imgs/blog20/PullRequest.png"></p><pre><code class="java">private String consumerGroup;//消费者组private MessageQueue messageQueue;//待拉取消息队列private ProcessQueue processQueue;//消息处理队列private long nextOffset;//待拉取的MessageQueue偏移量private boolean lockedFirst = false;//是否被锁定</code></pre><p><em><strong>代码：PullMessageService#pullMessage</strong></em></p><pre><code class="java">private void pullMessage(final PullRequest pullRequest) &#123;    //获得消费者实例    final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup());    if (consumer != null) &#123;        //强转为推送模式消费者        DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer;        //推送消息        impl.pullMessage(pullRequest);    &#125; else &#123;        log.warn(&quot;No matched consumer for the PullRequest &#123;&#125;, drop it&quot;, pullRequest);    &#125;&#125;</code></pre><p>####2）ProcessQueue实现机制</p><p>ProcessQueue是MessageQueue在消费端的重现、快照。PullMessageService从消息服务器默认每次拉取32条消息，按照消息的队列偏移量顺序存放在ProcessQueue中，PullMessageService然后将消息提交到消费者消费线程池，消息成功消费后从ProcessQueue中移除。</p><p><img src="/../imgs/blog20/ProcessQueue.png"></p><p><strong><u>属性</u></strong></p><pre><code class="java">//消息容器private final TreeMap&lt;Long, MessageExt&gt; msgTreeMap = new TreeMap&lt;Long, MessageExt&gt;();//读写锁private final ReadWriteLock lockTreeMap = new ReentrantReadWriteLock();//ProcessQueue总消息树private final AtomicLong msgCount = new AtomicLong();//ProcessQueue队列最大偏移量private volatile long queueOffsetMax = 0L;//当前ProcessQueue是否被丢弃private volatile boolean dropped = false;//上一次拉取时间戳private volatile long lastPullTimestamp = System.currentTimeMillis();//上一次消费时间戳private volatile long lastConsumeTimestamp = System.currentTimeMillis();</code></pre><p><strong><u>方法</u></strong></p><pre><code class="java">//移除消费超时消息public void cleanExpiredMsg(DefaultMQPushConsumer pushConsumer)//添加消息public boolean putMessage(final List&lt;MessageExt&gt; msgs)//获取消息最大间隔public long getMaxSpan()//移除消息public long removeMessage(final List&lt;MessageExt&gt; msgs)//将consumingMsgOrderlyTreeMap中消息重新放在msgTreeMap,并清空consumingMsgOrderlyTreeMap   public void rollback() //将consumingMsgOrderlyTreeMap消息清除,表示成功处理该批消息public long commit()//重新处理该批消息public void makeMessageToCosumeAgain(List&lt;MessageExt&gt; msgs) //从processQueue中取出batchSize条消息public List&lt;MessageExt&gt; takeMessags(final int batchSize)</code></pre><h4 id="3）消息拉取基本流程"><a href="#3）消息拉取基本流程" class="headerlink" title="3）消息拉取基本流程"></a>3）消息拉取基本流程</h4><p>#####1.客户端发起拉取请求</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B.png"></p><p><em><strong>代码：DefaultMQPushConsumerImpl#pullMessage</strong></em></p><pre><code class="java">public void pullMessage(final PullRequest pullRequest) &#123;    //从pullRequest获得ProcessQueue    final ProcessQueue processQueue = pullRequest.getProcessQueue();    //如果处理队列被丢弃,直接返回    if (processQueue.isDropped()) &#123;        log.info(&quot;the pull request[&#123;&#125;] is dropped.&quot;, pullRequest.toString());        return;    &#125;    //如果处理队列未被丢弃,更新时间戳    pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis());    try &#123;        this.makeSureStateOK();    &#125; catch (MQClientException e) &#123;        log.warn(&quot;pullMessage exception, consumer state not ok&quot;, e);        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);        return;    &#125;    //如果处理队列被挂起,延迟1s后再执行    if (this.isPause()) &#123;        log.warn(&quot;consumer was paused, execute pull request later. instanceName=&#123;&#125;, group=&#123;&#125;&quot;, this.defaultMQPushConsumer.getInstanceName(), this.defaultMQPushConsumer.getConsumerGroup());        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND);        return;    &#125;    //获得最大待处理消息数量    long cachedMessageCount = processQueue.getMsgCount().get();    //获得最大待处理消息大小    long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);    //从数量进行流控    if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123;        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);        if ((queueFlowControlTimes++ % 1000) == 0) &#123;            log.warn(                &quot;the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,                this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);        &#125;        return;    &#125;    //从消息大小进行流控    if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123;        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);        if ((queueFlowControlTimes++ % 1000) == 0) &#123;            log.warn(                &quot;the cached message size exceeds the threshold &#123;&#125; MiB, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,                this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);        &#125;        return;    &#125;        //获得订阅信息         final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());        if (null == subscriptionData) &#123;            this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);            log.warn(&quot;find the consumer&#39;s subscription failed, &#123;&#125;&quot;, pullRequest);            return;        //与服务端交互,获取消息        this.pullAPIWrapper.pullKernelImpl(        pullRequest.getMessageQueue(),        subExpression,        subscriptionData.getExpressionType(),        subscriptionData.getSubVersion(),        pullRequest.getNextOffset(),        this.defaultMQPushConsumer.getPullBatchSize(),        sysFlag,        commitOffsetValue,        BROKER_SUSPEND_MAX_TIME_MILLIS,        CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND,        CommunicationMode.ASYNC,        pullCallback    );            &#125;</code></pre><p>#####2.消息服务端Broker组装消息</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%9C%8D%E5%8A%A1%E7%AB%AFBroker%E7%BB%84%E8%A3%85%E6%B6%88%E6%81%AF.png"></p><p><em><strong>代码：PullMessageProcessor#processRequest</strong></em></p><pre><code class="java">//构建消息过滤器MessageFilter messageFilter;if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123;    messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData,        this.brokerController.getConsumerFilterManager());&#125; else &#123;    messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData,        this.brokerController.getConsumerFilterManager());&#125;//调用MessageStore.getMessage查找消息final GetMessageResult getMessageResult =    this.brokerController.getMessageStore().getMessage(                    requestHeader.getConsumerGroup(), //消费组名称                    requestHeader.getTopic(),//主题名称                    requestHeader.getQueueId(), //队列ID                    requestHeader.getQueueOffset(), //待拉取偏移量                    requestHeader.getMaxMsgNums(), //最大拉取消息条数                    messageFilter//消息过滤器            );</code></pre><p><em><strong>代码：DefaultMessageStore#getMessage</strong></em></p><pre><code class="java">GetMessageStatus status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;long nextBeginOffset = offset;//查找下一次队列偏移量long minOffset = 0;//当前消息队列最小偏移量long maxOffset = 0;//当前消息队列最大偏移量GetMessageResult getResult = new GetMessageResult();final long maxOffsetPy = this.commitLog.getMaxOffset();//当前commitLog最大偏移量//根据主题名称和队列编号获取消息消费队列ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId);...minOffset = consumeQueue.getMinOffsetInQueue();maxOffset = consumeQueue.getMaxOffsetInQueue();//消息偏移量异常情况校对下一次拉取偏移量if (maxOffset == 0) &#123;//表示当前消息队列中没有消息    status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;    nextBeginOffset = nextOffsetCorrection(offset, 0);&#125; else if (offset &lt; minOffset) &#123;//待拉取消息的偏移量小于队列的其实偏移量    status = GetMessageStatus.OFFSET_TOO_SMALL;    nextBeginOffset = nextOffsetCorrection(offset, minOffset);&#125; else if (offset == maxOffset) &#123;//待拉取偏移量为队列最大偏移量    status = GetMessageStatus.OFFSET_OVERFLOW_ONE;    nextBeginOffset = nextOffsetCorrection(offset, offset);&#125; else if (offset &gt; maxOffset) &#123;//偏移量越界    status = GetMessageStatus.OFFSET_OVERFLOW_BADLY;    if (0 == minOffset) &#123;        nextBeginOffset = nextOffsetCorrection(offset, minOffset);    &#125; else &#123;        nextBeginOffset = nextOffsetCorrection(offset, maxOffset);    &#125;&#125;...//根据偏移量从CommitLog中拉取32条消息SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy);</code></pre><p><em><strong>代码：PullMessageProcessor#processRequest</strong></em></p><pre><code class="java">//根据拉取结果填充responseHeaderresponse.setRemark(getMessageResult.getStatus().name());responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset());responseHeader.setMinOffset(getMessageResult.getMinOffset());responseHeader.setMaxOffset(getMessageResult.getMaxOffset());//判断如果存在主从同步慢,设置下一次拉取任务的ID为主节点switch (this.brokerController.getMessageStoreConfig().getBrokerRole()) &#123;    case ASYNC_MASTER:    case SYNC_MASTER:        break;    case SLAVE:        if (!this.brokerController.getBrokerConfig().isSlaveReadEnable()) &#123;            response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);            responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID);        &#125;        break;&#125;...//GetMessageResult与Response的Code转换switch (getMessageResult.getStatus()) &#123;    case FOUND://成功        response.setCode(ResponseCode.SUCCESS);        break;    case MESSAGE_WAS_REMOVING://消息存放在下一个commitLog中        response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);//消息重试        break;    case NO_MATCHED_LOGIC_QUEUE://未找到队列    case NO_MESSAGE_IN_QUEUE://队列中未包含消息        if (0 != requestHeader.getQueueOffset()) &#123;            response.setCode(ResponseCode.PULL_OFFSET_MOVED);            requestHeader.getQueueOffset(),            getMessageResult.getNextBeginOffset(),            requestHeader.getTopic(),            requestHeader.getQueueId(),            requestHeader.getConsumerGroup()            );        &#125; else &#123;            response.setCode(ResponseCode.PULL_NOT_FOUND);        &#125;        break;    case NO_MATCHED_MESSAGE://未找到消息        response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);        break;    case OFFSET_FOUND_NULL://消息物理偏移量为空        response.setCode(ResponseCode.PULL_NOT_FOUND);        break;    case OFFSET_OVERFLOW_BADLY://offset越界        response.setCode(ResponseCode.PULL_OFFSET_MOVED);        // XXX: warn and notify me        log.info(&quot;the request offset: &#123;&#125; over flow badly, broker max offset: &#123;&#125;, consumer: &#123;&#125;&quot;,                requestHeader.getQueueOffset(), getMessageResult.getMaxOffset(), channel.remoteAddress());        break;    case OFFSET_OVERFLOW_ONE://offset在队列中未找到        response.setCode(ResponseCode.PULL_NOT_FOUND);        break;    case OFFSET_TOO_SMALL://offset未在队列中        response.setCode(ResponseCode.PULL_OFFSET_MOVED);        requestHeader.getConsumerGroup(),         requestHeader.getTopic(),         requestHeader.getQueueOffset(),        getMessageResult.getMinOffset(), channel.remoteAddress());        break;    default:        assert false;        break;&#125;...//如果CommitLog标记可用,并且当前Broker为主节点,则更新消息消费进度boolean storeOffsetEnable = brokerAllowSuspend;storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag;storeOffsetEnable = storeOffsetEnable    &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE;if (storeOffsetEnable) &#123;    this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel),        requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset());&#125;</code></pre><p>#####3.消息拉取客户端处理消息</p><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%A4%84%E7%90%86%E6%B6%88%E6%81%AF.png"></p><p><em><strong>代码：MQClientAPIImpl#processPullResponse</strong></em></p><pre><code class="java">private PullResult processPullResponse(    final RemotingCommand response) throws MQBrokerException, RemotingCommandException &#123;    PullStatus pullStatus = PullStatus.NO_NEW_MSG;       //判断响应结果    switch (response.getCode()) &#123;        case ResponseCode.SUCCESS:            pullStatus = PullStatus.FOUND;            break;        case ResponseCode.PULL_NOT_FOUND:            pullStatus = PullStatus.NO_NEW_MSG;            break;        case ResponseCode.PULL_RETRY_IMMEDIATELY:            pullStatus = PullStatus.NO_MATCHED_MSG;            break;        case ResponseCode.PULL_OFFSET_MOVED:            pullStatus = PullStatus.OFFSET_ILLEGAL;            break;        default:            throw new MQBrokerException(response.getCode(), response.getRemark());    &#125;    //解码响应头    PullMessageResponseHeader responseHeader =        (PullMessageResponseHeader) response.decodeCommandCustomHeader(PullMessageResponseHeader.class);    //封装PullResultExt返回    return new PullResultExt(pullStatus, responseHeader.getNextBeginOffset(), responseHeader.getMinOffset(),        responseHeader.getMaxOffset(), null, responseHeader.getSuggestWhichBrokerId(), response.getBody());&#125;</code></pre><p><u><strong>PullResult类</strong></u></p><pre><code class="java">private final PullStatus pullStatus;//拉取结果private final long nextBeginOffset;//下次拉取偏移量private final long minOffset;//消息队列最小偏移量private final long maxOffset;//消息队列最大偏移量private List&lt;MessageExt&gt; msgFoundList;//拉取的消息列表</code></pre><p><img src="/../imgs/blog20/PullStatus.png"></p><p><em><strong>代码：DefaultMQPushConsumerImpl$PullCallback#OnSuccess</strong></em></p><pre><code class="java">//将拉取到的消息存入processQueueboolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList());//将processQueue提交到consumeMessageService中供消费者消费DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(    pullResult.getMsgFoundList(),    processQueue,    pullRequest.getMessageQueue(),    dispatchToConsume);//如果pullInterval大于0,则等待pullInterval毫秒后将pullRequest对象放入到PullMessageService中的pullRequestQueue队列中if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123;    DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest,        DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval());&#125; else &#123;    DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);&#125;</code></pre><h5 id="4-消息拉取总结"><a href="#4-消息拉取总结" class="headerlink" title="4.消息拉取总结"></a>4.消息拉取总结</h5><p><img src="/../imgs/blog20/%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93.png"></p><h4 id="4）消息拉取长轮询机制分析"><a href="#4）消息拉取长轮询机制分析" class="headerlink" title="4）消息拉取长轮询机制分析"></a>4）消息拉取长轮询机制分析</h4><p>RocketMQ未真正实现消息推模式，而是消费者主动向消息服务器拉取消息，RocketMQ推模式是循环向消息服务端发起消息拉取请求，如果消息消费者向RocketMQ拉取消息时，消息未到达消费队列时，如果不启用长轮询机制，则会在服务端等待shortPollingTimeMills时间后（挂起）再去判断消息是否已经到达指定消息队列，如果消息仍未到达则提示拉取消息客户端PULL—NOT—FOUND（消息不存在）；如果开启长轮询模式，RocketMQ一方面会每隔5s轮询检查一次消息是否可达，同时一有消息达到后立马通知挂起线程再次验证消息是否是自己感兴趣的消息，如果是则从CommitLog文件中提取消息返回给消息拉取客户端，否则直到挂起超时，超时时间由消息拉取方在消息拉取是封装在请求参数中，PUSH模式为15s，PULL模式通过DefaultMQPullConsumer#setBrokerSuspendMaxTimeMillis设置。RocketMQ通过在Broker客户端配置longPollingEnable为true来开启长轮询模式。</p><p><em><strong>代码：PullMessageProcessor#processRequest</strong></em></p><pre><code class="java">//当没有拉取到消息时，通过长轮询方式继续拉取消息case ResponseCode.PULL_NOT_FOUND:    if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123;        long pollingTimeMills = suspendTimeoutMillisLong;        if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;            pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();        &#125;        String topic = requestHeader.getTopic();        long offset = requestHeader.getQueueOffset();        int queueId = requestHeader.getQueueId();        //构建拉取请求对象        PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,            this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);        //处理拉取请求        this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);        response = null;        break;    &#125;</code></pre><p><strong><u>PullRequestHoldService方式实现长轮询</u></strong></p><p><em><strong>代码：PullRequestHoldService#suspendPullRequest</strong></em></p><pre><code class="java">//将拉取消息请求，放置在ManyPullRequest集合中public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123;    String key = this.buildKey(topic, queueId);    ManyPullRequest mpr = this.pullRequestTable.get(key);    if (null == mpr) &#123;        mpr = new ManyPullRequest();        ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr);        if (prev != null) &#123;            mpr = prev;        &#125;    &#125;    mpr.addPullRequest(pullRequest);&#125;</code></pre><p><em><strong>代码：PullRequestHoldService#run</strong></em></p><pre><code class="java">public void run() &#123;    log.info(&quot;&#123;&#125; service started&quot;, this.getServiceName());    while (!this.isStopped()) &#123;        try &#123;            //如果开启长轮询每隔5秒判断消息是否到达            if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;                this.waitForRunning(5 * 1000);            &#125; else &#123;                //没有开启长轮询,每隔1s再次尝试              this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills());            &#125;            long beginLockTimestamp = this.systemClock.now();            this.checkHoldRequest();            long costTime = this.systemClock.now() - beginLockTimestamp;            if (costTime &gt; 5 * 1000) &#123;                log.info(&quot;[NOTIFYME] check hold request cost &#123;&#125; ms.&quot;, costTime);            &#125;        &#125; catch (Throwable e) &#123;            log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    log.info(&quot;&#123;&#125; service end&quot;, this.getServiceName());&#125;</code></pre><p><em><strong>代码：PullRequestHoldService#checkHoldRequest</strong></em></p><pre><code class="java">//遍历拉取任务private void checkHoldRequest() &#123;    for (String key : this.pullRequestTable.keySet()) &#123;        String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR);        if (2 == kArray.length) &#123;            String topic = kArray[0];            int queueId = Integer.parseInt(kArray[1]);            //获得消息偏移量            final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId);            try &#123;                //通知有消息达到                this.notifyMessageArriving(topic, queueId, offset);            &#125; catch (Throwable e) &#123;                log.error(&quot;check hold request failed. topic=&#123;&#125;, queueId=&#123;&#125;&quot;, topic, queueId, e);            &#125;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：PullRequestHoldService#notifyMessageArriving</strong></em></p><pre><code class="java">//如果拉取消息偏移大于请求偏移量,如果消息匹配调用executeRequestWhenWakeup处理消息if (newestOffset &gt; request.getPullFromThisOffset()) &#123;    boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode,        new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap));    // match by bit map, need eval again when properties is not null.    if (match &amp;&amp; properties != null) &#123;        match = request.getMessageFilter().isMatchedByCommitLog(null, properties);    &#125;    if (match) &#123;        try &#123;            this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),                request.getRequestCommand());        &#125; catch (Throwable e) &#123;            log.error(&quot;execute request when wakeup failed.&quot;, e);        &#125;        continue;    &#125;&#125;//如果过期时间超时,则不继续等待将直接返回给客户端消息未找到if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123;    try &#123;        this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),            request.getRequestCommand());    &#125; catch (Throwable e) &#123;        log.error(&quot;execute request when wakeup failed.&quot;, e);    &#125;    continue;&#125;</code></pre><p>如果开启了长轮询机制，PullRequestHoldService会每隔5s被唤醒去尝试检测是否有新的消息的到来才给客户端响应，或者直到超时才给客户端进行响应，消息实时性比较差，为了避免这种情况，RocketMQ引入另外一种机制：当消息到达时唤醒挂起线程触发一次检查。</p><p><strong><u>DefaultMessageStore$ReputMessageService机制</u></strong></p><p><em><strong>代码：DefaultMessageStore#start</strong></em></p><pre><code class="java">//长轮询入口this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);this.reputMessageService.start();</code></pre><p><em><strong>代码：DefaultMessageStore$ReputMessageService#run</strong></em></p><pre><code class="java">public void run() &#123;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service started&quot;);    while (!this.isStopped()) &#123;        try &#123;            Thread.sleep(1);            //长轮询核心逻辑代码入口            this.doReput();        &#125; catch (Exception e) &#123;            DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);        &#125;    &#125;    DefaultMessageStore.log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><em><strong>代码：DefaultMessageStore$ReputMessageService#deReput</strong></em></p><pre><code class="java">//当新消息达到是,进行通知监听器进行处理if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole()    &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123;    DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());&#125;</code></pre><p><em><strong>代码：NotifyMessageArrivingListener#arriving</strong></em></p><pre><code class="java">public void arriving(String topic, int queueId, long logicOffset, long tagsCode,    long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123;    this.pullRequestHoldService.notifyMessageArriving(topic, queueId, logicOffset, tagsCode,        msgStoreTime, filterBitMap, properties);&#125;</code></pre><h3 id="2-5-5-消息队列负载与重新分布机制"><a href="#2-5-5-消息队列负载与重新分布机制" class="headerlink" title="2.5.5 消息队列负载与重新分布机制"></a>2.5.5 消息队列负载与重新分布机制</h3><p>RocketMQ消息队列重新分配是由RebalanceService线程来实现。一个MQClientInstance持有一个RebalanceService实现，并随着MQClientInstance的启动而启动。</p><p><em><strong>代码：RebalanceService#run</strong></em></p><pre><code class="java">public void run() &#123;    log.info(this.getServiceName() + &quot; service started&quot;);    //RebalanceService线程默认每隔20s执行一次mqClientFactory.doRebalance方法    while (!this.isStopped()) &#123;        this.waitForRunning(waitInterval);        this.mqClientFactory.doRebalance();    &#125;    log.info(this.getServiceName() + &quot; service end&quot;);&#125;</code></pre><p><em><strong>代码：MQClientInstance#doRebalance</strong></em></p><pre><code class="java">public void doRebalance() &#123;    //MQClientInstance遍历以注册的消费者,对消费者执行doRebalance()方法    for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123;        MQConsumerInner impl = entry.getValue();        if (impl != null) &#123;            try &#123;                impl.doRebalance();            &#125; catch (Throwable e) &#123;                log.error(&quot;doRebalance exception&quot;, e);            &#125;        &#125;    &#125;&#125;</code></pre><p><em><strong>代码：RebalanceImpl#doRebalance</strong></em></p><pre><code class="java">//遍历订阅消息对每个主题的订阅的队列进行重新负载public void doRebalance(final boolean isOrder) &#123;    Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner();    if (subTable != null) &#123;        for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123;            final String topic = entry.getKey();            try &#123;                this.rebalanceByTopic(topic, isOrder);            &#125; catch (Throwable e) &#123;                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;                    log.warn(&quot;rebalanceByTopic Exception&quot;, e);                &#125;            &#125;        &#125;    &#125;    this.truncateMessageQueueNotMyTopic();&#125;</code></pre><p><em><strong>代码：RebalanceImpl#rebalanceByTopic</strong></em></p><pre><code class="java">//从主题订阅消息缓存表中获取主题的队列信息Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);//查找该主题订阅组所有的消费者IDList&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);//给消费者重新分配队列if (mqSet != null &amp;&amp; cidAll != null) &#123;    List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;();    mqAll.addAll(mqSet);    Collections.sort(mqAll);    Collections.sort(cidAll);    AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;    List&lt;MessageQueue&gt; allocateResult = null;    try &#123;        allocateResult = strategy.allocate(            this.consumerGroup,            this.mQClientFactory.getClientId(),            mqAll,            cidAll);    &#125; catch (Throwable e) &#123;        log.error(&quot;AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName=&#123;&#125;&quot;, strategy.getName(),            e);        return;    &#125;</code></pre><p>RocketMQ默认提供5中负载均衡分配算法</p><pre><code class="java">AllocateMessageQueueAveragely:平均分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q2,q3c2:q4,q5,a6c3:q7,q8AllocateMessageQueueAveragelyByCircle:平均轮询分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q4,q7c2:q2,q5,a8c3:q3,q6</code></pre><p>注意：消息队列的分配遵循一个消费者可以分配到多个队列，但同一个消息队列只会分配给一个消费者，故如果出现消费者个数大于消息队列数量，则有些消费者无法消费消息。</p><h3 id="2-5-6-消息消费过程"><a href="#2-5-6-消息消费过程" class="headerlink" title="2.5.6 消息消费过程"></a>2.5.6 消息消费过程</h3><p>PullMessageService负责对消息队列进行消息拉取，从远端服务器拉取消息后将消息存储ProcessQueue消息队列处理队列中，然后调用ConsumeMessageService#submitConsumeRequest方法进行消息消费，使用线程池来消费消息，确保了消息拉取与消息消费的解耦。ConsumeMessageService支持顺序消息和并发消息，核心类图如下：</p><p><img src="/../imgs/blog20/ConsumeMessageService.png"></p><p><strong><u>并发消息消费</u></strong></p><p><em><strong>代码：ConsumeMessageConcurrentlyService#submitConsumeRequest</strong></em></p><pre><code class="java">//消息批次单次final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize();//msgs.size()默认最多为32条。//如果msgs.size()小于consumeBatchSize,则直接将拉取到的消息放入到consumeRequest,然后将consumeRequest提交到消费者线程池中if (msgs.size() &lt;= consumeBatchSize) &#123;    ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue);    try &#123;        this.consumeExecutor.submit(consumeRequest);    &#125; catch (RejectedExecutionException e) &#123;        this.submitConsumeRequestLater(consumeRequest);    &#125;&#125;else&#123;//如果拉取的消息条数大于consumeBatchSize,则对拉取消息进行分页       for (int total = 0; total &lt; msgs.size(); ) &#123;               List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize);               for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123;                   if (total &lt; msgs.size()) &#123;                       msgThis.add(msgs.get(total));                   &#125; else &#123;                       break;                   &#125;                          ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue);               try &#123;                   this.consumeExecutor.submit(consumeRequest);               &#125; catch (RejectedExecutionException e) &#123;                   for (; total &lt; msgs.size(); total++) &#123;                       msgThis.add(msgs.get(total));                               this.submitConsumeRequestLater(consumeRequest);               &#125;           &#125;&#125;</code></pre><p><em><strong>代码：ConsumeMessageConcurrentlyService$ConsumeRequest#run</strong></em></p><pre><code class="java">//检查processQueue的dropped,如果为true,则停止该队列消费。if (this.processQueue.isDropped()) &#123;    log.info(&quot;the message queue not be able to consume, because it&#39;s dropped. group=&#123;&#125; &#123;&#125;&quot;, ConsumeMessageConcurrentlyService.this.consumerGroup, this.messageQueue);    return;&#125;...//执行消息处理的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123;    consumeMessageContext = new ConsumeMessageContext();    consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace());    consumeMessageContext.setConsumerGroup(defaultMQPushConsumer.getConsumerGroup());    consumeMessageContext.setProps(new HashMap&lt;String, String&gt;());    consumeMessageContext.setMq(messageQueue);    consumeMessageContext.setMsgList(msgs);    consumeMessageContext.setSuccess(false);    ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext);&#125;...//调用应用程序消息监听器的consumeMessage方法,进入到具体的消息消费业务处理逻辑status = listener.consumeMessage(Collections.unmodifiableList(msgs), context);//执行消息处理后的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123;    consumeMessageContext.setStatus(status.toString());    consumeMessageContext.setSuccess(ConsumeConcurrentlyStatus.CONSUME_SUCCESS == status);    ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext);&#125;</code></pre><h3 id="2-5-7-定时消息机制"><a href="#2-5-7-定时消息机制" class="headerlink" title="2.5.7 定时消息机制"></a>2.5.7 定时消息机制</h3><p>定时消息是消息发送到Broker后，并不立即被消费者消费而是要等到特定的时间后才能被消费，RocketMQ并不支持任意的时间精度，如果要支持任意时间精度定时调度，不可避免地需要在Broker层做消息排序，再加上持久化方面的考量，将不可避免的带来巨大的性能消耗，所以RocketMQ只支持特定级别的延迟消息。消息延迟级别在Broker端通过messageDelayLevel配置，默认为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，delayLevel&#x3D;1表示延迟消息1s,delayLevel&#x3D;2表示延迟5s,依次类推。</p><p>RocketMQ定时消息实现类为ScheduleMessageService，该类在DefaultMessageStore中创建。通过在DefaultMessageStore中调用load方法加载该类并调用start方法启动。</p><p><em><strong>代码：ScheduleMessageService#load</strong></em></p><pre><code class="java">//加载延迟消息消费进度的加载与delayLevelTable的构造。延迟消息的进度默认存储路径为/store/config/delayOffset.jsonpublic boolean load() &#123;    boolean result = super.load();    result = result &amp;&amp; this.parseDelayLevel();    return result;&#125;</code></pre><p><em><strong>代码：ScheduleMessageService#start</strong></em></p><pre><code class="java">//遍历延迟队列创建定时任务,遍历延迟级别，根据延迟级别level从offsetTable中获取消费队列的消费进度。如果不存在，则使用0for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123;    Integer level = entry.getKey();    Long timeDelay = entry.getValue();    Long offset = this.offsetTable.get(level);    if (null == offset) &#123;        offset = 0L;    &#125;    if (timeDelay != null) &#123;        this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME);    &#125;&#125;//每隔10s持久化一次延迟队列的消息消费进度this.timer.scheduleAtFixedRate(new TimerTask() &#123;    @Override    public void run() &#123;        try &#123;            if (started.get()) ScheduleMessageService.this.persist();        &#125; catch (Throwable e) &#123;            log.error(&quot;scheduleAtFixedRate flush exception&quot;, e);        &#125;    &#125;&#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval());</code></pre><p><strong><u>调度机制</u></strong></p><p>ScheduleMessageService的start方法启动后，会为每一个延迟级别创建一个调度任务，每一个延迟级别对应SCHEDULE_TOPIC_XXXX主题下的一个消息消费队列。定时调度任务的实现类为DeliverDelayedMessageTimerTask，核心实现方法为executeOnTimeup</p><p><em><strong>代码：ScheduleMessageService$DeliverDelayedMessageTimerTask#executeOnTimeup</strong></em></p><pre><code class="java">//根据队列ID与延迟主题查找消息消费队列ConsumeQueue cq =    ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(SCHEDULE_TOPIC,        delayLevel2QueueId(delayLevel));...//根据偏移量从消息消费队列中获取当前队列中所有有效的消息SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset);...//遍历ConsumeQueue,解析消息队列中消息for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123;    long offsetPy = bufferCQ.getByteBuffer().getLong();    int sizePy = bufferCQ.getByteBuffer().getInt();    long tagsCode = bufferCQ.getByteBuffer().getLong();    if (cq.isExtAddr(tagsCode)) &#123;        if (cq.getExt(tagsCode, cqExtUnit)) &#123;            tagsCode = cqExtUnit.getTagsCode();        &#125; else &#123;            //can&#39;t find ext content.So re compute tags code.            log.error(&quot;[BUG] can&#39;t find consume queue extend file content!addr=&#123;&#125;, offsetPy=&#123;&#125;, sizePy=&#123;&#125;&quot;,                tagsCode, offsetPy, sizePy);            long msgStoreTime = defaultMessageStore.getCommitLog().pickupStoreTimestamp(offsetPy, sizePy);            tagsCode = computeDeliverTimestamp(delayLevel, msgStoreTime);        &#125;    &#125;    long now = System.currentTimeMillis();    long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode);        ...    //根据消息偏移量与消息大小,从CommitLog中查找消息.      MessageExt msgExt =   ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(       offsetPy, sizePy);&#125; </code></pre><h3 id="2-5-8-顺序消息"><a href="#2-5-8-顺序消息" class="headerlink" title="2.5.8 顺序消息"></a>2.5.8 顺序消息</h3><p>顺序消息实现类是org.apache.rocketmq.client.impl.consumer.ConsumeMessageOrderlyService</p><p><em><strong>代码：ConsumeMessageOrderlyService#start</strong></em></p><pre><code class="java">public void start() &#123;    //如果消息模式为集群模式，启动定时任务，默认每隔20s执行一次锁定分配给自己的消息消费队列    if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123;        this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                ConsumeMessageOrderlyService.this.lockMQPeriodically();            &#125;        &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS);    &#125;&#125;</code></pre><p><em><strong>代码：ConsumeMessageOrderlyService#submitConsumeRequest</strong></em></p><pre><code class="java">//构建消息任务,并提交消费线程池中public void submitConsumeRequest(    final List&lt;MessageExt&gt; msgs,    final ProcessQueue processQueue,    final MessageQueue messageQueue,    final boolean dispathToConsume) &#123;    if (dispathToConsume) &#123;        ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue);        this.consumeExecutor.submit(consumeRequest);    &#125;&#125;</code></pre><p><em><strong>代码：ConsumeMessageOrderlyService$ConsumeRequest#run</strong></em></p><pre><code class="java">//如果消息队列为丢弃,则停止本次消费任务if (this.processQueue.isDropped()) &#123;    log.warn(&quot;run, the message queue not be able to consume, because it&#39;s dropped. &#123;&#125;&quot;, this.messageQueue);    return;&#125;//从消息队列中获取一个对象。然后消费消息时先申请独占objLock锁。顺序消息一个消息消费队列同一时刻只会被一个消费线程池处理final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue);synchronized (objLock) &#123;    ...&#125;</code></pre><h3 id="2-5-9-小结"><a href="#2-5-9-小结" class="headerlink" title="2.5.9 小结"></a>2.5.9 小结</h3><p>RocketMQ消息消费方式分别为集群模式、广播模式。</p><p>消息队列负载由RebalanceService线程默认每隔20s进行一次消息队列负载，根据当前消费者组内消费者个数与主题队列数量按照某一种负载算法进行队列分配，分配原则为同一个消费者可以分配多个消息消费队列，同一个消息消费队列同一个时间只会分配给一个消费者。</p><p>消息拉取由PullMessageService线程根据RebalanceService线程创建的拉取任务进行拉取，默认每次拉取32条消息，提交给消费者消费线程后继续下一次消息拉取。如果消息消费过慢产生消息堆积会触发消息消费拉取流控。 </p><p>并发消息消费指消费线程池中的线程可以并发对同一个消息队列的消息进行消费，消费成功后，取出消息队列中最小的消息偏移量作为消息消费进度偏移量存储在于消息消费进度存储文件中，集群模式消息消费进度存储在Broker（消息服务器），广播模式消息消费进度存储在消费者端。</p><p>RocketMQ不支持任意精度的定时调度消息，只支持自定义的消息延迟级别，例如1s、2s、5s等，可通过在broker配置文件中设置messageDelayLevel。</p><p>顺序消息一般使用集群模式，是指对消息消费者内的线程池中的线程对消息消费队列只能串行消费。并并发消息消费最本质的区别是消息消费时必须成功锁定消息消费队列，在Broker端会存储消息消费队列的锁占用情况。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ消费者负载均衡</title>
      <link href="/2023/06/19/blog19/"/>
      <url>/2023/06/19/blog19/</url>
      
        <content type="html"><![CDATA[<h1 id="消费者负载均衡"><a href="#消费者负载均衡" class="headerlink" title="消费者负载均衡"></a>消费者负载均衡</h1><p>消费者从 Apache RocketMQ 获取消息消费时，通过消费者负载均衡策略，可将主题内的消息分配给指定消费者分组中的多个消费者共同分担，提高消费并发能力和消费者的水平扩展能力。本文介绍 Apache RocketMQ 消费者的负载均衡策略。</p><h2 id="背景信息"><a href="#背景信息" class="headerlink" title="背景信息"></a>背景信息</h2><p>了解消费者负载均衡策略，可以帮助您解决以下问题：</p><ul><li>消息消费处理的容灾策略：您可以根据消费者负载均衡策略，明确当局部节点出现故障时，消息如何进行消费重试和容灾切换。</li><li>消息消费的顺序性机制：通过消费者负载均衡策略，您可以进一步了解消息消费时，如何保证同一消息组内消息的先后顺序。</li><li>消息分配的水平拆分策略：了解消费者负载均衡策略，您可以明确消息消费压力如何被分配到不同节点，有针对性地进行流量迁移和水平扩缩容。</li></ul><h2 id="广播消费和共享消费"><a href="#广播消费和共享消费" class="headerlink" title="广播消费和共享消费"></a>广播消费和共享消费</h2><p>在 Apache RocketMQ 领域模型中，同一条消息支持被多个消费者分组订阅，同时，对于每个消费者分组可以初始化多个消费者。您可以根据消费者分组和消费者的不同组合，实现以下两种不同的消费效果：<img src="/../imgs/blog19/consumemode-74d53c59b3266f1f633b1392f5a0f279.png" alt="消费方式"></p><ul><li><p><strong>消费组间广播消费</strong> ：如上图所示，每个消费者分组只初始化唯一一个消费者，每个消费者可消费到消费者分组内所有的消息，各消费者分组都订阅相同的消息，以此实现单客户端级别的广播一对多推送效果。</p><p>该方式一般可用于网关推送、配置推送等场景。</p></li><li><p><strong>消费组内共享消费</strong> ：如上图所示，每个消费者分组下初始化了多个消费者，这些消费者共同分担消费者分组内的所有消息，实现消费者分组内流量的水平拆分和均衡负载。</p><p>该方式一般可用于微服务解耦场景。</p></li></ul><h2 id="什么是消费者负载均衡"><a href="#什么是消费者负载均衡" class="headerlink" title="什么是消费者负载均衡"></a>什么是消费者负载均衡</h2><p>如上文所述，消费组间广播消费场景下，每个消费者分组内只有一个消费者，因此不涉及消费者的负载均衡。</p><p>消费组内共享消费场景下，消费者分组内多个消费者共同分担消息，消息按照哪种逻辑分配给哪个消费者，就是由消费者负载均衡策略所决定的。</p><p>根据消费者类型的不同，消费者负载均衡策略分为以下两种模式：</p><ul><li><a href="https://rocketmq.apache.org/zh/docs/featureBehavior/08consumerloadbalance#section-x2b-2cu-gpf">消息粒度负载均衡</a>：PushConsumer和SimpleConsumer默认负载策略</li><li><a href="https://rocketmq.apache.org/zh/docs/featureBehavior/08consumerloadbalance#section-n9m-6xy-y77">队列粒度负载均衡</a>：PullConsumer默认负载策略</li></ul><h2 id="消息粒度负载均衡"><a href="#消息粒度负载均衡" class="headerlink" title="消息粒度负载均衡"></a>消息粒度负载均衡</h2><p><strong>使用范围</strong></p><p>对于PushConsumer和SimpleConsumer类型的消费者，默认且仅使用消息粒度负载均衡策略。</p><p>备注</p><p>上述说明是指5.0 SDK下，PushConsumer默认使用消息粒度负载均衡，对于3.x&#x2F;4.x等Remoting协议SDK 仍然使用了队列粒度负载均衡。业务集成如无特殊需求，建议使用新版本机制。</p><p><strong>策略原理</strong></p><p>消息粒度负载均衡策略中，同一消费者分组内的多个消费者将按照消息粒度平均分摊主题中的所有消息，即同一个队列中的消息，可被平均分配给多个消费者共同消费。 <img src="/../imgs/blog19/clustermode-dfd781d08bc0c69111841bda537aa302.png" alt="消息粒度负载"></p><p>如上图所示，消费者分组Group A中有三个消费者A1、A2和A3，这三个消费者将共同消费主题中同一队列Queue1中的多条消息。 <strong>注意</strong> 消息粒度负载均衡策略保证同一个队列的消息可以被多个消费者共同处理，但是该策略使用的消息分配算法结果是随机的，并不能指定消息被哪一个特定的消费者处理。</p><p>消息粒度的负载均衡机制，是基于内部的单条消息确认语义实现的。消费者获取某条消息后，服务端会将该消息加锁，保证这条消息对其他消费者不可见，直到该消息消费成功或消费超时。因此，即使多个消费者同时消费同一队列的消息，服务端也可保证消息不会被多个消费者重复消费。</p><p><strong>顺序消息负载机制</strong></p><p>在顺序消息中，消息的顺序性指的是同一消息组内的多个消息之间的先后顺序。因此，顺序消息场景下，消息粒度负载均衡策略还需要保证同一消息组内的消息，按照服务端存储的先后顺序进行消费。不同消费者处理同一个消息组内的消息时，会严格按照先后顺序锁定消息状态，确保同一消息组的消息串行消费。 <img src="/../imgs/blog19/fifoinclustermode-60b2f917ab49333f93029cee178b13f0.png" alt="顺序消息负载策略"></p><p>如上图所述，队列Queue1中有4条顺序消息，这4条消息属于同一消息组G1，存储顺序由M1到M4。在消费过程中，前面的消息M1、M2被消费者Consumer A1处理时，只要消费状态没有提交，消费者A2是无法并行消费后续的M3、M4消息的，必须等前面的消息提交消费状态后才能消费后面的消息。</p><p><strong>策略特点</strong></p><p>相对于队列粒度负载均衡策略，消息粒度负载均衡策略有以下特点：</p><ul><li>消费分摊更均衡传统队列级的负载均衡策略中，如果队列数量和消费者数量不均衡，则可能会出现部分消费者空闲，或部分消费者处理过多消息的情况。消息粒度负载均衡策略无需关注消费者和队列的相对数量，能够更均匀地分摊消息。</li><li>对非对等消费者更友好对于线上生产环境，由于网络机房分区延迟、消费者物理资源规格不一致等原因，消费者的处理能力可能会不一致，如果按照队列分配消息，则可能出现部分消费者消息堆积、部分消费者空闲的情况。消息粒度负载均衡策略按需分配，消费者处理任务更均衡。</li><li>队列分配运维更方便传统基于绑定队列的负载均衡策略，必须保证队列数量大于等于消费者数量，以免产生部分消费者获取不到队列出现空转的情况，而消息粒度负载均衡策略则无需关注队列数。</li></ul><p><strong>适用场景</strong></p><p>消息粒度消费负载均衡策略下，同一队列内的消息离散地分布于多个消费者，适用于绝大多数在线事件处理的场景。只需要基本的消息处理能力，对消息之间没有批量聚合的诉求。而对于流式处理、聚合计算场景，需要明确地对消息进行聚合、批处理时，更适合使用队列粒度的负载均衡策略。</p><p><strong>使用示例</strong></p><p>消息粒度负载均衡策略不需要额外设置，对于PushConsumer和SimpleConsumer消费者类型默认启用。</p><pre><code class="java">SimpleConsumer simpleConsumer = null;        //消费示例一：使用PushConsumer消费普通消息，只需要在消费监听器处理即可，无需关注消息负载均衡。        MessageListener messageListener = new MessageListener() &#123;            @Override            public ConsumeResult consume(MessageView messageView) &#123;                System.out.println(messageView);                //根据消费结果返回状态。                return ConsumeResult.SUCCESS;            &#125;        &#125;;        //消费示例二：使用SimpleConsumer消费普通消息，主动获取消息处理并提交。会按照订阅的主题自动获取，无需关注消息负载均衡。        List&lt;MessageView&gt; messageViewList = null;        try &#123;            messageViewList = simpleConsumer.receive(10, Duration.ofSeconds(30));            messageViewList.forEach(messageView -&gt; &#123;                System.out.println(messageView);                //消费处理完成后，需要主动调用ACK提交消费结果。                try &#123;                    simpleConsumer.ack(messageView);                &#125; catch (ClientException e) &#123;                    e.printStackTrace();                &#125;            &#125;);        &#125; catch (ClientException e) &#123;            //如果遇到系统流控等原因造成拉取失败，需要重新发起获取消息请求。            e.printStackTrace();        &#125;            </code></pre><h2 id="队列粒度负载均衡"><a href="#队列粒度负载均衡" class="headerlink" title="队列粒度负载均衡"></a>队列粒度负载均衡</h2><p><strong>使用范围</strong></p><p>对于历史版本（服务端4.x&#x2F;3.x版本）的消费者，包括PullConsumer、DefaultPushConsumer、DefaultPullConsumer、LitePullConsumer等，默认且仅能使用队列粒度负载均衡策略。</p><p><strong>策略原理</strong></p><p>队列粒度负载均衡策略中，同一消费者分组内的多个消费者将按照队列粒度消费消息，即每个队列仅被一个消费者消费。 <img src="/../imgs/blog19/clusterqueuemode-ce4f88dc594c1237ba95db2fa9146b8c.png" alt="队列级负载均衡原理"></p><p>如上图所示，主题中的三个队列Queue1、Queue2、Queue3被分配给消费者分组中的两个消费者，每个队列只能分配给一个消费者消费，该示例中由于队列数大于消费者数，因此，消费者A2被分配了两个队列。若队列数小于消费者数量，可能会出现部分消费者无绑定队列的情况。</p><p>队列粒度的负载均衡，基于队列数量、消费者数量等运行数据进行统一的算法分配，将每个队列绑定到特定的消费者，然后每个消费者按照取消息&gt;提交消费位点&gt;持久化消费位点的消费语义处理消息，取消息过程不提交消费状态，因此，为了避免消息被多个消费者重复消费，每个队列仅支持被一个消费者消费。</p><p>备注</p><p>队列粒度负载均衡策略保证同一个队列仅被一个消费者处理，该策略的实现依赖消费者和服务端的信息协商机制，Apache RocketMQ 并不能保证协商结果完全强一致。因此，在消费者数量、队列数量发生变化时，可能会出现短暂的队列分配结果不一致，从而导致少量消息被重复处理。</p><p><strong>策略特点</strong></p><p>相对于消息粒度负载均衡策略，队列粒度负载均衡策略分配粒度较大，不够灵活。但该策略在流式处理场景下有天然优势，能够保证同一队列的消息被相同的消费者处理，对于批量处理、聚合处理更友好。</p><p><strong>适用场景</strong></p><p>队列粒度负载均衡策略适用于流式计算、数据聚合等需要明确对消息进行聚合、批处理的场景。</p><p><strong>使用示例</strong></p><p>队列粒度负载均衡策略不需要额外设置，对于历史版本（服务端4.x&#x2F;3.x版本）的消费者类型PullConsumer默认启用。</p><p>具体示例代码，请访问<a href="https://github.com/apache/rocketmq/blob/develop/example/src/main/java/org/apache/rocketmq/example/simple/LitePullConsumerAssign.java">RocketMQ代码库</a>获取。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ事务消息</title>
      <link href="/2023/06/19/blog18/"/>
      <url>/2023/06/19/blog18/</url>
      
        <content type="html"><![CDATA[<h1 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h1><p>事务消息为 Apache RocketMQ 中的高级特性消息，本文为您介绍事务消息的应用场景、功能原理、使用限制、使用方法和使用建议。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p><strong>分布式事务的诉求</strong></p><p>分布式系统调用的特点为一个核心业务逻辑的执行，同时需要调用多个下游业务进行处理。因此，如何保证核心业务和多个下游业务的执行结果完全一致，是分布式事务需要解决的主要问题。 <img src="/../imgs/blog18/tradetrans01-636d42fb6584de6c51692d0889af5c2d.png" alt="事务消息诉求"></p><p>以电商交易场景为例，用户支付订单这一核心操作的同时会涉及到下游物流发货、积分变更、购物车状态清空等多个子系统的变更。当前业务的处理分支包括：</p><ul><li>主分支订单系统状态更新：由未支付变更为支付成功。</li><li>物流系统状态新增：新增待发货物流记录，创建订单物流记录。</li><li>积分系统状态变更：变更用户积分，更新用户积分表。</li><li>购物车系统状态变更：清空购物车，更新用户购物车记录。</li></ul><p><strong>传统XA事务方案：性能不足</strong></p><p>为了保证上述四个分支的执行结果一致性，典型方案是基于XA协议的分布式事务系统来实现。将四个调用分支封装成包含四个独立事务分支的大事务。基于XA分布式事务的方案可以满足业务处理结果的正确性，但最大的缺点是多分支环境下资源锁定范围大，并发度低，随着下游分支的增加，系统性能会越来越差。</p><p><strong>基于普通消息方案：一致性保障困难</strong></p><p>将上述基于XA事务的方案进行简化，将订单系统变更作为本地事务，剩下的系统变更作为普通消息的下游来执行，事务分支简化成普通消息+订单表事务，充分利用消息异步化的能力缩短链路，提高并发度。 <img src="/../imgs/blog18/transwithnormal-f7d951385520fc18aea8d85f0cd86c27.png" alt="普通消息方案"></p><p>该方案中消息下游分支和订单系统变更的主分支很容易出现不一致的现象，例如：</p><ul><li>消息发送成功，订单没有执行成功，需要回滚整个事务。</li><li>订单执行成功，消息没有发送成功，需要额外补偿才能发现不一致。</li><li>消息发送超时未知，此时无法判断需要回滚订单还是提交订单变更。</li></ul><p><strong>基于Apache RocketMQ分布式事务消息：支持最终一致性</strong></p><p>上述普通消息方案中，普通消息和订单事务无法保证一致的原因，本质上是由于普通消息无法像单机数据库事务一样，具备提交、回滚和统一协调的能力。</p><p>而基于Apache RocketMQ实现的分布式事务消息功能，在普通消息基础上，支持二阶段的提交能力。将二阶段提交和本地事务绑定，实现全局提交结果的一致性。 <img src="/../imgs/blog18/tradewithtrans-25be17fcdedb8343a0d2633e693d126d.png" alt="事务消息"></p><p>Apache RocketMQ事务消息的方案，具备高性能、可扩展、业务开发简单的优势。具体事务消息的原理和流程，请参见下文的功能原理。</p><h2 id="功能原理"><a href="#功能原理" class="headerlink" title="功能原理"></a>功能原理</h2><p><strong>什么是事务消息</strong></p><p>事务消息是 Apache RocketMQ 提供的一种高级消息类型，支持在分布式场景下保障消息生产和本地事务的最终一致性。</p><p><strong>事务消息处理流程</strong></p><p>事务消息交互流程如下图所示。<img src="/../imgs/blog18/transflow-0b07236d124ddb814aeaf5f6b5f3f72c.png" alt="事务消息"></p><ol><li>生产者将消息发送至Apache RocketMQ服务端。</li><li>Apache RocketMQ服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息被标记为”暂不能投递”，这种状态下的消息即为半事务消息。</li><li>生产者开始执行本地事务逻辑。</li><li>生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：<ul><li>二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。</li><li>二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。</li></ul></li><li>在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 <strong>说明</strong> 服务端回查的间隔时间和最大回查次数，请参见<a href="https://rocketmq.apache.org/zh/docs/introduction/03limits">参数限制</a>。</li><li>生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li><li>生产者根据检查到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。</li></ol><p><strong>事务消息生命周期</strong> <img src="/../imgs/blog18/lifecyclefortrans-fe4a49f1c9fdae5d590a64546722036f.png" alt="事务消息"></p><ul><li>初始化：半事务消息被生产者构建并完成初始化，待发送到服务端的状态。</li><li>事务待提交：半事务消息被发送到服务端，和普通消息不同，并不会直接被服务端持久化，而是会被单独存储到事务存储系统中，等待第二阶段本地事务返回执行结果后再提交。此时消息对下游消费者不可见。</li><li>消息回滚：第二阶段如果事务执行结果明确为回滚，服务端会将半事务消息回滚，该事务消息流程终止。</li><li>提交待消费：第二阶段如果事务执行结果明确为提交，服务端会将半事务消息重新存储到普通存储系统中，此时消息对下游消费者可见，等待被消费者获取并消费。</li><li>消费中：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。 此时服务端会等待消费者完成消费并提交消费结果，如果一定时间后没有收到消费者的响应，Apache RocketMQ会对消息进行重试处理。具体信息，请参见<a href="https://rocketmq.apache.org/zh/docs/featureBehavior/10consumerretrypolicy">消费重试</a>。</li><li>消费提交：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。 Apache RocketMQ默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。</li><li>消息删除：Apache RocketMQ按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。更多信息，请参见<a href="https://rocketmq.apache.org/zh/docs/featureBehavior/11messagestorepolicy">消息存储和清理机制</a>。</li></ul><h2 id="使用限制"><a href="#使用限制" class="headerlink" title="使用限制"></a>使用限制</h2><p><strong>消息类型一致性</strong></p><p>事务消息仅支持在 MessageType 为 Transaction 的主题内使用，即事务消息只能发送至类型为事务消息的主题中，发送的消息的类型必须和主题的类型一致。</p><p><strong>消费事务性</strong></p><p>Apache RocketMQ 事务消息保证本地主分支事务和下游消息发送事务的一致性，但不保证消息消费结果和上游事务的一致性。因此需要下游业务分支自行保证消息正确处理，建议消费端做好<a href="https://rocketmq.apache.org/zh/docs/featureBehavior/10consumerretrypolicy">消费重试</a>，如果有短暂失败可以利用重试机制保证最终处理成功。</p><p><strong>中间状态可见性</strong></p><p>Apache RocketMQ 事务消息为最终一致性，即在消息提交到下游消费端处理完成之前，下游分支和上游事务之间的状态会不一致。因此，事务消息仅适合接受异步执行的事务场景。</p><p><strong>事务超时机制</strong></p><p>Apache RocketMQ 事务消息的命周期存在超时机制，即半事务消息被生产者发送服务端后，如果在指定时间内服务端无法确认提交或者回滚状态，则消息默认会被回滚。</p><h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><p><strong>创建主题</strong></p><p>Apache RocketMQ 5.0版本下创建主题操作，推荐使用mqadmin工具，需要注意的是，对于消息类型需要通过属性参数添加。示例如下：</p><pre><code class="shell">sh mqadmin updateTopic -n &lt;nameserver_address&gt; -t &lt;topic_name&gt; -c &lt;cluster_name&gt; -a +message.type=Transaction</code></pre><p><strong>发送消息</strong></p><p>事务消息相比普通消息发送时需要修改以下几点：</p><ul><li>发送事务消息前，需要开启事务并关联本地的事务执行。</li><li>为保证事务一致性，在构建生产者时，必须设置事务检查器和预绑定事务消息发送的主题列表，客户端内置的事务检查器会对绑定的事务主题做异常状态恢复。</li></ul><p><strong>创建事务主题</strong></p><p><em>NORMAL类型Topic不支持TRANSACTION类型消息，生产消息会报错。</em></p><pre><code class="bash">./bin/mqadmin updatetopic -n localhost:9876 -t TestTopic -c DefaultCluster -a +message.type=TRANSACTION</code></pre><ul><li>-c 集群名称</li><li>-t Topic名称</li><li>-n nameserver地址</li><li>-a 额外属性，本例给主题添加了<code>message.type</code>为<code>TRANSACTION</code>的属性用来支持事务消息</li></ul><p>以Java语言为例，使用事务消息示例参考如下：</p><pre><code class="java">    //演示demo，模拟订单表查询服务，用来确认订单事务是否提交成功。    private static boolean checkOrderById(String orderId) &#123;        return true;    &#125;    //演示demo，模拟本地事务的执行结果。    private static boolean doLocalTransaction() &#123;        return true;    &#125;    public static void main(String[] args) throws ClientException &#123;        ClientServiceProvider provider = new ClientServiceProvider();        MessageBuilder messageBuilder = new MessageBuilder();        //构造事务生产者：事务消息需要生产者构建一个事务检查器，用于检查确认异常半事务的中间状态。        Producer producer = provider.newProducerBuilder()                .setTransactionChecker(messageView -&gt; &#123;                    /**                     * 事务检查器一般是根据业务的ID去检查本地事务是否正确提交还是回滚，此处以订单ID属性为例。                     * 在订单表找到了这个订单，说明本地事务插入订单的操作已经正确提交；如果订单表没有订单，说明本地事务已经回滚。                     */                    final String orderId = messageView.getProperties().get(&quot;OrderId&quot;);                    if (Strings.isNullOrEmpty(orderId)) &#123;                        // 错误的消息，直接返回Rollback。                        return TransactionResolution.ROLLBACK;                    &#125;                    return checkOrderById(orderId) ? TransactionResolution.COMMIT : TransactionResolution.ROLLBACK;                &#125;)                .build();        //开启事务分支。        final Transaction transaction;        try &#123;            transaction = producer.beginTransaction();        &#125; catch (ClientException e) &#123;            e.printStackTrace();            //事务分支开启失败，直接退出。            return;        &#125;        Message message = messageBuilder.setTopic(&quot;topic&quot;)                //设置消息索引键，可根据关键字精确查找某条消息。                .setKeys(&quot;messageKey&quot;)                //设置消息Tag，用于消费端根据指定Tag过滤消息。                .setTag(&quot;messageTag&quot;)                //一般事务消息都会设置一个本地事务关联的唯一ID，用来做本地事务回查的校验。                .addProperty(&quot;OrderId&quot;, &quot;xxx&quot;)                //消息体。                .setBody(&quot;messageBody&quot;.getBytes())                .build();        //发送半事务消息        final SendReceipt sendReceipt;        try &#123;            sendReceipt = producer.send(message, transaction);        &#125; catch (ClientException e) &#123;            //半事务消息发送失败，事务可以直接退出并回滚。            return;        &#125;        /**         * 执行本地事务，并确定本地事务结果。         * 1. 如果本地事务提交成功，则提交消息事务。         * 2. 如果本地事务提交失败，则回滚消息事务。         * 3. 如果本地事务未知异常，则不处理，等待事务消息回查。         *         */        boolean localTransactionOk = doLocalTransaction();        if (localTransactionOk) &#123;            try &#123;                transaction.commit();            &#125; catch (ClientException e) &#123;                // 业务可以自身对实时性的要求选择是否重试，如果放弃重试，可以依赖事务消息回查机制进行事务状态的提交。                e.printStackTrace();            &#125;        &#125; else &#123;            try &#123;                transaction.rollback();            &#125; catch (ClientException e) &#123;                // 建议记录异常信息，回滚异常时可以无需重试，依赖事务消息回查机制进行事务状态的提交。                e.printStackTrace();            &#125;        &#125;    &#125;</code></pre><h2 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h2><p><strong>避免大量未决事务导致超时</strong></p><p>Apache RocketMQ支持在事务提交阶段异常的情况下发起事务回查，保证事务一致性。但生产者应该尽量避免本地事务返回未知结果。大量的事务检查会导致系统性能受损，容易导致事务处理延迟。</p><p><strong>正确处理”进行中”的事务</strong></p><p>消息回查时，对于正在进行中的事务不要返回Rollback或Commit结果，应继续保持Unknown的状态。 一般出现消息回查时事务正在处理的原因为：事务执行较慢，消息回查太快。解决方案如下：</p><ul><li>将第一次事务回查时间设置较大一些，但可能导致依赖回查的事务提交延迟较大。</li><li>程序能正确识别正在进行中的事务。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内存屏障</title>
      <link href="/2023/06/18/blog17/"/>
      <url>/2023/06/18/blog17/</url>
      
        <content type="html"><![CDATA[<h2 id="初识volatile"><a href="#初识volatile" class="headerlink" title="初识volatile"></a>初识volatile</h2><p>Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。<br>这个概念听起来有些抽象，我们先看下面一个示例：</p><pre><code class="text">package com.zwx.concurrent;public class VolatileDemo &#123;    public static boolean finishFlag = false;    public static void main(String[] args) throws InterruptedException &#123;        new Thread(()-&gt;&#123;            int i = 0;            while (!finishFlag)&#123;                i++;            &#125;        &#125;,&quot;t1&quot;).start();        Thread.sleep(1000);//确保t1先进入while循环后主线程才修改finishFlag        finishFlag = true;    &#125;&#125;</code></pre><p>这里运行之后他t1线程中的while循环是停不下来的，因为我们是在主线程修改了finishFlag的值，而此值对t1线程不可见，如果我们把变量finishFlag加上volatile修饰:</p><pre><code class="text">public static volatile boolean finishFlag = false;</code></pre><p>这时候再去运行就会发现while循环很快就可以停下来了。<br>从这个例子中我们可以知道<strong>volatile可以解决线程间变量可见性问题</strong>。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。</p><h2 id="volatile如何保证可见性"><a href="#volatile如何保证可见性" class="headerlink" title="volatile如何保证可见性"></a>volatile如何保证可见性</h2><p>利用工具hsdis，打印出汇编指令，可以发现，加了volatile修饰之后打印出来的汇编指令多了下面一行：</p><p><img src="/../imgs/blog17/v2-dbb6b3be2159ff96baaf7738422ba37d_720w.webp" alt="img"></p><p>lock是一种控制指令，在多处理器环境下，lock 汇编指令可以基于总线锁或者缓存锁的机制来达到可见性的一个效果。</p><h2 id="可见性的本质"><a href="#可见性的本质" class="headerlink" title="可见性的本质"></a>可见性的本质</h2><h2 id="硬件层面"><a href="#硬件层面" class="headerlink" title="硬件层面"></a>硬件层面</h2><p>线程是CPU调度的最小单元，线程设计的目的最终仍然是更充分的利用计算机处理的效能，但是绝大部分的运算任务不能只依靠处理器“计算”就能完成，处理器还需要与内存交互，比如读取运算数据、存储运算结果，这个 I&#x2F;O 操作是很难消除的。而由于计算机的存储设备与处理器的运算速度差距非常大，所以现代计算机系统都会增加一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存和处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中。<br>查看我们个人电脑的配置可以看到，CPU有L1,L2,L3三级缓存,大致粗略的结构如下图所示:</p><p><img src="/../imgs/blog17/v2-ac2a8ea5a4d6da53a25317de508b93a5_720w.webp" alt="img"></p><p>从上图可以知道，L1和L2缓存为各个CPU独有，而有了高速缓存的存在以后，每个 CPU 的处理过程是，先将计算需要用到的数据缓存在 CPU 高速缓存中，在 CPU进行计算时，直接从高速缓存中读取数据并且在计算完成之后写入到缓存中。在整个运算过程完成后，再把缓存中的数据同步到主内存。<br>由于在多 CPU 中，每个线程可能会运行在不同的 CPU 内，并且每个线程拥有自己的高速缓存。同一份数据可能会被缓存到多个 CPU 中，如果在不同 CPU 中运行的不同线程看到同一份内存的缓存值不一样就会存在缓存不一致的问题，那么怎么解决缓存一致性问题呢？CPU层面提供了两种解决方法：<strong>总线锁</strong>和<strong>缓存锁</strong></p><h2 id="总线锁"><a href="#总线锁" class="headerlink" title="总线锁"></a>总线锁</h2><p>总线锁，简单来说就是，在多CPU下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个 LOCK#信号，这个信号使得其他处理器无法通过总线来访问到共享内存中的数据，总线锁定把 CPU 和内存之间的通信锁住了(CPU和内存之间通过总线进行通讯)，这使得锁定期间，其他处理器不能操作其他内存地址的数据。然而这种做法的代价显然太大，那么如何优化呢？优化的办法就是降低锁的粒度，所以CPU就引入了缓存锁。</p><h2 id="缓存锁"><a href="#缓存锁" class="headerlink" title="缓存锁"></a>缓存锁</h2><p>缓存锁的核心机制是基于缓存一致性协议来实现的，一个处理器的缓存回写到内存会导致其他处理器的缓存无效，IA-32处理器和Intel 64处理器使用MESI实现缓存一致性协议(注意，<strong>缓存一致性协议不仅仅是通过MESI实现的，不同处理器实现了不同的缓存一致性协议</strong>)</p><h2 id="MESI（缓存一致性协议）"><a href="#MESI（缓存一致性协议）" class="headerlink" title="MESI（缓存一致性协议）"></a>MESI（缓存一致性协议）</h2><p>MESI是一种比较常用的缓存一致性协议，MESI表示缓存行的四种状态，分别是：<br>1、M(Modify) 表示共享数据只缓存在当前 CPU 缓存中，并且是被修改状态，也就是缓存的数据和主内存中的数据不一致<br>2、E(Exclusive) 表示缓存的独占状态，数据只缓存在当前CPU缓存中，并且没有被修改<br>3、S(Shared) 表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致<br>4、I(Invalid) 表示缓存已经失效<br>在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且也监听(snoop)其它CPU的读写操作。<br>对于 MESI 协议，从 CPU 读写角度来说会遵循以下原则：<br><strong>CPU读请求</strong>：缓存处于 M、E、S 状态都可以被读取，I 状态CPU 只能从主存中读取数据<br><strong>CPU写请求</strong>：缓存处于 M、E 状态才可以被写。对于S状态的写，需要将其他CPU中缓存行置为无效才行。</p><h2 id="CPU工作流程"><a href="#CPU工作流程" class="headerlink" title="CPU工作流程"></a>CPU工作流程</h2><p>使用总线锁和缓存锁机制之后，CPU 对于内存的操作大概可以抽象成下面这样的结构。从而达到缓存一致性效果：</p><p><img src="/../imgs/blog17/v2-70c17b191e415d8c836f69756ea390c0_720w.webp" alt="img"></p><h2 id="MESI协议带来的问题"><a href="#MESI协议带来的问题" class="headerlink" title="MESI协议带来的问题"></a>MESI协议带来的问题</h2><p>MESI协议虽然可以实现缓存的一致性，但是也会存在一些问题：就是各个CPU缓存行的状态是通过消息传递来进行的。如果CPU0要对一个在缓存中共享的变量进行写入，首先需要发送一个失效的消息给到其他缓存了该数据的 CPU。并且要等到他们的确认回执。CPU0在这段时间内都会处于阻塞状态。为了避免阻塞带来的资源浪费。CPU中又引入了store bufferes：</p><p><img src="/../imgs/blog17/v2-bd53c745fd2151e273a7d5975ac58089_720w.webp" alt="img"></p><p>如上图，CPU0 只需要在写入共享数据时，直接把数据写入到 store bufferes中，同时发送invalidate消息，然后继续去处理其他指令（异步） 当收到其他所有 CPU 发送了invalidate acknowledge消息时，再将store bufferes中的数据数据存储至缓存行中，最后再从缓存行同步到主内存。但是这种优化就会带来了可见性问题，也可以认为是CPU的乱序执行引起的或者说是指令重排序(指令重排序不仅仅在CPU层面存在，编译器层面也存在指令重排序)。<br>我们通过下面一个简单的示例来看一下指令重排序带来的问题。</p><pre><code class="text">package com.zwx.concurrent;public class ReSortDemo &#123;    int value;    boolean isFinish;    void cpu0()&#123;        value = 10;//S-&gt;I状态，将value写入store bufferes，通知其他CPU当前value的缓存失效        isFinish=true;//E状态    &#125;    void cpu1()&#123;        if (isFinish)&#123;//true            System.out.println(value == 10);//可能为false        &#125;    &#125;&#125;</code></pre><p>这时候理论上当isFinish为true时，value也要等于10，然而由于当value修改为10之后，发送消息通知其他CPU还没有收到响应时，当前CPU0继续执行了isFinish&#x3D;true，所以就可能存在isFinsh为true时，而value并不等于10的问题。<br>我们想一想，其实从硬件层面很难去知道软件层面上的这种前后依赖关系，所以没有办法通过某种手段自动去解决，故而CPU层面就提供了内存屏障(Memory Barrier，Intel称之为 Memory Fence),使得软件层面可以决定在适当的地方来插入内存屏障来禁止指令重排序。</p><h2 id="CPU层面的内存屏障"><a href="#CPU层面的内存屏障" class="headerlink" title="CPU层面的内存屏障"></a>CPU层面的内存屏障</h2><p>CPU内存屏障主要分为以下三类：<br>**写屏障(Store Memory Barrier)**：告诉处理器在写屏障之前的所有已经存储在存储缓存(store bufferes)中的数据同步到主内存，简单来说就是使得写屏障之前的指令的结果对写屏障之后的读或者写是可见的。<br>**读屏障(Load Memory Barrier)**：处理器在读屏障之后的读操作,都在读屏障之后执行。配合写屏障，使得写屏障之前的内存更新对于读屏障之后的读操作是可见的。<br>**全屏障(Full Memory Barrier)**：确保屏障前的内存读写操作的结果提交到内存之后，再执行屏障后的读写操作。<br>这些概念听起来可能有点模糊，我们通过将上面的例子改写一下来说明：</p><pre><code class="text">package com.zwx.concurrent;public class ReSortDemo &#123;    int value;    boolean isFinish;    void cpu0()&#123;        value = 10;//S-&gt;I状态，将value写入store bufferes，通知其他CPU当前value的缓存失效        storeMemoryBarrier();//伪代码，插入一个写屏障，使得value=10这个值强制写入主内存        isFinish=true;//E状态    &#125;    void cpu1()&#123;        if (isFinish)&#123;//true            loadMemoryBarrier();//伪代码，插入一个读屏障，强制cpu1从主内存中获取最新数据            System.out.println(value == 10);//true        &#125;    &#125;    void storeMemoryBarrier()&#123;//写屏障    &#125;    void loadMemoryBarrier()&#123;//读屏障    &#125;&#125;</code></pre><p>通过以上内存屏障，我们就可以防止了指令重排序，得到我们预期的结果。<br>总的来说，内存屏障的作用可以通过防止 CPU 对内存的乱序访问来保证共享数据在多线程并行执行下的可见性，但是这个屏障怎么来加呢？回到最开始我们讲 volatile关键字的代码，这个关键字会生成一个 lock 的汇编指令，这个就相当于实现了一种内存屏障。接下来我们进入volatile原理分析的正题</p><h2 id="JVM层面"><a href="#JVM层面" class="headerlink" title="JVM层面"></a>JVM层面</h2><p>在JVM层面，定义了一种抽象的内存模型(JMM)来规范并控制重排序，从而解决可见性问题。</p><h2 id="JMM-Java内存模型"><a href="#JMM-Java内存模型" class="headerlink" title="JMM(Java内存模型)"></a>JMM(Java内存模型)</h2><p>JMM全称是Java Memory Model(Java内存模型),什么是JMM呢？通过前面的分析发现，导致可见性问题的根本原因是缓存以及指令重排序。 而JMM 实际上就是提供了合理的禁用缓存以及禁止重排序的方法。所以<strong>JMM最核心的价值在于解决可见性和有序性</strong>。<br>JMM属于语言级别的抽象内存模型，可以简单理解为对硬件模型的抽象，它定义了共享内存中多线程程序读写操作的行为规范，通过这些规则来规范对内存的读写操作从而保证指令的正确性，它解决了CPU 多级缓存、处理器优化、指令重排序导致的内存访问问题，保证了并发场景下的可见性。<br>需要注意的是，JMM并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序，也就是说在JMM中，也会存在缓存一致性问题和指令重排序问题。只是JMM把底层的问题抽象到JVM层面，再基于CPU层面提供的内存屏障指令，以及限制编译器的重排序来解决并发问题。</p><h2 id="JMM抽象模型结构"><a href="#JMM抽象模型结构" class="headerlink" title="JMM抽象模型结构"></a>JMM抽象模型结构</h2><p>JMM 抽象模型分为主内存、工作内存；主内存是所有线程共享的，一般是实例对象、静态字段、数组对象等存储在堆内存中的变量。工作内存是每个线程独占的，线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量，线程之间的共享变量值的传递都是基于主内存来完成，可以抽象为下图：</p><p><img src="/../imgs/blog17/v2-73fdde2b306840cdba458748dc1092ba_720w.webp" alt="img"></p><h2 id="JMM如何解决可见性问题"><a href="#JMM如何解决可见性问题" class="headerlink" title="JMM如何解决可见性问题"></a>JMM如何解决可见性问题</h2><p>从JMM的抽象模型结构图来看，如果线程A与线程B之间要通信的话，必须要经历下面2个步骤。<br>1）线程A把本地内存A中更新过的共享变量刷新到主内存中去。<br>2）线程B到主内存中去读取线程A之前已更新过的共享变量。<br>下面通过示意图来说明这两个步骤：</p><p><img src="/../imgs/blog17/v2-f7939f8a4fcc07624718f417bf320021_720w.webp" alt="img"></p><p>结合上图，假设初始时，这3个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存 A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内 存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。<strong>JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。</strong></p><h2 id="编译器的指令重排序"><a href="#编译器的指令重排序" class="headerlink" title="编译器的指令重排序"></a>编译器的指令重排序</h2><p>综合上面从硬件层面和JVM层面的分析，我们知道在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型：<br>1）<strong>编译器优化的重排序</strong>。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。<br>2）<strong>指令级并行的重排序</strong>。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。<br>3）<strong>内存系统的重排序</strong>。由于处理器使用缓存和读&#x2F;写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。<br>从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序，如下图：</p><p><img src="/../imgs/blog17/v2-f1f9a499565d9286778775e0d1a502e9_720w.webp" alt="img"></p><p>其中2和3属于处理器重排序(前面硬件层面已经分析过了)。而这些重排序都可能会导致可见性问题（编译器和处理器在重排序时会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序，编译器会遵守happens-before规则和as-if-serial语义）。<br>对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排 序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。<strong>JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证</strong>。正是因为volatile的这个特性，所以单例模式中可以通过volatile关键字来解决双重检查锁(DCL)写法中所存在的问题。</p><h2 id="JMM层面的内存屏障"><a href="#JMM层面的内存屏障" class="headerlink" title="JMM层面的内存屏障"></a>JMM层面的内存屏障</h2><p>在JMM 中把内存屏障分为四类：</p><p><img src="/../imgs/blog17/v2-dd126df57da384b42693fe00c8a85451_720w.webp" alt="img"></p><p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多数处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。</p><h2 id="happens-before规则"><a href="#happens-before规则" class="headerlink" title="happens-before规则"></a>happens-before规则</h2><p>happens-before表示的是前一个操作的结果对于后续操作是可见的，它是一种表达多个线程之间对于内存的可见性。所以我们可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在happens-before关系。这两个操作可以是同一个线程，也可以是不同的线程，如果想详细了解happens-before规则，可以点击这里。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>并发编程中有三大特性：<strong>原子性</strong>、<strong>可见性</strong>、<strong>有序性</strong>，volatile通过内存屏障禁止指令重排序，主要遵循以下三个规则：</p><ol><li>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</li><li>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</li><li>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</li></ol><p>为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略：</p><ul><li><strong>在每个volatile写操作的前面插入一个StoreStore屏障</strong>。</li><li><strong>在每个volatile写操作的后面插入一个StoreLoad屏障</strong>。</li><li><strong>在每个volatile读操作的后面插入一个LoadLoad屏障</strong>。</li><li><strong>在每个volatile读操作的后面插入一个LoadStore屏障</strong>。</li></ul><p>最后需要特别提一下原子性，Java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的写操作具有原子性。当JVM在这种处理器上运行时，可能会把一个64位long&#x2F;double型变量的写操作拆分为两个32位的写操作来执行，这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。<br>锁的语义决定了临界区代码的执行具有原子性。但是因为一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入，所以<strong>即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读&#x2F;写就具有原子性。但是多个volatile操作或类似于i++这种复合操作，这些操作整体上不具有原子性</strong>。针对于复合操作如i++这种，如果要保证原子性，需要通过synchronized关键字或者加其他锁来处理。<br>注意：在JSR-133之前的旧内存模型中，一个64位long&#x2F;double型变量的读&#x2F;写操作可以被拆分为两个32位的读&#x2F;写操作来执行。从JSR-133内存模型开始（即从JDK5开始），仅仅只允许把一个64位long&#x2F;double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR-133中都必须具有原子性（即任意读操作必须要在单个读事务中执行）。</p><blockquote><p>作者：双子孤狼<br>原文链接：<a href="https://link.zhihu.com/?target=https://blog.csdn.net/zwx900102/article/details/106306915">https://blog.csdn.net/zwx900102</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MyBatis的动态SQL实现原理</title>
      <link href="/2023/06/17/blog16/"/>
      <url>/2023/06/17/blog16/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>MyBatis</strong>提供了强大的动态<strong>SQL</strong>语句生成功能，以应对复杂的业务场景，本篇文章将结合<strong>MyBatis</strong>解析<strong>SQL</strong>语句的过程对<strong>MyBatis</strong>中对&lt;<strong>if**&gt;，&lt;**where**&gt;，&lt;**foreach**&gt;等动态</strong>SQL**标签的支持进行分析。</p><p><strong>MyBatis</strong>版本：<strong>3.5.6</strong></p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="一-XML文档中的节点概念"><a href="#一-XML文档中的节点概念" class="headerlink" title="一. XML文档中的节点概念"></a>一. XML文档中的节点概念</h3><p>在分析<strong>MyBatis</strong>如何支持<strong>SQL</strong>语句之前，本小节先分析<strong>XML</strong>文档中的节点概念。<strong>XML</strong>文档中的每个成分都是一个节点，<strong>DOM</strong>对<strong>XML</strong>节点的规定如下所示。</p><ul><li>整个文档是一个<strong>文档节点</strong>；</li><li>每个<strong>XML</strong>标签是一个<strong>元素节点</strong>；</li><li>包含在元素节点中的文本是<strong>文本节点</strong>。</li></ul><p>以一个<strong>XML</strong>文档进行说明，如下所示。</p><pre><code class="xml">xml复制代码&lt;provinces&gt;    &lt;province name=&quot;四川&quot;&gt;        &lt;capital&gt;成都&lt;/capital&gt;    &lt;/province&gt;    &lt;province name=&quot;湖北&quot;&gt;        &lt;capital&gt;武汉&lt;/capital&gt;    &lt;/province&gt;&lt;/provinces&gt;</code></pre><p>如上所示，整个<strong>XML</strong>文档是一个文档节点，这个文档节点有一个子节点，就是&lt;**provinces**&gt;元素节点，&lt;**provinces**&gt;元素节点有五个子节点，分别是：</p><ol><li>文本节点；</li><li>&lt;**province**&gt;元素节点；</li><li>文本节点，</li><li>&lt;**province**&gt;元素节点；</li><li>文本节点。</li></ol><p>注意，在&lt;**provinces**&gt;元素节点的子节点中的文本节点的文本值均是<code>\n</code>，表示换行符。</p><p>同样，&lt;**province**&gt;元素节点有三个子节点，分别是：</p><ol><li>文本节点；</li><li>&lt;**capital**&gt;元素节点；</li><li>文本节点。</li></ol><p>这里的文本节点的文本值也是<code>\n</code>。</p><p>然后&lt;<strong>capital**&gt;元素节点只有一个子节点，为一个文本节点。节点的子节点之间互为兄弟节点，例如&lt;**provinces**&gt;元素的五个子节点之间互为兄弟节点，</strong>name**为”<strong>四川</strong>“的&lt;**province**&gt;元素节点的上一个兄弟节点为文本节点，下一个兄弟节点也为文本节点。</p><h3 id="二-动态SQL解析流程说明"><a href="#二-动态SQL解析流程说明" class="headerlink" title="二. 动态SQL解析流程说明"></a>二. 动态SQL解析流程说明</h3><p>整体的一个解析流程如下所示。</p><p><img src="/../imgs/blog16/1aaaae5311a34af08caa8246cf4e6910tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="Mybatis-动态SQL解析图"></p><p>**也就是写在映射文件中的一条<code>SQL</code>，会最终被解析为<code>DynamicSqlSource</code>或者<code>RawSqlSource</code>，前者表示动态<code>SQL</code>，后者表示静态<code>SQL</code>**。</p><p>上图中的<strong>MixedSqlNode</strong>，其通常的包含关系可以由下图定义。</p><p><img src="/../imgs/blog16/f58a38d43a2b4c6981f8c692011a4355tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="Mybatis-动态SQL组合图"></p><p>也就是映射文件中定义一条<strong>SQL</strong>语句的<strong>CRUD</strong>标签里的各种子元素，均会被解析为一个<strong>SqlNode</strong>，比如包含了<code>$&#123;&#125;</code>的文本，会被解析为<strong>TextSqlNode</strong>，不包含<code>$&#123;&#125;</code>的文本，会被解析为<strong>StaticTextSqlNode</strong>，&lt;<strong>choose**&gt;标签会被解析为</strong>ChooseSqlNode<strong>等，同时又因为&lt;**choose**&gt;标签中会再有&lt;**when**&gt;和&lt;**otherwise**&gt;子标签，所以</strong>ChooseSqlNode<strong>中又会持有这些子标签的</strong>SqlNode**。</p><p><strong>所以一条<code>SQL</code>最终就是由这条<code>SQL</code>对应的<code>CRUD</code>标签解析成的各种<code>SqlNode</code>组合而成</strong>。</p><h3 id="三-MyBatis解析动态SQL源码分析"><a href="#三-MyBatis解析动态SQL源码分析" class="headerlink" title="三. MyBatis解析动态SQL源码分析"></a>三. MyBatis解析动态SQL源码分析</h3><p>在<a href="https://juejin.cn/post/7203925850398883896">详解MyBatis加载映射文件和动态代理</a>中已经知道，在<strong>XMLStatementBuilder</strong>的<strong>parseStatementNode()</strong> 方法中，会解析映射文件中的&lt;<strong>select**&gt;，&lt;**insert**&gt;，&lt;**update**&gt;和&lt;**delete**&gt;标签（后续统一称为</strong>CURD<strong>标签），并生成</strong>MappedStatement<strong>然后缓存到</strong>Configuration**中。</p><p><strong>CURD</strong>标签的解析由<strong>XMLLanguageDriver</strong>完成，每个标签解析之后会生成一个<strong>SqlSource</strong>，可以理解为<strong>SQL</strong>语句，本小节将对<strong>XMLLanguageDriver</strong>如何完成<strong>CURD</strong>标签的解析进行讨论。</p><p><strong>XMLLanguageDriver</strong>创建<strong>SqlSource</strong>的<strong>createSqlSource()</strong> 方法如下所示。</p><pre><code class="java">java复制代码public SqlSource createSqlSource(Configuration configuration,         XNode script, Class&lt;?&gt; parameterType) &#123;    XMLScriptBuilder builder = new XMLScriptBuilder(            configuration, script, parameterType);    return builder.parseScriptNode();&#125;</code></pre><p>如上所示，<strong>createSqlSource()</strong> 方法的入参中，<strong>XNode</strong>就是<strong>CURD</strong>标签对应的节点，在<strong>createSqlSource()</strong> 方法中先是创建了一个<strong>XMLScriptBuilder</strong>，然后通过<strong>XMLScriptBuilder</strong>来生成<strong>SqlSource</strong>。先看一下<strong>XMLScriptBuilder</strong>的构造方法，如下所示。</p><pre><code class="java">java复制代码public XMLScriptBuilder(Configuration configuration, XNode context,                     Class&lt;?&gt; parameterType) &#123;    super(configuration);    this.context = context;    this.parameterType = parameterType;    initNodeHandlerMap();&#125;</code></pre><p>在<strong>XMLScriptBuilder</strong>的构造方法中，主要是将<strong>CURD</strong>标签对应的节点缓存起来，然后初始化<strong>nodeHandlerMap</strong>，<strong>nodeHandlerMap</strong>中存放着处理<strong>MyBatis</strong>提供的支持动态<strong>SQL</strong>的标签的处理器，<strong>initNodeHandlerMap()</strong> 方法如下所示。</p><pre><code class="java">java复制代码private void initNodeHandlerMap() &#123;    nodeHandlerMap.put(&quot;trim&quot;, new TrimHandler());    nodeHandlerMap.put(&quot;where&quot;, new WhereHandler());    nodeHandlerMap.put(&quot;set&quot;, new SetHandler());    nodeHandlerMap.put(&quot;foreach&quot;, new ForEachHandler());    nodeHandlerMap.put(&quot;if&quot;, new IfHandler());    nodeHandlerMap.put(&quot;choose&quot;, new ChooseHandler());    nodeHandlerMap.put(&quot;when&quot;, new IfHandler());    nodeHandlerMap.put(&quot;otherwise&quot;, new OtherwiseHandler());    nodeHandlerMap.put(&quot;bind&quot;, new BindHandler());&#125;</code></pre><p>现在分析<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法，该方法会创建<strong>SqlSource</strong>，如下所示。</p><pre><code class="java">java复制代码public SqlSource parseScriptNode() &#123;    // 解析动态标签    MixedSqlNode rootSqlNode = parseDynamicTags(context);    SqlSource sqlSource;    if (isDynamic) &#123;        // 创建DynamicSqlSource并返回        sqlSource = new DynamicSqlSource(configuration, rootSqlNode);    &#125; else &#123;        // 创建RawSqlSource并返回        sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType);    &#125;    return sqlSource;&#125;</code></pre><p>在<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法中，会根据<strong>XMLScriptBuilder</strong>中的<strong>isDynamic</strong>属性判断是创建<strong>DynamicSqlSource</strong>还是<strong>RawSqlSource</strong>，在这里暂时不分析<strong>DynamicSqlSource</strong>与<strong>RawSqlSource</strong>的区别，但是可以推测在<strong>parseDynamicTags()</strong> 方法中会改变<strong>isDynamic</strong>属性的值，即在<strong>parseDynamicTags()</strong> 方法中会根据<strong>CURD</strong>标签的节点生成一个<strong>MixedSqlNode</strong>，同时还会改变<strong>isDynamic</strong>属性的值以指示当前<strong>CURD</strong>标签中的<strong>SQL</strong>语句是否是动态的。</p><p><strong>MixedSqlNode</strong>是什么，<strong>isDynamic</strong>属性值在什么情况下会变为<strong>true</strong>，带着这些疑问，继续看<strong>parseDynamicTags()</strong> 方法，如下所示。</p><pre><code class="java">java复制代码protected MixedSqlNode parseDynamicTags(XNode node) &#123;    List&lt;SqlNode&gt; contents = new ArrayList&lt;&gt;();    // 获取节点的子节点    NodeList children = node.getNode().getChildNodes();    // 遍历所有子节点    for (int i = 0; i &lt; children.getLength(); i++) &#123;        XNode child = node.newXNode(children.item(i));        if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE                     || child.getNode().getNodeType() == Node.TEXT_NODE) &#123;            // 子节点为文本节点            String data = child.getStringBody(&quot;&quot;);            // 基于文本节点的值并创建TextSqlNode            TextSqlNode textSqlNode = new TextSqlNode(data);            // isDynamic()方法可以判断文本节点值是否有$&#123;&#125;占位符            if (textSqlNode.isDynamic()) &#123;                // 文本节点值有$&#123;&#125;占位符                // 添加TextSqlNode到集合中                contents.add(textSqlNode);                // 设置isDynamic为true                isDynamic = true;            &#125; else &#123;                // 文本节点值没有占位符                // 创建StaticTextSqlNode并添加到集合中                contents.add(new StaticTextSqlNode(data));            &#125;        &#125; else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) &#123;            // 子节点为元素节点            // CURD节点的子节点中的元素节点只可能为&lt;if&gt;，&lt;foreach&gt;等动态Sql标签节点            String nodeName = child.getNode().getNodeName();            // 根据动态Sql标签节点的名称获取对应的处理器            NodeHandler handler = nodeHandlerMap.get(nodeName);            if (handler == null) &#123;                throw new BuilderException(&quot;Unknown element &lt;&quot; + nodeName + &quot;&gt; in SQL statement.&quot;);            &#125;            // 处理动态Sql标签节点            handler.handleNode(child, contents);            // 设置isDynamic为true            isDynamic = true;        &#125;    &#125;    // 创建MixedSqlNode    return new MixedSqlNode(contents);&#125;</code></pre><p>按照正常执行流程调用<strong>parseDynamicTags()</strong> 时，入参是<strong>CURD</strong>标签节点，此时会遍历<strong>CURD</strong>标签节点的所有子节点，基于每个子节点都会创建一个<strong>SqlNode</strong>然后添加到<strong>SqlNode</strong>集合<strong>contents</strong>中，最后将<strong>contents</strong>作为入参创建<strong>MixedSqlNode</strong>并返回。</p><p><strong>SqlNode</strong>是一个接口，在<strong>parseDynamicTags()</strong> 方法中，可以知道，<strong>TextSqlNode</strong>实现了<strong>SqlNode</strong>接口，<strong>StaticTextSqlNode</strong>实现了<strong>SqlNode</strong>接口，所以当节点的子节点是文本节点时，如果文本值包含有<code>$&#123;&#125;</code>占位符，则创建<strong>TextSqlNode</strong>添加到<strong>contents</strong>中并设置<strong>isDynamic</strong>为<strong>true</strong>，如果文本值不包含<code>$&#123;&#125;</code>占位符，则创建<strong>StaticTextSqlNode</strong>并添加到<strong>contents</strong>中。</p><p>如果<strong>CURD</strong>标签节点的子节点是元素节点，由于<strong>CURD</strong>标签节点的元素节点只可能为&lt;<strong>if**&gt;，&lt;**foreach**&gt;等动态</strong>SQL<strong>标签节点，所以直接会设置</strong>isDynamic<strong>为</strong>true<strong>，同时还会调用动态</strong>SQL<strong>标签节点对应的处理器来生成</strong>SqlNode<strong>并添加到</strong>contents<strong>中。这里以&lt;**if**&gt;标签节点对应的处理器的</strong>handleNode()** 方法为例进行说明，如下所示。</p><pre><code class="java">java复制代码public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123;    // 递归调用parseDynamicTags()解析&lt;if&gt;标签节点    MixedSqlNode mixedSqlNode = parseDynamicTags(nodeToHandle);    String test = nodeToHandle.getStringAttribute(&quot;test&quot;);    // 创建IfSqlNode    IfSqlNode ifSqlNode = new IfSqlNode(mixedSqlNode, test);    // 将IfSqlNode添加到contents中    targetContents.add(ifSqlNode);&#125;</code></pre><p>在&lt;<strong>if**&gt;标签节点对应的处理器的</strong>handleNode()** 方法中，递归的调用了<strong>parseDynamicTags()</strong> 方法来解析&lt;<strong>if**&gt;标签节点，例如&lt;**where**&gt;，&lt;**foreach**&gt;等标签节点对应的处理器的</strong>handleNode()** 方法中也会递归调用<strong>parseDynamicTags()</strong> 方法，这是因为这些动态<strong>SQL</strong>标签是可以嵌套使用的，比如&lt;<strong>where**&gt;标签节点的子节点可以为&lt;**if**&gt;标签节点。通过上面的</strong>handleNode()** 方法，大致可以知道<strong>MixedSqlNode</strong>和<strong>IfSqlNode</strong>也实现了<strong>SqlNode</strong>接口，下面看一下<strong>MixedSqlNode</strong>和<strong>IfSqlNode</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class MixedSqlNode implements SqlNode &#123;    private final List&lt;SqlNode&gt; contents;    public MixedSqlNode(List&lt;SqlNode&gt; contents) &#123;        this.contents = contents;    &#125;    @Override    public boolean apply(DynamicContext context) &#123;        contents.forEach(node -&gt; node.apply(context));        return true;    &#125;    &#125;public class IfSqlNode implements SqlNode &#123;    private final ExpressionEvaluator evaluator;    private final String test;    private final SqlNode contents;    public IfSqlNode(SqlNode contents, String test) &#123;        this.test = test;        this.contents = contents;        this.evaluator = new ExpressionEvaluator();    &#125;    @Override    public boolean apply(DynamicContext context) &#123;        if (evaluator.evaluateBoolean(test, context.getBindings())) &#123;            contents.apply(context);            return true;        &#125;        return false;    &#125;&#125;</code></pre><p>其实到这里已经逐渐清晰明了了，按照正常执行流程调用<strong>parseDynamicTags()</strong> 方法时，是为了将<strong>CURD</strong>标签节点的所有子节点根据子节点类型生成不同的<strong>SqlNode</strong>并放在<strong>MixedSqlNode</strong>中，然后将<strong>MixedSqlNode</strong>返回，但是<strong>CURD</strong>标签节点的子节点中如果存在动态<strong>SQL</strong>标签节点，因为这些动态<strong>SQL</strong>标签节点也会有子节点，所以此时会递归的调用<strong>parseDynamicTags()</strong> 方法，以解析动态<strong>SQL</strong>标签节点的子节点，同样会将这些子节点生成<strong>SqlNode</strong>并放在<strong>MixedSqlNode</strong>中然后将<strong>MixedSqlNode</strong>返回，递归调用<strong>parseDynamicTags()</strong> 方法时得到的<strong>MixedSqlNode</strong>会保存在动态<strong>SQL</strong>标签节点对应的<strong>SqlNode</strong>中，比如<strong>IfSqlNode</strong>中就会将递归调用<strong>parseDynamicTags()</strong> 生成的<strong>MixedSqlNode</strong>赋值给<strong>IfSqlNode</strong>的<strong>contents</strong>字段。</p><p>不同的<strong>SqlNode</strong>都是可以包含彼此的，这是<strong>组合设计模式</strong>的应用，<strong>SqlNode</strong>之间的关系如下所示。</p><p><img src="/../imgs/blog16/220c3d1140904b3aafaa40b4206c5740tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="SqlNode类图"></p><p><strong>SqlNode</strong>接口定义了一个方法，如下所示。</p><pre><code class="java">java复制代码public interface SqlNode &#123;    boolean apply(DynamicContext context);&#125;</code></pre><p>每个<strong>SqlNode</strong>的<strong>apply()</strong> 方法中，除了实现自己本身的逻辑外，还会调用自己所持有的所有<strong>SqlNode</strong>的<strong>apply()</strong> 方法，最终逐层调用下去，所有<strong>SqlNode</strong>的<strong>apply()</strong> 方法均会被执行。</p><h3 id="四-DynamicSqlSource和RawSqlSource源码分析"><a href="#四-DynamicSqlSource和RawSqlSource源码分析" class="headerlink" title="四. DynamicSqlSource和RawSqlSource源码分析"></a>四. DynamicSqlSource和RawSqlSource源码分析</h3><p>回到<strong>XMLScriptBuilder</strong>的<strong>parseScriptNode()</strong> 方法，该方法中会调用<strong>parseDynamicTags()</strong> 方法以解析<strong>CURD</strong>标签节点并得到<strong>MixedSqlNode</strong>，<strong>MixedSqlNode</strong>中含有被解析的<strong>CURD</strong>标签节点的所有子节点对应的<strong>SqlNode</strong>，最后会基于<strong>MixedSqlNode</strong>创建<strong>DynamicSqlSource</strong>或者<strong>RawSqlSource</strong>，如果<strong>CURD</strong>标签中含有动态<strong>SQL</strong>标签或者<strong>SQL</strong>语句中含有<code>$&#123;&#125;</code>占位符，则创建<strong>DynamicSqlSource</strong>，否则创建<strong>RawSqlSource</strong>。下面分别对<strong>DynamicSqlSource</strong>和<strong>RawSqlSource</strong>的实现进行分析。</p><h4 id="1-DynamicSqlSource源码分析"><a href="#1-DynamicSqlSource源码分析" class="headerlink" title="1. DynamicSqlSource源码分析"></a>1. DynamicSqlSource源码分析</h4><p><strong>DynamicSqlSource</strong>的实现如下所示。</p><pre><code class="java">java复制代码public class DynamicSqlSource implements SqlSource &#123;    private final Configuration configuration;    private final SqlNode rootSqlNode;    public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123;        // 构造函数只是进行了简单的赋值操作        this.configuration = configuration;        this.rootSqlNode = rootSqlNode;    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        DynamicContext context = new DynamicContext(configuration, parameterObject);        // 调用SqlNode的apply()方法完成Sql语句的生成        rootSqlNode.apply(context);        // SqlSourceBuilder可以将Sql语句中的#&#123;&#125;占位符替换为?        SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);        Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass();        // 将Sql语句中的#&#123;&#125;占位符替换为?，并生成一个StaticSqlSource        SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings());        // StaticSqlSource中保存有动态生成好的Sql语句，并且#&#123;&#125;占位符全部替换成了?        BoundSql boundSql = sqlSource.getBoundSql(parameterObject);        // 生成有序参数映射列表        context.getBindings().forEach(boundSql::setAdditionalParameter);        return boundSql;    &#125;&#125;</code></pre><p><strong>DynamicSqlSource</strong>的构造函数只是进行了简单的赋值操作，重点在于其<strong>getBoundSql()</strong> 方法，在<strong>getBoundSql()</strong> 方法中，先是调用<strong>DynamicSqlSource</strong>中的<strong>SqlNode</strong>的<strong>apply()</strong> 方法以完成动态<strong>SQL</strong>语句的生成，此时生成的<strong>SQL</strong>语句中的占位符（如果有的话）为<code>#&#123;&#125;</code>，然后再调用<strong>SqlSourceBuilder</strong>的<strong>parse()</strong> 方法将<strong>SQL</strong>语句中的占位符从<code>#&#123;&#125;</code>替换为<code>?</code>并基于替换占位符后的<strong>SQL</strong>语句生成一个<strong>StaticSqlSource</strong>并返回，这里可以看一下<strong>StaticSqlSource</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class StaticSqlSource implements SqlSource &#123;    private final String sql;    private final List&lt;ParameterMapping&gt; parameterMappings;    private final Configuration configuration;    public StaticSqlSource(Configuration configuration, String sql) &#123;        this(configuration, sql, null);    &#125;    public StaticSqlSource(Configuration configuration, String sql,                            List&lt;ParameterMapping&gt; parameterMappings) &#123;        // 构造函数只是进行简单的赋值操作        this.sql = sql;        this.parameterMappings = parameterMappings;        this.configuration = configuration;    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        // 基于Sql语句创建一个BoundSql并返回        return new BoundSql(configuration, sql, parameterMappings, parameterObject);    &#125;&#125;</code></pre><p>所以分析到这里，可以知道<strong>DynamicSqlSource</strong>的<strong>getBoundSql()</strong> 方法实际上会完成动态<strong>SQL</strong>语句的生成和<code>#&#123;&#125;</code>占位符替换，然后基于生成好的<strong>SQL</strong>语句创建<strong>BoundSql</strong>并返回。<strong>BoundSql</strong>对象的类图如下所示。</p><p><img src="/../imgs/blog16/f035a68cdbf943cfa477c26e217baf4dtplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp" alt="BoundSql类图"></p><p>实际上，<strong>MyBatis</strong>中执行<strong>SQL</strong>语句时，如果映射文件中的<strong>SQL</strong>使用到了动态<strong>SQL</strong>标签，那么<strong>MyBatis</strong>中的<strong>Executor</strong>（执行器，后续文章中会进行介绍）会调用<strong>MappedStatement</strong>的<strong>getBoundSql()</strong> 方法，然后在<strong>MappedStatement</strong>的<strong>getBoundSql()</strong> 方法中又会调用<strong>DynamicSqlSource</strong>的<strong>getBoundSql()</strong> 方法，所以<strong>MyBatis</strong>中的动态<strong>SQL</strong>语句会在这条语句实际要执行时才会生成。</p><h4 id="2-RawSqlSource源码分析"><a href="#2-RawSqlSource源码分析" class="headerlink" title="2. RawSqlSource源码分析"></a>2. RawSqlSource源码分析</h4><p>现在看一下<strong>RawSqlSource</strong>的实现，如下所示。</p><pre><code class="java">java复制代码public class RawSqlSource implements SqlSource &#123;    private final SqlSource sqlSource;    public RawSqlSource(Configuration configuration, SqlNode rootSqlNode, Class&lt;?&gt; parameterType) &#123;        // 先调用getSql()方法获取Sql语句        // 然后再执行构造函数        this(configuration, getSql(configuration, rootSqlNode), parameterType);    &#125;    public RawSqlSource(Configuration configuration, String sql, Class&lt;?&gt; parameterType) &#123;        SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);        Class&lt;?&gt; clazz = parameterType == null ? Object.class : parameterType;        // 将Sql语句中的#&#123;&#125;占位符替换为?，生成一个StaticSqlSource并赋值给sqlSource        sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;&gt;());    &#125;    private static String getSql(Configuration configuration, SqlNode rootSqlNode) &#123;        DynamicContext context = new DynamicContext(configuration, null);        rootSqlNode.apply(context);        return context.getSql();    &#125;    @Override    public BoundSql getBoundSql(Object parameterObject) &#123;        // 实际是调用StaticSqlSource的getBoundSql()方法        return sqlSource.getBoundSql(parameterObject);    &#125;&#125;</code></pre><p><strong>RawSqlSource</strong>会在构造函数中就将<strong>SQL</strong>语句生成好并替换<code>#&#123;&#125;</code>占位符，在<strong>SQL</strong>语句实际要执行时，就直接将生成好的<strong>SQL</strong>语句返回。所以<strong>MyBatis</strong>中，静态<strong>SQL</strong>语句的执行通常要快于动态<strong>SQL</strong>语句的执行，这在<strong>RawSqlSource</strong>类的注释中也有提及，如下所示。</p><blockquote><p><strong>Static SqlSource. It is faster than {@link DynamicSqlSource} because mappings are calculated during startup.</strong></p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>MyBatis</strong>会为映射文件中的每个<strong>CURD</strong>标签节点里的<strong>SQL</strong>语句生成一个<strong>SqlSource</strong>：</p><ol><li>如果是静态<strong>SQL</strong>语句，那么会生成<strong>RawSqlSource</strong>；</li><li>如果是动态<strong>SQL</strong>语句，则会生成<strong>DynamicSqlSource</strong>。</li></ol><p><strong>MyBatis</strong>在生成<strong>SqlSource</strong>时，会为<strong>CURD</strong>标签节点的每个子节点都生成一个<strong>SqlNode</strong>，无论子节点是文本值节点还是动态<strong>SQL</strong>元素节点，最终所有子节点对应的<strong>SqlNode</strong>都会放在<strong>SqlSource</strong>中以供生成<strong>SQL</strong>语句使用。</p><p>如果是静态<strong>SQL</strong>语句，那么在创建<strong>RawSqlSource</strong>时就会使用<strong>SqlNode</strong>完成<strong>SQL</strong>语句的生成以及将<strong>SQL</strong>语句中的<code>#&#123;&#125;</code>占位符替换为<code>?</code>，然后保存在<strong>RawSqlSource</strong>中，等到这条静态<strong>SQL</strong>语句要被执行时，就直接返回这条静态<strong>SQL</strong>语句。</p><p>如果是动态<strong>SQL</strong>语句，在创建<strong>DynamicSqlSource</strong>时只会简单的将<strong>SqlNode</strong>保存下来，等到这条动态<strong>SQL</strong>语句要被执行时，才会使用<strong>SqlNode</strong>完成<strong>SQL</strong>语句的生成以及将<strong>SQL</strong>语句中的<code>#&#123;&#125;</code>占位符替换为<code>?</code>，最后返回<strong>SQL</strong>语句。</p><p><strong>所以<code>MyBatis</code>中，静态<code>SQL</code>语句的获取要快于动态<code>SQL</code>语句</strong>。</p><p>原文链接：<a href="https://juejin.cn/post/7204115174412238907">https://juejin.cn/post/7204115174412238907</a><br>来源：稀土掘金        作者：半夏之沫</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO模型</title>
      <link href="/2023/06/16/blog15/"/>
      <url>/2023/06/16/blog15/</url>
      
        <content type="html"><![CDATA[<p>本文讨论的背景是Linux环境下的network IO。本文最重要的参考文献是Richard Stevens 的 “UNIX? Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I&#x2F;O Models ”，Stevens在这节中详细说明了各种IO的特点和区别，如果英文够好的话，推荐直接阅读。Stevens的文风是有名的深入浅出，所以不用担心看不懂。本文中的流程图也是截取自参考文献。</p><p>Stevens在文章中一共比较了五种IO Model：</p><p>* blocking IO</p><p>* nonblocking IO</p><p>* IO multiplexing</p><p>* signal driven IO</p><p>* asynchronous IO</p><p>由于signal driven IO在实际中并不常用，所以主要介绍其余四种IO Model。</p><p>再说一下IO发生时涉及的对象和步骤。对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：</p><p>1） 等 待 数 据 准 备  (Waiting  for  the  data  to  be   ready) </p><p>2）将数据从内核拷贝到进程中(Copying the data from the kernel to the process)</p><p>记住这两点很重要，因为这些IO模型的区别就是在两个阶段上各有不同的情况。</p><h1 id="1、阻塞IO（blocking-IO）"><a href="#1、阻塞IO（blocking-IO）" class="headerlink" title="1、阻塞IO（blocking IO）"></a>1、阻塞IO（blocking IO）</h1><p>在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：</p><p><img src="/../imgs/blog15/clip_image002.jpg" alt="img"></p><p>当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。</p><p><strong>所以，blocking  IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。</strong></p><p>几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv() 等接口开始的，这些接口都是阻塞型的。使用这些接口可以很方便的构建服务器&#x2F;客户机的模型。下面是一个简单地“一问一答”的服务器。</p><p><img src="/../imgs/blog15/clip_image004.jpg" alt="img"></p><p>我们注意到，大部分的socket接口都是阻塞型的。所谓阻塞型接口是指系统调用（一般是IO接口）不返回调用结果并让当前线程一直阻塞，只有当该系统调用获得结果或者超时出错时才返回。</p><p>实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的。这给网络编程带来了一个很大的问题，如在调用send()的同时，线程将被阻塞，在  此期间，线程将无法执行任何运算或响应任何的网络请求。</p><p>一个简单的改进方案是在服务器端使用多线程（或多进程）。多线程（或多进  程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。具体使用多进程还是多线程，并没有一个特定的模式。</p><p>传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户机提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的CPU资源，譬如需要进行大规模或长时间的数据运算或文件访问，则进程较为安全。**通常，使用pthread_create ()创建新线程，fork()创建新进程。</p><p>我们假设对上述的服务器 &#x2F; 客户机模型，提出更高的要求，即让服务器同时为多个客户机提供一问一答的服务。于是有了如下的模型。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image006.jpg" alt="img"></td></tr></tbody></table><p>在上述的线程 &#x2F; 时间图例中，主线程持续等待客户端的连接请求，如果有连接， 则创建新线程，并在新线程中提供为前例同样的问答服务。</p><p>很多初学者可能不明白为何一个socket可以accept多次。实际上socket的设计者  可能特意为多客户机的情况留留下了伏笔，让accept()能够返回一个新的socket。下面是 accept 接口的原型：</p><pre><code>int accept(int s, struct sockaddr *addr, socklen_t *addrlen);</code></pre><p>输入参数s是从socket()，bind()和listen()中沿用下来的socket句柄值。执行完bind()和listen()后，操作系统已经开始在指定的端口处监听所有的连接请求，如果 有请求，则将该连接请求加入请求队列。调用accept()接口正是从 socket s 的请求队列抽取第一个连接信息，创建一个与s同类的新的socket返回句柄。新的socket 句柄即是后续read()和recv()的输入参数。如果请求队列当前没有请求，则accept() 将进入阻塞状态直到有请求进入队列。</p><p>上述多线程的服务器模型似乎完美的解决了为多个客户机提供问答服务的要   求，但其实并不尽然。如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而线程与进程本身也更容易进入假死状态。</p><p>很多程序员可能会考虑使用线程池或连接池。“线程池”旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。“连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统，如websphere、tomcat和各种数据库等。但是，“线程池”和“连接池”技术也只是在一定程度上缓解了频繁调用IO接口带来的资源占用。而且，所谓“池”始终有其上  限，当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有池的时候效果好多少。所以使用“池”必须考虑其面临的响应规模，并根据响应规模调整“池”的大小。</p><p>对应上例中的所面临的可能同时出现的上千甚至上万次的客户端请求，“线程池”或“连接池”或许可以缓解部分压力，但是不能解决所有问题。总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞接口来尝试解决这个问题。</p><h1 id="2、非阻塞IO（non-blocking-IO）"><a href="#2、非阻塞IO（non-blocking-IO）" class="headerlink" title="2、非阻塞IO（non-blocking IO）"></a>2、非阻塞IO（non-blocking IO）</h1><p>Linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：</p><p><img src="/../imgs/blog15/clip_image008.jpg" alt="img"></p><p>从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ， 它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read 操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call， 那么它马上就将数据拷贝到了用户内存，然后返回。</p><p><strong>所以，在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有。</strong></p><p>非阻塞的接口相比于阻塞型接口的显著差异在于，在被调用之后立即返回。使用如下的函数可以将某句柄fd设为非阻塞状态。</p><pre><code>fcntl( fd, F_SETFL, O_NONBLOCK );</code></pre><p>下面将给出只用一个线程，但能够同时从多个连接中检测数据是否送达，并且接受数据的模型。</p><p><img src="/../imgs/blog15/clip_image010.jpg" alt="img"></p><p>在非阻塞状态下，recv() 接口在被调用后立即返回，返回值代表了不同的含义。如在本例中，</p><p>* recv() 返回值大于 0，表示接受数据完毕，返回值即是接受到的字节数；</p><p>* recv() 返回 0，表示连接已经正常断开；</p><p>* recv() 返回 -1，且 errno 等于 EAGAIN，表示 recv 操作还没执行完成；</p><p>* recv() 返回 -1，且 errno 不等于 EAGAIN，表示 recv 操作遇到系统错误errno。</p><p>可以看到服务器线程可以通过循环调用recv()接口，可以在单个线程内实现对所有连接的数据接收工作。但是上述模型绝不被推荐。因为，循环调用recv()将大幅度推高CPU 占用率；此外，在这个方案中recv()更多的是起到检测“操作是否完成”的作用，实际操作系统提供了更为高效的检测“操作是否完成“作用的接口，例如select()多路复用模式，可以一次检测多个连接是否活跃。</p><h1 id="3、多路复用IO（IO-multiplexing）"><a href="#3、多路复用IO（IO-multiplexing）" class="headerlink" title="3、多路复用IO（IO multiplexing）"></a>3、多路复用IO（IO multiplexing）</h1><p> IO multiplexing这个词可能有点陌生，但是如果我说select&#x2F;epoll，大概就都能明白了。有些地方也称这种IO方式为<strong>事件驱动IO</strong>(event driven IO)。我们都知道， select&#x2F;epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基  本原理就是select&#x2F;epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image012.jpg" alt="img"></td></tr></tbody></table><p>当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所  有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。  这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。</p><p>这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一局：所以，如果处理的连接数不是很高的话，使用select&#x2F;epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select&#x2F;epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）</p><p><strong>在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。</strong>只不过process是被select这个函数block，而不是被socket  IO给block。因此select()与非阻塞IO类似。大部分Unix&#x2F;Linux都支持select函数，该函数用于探测多个文件句柄的状态变化。下面给出select接口的原型：</p><pre><code>FD_ZERO(int fd, fd_set* fds) FD_SET(int fd, fd_set* fds) FD_ISSET(int fd, fd_set* fds) FD_CLR(int fd, fd_set* fds)int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout)</code></pre><p>这里，fd_set 类型可以简单的理解为按 bit 位标记句柄的队列，例如要在某fd_set  中标记一个值为16的句柄，则该fd_set的第16个bit位被标记为1。具体的置位、验证可使用 FD_SET、FD_ISSET等宏实现。在select()函数中，readfds、writefds和exceptfds同时作为输入参数和输出参数。如果输入的readfds标记了16  号句柄，则select()将检测16号句柄是否可读。在select()返回后，可以通过检查readfds有否标记16号句柄，来判断该“可读”事件是否发生。另外，用户可以设置timeout时间。</p><p>下面将重新模拟上例中从多个客户端接收数据的模型。</p><p><img src="/../imgs/blog15/clip_image014.jpg" alt="img"></p><p>该模型只是描述了使用select()接口同时从多个客户端接收数据的过程；由于select()接口可以同时对多个句柄进行读状态、写状态和错误状态的探测，所以可以很容易易构建为多个客户端提供独立问答服务的服务器系统。如下图。</p><p><img src="/../imgs/blog15/clip_image016.jpg" alt="img"></p><p>这里需要指出的是，客户端的一个 connect() 操作，将在服务器端激发一个“可读事件”，所以 select() 也能探测来自客户端的 connect() 行为。</p><p>上述模型中，最关键的地方是如何动态维护select()的三个参数readfds、writefds和exceptfds。作为输入参数，readfds应该标记所有的需要探测的“可读事件”的句柄，其中永远包括那个探测 connect() 的那个“母”句柄；同时，writefds 和exceptfds 应该标记所有需要探测的“可写事件”和“错误事件”的句柄 ( 使用FD_SET() 标记 )。作为输出参数，readfds、writefds和exceptfds中的保存了 select() 捕捉到的所有事件的句柄值。程序员需要检查的所有的标记位 ( 使用FD_ISSET()检查 )，以确定到底哪些句柄发生了事件。</p><p>上述模型主要模拟的是“一问一答”的服务流程，所以如果select()发现某句柄捕捉到了“可读事件”，服务器程序应及时做recv()操作，并根据接收到的数据准备好待发送数据，并将对应的句柄值加入writefds，准备下一次的“可写事件”的select()  探测。同样，如果select()发现某句柄捕捉到“可写事件”，则程序应及时做send()操  作，并准备好下一次的“可读事件”探测准备。下图描述的是上述模型中的一个执行周期。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image018.jpg" alt="img"></td></tr></tbody></table><p>这种模型的特征在于每一个执行周期都会探测一次或一组事件，一个特定的事  件会触发某个特定的响应。我们可以将这种模型归类为“<strong>事件驱动模型</strong>”。</p><p>相比其他模型，使用select() 的事件驱动模型只用单线程（进程）执行，占用资源少，不消耗太多  CPU，同时能够为多客户端提供服务。如果试图建立一个简单的事件驱动的服务器程序，这个模型有一定的参考价值。</p><p>但这个模型依旧有着很多问题。首先select()接口并不是实现“事件驱动”的最好选择。因为当需要探测的句柄值较大时，select()接口本身需要消耗大量量时间去轮询各个句柄。很多操作系统提供了更为高效的接口，如linux提供了epoll，BSD提供了kqueue， Solaris提供了&#x2F;dev&#x2F;poll，…。如果需要实现更高效的服务器程序，类似epoll这样的接口更被推荐。遗憾的是不同的操作系统特供的epoll接口有很大差异，所以使用类似于epoll的接口实现具有较好跨平台能力力的服务器会比较困难。其次，该模型将事件探测和事件响应夹杂在一起，一旦事件响应的执行体庞大，则对整个模型是灾难性的。如下例，庞大的执行体1的将直接导致响应事件2的执行体迟迟得不到执行，并在很大程度上降低了事件探测的及时性。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image020.jpg" alt="img"></td></tr></tbody></table><p>幸运的是，有很多高效的事件驱动库可以屏蔽上述的困难，常见的事件驱动库有<strong>libevent库</strong>，还有作为libevent替代者的<strong>libev库</strong>。这些库会根据操作系统的特点选 择最合适的事件探测接口，并且加入了信号(signal) 等技术以支持异步响应，这使得这些库成为构建事件驱动模型的不二选择。下章将介绍如何使用libev库替换select或epoll接口，实现高效稳定的服务器模型。</p><p>实际上，Linux内核从2.6开始，也引入了支持异步响应的IO操作，如aio_read, aio_write，这就是异步IO。</p><h1 id="4、异步IO（Asynchronous-I-x2F-O）"><a href="#4、异步IO（Asynchronous-I-x2F-O）" class="headerlink" title="4、异步IO（Asynchronous I&#x2F;O）"></a>4、异步IO（Asynchronous I&#x2F;O）</h1><p> Linux下的asynchronous  IO其实用得不多，从内核2.6版本才开始引入。先看一下它的流程：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td></td><td><img src="/../imgs/blog15/clip_image022.jpg" alt="img"></td></tr></tbody></table><p>用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据  拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。</p><p>用异步IO实现的服务器这里就不举例了，以后有时间另开文章来讲述。异步IO 是真正非阻塞的，它不会对请求进程产生任何的阻塞，因此对高并发的网络服务器实现至关重要。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>到目前为止，已经将四个IO模型都介绍完了。现在回过头来回答最初的那几个问题：blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪。</p><p>先回答最简单的这个：blocking与non-blocking。前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成， 而non-blocking IO在kernel还在准备数据的情况下会立刻返回。</p><p>在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的：</p><p>* A synchronous I&#x2F;O operation causes the requesting process to be blocked until that I&#x2F;O operation completes;</p><p>* An asynchronous I&#x2F;O operation does not cause the requesting process to be blocked;</p><p><strong>两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。</strong>按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个系统调用。non-blocking   IO在执行recvfrom这个系统调用的时候，如果kernel的数据没有准备好，这时候不会block进程。但是当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内进程是被block的。而asynchronous IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。</p><p>还有一种不常用的signal driven IO，即信号驱动IO。总的来说，UNP中总结的IO模型有5种之多：阻塞IO，非阻塞IO，IO复用，信号驱动IO，异步IO。前四种都属于同步IO。阻塞IO不必说了。非阻塞IO ，IO请求时加上O_NONBLOCK一类的标志位，立刻返回，IO没有就绪会返回错误，需要请求进程主动轮询不断发IO请求直到返回正确。IO复用同非阻塞IO本质一样，不过利利用了新的select系统调用，   由内核来负责本来是请求进程该做的轮询操作。看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才算提高了效率。信号驱动IO，调用sigaltion系统调用，当内核中IO数据就绪时以SIGIO信号通知请求进程，请求进程再把数据从内核读入到用户空间，这一步是阻塞的。异步IO，如定义所说，不会因为IO操作阻塞，IO操作全部完成才通知请求进程。  各个IO Model的比较如图所示：</p><p><img src="/../imgs/blog15/clip_image024.jpg" alt="img"></p><p>经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。</p><p>参考文献：</p><p>IO - 同步，异步，阻塞，非阻塞 ：<a href="http://blog.csdn.net/historyasamirror/article/details/5778378">http://blog.csdn.net/historyasamirror/article/details/5778378 </a></p><p>使用事件驱动模型实现高效稳定的网络服务器程序：<a href="http://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/">http://www.ibm.com/developerworks/cn/linux/l-cn-edntwk/</a></p><p><a href="http://blog.chinaunix.net/uid-28458801-id-4464639.html">http://blog.chinaunix.net/uid-28458801-id-4464639.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从链表中删去总和值为零的连续节点</title>
      <link href="/2023/06/12/blog14/"/>
      <url>/2023/06/12/blog14/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><p><a href="https://leetcode.cn/problems/remove-zero-sum-consecutive-nodes-from-linked-list/description/">1171. 从链表中删去总和值为零的连续节点 - 力扣（Leetcode）</a></p><p>给你一个链表的头节点 <code>head</code>，请你编写代码，反复删去链表中由 <strong>总和</strong> 值为 <code>0</code> 的连续节点组成的序列，直到不存在这样的序列为止。</p><p>删除完毕后，请你返回最终结果链表的头节点。</p><p>你可以返回任何满足题目要求的答案。</p><p>（注意，下面示例中的所有序列，都是对 <code>ListNode</code> 对象序列化的表示。）</p><p><strong>示例 1：</strong></p><pre><code>输入：head = [1,2,-3,3,1]输出：[3,1]提示：答案 [1,2,1] 也是正确的。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：head = [1,2,3,-3,4]输出：[1,2,4]</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：head = [1,2,3,-3,-2]输出：[1]</code></pre><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>若链表节点的两个前缀和相等，说明两个前缀和之间的连续节点序列的和为 0，那么可以消去这部分连续节点。</p><p>我们第一次遍历链表，用哈希表 last记录前缀和以及对应的链表节点，对于同一前缀和s，后面出现的节点覆盖前面的节点。</p><p>接下来，我们再次遍历链表，若当前节点 cur 的前缀和 s在 last出现，说明 cur与 last[s]之间的所有节点和为 0，我们直接修改 cur 的指向，即 <code>cur.next=last[s].next</code>，这样就删去了这部分和为 000 的连续节点。继续往后遍历，删除所有和为 0的连续节点。</p><p>最后返回链表的头节点 <code>dummy.next</code>。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code class="java">class Solution &#123;  public ListNode removeZeroSumSublists(ListNode head) &#123;​    ListNode dummy = new ListNode(0, head);​    Map&lt;Integer, ListNode&gt; last = new HashMap&lt;&gt;();​    int s = 0;​    ListNode cur = dummy;​    while(cur!=null)&#123;​      s+=cur.val;​      last.put(s, cur);​      cur = cur.next;​    &#125;​    s=0;​    cur=dummy;​    while(cur!=null)&#123;​      s+=cur.val;​      cur.next = last.get(s).next;​      cur = cur.next;​    &#125;​    return dummy.next;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>老鼠和奶酪</title>
      <link href="/2023/06/07/blog13/"/>
      <url>/2023/06/07/blog13/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><p><a href="https://leetcode.cn/problems/mice-and-cheese/description/">2611. 老鼠和奶酪 - 力扣（Leetcode）</a></p><p>有两只老鼠和 <code>n</code> 块不同类型的奶酪，每块奶酪都只能被其中一只老鼠吃掉。</p><p>下标为 <code>i</code> 处的奶酪被吃掉的得分为：</p><ul><li>如果第一只老鼠吃掉，则得分为 <code>reward1[i]</code> 。</li><li>如果第二只老鼠吃掉，则得分为 <code>reward2[i]</code> 。</li></ul><p>给你一个正整数数组 <code>reward1</code> ，一个正整数数组 <code>reward2</code> ，和一个非负整数 <code>k</code> 。</p><p>请你返回第一只老鼠恰好吃掉 <code>k</code> 块奶酪的情况下，<strong>最大</strong> 得分为多少。</p><p><strong>示例 1：</strong></p><pre><code>输入：reward1 = [1,1,3,4], reward2 = [4,4,1,1], k = 2输出：15解释：这个例子中，第一只老鼠吃掉第 2 和 3 块奶酪（下标从 0 开始），第二只老鼠吃掉第 0 和 1 块奶酪。总得分为 4 + 4 + 3 + 4 = 15 。15 是最高得分。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：reward1 = [1,1], reward2 = [1,1], k = 2输出：2解释：这个例子中，第一只老鼠吃掉第 0 和 1 块奶酪（下标从 0 开始），第二只老鼠不吃任何奶酪。总得分为 1 + 1 = 2 。2 是最高得分。</code></pre><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>​假设所有的奶酪都被第二只老鼠吃掉，记录下此时得分<code>res</code>。若第<code>i</code>块奶酪被第一只老鼠吃掉，得分变化为<code>reward1[i]-reward2[i]</code>，建立数组reward，其中<code>reward[i]=rewar1d[i]-reward2[i]</code>，并对reward数组排序，res加上reward后k个元素（也就是第一只老鼠吃k块的最大值变化）即为最终结果。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code class="java">class Solution &#123;  public int miceAndCheese(int[] reward1, int[] reward2, int k) &#123;​    int ans = 0;​    int n = reward1.length;​    int[] diffs = new int[n];​    for (int i = 0; i &lt; n; i++) &#123;​      ans += reward2[i];​      diffs[i] = reward1[i] - reward2[i];​    &#125;​    Arrays.sort(diffs);​    for (int i = 1; i &lt;= k; i++) &#123;​      ans += diffs[n - i];​    &#125;​    return ans;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch面试题</title>
      <link href="/2023/06/06/blog12/"/>
      <url>/2023/06/06/blog12/</url>
      
        <content type="html"><![CDATA[<h2 id="1-为什么要使用ElasticSearch"><a href="#1-为什么要使用ElasticSearch" class="headerlink" title="1 为什么要使用ElasticSearch?"></a>1 为什么要使用ElasticSearch?</h2><p>​系统中的数据，随着业务的发展，时间的推移，将会非常多，而业务中往往采用模糊查询进行数据的搜索，而模糊查询会导致查询引擎放弃索引，导致系统查询数据时都是全表扫描，在百万级别的数据库中，查询效率是非常低下的，而我们使用ES做一个全文索引，将经常查询的系统功能的某些字段，比如说电商系统的商品表中商品名，描述、价格还有id这些字段我们放入ES索引库里，可以提高查询速度。</p><h2 id="2-ElasticSearch的master选举流程？"><a href="#2-ElasticSearch的master选举流程？" class="headerlink" title="2 ElasticSearch的master选举流程？"></a>2 ElasticSearch的master选举流程？</h2><p>​ElasticSearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分</p><p>​对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</p><p>​如果对某个节点的投票数达到一定的值（可以成为master节点数n&#x2F;2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。</p><p>​master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</p><h2 id="3-ElasticSearch集群脑裂问题？"><a href="#3-ElasticSearch集群脑裂问题？" class="headerlink" title="3 ElasticSearch集群脑裂问题？"></a>3 ElasticSearch集群脑裂问题？</h2><p><strong>“脑裂”问题可能的成因</strong><strong>:</strong></p><p>​ <strong>网络问题</strong>：集群间的网络延迟导致一些节点访问不到master，认为master挂掉了从而选举出新的master，并对master上的分片和副本标红，分配新的主分片</p><p>​<strong>节点负载</strong>：主节点的角色既为master又为data，访问量较大时可能会导致ES停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。</p><p>​<strong>内存回收</strong>：data节点上的ES进程占用的内存较大，引发JVM的大规模内存回收，造成ES进程失去响应。</p><p><strong>脑裂问题解决方案：</strong></p><p>​<strong>减少误判：</strong>discovery.zen.ping_timeout节点状态的响应时间，默认为3s，可以适当调大，如果master在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如6s，discovery.zen.ping_timeout:6），可适当减少误判。</p><p>​<strong>选举触发</strong>: discovery.zen.minimum_master_nodes:1</p><p>该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值， 且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为（n&#x2F;2）+1，n为主节点个数 （即有资格成为主节点的节点个数）</p><p>​<strong>角色分离</strong>：即master节点与data节点分离，限制角色</p><p>主节点配置为：node.master: true node.data: false</p><p>从节点配置为：node.master: false node.data: true</p><h2 id="4-ElasticSearch索引文档的流程？"><a href="#4-ElasticSearch索引文档的流程？" class="headerlink" title="4 ElasticSearch索引文档的流程？"></a>4 ElasticSearch索引文档的流程？</h2><p><img src="/imgs/blog12/clip_image002.jpg" alt="img"></p><p>​ 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片：</p><p><strong>shard &#x3D; hash(document_id) % (num_of_primary_shards)</strong></p><p>​ 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Memory Buffer到Filesystem Cache的过程就叫做refresh；</p><p>​ 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；</p><p>​在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。</p><p>​flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；</p><h2 id="5-ElasticSearch更新和删除文档的流程？"><a href="#5-ElasticSearch更新和删除文档的流程？" class="headerlink" title="5 ElasticSearch更新和删除文档的流程？"></a>5 ElasticSearch更新和删除文档的流程？</h2><p>​删除和更新也都是写操作，但是ElasticSearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；</p><p>​磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。</p><p>​在新的文档被创建时，ElasticSearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</p><h2 id="6-ElasticSearch搜索的流程？"><a href="#6-ElasticSearch搜索的流程？" class="headerlink" title="6 ElasticSearch搜索的流程？"></a>6 ElasticSearch搜索的流程？</h2><p><img src="/imgs/blog12/clip_image004.jpg" alt="img"></p><p>​ 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；</p><p>​ 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。</p><p>​每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</p><p>​接下来就是取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</p><p>​Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。</p><h2 id="7-ElasticSearch-在部署时，对-Linux-的设置有哪些优化方法？"><a href="#7-ElasticSearch-在部署时，对-Linux-的设置有哪些优化方法？" class="headerlink" title="7 ElasticSearch 在部署时，对 Linux 的设置有哪些优化方法？"></a>7 ElasticSearch 在部署时，对 Linux 的设置有哪些优化方法？</h2><p>​64 GB 内存的机器是非常理想的， 但是32 GB 和16 GB 机器也是很常见的。少于8 GB 会适得其反。</p><p>​如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。</p><p>​如果你负担得起 SSD，它将远远超出任何旋转介质。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起，SSD 是一个好的选择。</p><p>​即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。</p><p>​请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。 在 ElasticSearch 的几个地方，使用 Java 的本地序列化。</p><p>​通过设置gateway.recover_after_nodes、gateway.expected_nodes、gateway.recover_after_time可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。</p><p>​ElasticSearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。最好使用单播代替组播。</p><p>​不要随意修改垃圾回收器（CMS）和各个线程池的大小。</p><p>​把你的内存的（少于）一半给 Lucene（但不要超过 32 GB！），通过ES_HEAP_SIZE 环境变量设置。</p><p>​内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。 再想想那么多 10 微秒的操作时延累加起来。 不难看出 swapping 对于性能是多么可怕。</p><p>​Lucene 使用了大量的文件。同时，ElasticSearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字。 所有这一切都需要足够的文件描述符。你应该增加你的文件描述符，设置一个很大的值，如 64,000。</p><p><strong>补充：索引阶段性能提升方法</strong></p><p>​使用批量请求并调整其大小：每次批量数据 5–15 MB 大是个不错的起始点。</p><p>​存储：使用 SSD</p><p>​段和合并：ElasticSearch 默认值是 20 MB&#x2F;s，对机械磁盘应该是个不错的设置。如果你用的是 SSD，可以考虑提高到 100–200 MB&#x2F;s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。另外还可以增加 index.translog.flush_threshold_size 设置，从默认的 512 MB 到更大一些的值，比如 1 GB，这可以在一次清空触发的时候在事务日志里积累出更大的段。</p><p>​如果你的搜索结果不需要近实时的准确度，考虑把每个索引的index.refresh_interval 改到30s。</p><p>​如果你在做大批量导入，考虑通过设置index.number_of_replicas: 0 关闭副本。</p><h2 id="8-GC方面，在使用ElasticSearch时要注意什么？"><a href="#8-GC方面，在使用ElasticSearch时要注意什么？" class="headerlink" title="8 GC方面，在使用ElasticSearch时要注意什么？"></a>8 GC方面，在使用ElasticSearch时要注意什么？</h2><p>​倒排词典的索引需要常驻内存，无法GC，需要监控data node上segment memory增长趋势。</p><p>​各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小，并且要应该根据最坏的情况来看heap是否够用，也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？避免采用clear cache等“自欺欺人”的方式来释放内存。</p><p>​避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan &amp; scroll api来实现。</p><p>​cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。</p><p>​想知道heap够不够，必须结合实际应用场景，并对集群的heap使用情况做持续的监控。</p><h2 id="9-ElasticSearch对于大数据量（上亿量级）的聚合如何实现？"><a href="#9-ElasticSearch对于大数据量（上亿量级）的聚合如何实现？" class="headerlink" title="9 ElasticSearch对于大数据量（上亿量级）的聚合如何实现？"></a>9 ElasticSearch对于大数据量（上亿量级）的聚合如何实现？</h2><p>ElasticSearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 </p><h2 id="10-在并发情况下，ElasticSearch如果保证读写一致？"><a href="#10-在并发情况下，ElasticSearch如果保证读写一致？" class="headerlink" title="10 在并发情况下，ElasticSearch如果保证读写一致？"></a>10 在并发情况下，ElasticSearch如果保证读写一致？</h2><p>​可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；</p><p>​另外对于写操作，一致性级别支持quorum&#x2F;one&#x2F;all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。</p><p>​对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。</p><h2 id="11-如何监控-ElasticSearch-集群状态？"><a href="#11-如何监控-ElasticSearch-集群状态？" class="headerlink" title="11 如何监控 ElasticSearch 集群状态？"></a>11 如何监控 ElasticSearch 集群状态？</h2><p>​ElasticSearch-head插件</p><p>​通过 Kibana 监控 ElasticSearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标</p><h2 id="12-是否了解字典树？"><a href="#12-是否了解字典树？" class="headerlink" title="12 是否了解字典树？"></a>12 是否了解字典树？</h2><p>​常用字典数据结构如下所示:</p><p><img src="/imgs/blog12/clip_image006.jpg" alt="img"></p><p>​字典树又称单词查找树，<a href="https://baike.baidu.com/item/Trie%E6%A0%91">Trie树</a>，是一种<a href="https://baike.baidu.com/item/%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84/9663807">树形结构</a>，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的<a href="https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6">字符</a>串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。</p><p>​Trie的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有3个基本性质:</p><p>​①根节点不包含字符，除根节点外每一个节点都只包含一个字符。</p><p>​②从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。</p><p>​③每个节点的所有子节点包含的字符都不相同。</p><p>​对于中文的字典树，每个节点的子节点用一个哈希表存储，这样就不用浪费太大的空间，而且查询速度上可以保留哈希的复杂度O(1)。</p><h2 id="13-ElasticSearch中的集群、节点、索引、文档、类型是什么？"><a href="#13-ElasticSearch中的集群、节点、索引、文档、类型是什么？" class="headerlink" title="13 ElasticSearch中的集群、节点、索引、文档、类型是什么？"></a>13 ElasticSearch中的集群、节点、索引、文档、类型是什么？</h2><p>​集群是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“ElasticSearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。</p><p>​节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。</p><p>​索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL &#x3D;&gt;数据库 ElasticSearch &#x3D;&gt;索引</p><p>​文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL &#x3D;&gt; Databases &#x3D;&gt; Tables &#x3D;&gt; Columns &#x2F; Rows ElasticSearch &#x3D;&gt; Indices &#x3D;&gt; Types &#x3D;&gt;具有属性的文档</p><p>​类型是索引的逻辑类别&#x2F;分区，其语义完全取决于用户。</p><h2 id="14-ElasticSearch中的倒排索引是什么？"><a href="#14-ElasticSearch中的倒排索引是什么？" class="headerlink" title="14 ElasticSearch中的倒排索引是什么？"></a>14 ElasticSearch中的倒排索引是什么？</h2><p>​倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。ES中的倒排索引其实就是lucene的倒排索引，区别于传统的正向索引，倒排索引会再存储数据时将关键词和数据进行关联，保存到倒排表中，然后查询时，将查询内容进行分词后在倒排表中进行查询，最后匹配数据即可。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch分片集群</title>
      <link href="/2023/06/06/blog11/"/>
      <url>/2023/06/06/blog11/</url>
      
        <content type="html"><![CDATA[<h2 id="1-分布式集群"><a href="#1-分布式集群" class="headerlink" title="1 分布式集群"></a>1 分布式集群</h2><h3 id="1-1-单节点集群"><a href="#1-1-单节点集群" class="headerlink" title="1.1 单节点集群"></a>1.1 单节点集群</h3><p>我们在包含一个空节点的集群内创建名为 users 的索引，为了演示目的，我们将分配3个主分片和一份副本（每个主分片拥有一个副本分片）</p><p>{</p><p>  “settings” : {</p><p>   “number_of_shards” : 3,</p><p>   “number_of_replicas” : 1</p><p>  }</p><p>}</p><p><img src="/imgs/blog11/clip_image002-16860529743441.jpg" alt="img"></p><p>我们的集群现在是拥有一个索引的单节点集群。所有3个主分片都被分配在 node-1 。</p><p><img src="/imgs/blog11/clip_image004-16860529743442.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image006.jpg" alt="img"></p><p>  集群健康值:yellow( 3 of 6 ) : 表示当前集群的全部主分片都正常运行，但是副本分片没有全部处在正常状态  <img src="/imgs/blog11/clip_image008.jpg" alt="img">: 3个主分片正常  <img src="/imgs/blog11/clip_image010.jpg" alt="img">: 3个副本分片都是  Unassigned —— 它们都没有被分配到任何节点。 在同一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点上的所有副本数据。  </p><p>当前我们的集群是正常运行的，但是在硬件故障时有丢失数据的风险。</p><h3 id="1-2-故障转移"><a href="#1-2-故障转移" class="headerlink" title="1.2 故障转移"></a>1.2 故障转移</h3><p>当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。 但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。</p><p>如果启动了第二个节点，我们的集群将会拥有两个节点的集群 : 所有主分片和副本分片都已被分配</p><p><img src="/imgs/blog11/clip_image012.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image014.jpg" alt="img"></p><p>  集群健康值:green( 6 of 6 ) : 表示所有6个分片（包括3个主分片和3个副本分片）都在正常运行。  <img src="/imgs/blog11/clip_image008.jpg" alt="img">: 3个主分片正常  <img src="/imgs/blog11/clip_image016.jpg" alt="img">: 当第二个节点加入到集群后，3个副本分片将会分配到这个节点上——每个主分片对应一个副本分片。这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。所有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们既可以从主分片又可以从副本分片上获得文档。  </p><h3 id="1-3-水平扩容"><a href="#1-3-水平扩容" class="headerlink" title="1.3 水平扩容"></a>1.3 水平扩容</h3><p>怎样为我们的正在增长中的应用程序按需扩容呢？当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配</p><p><img src="/imgs/blog11/clip_image018.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image020.jpg" alt="img"></p><p>  集群健康值:green( 6 of 6 ) : 表示所有6个分片（包括3个主分片和3个副本分片）都在正常运行。  <img src="/imgs/blog11/clip_image022.jpg" alt="img">  <img src="/imgs/blog11/clip_image024.jpg" alt="img">  <img src="/imgs/blog11/clip_image026.jpg" alt="img">  Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点，现在每个节点上都拥有2个分片，而不是之前的3个。 这表示每个节点的硬件资源（CPU, RAM, I&#x2F;O）将被更少的分片所共享，每个分片的性能将会得到提升。  分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。  </p><p>**<img src="/imgs/blog11/clip_image028.jpg" alt="img"><strong><strong>但是如果我们想要扩容超过6</strong></strong>个节点怎么办呢？**</p><p>主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。</p><p>在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 1 增加到 2</p><p>{</p><p>  “number_of_replicas” : 2</p><p>}</p><p><img src="/imgs/blog11/clip_image030.jpg" alt="img"></p><p>users索引现在拥有9个分片：3个主分片和6个副本分片。 这意味着我们可以将集群扩容到9个节点，每个节点上一个分片。相比原来3个节点时，集群搜索性能可以提升 3 倍。</p><p><img src="/imgs/blog11/clip_image032.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况</p><p><img src="/imgs/blog11/clip_image034.jpg" alt="img"></p><p>当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。</p><p>但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去2个节点的情况下不丢失任何数据。</p><h3 id="1-4-应对故障"><a href="#1-4-应对故障" class="headerlink" title="1.4 应对故障"></a>1.4 应对故障</h3><p>我们关闭第一个节点，这时集群的状态为:关闭了一个节点后的集群。</p><p><img src="/imgs/blog11/clip_image036.jpg" alt="img"><img src="/imgs/blog11/clip_image038.jpg" alt="img"></p><p><img src="/imgs/blog11/clip_image040.jpg" alt="img"></p><p>我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： Node 2 。在我们关闭 Node 1 的同时也失去了主分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。</p><p><img src="/imgs/blog11/clip_image042.jpg" alt="img"></p><p>幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为 yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。</p><p>**<img src="/imgs/blog11/clip_image043.jpg" alt="img">**<strong>为什么我们集群状态是 yellow</strong> <strong>而不是 green</strong> <strong>呢</strong>？ </p><p>虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应2份副本分片，而此时只存在一份副本分片。 所以集群不能为 green 的状态，不过我们不必过于担心：如果我们同样关闭了 Node 2 ，我们的程序 依然 可以保持在不丢任何数据的情况下运行，因为 Node 3 为每一个分片都保留着一份副本。</p><p>如果我们重新启动 Node 1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。 如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是Master节点切换了。</p><p><img src="/imgs/blog11/clip_image045.jpg" alt="img"></p><h2 id="2路由计算"><a href="#2路由计算" class="headerlink" title="2路由计算"></a>2路由计算</h2><p>当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：</p><p><img src="/imgs/blog11/clip_image047.jpg" alt="img"></p><p>routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。</p><p>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</p><p>所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。</p><h2 id="3分片控制"><a href="#3分片控制" class="headerlink" title="3分片控制"></a>3分片控制</h2><p>我们假设有一个集群由三个节点组成。 它包含一个叫 emps 的索引，有两个主分片，每个主分片有两个副本分片。相同分片的副本不会放在同一节点。</p><p><img src="/imgs/blog11/clip_image049.jpg" alt="img"></p><p><img src="/imgs/blog11/clip_image051.jpg" alt="img"></p><p>通过elasticsearch-head插件查看集群情况，所以我们的集群是一个有三个节点和一个索引的集群。</p><p><img src="/imgs/blog11/clip_image053.jpg" alt="img"></p><p>我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 在下面的例子中，将所有的请求发送到 Node 1，我们将其称为 <strong>协调节点</strong>(coordinating node) 。</p><p><img src="/imgs/blog11/clip_image055.jpg" alt="img">：<strong>当发送请求的时候，</strong> <strong>为了扩展负载，更好的做法是轮询集群中所有的节点。</strong></p><h3 id="3-1-写流程"><a href="#3-1-写流程" class="headerlink" title="3.1 写流程"></a>3.1 写流程</h3><p>新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片</p><p><img src="/imgs/blog11/clip_image057.jpg" alt="img"></p><p><strong>新建，索引和删除文档所需要的步骤顺序</strong>：</p><p>\1.     客户端向 Node 1 发送新建、索引或者删除请求。</p><p>\2.     节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。</p><p>\3.     Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。</p><p>在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。</p><p>有一些可选的请求参数允许您影响这个过程，可能以数据安全为代价提升性能。这些选项很少使用，因为Elasticsearch已经很快，但是为了完整起见，请参考下面表格：</p><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>consistency</td><td>consistency，即一致性。在默认设置下，即使仅仅是在试图执行一个_写_操作之前，主分片都会要求 必须要有 规定数量(quorum)（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行_写_操作(其中分片副本可以是主分片或者副本分片)。这是为了避免在发生网络分区故障（network partition）的时候进行_写_操作，进而导致数据不一致。_规定数量_即：  <strong>int( (primary  + number_of_replicas) &#x2F; 2 ) + 1</strong>  consistency 参数的值可以设为 one （只要主分片状态 ok 就允许执行_写_操作）,all（必须要主分片和所有副本分片的状态没问题才允许执行_写_操作）, 或 quorum 。默认值为  quorum , 即大多数的分片副本状态没问题就允许执行_写_操作。  注意，规定数量 的计算公式中 number_of_replicas 指的是在索引设置中的设定副本分片数，而不是指当前处理活动状态的副本分片数。如果你的索引设置中指定了当前索引拥有三个副本分片，那规定数量的计算结果即：  <strong>int( (primary  + 3 replicas) &#x2F; 2 ) + 1 &#x3D; 3</strong>  如果此时你只启动两个节点，那么处于活跃状态的分片副本数量就达不到规定数量，也因此您将无法索引和删除任何文档。</td></tr><tr><td>timeout</td><td>如果没有足够的副本分片会发生什么？ Elasticsearch会等待，希望更多的分片出现。默认情况下，它最多等待1分钟。 如果你需要，你可以使用 timeout 参数 使它更早终止： 100 100毫秒，30s 是30秒。</td></tr></tbody></table><p><img src="/imgs/blog11/clip_image059.jpg" alt="img">新索引默认有 1 个副本分片，这意味着为满足规定数量应该需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当 number_of_replicas 大于1的时候，规定数量才会执行。</p><h3 id="3-2-读流程"><a href="#3-2-读流程" class="headerlink" title="3.2 读流程"></a>3.2 读流程</h3><p>我们可以从主分片或者从其它任意副本分片检索文档</p><p><img src="/imgs/blog11/clip_image061.jpg" alt="img"></p><p><strong>从主分片或者副本分片检索文档的步骤顺序</strong>：</p><p>\1.     客户端向 Node 1 发送获取请求。</p><p>\2.     节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。</p><p>\3.     Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。</p><p>在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p><h3 id="3-3-更新流程"><a href="#3-3-更新流程" class="headerlink" title="3.3 更新流程"></a>3.3 更新流程</h3><p>部分更新一个文档结合了先前说明的读取和写入流程：</p><p><img src="/imgs/blog11/clip_image063.jpg" alt="img"></p><p><strong>部分更新一个文档的步骤如下</strong>：</p><p>\1.     客户端向 Node 1 发送更新请求。</p><p>\2.     它将请求转发到主分片所在的 Node 3 。</p><p>\3.     Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。</p><p>\4.     如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。</p><p>当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果Elasticsearch仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。</p><h3 id="3-4-多文档操作流程"><a href="#3-4-多文档操作流程" class="headerlink" title="3.4 多文档操作流程"></a>3.4 多文档操作流程</h3><p>mget 和 bulk API 的模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成 每个分片 的多文档请求，并且将这些请求并行转发到每个参与节点。</p><p>协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端</p><p><img src="/imgs/blog11/clip_image065.jpg" alt="img"></p><p><strong>用单个 mget</strong> <strong>请求取回多个文档所需的步骤顺序</strong>:</p><p>\1.     客户端向 Node 1 发送 mget 请求。</p><p>\2.     Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。</p><p>可以对 docs 数组中每个文档设置 routing 参数。</p><p><strong>bulk API</strong>， 允许在单个批量请求中执行多个创建、索引、删除和更新请求。</p><p><img src="/imgs/blog11/clip_image067.jpg" alt="img"></p><p>bulk API 按如下步骤顺序执行：</p><p>\1.     客户端向 Node 1 发送 bulk 请求。</p><p>\2.     Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</p><p>\3.     主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud常用组件对比</title>
      <link href="/2023/06/04/blog10/"/>
      <url>/2023/06/04/blog10/</url>
      
        <content type="html"><![CDATA[<h1 id="Eurka和Nacos"><a href="#Eurka和Nacos" class="headerlink" title="Eurka和Nacos"></a>Eurka和Nacos</h1><p>Nacos和Eureka都是服务注册和发现的开源项目，用于构建分布式系统和微服务架构。它们的主要区别如下：</p><h2 id="服务注册和发现机制："><a href="#服务注册和发现机制：" class="headerlink" title="服务注册和发现机制："></a>服务注册和发现机制：</h2><ul><li>Nacos：Nacos提供了基于实例的服务注册和发现机制。服务提供者在启动时向Nacos注册自己的服务实例，并定期发送心跳来保持注册。服务消费者通过向Nacos查询服务列表来发现可用的服务实例。</li><li>Eureka：Eureka采用了基于中心化的服务注册和发现模式。服务提供者在启动时向Eureka注册自己的服务实例，并周期性地发送心跳来保持注册。服务消费者通过向Eureka服务器获取服务注册表来发现可用的服务实例。</li><li>Nacos支持服务端主动检测提供者状态:临时实例采用心跳模式，非临时实例采用主动检测模式临时实例心跳不正常会被剔除，非临时实例则不会被剔除。另外Nacos支持服务列表变更的消息推送模式，服务列表更新更及时</li></ul><h2 id="容错性和高可用性："><a href="#容错性和高可用性：" class="headerlink" title="容错性和高可用性："></a>容错性和高可用性：</h2><ul><li>Nacos：Nacos支持多节点的集群部署，具有高可用性和容错性。它使用Raft算法来保证数据的一致性和可用性，并支持自动的主从切换和故障恢复。</li><li>Eureka：Eureka的设计目标是在AWS云平台上实现高可用性。它使用了主从架构，其中一个Eureka服务器作为主服务器，其他服务器作为从服务器。当主服务器失效时，会触发Eureka客户端的自我保护机制，但这可能导致注册信息的延迟和不一致。</li><li>Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式。Eureka只有AP模式</li></ul><h2 id="配置管理："><a href="#配置管理：" class="headerlink" title="配置管理："></a>配置管理：</h2><ul><li>Nacos：Nacos提供了功能强大的配置管理功能。它支持动态配置的发布、监听和刷新，可以动态地修改配置参数而无需重启服务。Nacos还提供了命名空间、配置组和配置版本等概念，可以对配置进行灵活的管理和隔离。</li><li>Eureka：Eureka本身并没有内置的配置管理功能。如果需要配置管理，可以结合其他的配置中心（如Spring Cloud Config）与Eureka一起使用。</li></ul><h2 id="自我保护机制"><a href="#自我保护机制" class="headerlink" title="自我保护机制"></a>自我保护机制</h2><p>​        相同点: 保护阈值都是个比例，0-1 范围，表示健康的 instance 占全部instance 的比例。<br>​        不同点:<br>​        (1)保护方式不同<br>​        Eureka保护方式:当在短时间内，统计续约失败的比例，如果达到一定阈值，则会触发自我保护的机制，在该机制下Eureka Server不会别除任何的微服务，等到正常后，再退出自我保护机制。自我保护开关(eureka.server.enable-self.preservation. false)<br>​        Nacos保护方式: 当域名健康实例 (nstance) 占总服务实例(nstance)的比例小于阈值时，无论实例(Instance) 是否健康，都会将这个实例 (instance)返回给客户端。这样做虽然损失了一部分流量，但是保证了集群的剩余健康实例(Instance)能正常工作。<br>​        (2)范围不同<br>​        Nacos 的阈值是针对某个具体 Service 的，而不是针对所有服务的。但 Eureka的自我保护阈值是针对所有服务的.</p><h2 id="社区支持和集成："><a href="#社区支持和集成：" class="headerlink" title="社区支持和集成："></a>社区支持和集成：</h2><ul><li>Nacos：Nacos由阿里巴巴开源，得到了广泛的社区支持。它与Spring Cloud紧密集成，并提供了丰富的文档和示例来帮助开发者使用。</li><li>Eureka：Eureka最初由Netflix开发，虽然已经开源并得到了一定的社区支持，但相比Nacos而言，社区支持相对较少。然而，Eureka与Netflix的开源项目（如Ribbon和Hystrix）紧密集成，并在Netflix的生态系统中被广泛应用。</li></ul><h1 id="Hystrix和Sentinel"><a href="#Hystrix和Sentinel" class="headerlink" title="Hystrix和Sentinel"></a>Hystrix和Sentinel</h1><p>​        Sentinel和Hystrix都是用于实现服务容错和熔断的开源项目。 Hystrix 的关注点在于以 <em>隔离</em> 和 <em>熔断</em> 为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。而 Sentinel 的侧重点在于：多样化的流量控制、熔断降级、系统负载保护、实时监控和控制台。</p><h2 id="资源模型和执行模型上的对比"><a href="#资源模型和执行模型上的对比" class="headerlink" title="资源模型和执行模型上的对比"></a>资源模型和执行模型上的对比</h2><p>​        Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象（<code>HystrixCommand</code> &#x2F; <code>HystrixObservableCommand</code>），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。</p><p>​        Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流&#x2F;降级&#x2F;负载保护策略。在 Sentinel 中资源定义和规则配置是分离的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则。埋点方式有两种：</p><ul><li>try-catch 方式（通过 <code>SphU.entry(...)</code>），用户在 catch 块中执行异常处理 &#x2F; fallback</li><li>if-else 方式（通过 <code>SphO.entry(...)</code>），当返回 false 时执行异常处理 &#x2F; fallback</li></ul><p>​        Sentinel 还支持基于注解的资源定义方式，可以通过 <code>@SentinelResource</code> 注解参数指定异常处理函数和 fallback 函数。</p><h2 id="隔离设计上的对比"><a href="#隔离设计上的对比" class="headerlink" title="隔离设计上的对比"></a>隔离设计上的对比</h2><p>​        隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。</p><p>​        但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的线程池会非常影响性能。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。</p><p>​        Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。</p><h2 id="熔断降级对比"><a href="#熔断降级对比" class="headerlink" title="熔断降级对比"></a>熔断降级对比</h2><p>​        Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。</p><h2 id="实时指标统计实现对比"><a href="#实时指标统计实现对比" class="headerlink" title="实时指标统计实现对比"></a>实时指标统计实现对比</h2><p>​        Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功&#x2F;失败&#x2F;超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。</p><p>​        Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 <code>LeapArray</code> 的高性能滑动窗口，后续根据需要可能会引入 reactive stream 等实现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th></th><th>Sentinel</th><th>Hystrix</th></tr></thead><tbody><tr><td>隔离策略</td><td>信号量隔离</td><td>线程池隔离&#x2F;信号量隔离</td></tr><tr><td>熔断降级策略</td><td>基于慢调用比例或异常比例</td><td>基于失败比率</td></tr><tr><td>实时指标实现</td><td>滑动窗口</td><td>滑动窗口（基于 RxJava）</td></tr><tr><td>规则配置</td><td>支持多种数据源</td><td>支持多种数据源</td></tr><tr><td>扩展性</td><td>多个扩展点</td><td>插件的形式</td></tr><tr><td>基于注解的支持</td><td>支持</td><td>支持</td></tr><tr><td>限流</td><td>基于 QPS，支持基于调用关系的限流</td><td>有限的支持</td></tr><tr><td>流量整形</td><td>支持慢启动、匀速排队模式</td><td>不支持</td></tr><tr><td>系统自适应保护</td><td>支持</td><td>不支持</td></tr><tr><td>控制台</td><td>开箱即用，可配置规则、查看秒级监控、机器发现等</td><td>不完善</td></tr><tr><td>常见框架的适配</td><td>Servlet、Spring Cloud、Dubbo、gRPC 等</td><td>Servlet、Spring Cloud Netflix</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hystrix简介</title>
      <link href="/2023/06/03/blog9/"/>
      <url>/2023/06/03/blog9/</url>
      
        <content type="html"><![CDATA[<h1 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h1><p>​Hystrix是一个用于构建弹性和容错系统的Java库，由Netflix开发和维护。它旨在帮助开发者构建具有容错能力的分布式系统，特别是在处理复杂的网络通信时。</p><p>​Hystrix主要解决的问题是在分布式系统中的服务之间进行通信时可能出现的故障和延迟。这些问题可能导致级联故障，即一个服务的故障传递到其他服务，最终导致整个系统不可用。Hystrix通过引入隔离、断路器和回退机制来解决这些问题。</p><p>​隔离是Hystrix的核心概念之一。它通过将每个服务调用封装在独立的线程池中运行，实现了请求的隔离。这样，当某个服务调用失败或延迟较高时，不会对其他服务产生负面影响。</p><p>​断路器是Hystrix的另一个重要概念。它监控服务调用的错误率和延迟情况。当错误率或延迟超过预设的阈值时，断路器会打开，停止对该服务的调用，并快速失败。这样可以防止级联故障，并且当服务恢复正常后，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>此外，Hystrix还提供了回退机制，用于在服务调用失败时提供备选方案。开发者可以定义回退逻辑，当服务调用失败时，Hystrix会自动调用回退逻辑来返回预先定义的备选结果，保证系统的稳定性和可用性。</p><p>​Hystrix还提供了丰富的监控和度量功能，开发者可以实时监控服务调用的成功率、失败率、延迟等指标，并通过配置仪表盘和报警机制来及时发现和处理故障。</p><p>​总而言之，Hystrix是一个弹性和容错库，可以帮助开发者构建可靠的分布式系统。它通过隔离、断路器和回退机制来处理故障和延迟，并提供监控和度量功能来帮助开发者实时了解系统的健康状态。</p><h1 id="Hystrix服务降级"><a href="#Hystrix服务降级" class="headerlink" title="Hystrix服务降级"></a>Hystrix服务降级</h1><p>​Hystrix中的服务降级是指在系统出现故障或异常情况时，为了保证系统的可用性和稳定性，临时替代原本的服务调用，返回一个备选的响应结果。</p><p>​服务降级是通过定义回退逻辑来实现的。在使用Hystrix时，开发者可以为每个服务调用定义一个回退方法（Fallback Method），该方法在服务调用失败或超时时被触发，返回一个备选结果。</p><p>​回退方法的实现应尽量快速且轻量级，避免引入新的故障点。它可以返回一个默认值、预先计算的结果、缓存的数据或静态错误页面等，具体根据业务需求而定。通过合理定义回退逻辑，可以提供用户友好的响应或保证系统的基本功能仍能正常运行。</p><p>​Hystrix提供了多种方式来实现服务降级：</p><ol><li>注解方式：通过在服务调用的方法上添加@HystrixCommand注解，指定回退方法。当服务调用发生异常、超时或熔断时，会触发回退方法。</li><li>编程方式：通过Hystrix提供的命令模式（HystrixCommand）或可观察者模式（HystrixObservableCommand）进行服务调用，并在调用链中指定回退方法。</li><li>信号量隔离：除了使用线程池隔离外，Hystrix还支持信号量隔离，可以在同一线程中执行服务调用和回退方法，减少线程切换和上下文切换的开销。</li></ol><p>通过服务降级，Hystrix可以在服务故障或不可用时，提供一种临时替代方案，保证系统的可用性和稳定性。开发者可以根据具体情况定义合适的回退逻辑，提供良好的用户体验或保持基本功能的正常运行。</p><h1 id="Hystrix服务熔断"><a href="#Hystrix服务熔断" class="headerlink" title="Hystrix服务熔断"></a>Hystrix服务熔断</h1><p>​Hystrix中的服务熔断是一种用于防止故障扩散和快速恢复的机制。当服务调用失败率超过一定阈值时，Hystrix会打开断路器，停止对该服务的调用，并且在一段时间内直接返回预先设定的备选结果，而不去执行实际的服务调用。</p><p>​服务熔断的目的是防止级联故障，当一个服务出现问题时，避免对依赖它的其他服务造成更大的影响。通过断路器的打开，可以快速失败并迅速恢复正常。当断路器处于打开状态时，Hystrix会定期允许一部分流量通过，以便检测服务是否恢复正常。如果服务调用成功率达到一定阈值，断路器会逐渐闭合，重新允许对该服务的调用。</p><p>​Hystrix中的服务熔断通过以下方式实现：</p><ol><li>错误百分比阈值：开发者可以配置一个错误百分比阈值，当在一个统计窗口内的请求错误率超过该阈值时，断路器将打开。</li><li>请求阈值：开发者可以配置一个请求阈值，当在一个统计窗口内的请求数量低于该阈值时，不会触发断路器。这是为了避免在服务启动初期的误判。</li><li>熔断器状态：断路器有三种状态：关闭、打开和半开。初始状态为关闭。当错误百分比超过阈值时，断路器打开；在打开状态下，所有请求都会直接返回备选结果；在一段时间后，断路器进入半开状态，允许一部分流量通过以检测服务的健康状态；如果半开状态下的请求成功，则断路器闭合；否则，重新打开断路器。</li></ol><p>通过服务熔断，Hystrix可以及时停止对不可用的服务的调用，防止故障的扩散，并通过快速失败和自动恢复的机制来提高系统的稳定性和可用性。开发者可以根据具体需求，配置合适的错误百分比阈值和请求阈值，以及定义适当的备选结果，从而保护系统免受不可用服务的影响。</p><h1 id="Hystrix服务限流"><a href="#Hystrix服务限流" class="headerlink" title="Hystrix服务限流"></a>Hystrix服务限流</h1><p>​Hystrix中的服务限流是一种控制系统资源使用的机制，用于保护系统免受过多请求的影响。通过限制对某个服务的并发请求量，可以防止系统资源被过度消耗，确保系统的稳定性和可用性。</p><p>​在Hystrix中，可以通过以下方式来实现服务限流：</p><ol><li>线程池隔离：Hystrix将每个服务调用封装在独立的线程池中运行，通过配置线程池的大小和队列容量，可以限制同时执行的并发请求数量。当线程池满了，新的请求将被拒绝或排队等待。</li><li>信号量隔离：除了线程池隔离外，Hystrix还支持使用信号量来限制并发请求的数量。开发者可以在服务调用的方法上添加@HystrixCommand注解，并指定一个信号量的数量作为参数，从而限制对该服务的并发访问。</li><li>请求队列：线程池隔离模式下，可以设置一个请求队列，用于缓冲未能立即执行的请求。请求队列的大小也可以作为限制并发请求的一种手段。当队列已满时，新的请求将被拒绝。</li></ol><p>​通过配置线程池大小、队列容量和信号量数量，开发者可以根据系统的资源情况和负载情况，灵活地控制并发请求的数量。适当的限流策略可以保护系统免受过载的影响，避免资源耗尽和性能下降。</p><p>​需要注意的是，服务限流只是一种保护机制，不能替代系统的容量规划和性能优化。合理的限流策略应结合实际情况进行调整，以达到最佳的系统性能和用户体验。</p><h1 id="Hystrix工作流程"><a href="#Hystrix工作流程" class="headerlink" title="Hystrix工作流程"></a>Hystrix工作流程</h1><p>​Hystrix的工作流程可以概括为以下几个步骤：</p><ol><li>发起服务调用：应用程序通过调用封装了服务调用的Hystrix命令（HystrixCommand）或可观察者（HystrixObservableCommand）来发起服务调用。这些命令包含了要执行的服务逻辑以及相关的配置信息。</li><li>降级检查：在服务调用之前，Hystrix会检查是否配置了回退逻辑（Fallback），以应对服务调用失败或超时的情况。如果配置了回退逻辑，Hystrix会将其与原始服务调用绑定。</li><li>断路器判断：在发起服务调用之前，Hystrix会检查断路器的状态。如果断路器处于打开状态（Open），Hystrix会立即触发回退逻辑，不会实际发起服务调用。</li><li>服务调用：如果降级检查和断路器判断通过，Hystrix会尝试发起实际的服务调用。根据配置，服务调用可能会在一个独立的线程池中执行，以实现请求隔离。Hystrix还可以通过信号量来控制并发请求数量。</li><li>容错处理：在服务调用过程中，Hystrix会监控请求的结果。如果请求发生故障、超时或异常，Hystrix会根据配置的容错策略执行相应的操作，例如打开断路器、触发回退逻辑等。</li><li>回退逻辑执行：当服务调用失败或超时时，Hystrix会执行与之绑定的回退逻辑。回退逻辑可以是预先定义的备选结果、缓存数据、静态错误页面等，以提供系统的基本功能或友好的用户体验。</li><li>断路器状态更新：根据服务调用的结果，Hystrix会更新断路器的状态。如果服务调用成功，断路器会逐渐闭合；如果服务调用失败或发生故障，断路器会打开，停止对该服务的调用。断路器在一段时间后会尝试半开状态，允许一部分流量通过以检测服务的健康状态。</li></ol><p>​通过以上的工作流程，Hystrix能够提供服务的容错和弹性处理，防止故障的扩散和级联故障的发生。它通过断路器、降级逻辑和线程隔离等机制来保护系统的可用性和稳定性，并提供监控和度量功能来实时了解系统的健康状况。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ribbon、Gateway、Nginx</title>
      <link href="/2023/06/03/blog8/"/>
      <url>/2023/06/03/blog8/</url>
      
        <content type="html"><![CDATA[<h1 id="Ribbon、Gateway、Nginx区别"><a href="#Ribbon、Gateway、Nginx区别" class="headerlink" title="Ribbon、Gateway、Nginx区别"></a>Ribbon、Gateway、Nginx区别</h1><h2 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h2><p>​Ribbon 是一个用于客户端负载均衡的开源项目，最初由 Netflix 开发并开源。它主要用于在分布式系统中选择合适的服务实例并进行负载均衡。</p><p>​在微服务架构中，服务通常以多个实例运行，这些实例可能分布在不同的主机或容器中。Ribbon 可以与服务注册中心（如 Eureka、Consul 等）集成，通过查询注册中心获取可用的服务实例列表。</p><p>​Ribbon 在客户端应用内部工作，作为一个负载均衡组件，它会根据一定的负载均衡策略选择一个合适的服务实例来发送请求。这些负载均衡策略包括轮询、随机、加权随机、最少连接等。选择的服务实例将接收客户端的请求，并将响应返回给客户端。</p><p>​Ribbon 还提供了一些其他功能，如超时设置、重试机制、服务实例健康检查等。它可以根据服务实例的健康状态和负载情况动态地选择合适的实例，以实现负载均衡和故障恢复。</p><p>​Ribbon 的优点是简单轻量、易于集成和扩展。它与多种服务注册中心和开发框架兼容，适用于各种微服务架构中的负载均衡需求。</p><h2 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h2><p>​Gateway是一种在分布式系统中充当入口点的中间层组件。它位于客户端和后端服务之间，负责接收来自客户端的请求，并将请求转发到适当的后端服务进行处理。</p><p>​网关的主要功能包括：</p><ol><li><p>请求路由：网关根据预定义的路由规则将请求路由到相应的后端服务。路由规则可以基于请求的路径、请求方法、请求头等进行匹配和转发。</p></li><li><p>协议转换：网关可以根据需要将请求和响应从一种协议转换为另一种协议。例如，可以将传入的请求从 HTTP 转换为 gRPC，或将响应从 gRPC 转换为 JSON。</p></li><li><p>负载均衡：网关可以实现负载均衡策略，将请求均匀地分发到多个后端服务实例。这可以通过集成服务发现组件（如 Eureka、Consul 等）来实现，并根据服务实例的健康状态和负载情况进行动态选择。</p></li><li><p>安全认证与授权：网关可以提供身份验证和授权功能，保护后端服务免受未经授权的访问。它可以验证请求的身份信息（如令牌、证书等），并根据配置的权限规则控制访问权限。</p></li><li><p>监控与日志记录：网关可以记录请求和响应的日志，并提供监控指标和统计信息，用于系统性能分析、故障排查和流量监控。</p></li><li><p>缓存：网关可以缓存经常请求的响应，以提高系统的响应速度和吞吐量。这可以减少后端服务的负载，并提供更快的响应时间。</p></li></ol><p>​网关在微服务架构中扮演着重要的角色，它提供了一种集中管理和处理请求的方式，简化了客户端和后端服务之间的通信和协调。常见的网关实现包括 Spring Cloud Gateway、Netflix Zuul、Kong 等。这些网关可以与其他微服务组件集成，并提供丰富的功能来支持复杂的系统架构和需求。</p><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><p>​Nginx是一个高性能的开源反向代理服务器、负载均衡器和Web服务器。它具有轻量级、高效率和可扩展性的特点，被广泛应用于构建高性能的Web应用和服务。</p><ol><li><p>反向代理：<br>Nginx作为反向代理服务器，接收客户端请求，并将请求转发到后端服务器。它可以隐藏后端服务器的细节，并提供负载均衡功能，将请求分发到多个后端服务器上，从而提高系统的可用性和性能。</p></li><li><p>负载均衡：<br>Nginx支持多种负载均衡算法，如轮询、IP哈希、最少连接等。它可以根据配置的负载均衡策略将请求均匀地分发到多个后端服务器，以实现负载均衡和故障恢复。</p></li><li><p>静态文件服务：<br>Nginx可以快速高效地提供静态文件的服务，如HTML、CSS、JavaScript、图像文件等。它通过使用异步非阻塞的方式处理请求，以及内置的缓存机制，提供了出色的性能和可扩展性。</p></li><li><p>SSL&#x2F;TLS加密：<br>Nginx支持SSL&#x2F;TLS协议，可以用于配置安全的HTTPS连接，为网站和应用程序提供加密和安全传输的功能。它可以作为SSL终端点，处理与客户端之间的加密通信。</p></li><li><p>动态请求转发：<br>Nginx还可以根据请求的内容或规则将请求转发到不同的后端服务。它支持配置灵活的反向代理规则，根据URL路径、请求头、参数等条件进行请求转发和路由。</p></li><li><p>高性能和可扩展性：<br>Nginx采用事件驱动、非阻塞的架构设计，可以处理大量并发连接和高流量的请求，具有出色的性能表现。它还支持多进程、多线程的部署模式，可以根据需求进行水平扩展。</p></li><li><p>日志记录和监控：<br>Nginx提供详细的访问日志记录，记录请求和响应的信息，便于故障排查和性能优化。它还支持实时监控和统计指标的收集，可以与其他监控工具集成，实现对系统的监控和管理。</p></li></ol><p>​Nginx是一个强大而灵活的服务器软件，广泛应用于Web应用、反向代理、负载均衡、缓存、媒体流服务等多个领域。</p><h2 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a>三者区别</h2><ol><li>功能定位：<ul><li>Gateway: 网关是一个完整的请求路由和代理解决方案，通常用于构建微服务架构中的入口点，负责请求的接收、路由、转发、安全性、监控等。</li><li>Ribbon: Ribbon是一个客户端负载均衡组件，用于在客户端应用内部选择合适的服务实例，主要负责服务实例的选择和负载均衡算法的应用。</li><li>Nginx: Nginx是一个高性能的反向代理服务器，可以作为负载均衡器，接收客户端请求并将其转发到后端服务器，主要负责请求转发和负载均衡算法的实现。</li></ul></li><li>部署位置：<ul><li>Gateway: 网关通常位于整个架构的边界，作为对外的入口点，接收外部请求并路由到内部的服务实例。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，嵌入在客户端应用中，与应用共存于同一个进程内。</li><li>Nginx: Nginx作为反向代理服务器，通常部署在服务器端，位于客户端与后端服务之间，接收客户端请求并将其转发到后端服务器。</li></ul></li><li>负载均衡算法：<ul><li>Gateway: 网关可以结合多种负载均衡算法，如轮询、权重、哈希等，根据不同的路由规则和服务实例情况进行选择。</li><li>Ribbon: Ribbon提供了丰富的负载均衡算法选择，如轮询、随机、加权随机、最少连接等，可以根据需要选择合适的算法。</li><li>Nginx: Nginx也支持多种负载均衡算法，如轮询、IP哈希、最少连接等，可以根据需求进行配置。</li></ul></li><li>扩展性和灵活性：<ul><li>Gateway: 网关通常提供了更多的功能，如认证、授权、监控等，以及自定义路由规则的灵活性，可以根据具体需求进行定制开发。</li><li>Ribbon: Ribbon作为客户端负载均衡组件，对于客户端应用来说，具有更高的扩展性和灵活性，可以根据业务需求进行自定义的负载均衡逻辑实现。</li><li>Nginx: Nginx作为反向代理服务器，可以灵活配置代理规则和负载均衡算法，同时也支持自定义的扩展模块。</li></ul></li></ol><p>​</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​在项目中同时使用到这三者的情况时候，可以这么理解，用户请求进来是先过Nginx网关，这里的Nginx就相当于一个流量网关，是属于用户访问的一个入口。 然后在进入到gateway网关中，这里的getway网关属于一个业务网关，通过对应的属性配置将请求传递到每一个业务微服务中去。而Ribbon负责微服务之间调用时的负载均衡。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>统计范围内的元音字符串数</title>
      <link href="/2023/06/02/blog7/"/>
      <url>/2023/06/02/blog7/</url>
      
        <content type="html"><![CDATA[<h2 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h2><p><a href="https://leetcode.cn/problems/count-vowel-strings-in-ranges/description/">2559. 统计范围内的元音字符串数 - 力扣（Leetcode）</a></p><p>给你一个下标从 <strong>0</strong> 开始的字符串数组 <code>words</code> 以及一个二维整数数组 <code>queries</code> 。</p><p>每个查询 <code>queries[i] = [li, ri]</code> 会要求我们统计在 <code>words</code> 中下标在 <code>li</code> 到 <code>ri</code> 范围内（<strong>包含</strong> 这两个值）并且以元音开头和结尾的字符串的数目。</p><p>返回一个整数数组，其中数组的第 <code>i</code> 个元素对应第 <code>i</code> 个查询的答案。</p><p><strong>注意：</strong>元音字母是 <code>&#39;a&#39;</code>、<code>&#39;e&#39;</code>、<code>&#39;i&#39;</code>、<code>&#39;o&#39;</code> 和 <code>&#39;u&#39;</code> 。</p><p><strong>示例 1：</strong></p><pre><code>输入：words = [&quot;aba&quot;,&quot;bcb&quot;,&quot;ece&quot;,&quot;aa&quot;,&quot;e&quot;], queries = [[0,2],[1,4],[1,1]]输出：[2,3,0]解释：以元音开头和结尾的字符串是 &quot;aba&quot;、&quot;ece&quot;、&quot;aa&quot; 和 &quot;e&quot; 。查询 [0,2] 结果为 2（字符串 &quot;aba&quot; 和 &quot;ece&quot;）。查询 [1,4] 结果为 3（字符串 &quot;ece&quot;、&quot;aa&quot;、&quot;e&quot;）。查询 [1,1] 结果为 0 。返回结果 [2,3,0] 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：words = [&quot;a&quot;,&quot;e&quot;,&quot;i&quot;], queries = [[0,2],[0,1],[2,2]]输出：[3,2,1]解释：每个字符串都满足这一条件，所以返回 [3,2,1] 。</code></pre><h2 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h2><p>​简单啊，直接暴力求解就完了</p><p>​写代码，测试，提交，，，，然后就超时了，，，，emmmmmmmmmm</p><p>​前缀和优化下，通过</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre><code class="java">class Solution &#123;    public int[] vowelStrings(String[] words, int[][] queries) &#123;        Set&lt;Character&gt; vowels = Set.of(&#39;a&#39;, &#39;e&#39;, &#39;i&#39;, &#39;o&#39;, &#39;u&#39;);        int n = words.length;        int[] prefixSums = new int[n + 1];        for (int i = 0; i &lt; n; ++i) &#123;            char a = words[i].charAt(0), b = words[i].charAt(words[i].length() - 1);            if (vowels.contains(a) &amp;&amp; vowels.contains(b)) &#123;                prefixSums[i+1] = prefixSums[i] + 1;            &#125;else&#123;                prefixSums[i+1] = prefixSums[i];            &#125;        &#125;        int q = queries.length;        int[] ans = new int[q];        for (int i = 0; i &lt; q; i++) &#123;            int start = queries[i][0], end = queries[i][1];            ans[i] = prefixSums[end + 1] - prefixSums[start];        &#125;        return ans;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis主从同步</title>
      <link href="/2023/06/02/blog6/"/>
      <url>/2023/06/02/blog6/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis主从同步"><a href="#Redis主从同步" class="headerlink" title="Redis主从同步"></a>Redis主从同步</h1><h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p><p><img src="/../imgs/blog6/image-20210725152222497.png" alt="image-20210725152222497"></p><p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p><p>有几个概念，可以作为判断依据：</p><ul><li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</li><li><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</li></ul><p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p><p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p><p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p><p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p><p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p><p>如图：</p><p><img src="/../imgs/blog6/image-20210725152700914.png" alt="image-20210725152700914"></p><p>完整流程描述：</p><ul><li>slave节点请求增量同步</li><li>master节点判断replid，发现不一致，拒绝增量同步</li><li>master将完整内存数据生成RDB，发送RDB到slave</li><li>slave清空本地数据，加载master的RDB</li><li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li><li>slave执行接收到的命令，保持与master之间的同步</li></ul><h3 id="2-2-2-增量同步"><a href="#2-2-2-增量同步" class="headerlink" title="2.2.2.增量同步"></a>2.2.2.增量同步</h3><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p><p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p><p><img src="/../imgs/blog6/image-20210725153201086.png" alt="image-20210725153201086"></p><p>那么master怎么知道slave与自己的数据差异在哪里呢?</p><h3 id="repl-backlog原理"><a href="#repl-backlog原理" class="headerlink" title="repl_backlog原理"></a>repl_backlog原理</h3><p>master怎么知道slave与自己的数据差异在哪里呢?</p><p>这就要说到全量同步时的repl_baklog文件了。</p><p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p><p>repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p><p><img src="/../imgs/blog6/image-20210725153359022.png" alt="image-20210725153359022"> </p><p>slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。</p><p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p><p><img src="/../imgs/blog6/image-20210725153524190.png" alt="image-20210725153524190"> </p><p>直到数组被填满：</p><p><img src="/../imgs/blog6/image-20210725153715910.png" alt="image-20210725153715910"> </p><p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p><p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset： </p><p><img src="/../imgs/blog6/image-20210725153937031.png" alt="image-20210725153937031"> </p><p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p><p><img src="/../imgs/blog6/image-20210725154155984.png" alt="image-20210725154155984"> </p><p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p><p><img src="/../imgs/blog6/image-20210725154216392.png" alt="image-20210725154216392"></p><h3 id="主从同步优化"><a href="#主从同步优化" class="headerlink" title="主从同步优化"></a>主从同步优化</h3><p>主从同步可以保证主从数据的一致性，非常重要。</p><p>可以从以下几个方面来优化Redis主从就集群：</p><ul><li>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。</li><li>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</li><li>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</li><li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</li></ul><p>主从从架构图：</p><p><img src="/../imgs/blog6/image-20210725154405899.png" alt="image-20210725154405899"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>简述全量同步和增量同步区别？</p><ul><li>全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。</li><li>增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave</li></ul><p>什么时候执行全量同步？</p><ul><li>slave节点第一次连接master节点时</li><li>slave节点断开时间太久，repl_baklog中的offset已经被覆盖时</li></ul><p>什么时候执行增量同步？</p><ul><li>slave节点断开又恢复，并且在repl_baklog中能找到offset时</li></ul><p>转载自：黑马程序员Redis教程（【黑马程序员Redis入门到实战教程，深度透析redis底层原理+redis分布式锁+企业解决方案+黑马点评实战项目】 <a href="https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web%EF%BC%89">https://www.bilibili.com/video/BV1cr4y1671t/?share_source=copy_web）</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>礼盒的最大甜蜜度</title>
      <link href="/2023/06/01/blog5/"/>
      <url>/2023/06/01/blog5/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/"><a href="https://leetcode.cn/problems/maximum-tastiness-of-candy-basket/description/">2517. 礼盒的最大甜蜜度 - 力扣（Leetcode）</a></a></p><p>​给你一个正整数数组 <code>price</code> ，其中 <code>price[i]</code> 表示第 <code>i</code> 类糖果的价格，另给你一个正整数 <code>k</code> 。</p><p>商店组合 <code>k</code> 类 <strong>不同</strong> 糖果打包成礼盒出售。礼盒的 <strong>甜蜜度</strong> 是礼盒中任意两种糖果 <strong>价格</strong> 绝对差的最小值。</p><p>返回礼盒的 <strong>最大</strong> 甜蜜度<em>。</em></p><p><strong>示例 1：</strong></p><pre><code>输入：price = [13,5,1,8,21,2], k = 3输出：8解释：选出价格分别为 [13,5,21] 的三类糖果。礼盒的甜蜜度为 min(|13 - 5|, |13 - 21|, |5 - 21|) = min(8, 8, 16) = 8 。可以证明能够取得的最大甜蜜度就是 8 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：price = [1,3,1], k = 2输出：2解释：选出价格分别为 [1,3] 的两类糖果。 礼盒的甜蜜度为 min(|1 - 3|) = min(2) = 2 。可以证明能够取得的最大甜蜜度就是 2 。</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：price = [7,7,7,7], k = 2输出：0解释：从现有的糖果中任选两类糖果，甜蜜度都会是 0 。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​最小最大，基本要想到二分了，直接二分甜蜜值，因为选择的差值跟顺序无关，我们可以排序后贪心，当前选择大于之前选择加甜蜜值就统计答案一次，如果最终次数大于等于tastiness，说明甜蜜值还可以更大，收缩左边界，否则收缩右边界。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int maximumTastiness(int[] price, int k) &#123;​    Arrays.sort(price);​    int left = 0, right = price[price.length - 1];​    while (left +1 != right) &#123;​      int mid = (left + right) / 2;​      if (check(price, k, mid)) &#123;​        left = mid;​      &#125; else &#123;​        right = mid;​      &#125;​    &#125;​    return left;  &#125;  public boolean check(int[] price, int k, int tastiness) &#123;​    int prev = Integer.MIN_VALUE / 2;​    int cnt = 0;​    for (int p : price) &#123;​      if (p - prev &gt;= tastiness) &#123;​        cnt++;​        prev = p;​      &#125;​    &#125;​    return cnt &gt;= k;  &#125;&#125;</code></pre><p>甜蜜的祝自己节日快乐</p>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么Redis集群分片最大槽数是16384个</title>
      <link href="/2023/06/01/blog4/"/>
      <url>/2023/06/01/blog4/</url>
      
        <content type="html"><![CDATA[<h4 id="为什么Redis集群分片最大槽数是16384个？"><a href="#为什么Redis集群分片最大槽数是16384个？" class="headerlink" title="为什么Redis集群分片最大槽数是16384个？"></a>为什么Redis集群分片最大槽数是16384个？</h4><p>​GitHub上已有关于这个问题的解答，<a href="https://github.com/redis/redis/issues/2576">why redis-cluster use 16384 slots? · Issue #2576 · redis&#x2F;redis (github.com)</a>，这里只做大概解释</p><p>​Redis集群通过CRC16算法对key进行哈希并对16384取模来决定该key具体放在哪个槽位，而该算法的hash结果有16位，也就是65536个值，那为啥不分配65536个槽而是16384（2^14）个？</p><p>​首先翻译一下作者的解答：</p><p>​正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间(使用65K的插槽)。同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot &#x2F; N位占设置位的很大百分比。</p><p>​翻译了又好像没翻译，还是没看懂，，，</p><p>​其实总结起来就是以下三个因素的考虑。</p><p>（1）如果槽位个数为65536，发送的心跳信息头达到8k，发送的心跳包过大。</p><p><img src="/imgs/blog4/image-20230601095147944.png"></p><p>上图即为Redis节点发送的信息头结构，其中占据最大空间的就是myslots[CLUSTER_SLOTS&#x2F;8]。如果槽位为65536个，大小为65536 &#x2F; 8 &#x2F; 1024 &#x3D; 8 kb。如果槽位为16384个，大小为16384 &#x2F; 8 &#x2F; 1024 &#x3D; 2 kb。在Redis集群中，Redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536个，发送的消息头太大，浪费带宽。</p><p>（2）Redis的集群主节点数量基本不可能超过1000个，16384个槽位已经够用<br>集群节点越多，心跳包的消息体内携带的数据越多。如果节点超过1000个，也会导致网络拥堵。因此Redis作者不建议Redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。</p><p>（3）节点一定的情况下，槽位越少，压缩比越高，容易传输<br>Redis主节点的配置信息中它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中会对bitmap进行压缩，但是如果bitmap的填充率slots &#x2F;N很高的话(N表示节点数)，bitmap的压缩率就很低。也就是说当节点数一定时，哈希槽数量很多的话，bitmap的压缩率就很低，不易传输。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无重复字符的最长子串</title>
      <link href="/2023/05/31/blog3/"/>
      <url>/2023/05/31/blog3/</url>
      
        <content type="html"><![CDATA[<h3 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h3><p>​题目链接：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/">3. 无重复字符的最长子串 - 力扣（Leetcode）</a></p><p>​给定一个字符串 <code>s</code> ，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。</p><p><strong>示例 1:</strong></p><pre><code>输入: s = &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: s = &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。</code></pre><p><strong>示例 3:</strong></p><pre><code>输入: s = &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。     请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。</code></pre><h3 id="题目思路"><a href="#题目思路" class="headerlink" title="题目思路"></a>题目思路</h3><p>​没啥好说的，一眼滑动窗口。。。</p><p>​以示例1为例，对于“abcabcbb”，定义两个指针（ left 和 right ），初始都指向字符串0位置，两个指针之间的字符串即为当前找到的子串，right指针向右遍历，使用hashmap记录出现过的字符和字符最后一次出现的位置，当前字串出现重复字符时（即hashmap中存在当前right指向的字符），将left指针移动到重复字符的下一个位置即可（map.get(s.charAt(i)) + 1），遍历过程中记录字串长度最大值。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code class="java">class Solution &#123;  public int lengthOfLongestSubstring(String s) &#123;​    if (s.length() &lt;=  1)&#123;​      return s.length();​    &#125;​    HashMap&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;();​    int ans = 0;​    int left = 0;​    for(int i = 0; i &lt; s.length(); i++)&#123;​      if(map.containsKey(s.charAt(i)))&#123;​        left = Math.max(left, map.get(s.charAt(i)) + 1);​      &#125;​      map.put(s.charAt(i), i);​      ans = Math.max(ans, i-left+1);​    &#125;​    return ans;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法和数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引失效情况</title>
      <link href="/2023/05/31/blog2/"/>
      <url>/2023/05/31/blog2/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL索引失效"><a href="#MySQL索引失效" class="headerlink" title="MySQL索引失效"></a>MySQL索引失效</h1><p>​简单介绍下几种MySQL索引失效的常见情况。</p><h3 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1.数据准备"></a>1.数据准备</h3><p>​首先准备一张数据表user_info并建立索引</p><pre><code class="mysql">`CREATE TABLE `user_info` ( `id` int(8) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;, `number` varchar(12) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;编号&#39;, `username` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#39;用户名&#39;, `age` int(11) DEFAULT NULL COMMENT &#39;年龄&#39;, `birthday` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &#39;生日&#39;, PRIMARY KEY (`id`), KEY `union_idx` (`number`,`username`,`age`), KEY `create_time_idx` (`birthday`) );`</code></pre><p>该表包含3个索引：</p><p>主键：id</p><p>联合索引：number、username、age</p><p>普通索引：birthday</p><p>然后插入一些数据</p><pre><code class="mysql">INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1244&#39;, &#39;Mercury&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3546&#39;, &#39;Diana&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;1124&#39;, &#39;Mars&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6426&#39;, &#39;Saturn&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3525&#39;, &#39;Eureka&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;5245&#39;, &#39;Mercury1&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;3235246&#39;, &#39;Diana1&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6346&#39;, &#39;Mars1&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;623461&#39;, &#39;Saturn1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;235&#39;, &#39;Eureka1&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;11244&#39;, &#39;Mercury3&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;13546&#39;, &#39;Diana3&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;112244&#39;, &#39;Mars3&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;643126&#39;, &#39;Saturn3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;35215&#39;, &#39;Eureka3&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;52145&#39;, &#39;Mercury4&#39;, 23, &#39;2000-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;32235246&#39;, &#39;Diana4&#39;, 12, &#39;2011-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6332446&#39;, &#39;Mars4&#39;, 77, &#39;1946-01-01 00:00:00&#39;); INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;6231461&#39;, &#39;Saturn4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);INSERT INTO user_info (id, number, username, age, birthday) VALUES (null, &#39;231115&#39;, &#39;Eureka4&#39;, 32, &#39;1991-01-01 00:00:00&#39;);</code></pre><p>注：测试MySQL版本为8.0.28</p><h3 id="2-案例测试"><a href="#2-案例测试" class="headerlink" title="2.案例测试"></a>2.案例测试</h3><h4 id="2-1-联合索引不满足最左匹配原则"><a href="#2-1-联合索引不满足最左匹配原则" class="headerlink" title="2.1 联合索引不满足最左匹配原则"></a>2.1 联合索引不满足最左匹配原则</h4><p>​最左前缀匹配原则：在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左列开始匹配。如本例中联合索引（number，username，age），若想查询走该索引，查询条件中应出现最左边的列，即number。</p><p>测试1：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39;;</code></pre><p>运行结果：</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%951.png"></p><p>key为“union_idx”说明查询走了联合索引。</p><p>测试2：</p><pre><code class="mysql">explain select * from user_info where number = &#39;1244&#39; and age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%952.png"></p><p>测试2结果中‘key_len’与测试1相同，说明该查询虽然走了联合索引，但因未满足最左匹配原则（查询条件中未出现username），导致username之后的联合索引失效。若number使用范围查询如number&gt;‘1244’，后面的查询条件即使有username也不会生效，这里不做测试。</p><p>但是where后面查询列出现顺序不会影响索引，如</p><p>测试3：</p><pre><code class="mysql">explain select * from user_info where username = &#39;Mercury&#39; and number = &#39;1244&#39;;explain select * from user_info where number = &#39;1244&#39; and username = &#39;Mercury&#39;;</code></pre><p>上面两条语句‘ken_len’相同</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%953.png" alt="image-20230531203957562"></p><h4 id="2-2-索引列使用数学运算"><a href="#2-2-索引列使用数学运算" class="headerlink" title="2.2 索引列使用数学运算"></a>2.2 索引列使用数学运算</h4><p>测试4：</p><pre><code class="mysql">explain select * from user_info where id + 1 = 2;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%954.png"></p><p>查询类型为全表扫面，并未使用索引</p><h4 id="2-3-隐式类型转换"><a href="#2-3-隐式类型转换" class="headerlink" title="2.3 隐式类型转换"></a>2.3 隐式类型转换</h4><p>测试5：</p><pre><code class="mysql">explain select * from user_info where number = 1244;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%955.png" alt="测试5"></p><p>number字段为varchar类型，而查询条件为int，类型不匹配导致索引失效。</p><h4 id="2-4模糊查询以-开头"><a href="#2-4模糊查询以-开头" class="headerlink" title="2.4模糊查询以%开头"></a>2.4模糊查询以%开头</h4><p>测试6：</p><pre><code class="mysql">explain select * from user_info where number like &#39;%2&#39;;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%956.png" alt="测试6"></p><h4 id="2-5-使用or"><a href="#2-5-使用or" class="headerlink" title="2.5 使用or"></a>2.5 使用or</h4><p>测试7：</p><pre><code class="mysql">explain select * from user_info where id = 1 or age = 23;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%957.png" alt="测试7"></p><p>age列无索引，导致前面id列索引失效。使用or时切记两边查询条件都要有索引。</p><h4 id="2-6索引列使用函数"><a href="#2-6索引列使用函数" class="headerlink" title="2.6索引列使用函数"></a>2.6索引列使用函数</h4><p>测试8：</p><p>explain select * from user_info where SUBSTR(number, 2,3) &#x3D; ‘12’;</p><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%958.png" alt="测试8"></p><h4 id="2-7两列作比较或者运算"><a href="#2-7两列作比较或者运算" class="headerlink" title="2.7两列作比较或者运算"></a>2.7两列作比较或者运算</h4><p>测试9：</p><pre><code class="mysql">explain select * from user_info where id &lt; age;explain select * from user_info where id + age = 25;</code></pre><p><img src="/../imgs/blog2/%E6%B5%8B%E8%AF%959.png" alt="测试9"></p><h4 id="2-8其他"><a href="#2-8其他" class="headerlink" title="2.8其他"></a>2.8其他</h4><p>​使用不等于&lt;&gt;，not in， not exists， is not null 以及MySQL优化器认为走全表扫描效率更高的查询。好累啊不想做测试了，开摆。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化</title>
      <link href="/2023/05/31/blog1/"/>
      <url>/2023/05/31/blog1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Redis持久化"><a href="#1-Redis持久化" class="headerlink" title="1.Redis持久化"></a>1.Redis持久化</h1><p>Redis有两种持久化方案：</p><ul><li>RDB持久化</li><li>AOF持久化</li></ul><h2 id="1-1-RDB"><a href="#1-1-RDB" class="headerlink" title="1.1.RDB"></a>1.1.RDB</h2><p>RDB全称Redis Database Backup file（Redis数据备份文件），RDB其实就是把数据以快照的形式保存在磁盘上。什么是快照呢，你可以理解成把当前时刻的数据拍成一张照片保存下来。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。</p><h3 id="1-1-1-RDB执行"><a href="#1-1-1-RDB执行" class="headerlink" title="1.1.1.RDB执行"></a>1.1.1.RDB执行</h3><p>RDB持久化在四种情况下会执行：</p><ul><li>执行save命令</li><li>执行bgsave命令</li><li>Redis停机时</li><li>触发RDB条件时</li></ul><p><strong>1）save命令</strong></p><p>save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。</p><p><strong>2）bgsave命令</strong></p><p>bgsave命令执行后Redis执行fork操作创建子进程完成RDB，主进程可以继续处理用户请求，不会阻塞。</p><p><strong>3）停机时</strong></p><p>Redis停机时会执行一次save命令，实现RDB持久化。</p><p><strong>4）触发RDB条件</strong></p><p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p><pre><code class="properties"># 下面的配置代表600秒内如果至少有10个key被修改，则执行bgsavesave 600 10  </code></pre><p>RDB的其它配置也可以在redis.conf文件中设置：</p><pre><code class="properties"># 是否进行压缩（会耗费cpu资源）rdbcompression yes# RDB文件保存名称（默认为dump.rdb）dbfilename dump.rdb  </code></pre><h3 id="1-1-2-RDB原理"><a href="#1-1-2-RDB原理" class="headerlink" title="1.1.2.RDB原理"></a>1.1.2.RDB原理</h3><p>bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。</p><p>fork采用的是copy-on-write技术：</p><ul><li>当主进程执行读操作时，访问共享内存；</li><li>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</li></ul><p><img src="/imgs/blog1/image-20210725151319695-16855170885551.png"></p><h2 id="1-2-AOF"><a href="#1-2-AOF" class="headerlink" title="1.2.AOF"></a>1.2.AOF</h2><h3 id="1-2-1-AOF原理"><a href="#1-2-1-AOF原理" class="headerlink" title="1.2.1.AOF原理"></a>1.2.1.AOF原理</h3><p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。</p><h3 id="1-2-2-AOF配置"><a href="#1-2-2-AOF配置" class="headerlink" title="1.2.2.AOF配置"></a>1.2.2.AOF配置</h3><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p><pre><code class="properties"># 是否开启AOF功能，默认是noappendonly yes</code></pre><p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p><pre><code class="properties"># 每执行一次写命令，立即记录appendfsync always # 每隔1秒将缓冲区数据写到AOF文件（默认）appendfsync everysec # 由操作系统决定何时将缓冲区内容写回磁盘appendfsync no</code></pre><p>三种策略对比：</p><p><img src="/imgs/blog1/image-20210725151654046-16855171063852.png"></p><h3 id="1-2-3-AOF文件重写"><a href="#1-2-3-AOF文件重写" class="headerlink" title="1.2.3.AOF文件重写"></a>1.2.3.AOF文件重写</h3><p>AOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。</p><p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p><pre><code class="properties"># AOF文件相比上次增长超过多少百分比则触发bgrewriteaofauto-aof-rewrite-percentage 100# AOF文件达到一定大小触发bgrewriteaofauto-aof-rewrite-min-size 64mb </code></pre><p>重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。</p><h2 id="1-3-RDB与AOF对比"><a href="#1-3-RDB与AOF对比" class="headerlink" title="1.3.RDB与AOF对比"></a>1.3.RDB与AOF对比</h2><p>RDB和AOF各有优缺点，在实际开发中一般会<strong>结合</strong>两者来使用。</p><p><img src="/imgs/blog1/image-20210725151940515-16855171206073.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
